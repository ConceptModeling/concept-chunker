1. O O
draw O O
an O O
arc O O
in O O
the O O
image B B
delineating O O
the O O
extent O O
of O O
the O O
rainbow O O
. O O
for O O
example O O
, O O
in O O
large O O
structure O O
from O O
motion B B
problems O O
, O O
a O O
large O O
sparse O O
hessian O O
normally O O
results O O
in O O
a O O
full O O
dense O O
covariance O O
matrix O O
. O O
one O O
way O O
to O O
reduce O O
this O O
by O O
a O O
signiﬁcant O O
amount O O
is O O
to O O
divide O O
the O O
image B B
up O O
into O O
smaller O O
sub-blocks O O
( O O
patches O O
) O O
pj O O
and O O
to O O
only O O
accumulate O O
the O O
simpler O O
2 O O
× O O
2 O O
quantities O O
inside O O
the O O
square O O
brackets O O
at O O
the O O
pixel O O
level O O
( O O
shum O O
and O O
szeliski O O
2000 O O
) O O
, O O
aj O O
= O O
( O O
cid:88 O O
) O O
i∈pj O O
bj O O
= O O
( O O
cid:88 O O
) O O
i∈pj O O
∇i O O
t O O
1 O O
( O O
x O O
( O O
cid:48 O O
) O O
i O O
) O O
∇i1 O O
( O O
x O O
( O O
cid:48 O O
) O O
i O O
) O O
ei∇i O O
t O O
1 O O
( O O
x O O
( O O
cid:48 O O
) O O
i O O
) O O
. O O
while O O
sparse B B
( O O
robust B B
) O O
derivative O O
priors O O
can O O
reduce O O
rippling O O
effects O O
and O O
increase O O
edge O O
sharpness O O
, O O
they O O
can O O
not O O
hallucinate O O
higher-frequency O O
texture B B
or O O
details O O
. O O
polyhedral O O
visual O O
hulls O O
for O O
real-time O O
in O O
12th O O
eurographics O O
workshop O O
on O O
rendering B B
techniques O O
, O O
pp O O
. O O
note O O
that O O
while O O
beier O O
and O O
neely O O
describe O O
this O O
algorithm B B
as O O
a O O
forward B B
warp O O
, O O
an O O
equivalent O O
algorithm B B
can O O
be O O
written O O
by O O
sequencing O O
through O O
the O O
destination O O
pixels O O
. O O
image B B
does O O
not O O
pass O O
through O O
the O O
input O O
data O O
points O O
) O O
that O O
produces O O
soft O O
images O O
with O O
reduced O O
high-frequency O O
detail O O
. O O
in O O
order B B
to O O
quantify O O
what O O
it O O
means O O
to O O
ﬁnd O O
a O O
smooth O O
solution O O
, O O
we O O
can O O
deﬁne O O
a O O
norm O O
on O O
the O O
solution O O
space O O
. O O
ex O O
13.7 O O
: O O
light B O
ﬁeld I I
transformations O O
derive O O
the O O
equations B B
relating O O
regular O O
images O O
to O O
4d O O
light B O
ﬁeld I I
coordinates O O
. O O
figure O O
5.13 O O
shows O O
the O O
results O O
of O O
running O O
the O O
watershed B B
algorithm O O
with O O
some O O
manually O O
placed O O
markers O O
on O O
a O O
confocal O O
microscopy O O
image B B
. O O
1986 O O
; O O
black O O
and O O
rangarajan O O
1996 O O
; O O
stewart O O
1999 O O
) O O
and O O
involves O O
applying O O
a O O
robust B B
penalty O O
function O O
ρ O O
( O O
r O O
) O O
to O O
the O O
residuals O O
erls O O
( O O
∆p O O
) O O
= O O
( O O
cid:88 O O
) O O
i O O
ρ O O
( O O
( O O
cid:107 O O
) O O
ri O O
( O O
cid:107 O O
) O O
) O O
( O O
b.17 O O
) O O
instead O O
of O O
squaring O O
them O O
. O O
784 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
bundler O O
, O O
structure B O
from I I
motion I I
for O O
unordered O O
image B B
collections O O
, O O
http O O
: O O
//phototour.cs O O
. O O
246–253 O O
, O O
hilton O O
head B B
island O O
. O O
the O O
noise B B
can O O
be O O
estimated O O
either O O
at O O
each O O
pixel O O
independently O O
, O O
by O O
taking O O
repeated O O
exposures O O
and O O
computing O O
the O O
temporal O O
variance O O
in O O
the O O
measurements O O
( O O
healey O O
and O O
kondepudy O O
1994 O O
) O O
, O O
or O O
over O O
regions O O
, O O
by O O
assuming O O
that O O
pixel O O
values O O
should O O
all O O
be O O
the O O
same O O
within O O
some O O
region B B
( O O
e.g. O O
, O O
inside O O
a O O
color B B
checker O O
square O O
) O O
and O O
computing O O
a O O
spatial O O
variance O O
. O O
instead O O
, O O
they O O
are O O
made O O
up O O
of O O
discrete B B
color O O
or O O
intensity O O
values O O
. O O
an O O
anthropometric O O
face B B
model O O
using O O
variational O O
techniques O O
. O O
this O O
can O O
be O O
w/2fθ/2 O O
( O O
x O O
, O O
y,1 O O
) O O
( O O
x O O
, O O
y O O
, O O
z O O
) O O
z O O
54 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
accomplished O O
using O O
modiﬁed O O
normalized B B
device O O
coordinates O O
, O O
x O O
( O O
cid:48 O O
) O O
s O O
= O O
( O O
2xs O O
− O O
w O O
) O O
/s O O
and O O
y O O
( O O
cid:48 O O
) O O
s O O
= O O
( O O
2ys O O
− O O
h O O
) O O
/s O O
, O O
where O O
s O O
= O O
max O O
( O O
w O O
, O O
h O O
) O O
. O O
the O O
role O O
of O O
context B B
in O O
object O O
recognition B B
. O O
4. O O
can O O
you O O
think O O
of O O
any O O
reason O O
why O O
you O O
might O O
want O O
to O O
perform O O
a O O
color B B
twist O O
( O O
sec- O O
tion B B
3.1.2 O O
) O O
on O O
the O O
images O O
? O O
see O O
also O O
exercise O O
2.9 O O
for O O
some O O
related O O
ideas O O
. O O
recovering O O
consistent O O
video B B
depth O O
in O O
ieee O O
computer O O
society O O
conference O O
on O O
computer O O
maps O O
via O O
bundle O O
optimization O I
. O O
3.3.3 O O
distance O O
transforms O O
the O O
distance O O
transform O O
is O O
useful O O
in O O
quickly O O
precomputing O O
the O O
distance O O
to O O
a O O
curve O O
or O O
set O O
of O O
points B B
using O O
a O O
two-pass O O
raster O O
algorithm B B
( O O
rosenfeld O O
and O O
pfaltz O O
1966 O O
; O O
danielsson O O
1980 O O
; O O
borge- O O
fors O O
1986 O O
; O O
paglieroni O O
1992 O O
; O O
breu O O
, O O
gil O O
, O O
kirkpatrick O O
et O O
al O O
. O O
in O O
most O O
of O O
the O O
examples B B
seen O O
on O O
the O O
web O O
, O O
the O O
images O O
are O O
aligned O O
by O O
hand O O
for O O
best O O
artistic O O
effect.4 O O
however O O
, O O
it O O
is O O
also O O
possible O O
to O O
use O O
feature B B
matching O O
and O O
alignment B B
techniques O O
to O O
perform O O
the O O
registration B B
automatically O O
( O O
nomura O O
, O O
zhang O O
, O O
and O O
nayar O O
2007 O O
; O O
zelnik-manor O O
and O O
perona O O
2007 O O
) O O
. O O
similar O O
observations O O
, O O
formulated O O
in O O
terms O O
of O O
total B B
least O O
squares O O
( O O
van O O
huffel O O
and O O
vandewalle O O
1991 O O
; O O
van O O
huffel O O
and O O
lemmerling O O
2002 O O
) O O
, O O
have O O
been O O
made O O
by O O
other O O
researchers O O
studying O O
optical B O
ﬂow I I
( O O
weber O O
and O O
malik O O
1995 O O
; O O
bab- O O
hadiashar O O
and O O
suter O O
1998b O O
; O O
m¨uhlich O O
and O O
mester O O
1998 O O
) O O
. O O
in O O
ieee O O
computer O O
society O O
conference O O
on O O
computer O O
vision O O
and O O
pattern O O
recognition B B
( O O
cvpr O O
’ O O
2005 O O
) O O
, O O
pp O O
. O O
in O O
order B B
to O O
reduce O O
chromatic O O
and O O
other O O
kinds O O
of O O
aberrations O O
, O O
most O O
photographic O O
lenses O O
today O O
are O O
compound B O
lenses O O
made O O
of O O
different O O
glass O O
elements O O
( O O
with O O
different O O
coatings O O
) O O
. O O
( O O
eds O O
) O O
, O O
toward O O
category-level O O
object O O
recognition B B
, O O
pp O O
. O O
ieee O O
transactions O O
on O O
image B B
processing O O
, O O
6 O O
( O O
5 O O
) O O
:642–655 O O
. O O
the O O
same O O
applies O O
to O O
ﬁltering O O
the O O
even O O
sequence O O
with O O
the O O
correction O O
ﬁlter O O
c O O
, O O
which O O
is O O
used O O
to O O
ensure O O
that O O
the O O
even O O
sequence O O
is O O
low-pass B B
. O O
8.2 O O
parametric B B
motion O O
many O O
image B B
alignment O O
tasks O O
, O O
for O O
example O O
image B B
stitching I I
with O O
handheld O O
cameras O O
, O O
require O O
the O O
use O O
of O O
more O O
sophisticated O O
motion B B
models I I
, O O
as O O
described O O
in O O
section O O
2.1.2. O O
since O O
these O O
models O O
, O O
e.g. O O
, O O
afﬁne B B
deformations O O
, O O
typically O O
have O O
more O O
parameters B B
than O O
pure B O
translation I O
, O O
a O O
full O O
search O O
over O O
the O O
possible O O
range O O
of O O
values O O
is O O
impractical O O
. O O
matching B B
the O O
frequency O O
characteristics O O
, O O
which O O
is O O
equivalent O O
to O O
matching B B
spatial O O
correlations O O
, O O
is O O
in O O
itself O O
not O O
sufﬁcient O O
. O O
1999 O O
; O O
szeliski O O
, O O
winder O O
, O O
and O O
uyttendaele O O
2010 O O
) O O
and O O
in O O
computer O O
graphics O O
( O O
williams O O
1983 O O
; O O
heckbert O O
1986 O O
; O O
barkans O O
1997 O O
; O O
akenine-m¨oller O O
and O O
haines O O
2002 O O
) O O
, O O
where O O
they O O
go O O
under O O
the O O
name O O
of O O
texture B B
mapping O O
. O O
we O O
also O O
look O O
at O O
the O O
topic O O
of O O
multi-view B B
stereo I I
algorithms O O
that O O
produce O O
complete O O
3d O O
volumetric B B
or O O
surface-based O O
object O O
models O O
. O O
spline B B
patches O O
where O O
the O O
motion B B
is O O
inconsistent O O
, O O
i.e. O O
, O O
the O O
squared O O
residual O O
( O O
8.67 O O
) O O
is O O
above O O
a O O
threshold O O
, O O
are O O
subdivided O O
into O O
smaller O O
patches O O
. O O
14.3.3 O O
application O O
: O O
location B B
recognition I I
one O O
of O O
the O O
most O O
exciting O O
applications O O
of O O
instance B B
recognition O O
today O O
is O O
in O O
the O O
area O O
of O O
location B O
recognition I O
, O O
which O O
can O O
be O O
used O O
both O O
in O O
desktop O O
applications O O
( O O
where O O
did O O
i O O
take O O
this O O
holiday O O
snap O O
? O O
) O O
and O O
in O O
mobile O B
( O O
cell-phone O O
) O O
applications O O
. O O
the O O
seminal O O
paper O O
on O O
markov O O
random O O
ﬁelds O O
is O O
the O O
work O O
of O O
geman O O
and O O
geman O O
( O O
1984 O O
) O O
, O O
who O O
introduced O O
this O O
formalism O O
to O O
computer O O
vision O O
researchers O O
and O O
also O O
introduced O O
the O O
no- O O
tion B B
of O O
line O O
processes O O
, O O
additional O O
binary O O
variables O O
that O O
control O O
whether O O
smoothness B B
penalties O O
are O O
enforced O O
or O O
not O O
. O O
the O O
most O O
widely O O
used O O
3d O O
registration B O
technique O O
is O O
the O O
iterated O O
closest O O
point O O
( O O
icp O O
) O O
algo- O O
12.2 O O
active O O
rangeﬁnding O O
589 O O
rithm O O
, O O
which O O
alternates O O
between O O
ﬁnding O O
the O O
closest O O
point O O
matches O O
between O O
the O O
two O O
surfaces O O
being O O
aligned O O
and O O
then O O
solving O O
a O O
3d O O
absolute B O
orientation I O
problem O O
( O O
section O O
6.1.5 O O
, O O
( O O
6.31–6.32 O O
) O O
( O O
besl O O
and O O
mckay O O
1992 O O
; O O
chen O O
and O O
medioni O O
1992 O O
; O O
zhang O O
1994 O O
; O O
szeliski O O
and O O
lavall´ee O O
1996 O O
; O O
gold O O
, O O
rangarajan O O
, O O
lu O O
et O O
al O O
. O O
in O O
ieee O O
computer O O
society O O
conference O O
on O O
computer O O
vision O O
and O O
pattern O O
recognition B B
( O O
cvpr O O
’ O O
92 O O
) O O
, O O
pp O O
. O O
a O O
more O O
direct B B
way O O
to O O
ﬁnd O O
a O O
global B B
energy O O
minimum O O
is O O
to O O
use O O
dynamic B B
programming I I
( O O
amini O O
, O O
weymouth O O
, O O
and O O
jain O O
1990 O O
; O O
williams O O
and O O
shah O O
1992 O O
) O O
, O O
but O O
this O O
is O O
not O O
often O O
used O O
in O O
practice O O
, O O
since O O
it O O
has O O
been O O
superseded O O
by O O
even O O
more O O
efﬁcient O O
or O O
interactive B B
algorithms O O
such O O
as O O
intelligent B B
scissors I I
( O O
section O O
5.1.3 O O
) O O
and O O
grabcut O O
( O O
section O O
5.5 O O
) O O
. O O
since O O
this O O
system O O
of O O
equations B B
is O O
only O O
deﬁned O O
up O O
to O O
an O O
additive O O
constraint B B
, O O
agarwala O O
, O O
dontcheva O O
, O O
agrawala O O
et O O
al O O
. O O
closely O O
related O O
to O O
the O O
match B O
move I O
problem O O
is O O
robotics O O
navigation O O
, O O
where O O
a O O
robot O O
must O O
es- O O
timate O O
its O O
location O O
relative O O
to O O
its O O
environment O O
, O O
while O O
simultaneously O O
avoiding O O
any O O
dangerous O O
obstacles O O
. O O
photo O O
sharing O O
site O O
or O O
the O O
internet O O
, O O
it O O
is O O
sometimes O O
possible O O
to O O
copy O O
a O O
single O O
contiguous O O
image B B
region O O
to O O
ﬁll O O
the O O
hole O O
. O O
shape O O
reconstruction O O
in O O
projective B B
grid O O
space O O
from O O
large O O
in O O
ieee O O
computer O O
society O O
conference O O
on O O
computer O O
vision O O
and O O
number O O
of O O
images O O
. O O
database O O
of O O
matched O O
image B B
patches O O
for O O
learning O O
and O O
feature B B
descriptor O O
evaluation B B
, O O
http O O
: O O
//cvlab.epﬂ.ch/∼brown/patchdata/patchdata.html O O
( O O
winder O O
and O O
brown O O
2007 O O
; O O
hua O O
, O O
brown O O
, O O
and O O
winder O O
2007 O O
) O O
. O O
quan O O
and O O
lan O O
( O O
1999 O O
) O O
give O O
accuracy B B
results O O
for O O
this O O
and O O
other O O
techniques O O
, O O
which O O
use O O
fewer O O
points B B
but O O
require O O
more O O
complicated O O
algebraic O O
manipulations O O
. O O
in O O
their O O
work O O
, O O
they O O
extract O O
afﬁne B B
region O O
descriptors O O
( O O
lazebnik O O
, O O
schmid O O
, O O
and O O
ponce O O
2005 O O
) O O
and O O
quantize O O
them O O
into O O
visual B O
words I O
. O O
an O O
interesting O O
variant O O
on O O
light B O
stripe I O
rangeﬁnding O O
is O O
presented O O
by O O
bouguet O O
and O O
perona O O
( O O
1999 O O
) O O
. O O
11.2.1 O O
3d O O
curves O O
and O O
proﬁles B O
. O O
the O O
wii O O
system O O
can O O
be O O
extended O O
to O O
a O O
variety O O
of O O
other O O
user O O
interaction O O
applications O O
by O O
mounting O O
the O O
bar O O
on O O
a O O
hand-held O O
device O O
, O O
as O O
described O O
by O O
johnny O O
lee.11 O O
exercises O O
6.4 O O
and O O
6.5 O O
have O O
you O O
implement O O
two O O
different O O
tracking O O
and O O
pose O O
estimation B B
sys- O O
tems O O
for O O
augmented-reality O O
applications O O
. O O
6.2.2 O O
6.2.3 O O
application O O
: O O
augmented B B
reality I I
. O O
this O O
is O O
because O O
the O O
compositional B O
algorithm O O
essentially O O
makes O O
small O O
perturbations O O
to O O
the O O
target O O
. O O
given O O
a O O
known O O
image B B
noise O O
level O O
, O O
their O O
technique O O
computes O O
, O O
for O O
every O O
pixel O O
, O O
the O O
minimum O O
scale O O
at O O
which O O
an O O
edge O O
can O O
be O O
reliably O O
detected O O
( O O
figure O O
4.32d O O
) O O
. O O
6.3 O O
geometric B B
intrinsic O O
calibration B B
as O O
described O O
above O O
in O O
equations B B
( O O
6.42–6.43 O O
) O O
, O O
the O O
computation O O
of O O
the O O
internal O O
( O O
intrinsic B B
) O O
cam- O O
era O O
calibration B O
parameters O O
can O O
occur O O
simultaneously O O
with O O
the O O
estimation B B
of O O
the O O
( O O
extrinsic B O
) O O
pose O O
of O O
the O O
camera B B
with O O
respect O O
to O O
a O O
known O O
calibration B B
target O O
. O O
we O O
can O O
compute O O
the O O
total B B
within-class O O
scatter O O
matrix O O
as O O
sw O O
= O O
sk O O
= O O
( O O
xi O O
− O O
mk O O
) O O
( O O
xi O O
− O O
mk O O
) O O
t O O
, O O
( O O
14.17 O O
) O O
k−1 O O
( O O
cid:88 O O
) O O
k=0 O O
k−1 O O
( O O
cid:88 O O
) O O
k=0 O O
( O O
cid:88 O O
) O O
i∈ck O O
where O O
mk O O
is O O
the O O
mean O O
of O O
class O O
k O O
and O O
sk O O
is O O
its O O
within-class B O
scatter O O
matrix.11 O O
similarly O O
, O O
we O O
can O O
compute O O
the O O
between-class B O
scatter O O
as O O
sb O O
= O O
k−1 O O
( O O
cid:88 O O
) O O
k=0 O O
nk O O
( O O
mk O O
− O O
m O O
) O O
( O O
mk O O
− O O
m O O
) O O
t O O
, O O
( O O
14.18 O O
) O O
where O O
nk O O
are O O
the O O
number O O
of O O
exemplars O O
in O O
each O O
class O O
and O O
m O O
is O O
the O O
overall O O
mean O O
. O O
up B O
vector I O
selection I O
. O O
close-range O O
camera B B
calibration O O
. O O
( O O
alternatively O O
, O O
they O O
can O O
use O O
the O O
joint B B
feature I O
space I O
distances O O
( O O
5.42 O O
) O O
introduced O O
by O O
comaniciu O O
and O O
meer O O
( O O
2002 O O
) O O
, O O
which O O
we O O
discuss O O
in O O
section O O
5.3.2 O O
. O O
alternatively O O
, O O
separate O O
detection B B
and O O
alignment B B
stages O O
can O O
be O O
run O O
to O O
ﬁrst O O
localize O O
and O O
orient O O
the O O
objects O O
of O O
interest O O
( O O
cootes O O
, O O
cooper O O
, O O
taylor O O
et O O
al O O
. O O
in O O
order B B
to O O
prevent O O
aliasing B B
, O O
however O O
, O O
it O O
may O O
be O O
necessary O O
to O O
upsample O O
in O O
the O O
opposite O O
di- O O
rection O O
before O O
applying O O
a O O
shearing O O
transformation O O
( O O
szeliski O O
, O O
winder O O
, O O
and O O
uyttendaele O O
2010 O O
) O O
. O O
understanding O O
belief B B
propagation I I
and O O
its O O
generalization O O
. O O
once O O
they O O
have O O
been O O
aligned O O
, O O
range O O
scans O O
can O O
be O O
merged O O
using O O
techniques O O
that O O
model O O
the O O
signed B B
distance O O
of O O
surfaces O O
to O O
volumetric B B
sam- O O
ple O O
points B O
( O O
hoppe O O
, O O
derose O O
, O O
duchamp O O
et O O
al O O
. O O
the O O
use O O
of O O
computer O O
vision O O
algorithms O O
for O O
collecting O O
recognition B B
databases O O
dates O O
back O O
to O O
the O O
work O O
of O O
fergus O O
, O O
fei-fei O O
, O O
perona O O
et O O
al O O
. O O
discarding O O
pixels O O
near O O
high O B
gra- O O
dients O O
( O O
which O O
are O O
affected O O
by O O
camera O O
motion B O
) O O
, O O
plot O O
for O O
each O O
color B B
channel O O
the O O
standard O O
deviation O O
at O O
each O O
pixel O O
as O O
a O O
function O O
of O O
its O O
output O O
value O O
. O O
) O O
an O O
alternative O O
way O O
to O O
write O O
this O O
prior B B
energy O O
( O O
boykov O O
, O O
veksler O O
, O O
and O O
zabih O O
2001 O O
; O O
szeliski O O
, O O
zabih O O
, O O
scharstein O O
et O O
al O O
. O O
graph B B
cut I I
based O O
optimization O O
for O O
mrfs O O
with O O
truncated O O
convex O O
priors O O
. O O
the O O
hough O O
space O O
itself O O
can O O
either O O
be O O
represented O O
using O O
spherical O B
coordinates O O
( O O
4.27 O O
) O O
or O O
as O O
a O O
cube B B
map I I
( O O
figure O O
4.44a O O
) O O
. O O
this O O
approach O O
is O O
discussed O O
in O O
more O O
detail O O
in O O
section O O
10.2 O O
on O O
high B B
dynamic I I
range I I
imaging O O
. O O
this O O
is O O
shown O O
schematically O O
as O O
red O O
arcs O O
in O O
figure O O
13.13b O O
, O O
where O O
the O O
red O O
bar O O
indicates O O
which O O
video B B
frame O O
is O O
currently O O
be- O O
ing O O
displayed O O
, O O
and O O
arcs O O
light O O
up O O
as O O
a O O
forward B B
or O O
backward O O
transition O O
is O O
taken O O
. O O
pattern O O
recognition B B
, O O
29 O O
( O O
7 O O
) O O
:1061–1073 O O
. O O
the O O
results O O
of O O
applying O O
these O O
techniques O O
to O O
the O O
multi-frame B O
ﬂower O O
garden O O
image B B
sequence O O
are O O
shown O O
in O O
figure O O
11.17 O O
, O O
which O O
compares O O
the O O
results O O
of O O
using O O
regular O O
( O O
non-shifted O O
) O O
sssd O O
with O O
spatially O O
shifted O O
windows O O
and O O
full O O
spatio-temporal O O
window O O
selection O O
. O O
first O O
, O O
since O O
a O O
summation O O
is O O
taken O O
over O O
all O O
pairs B B
with O O
corresponding O O
features O O
, O O
features O O
that O O
are O O
observed O O
many O O
times O O
are O O
overweighted O O
in O O
the O O
ﬁnal O O
solution O O
. O O
what O O
is O O
worse O O
, O O
it O O
is O O
not O O
always O O
possible O O
to O O
move O O
smoothly O O
in O O
the O O
parameter O O
space O O
, O O
i.e. O O
, O O
sometimes O O
one O O
or O O
more O O
of O O
the O O
euler O O
angles O O
change O O
dramatically O O
in O O
response O O
to O O
a O O
small O O
change O O
in O O
rotation.1 O O
for O O
these O O
reasons O O
, O O
we O O
do O O
not O O
even O O
give O O
the O O
formula O O
for O O
euler O O
angles O O
in O O
this O O
book—interested O O
readers O O
can O O
look O O
in O O
other O O
textbooks B B
or O O
technical O O
reports O O
( O O
faugeras O O
1993 O O
; O O
diebel O O
2006 O O
) O O
. O O
2001 O O
) O O
c O O
( O O
cid:13 O O
) O O
2001 O O
ieee O O
: O O
( O O
a O O
) O O
source O O
image B B
; O O
( O O
b O O
) O O
extracted O O
foreground O O
object O O
f O O
; O O
( O O
c O O
) O O
alpha B O
matte I O
α O O
shown O O
in O O
grayscale O O
; O O
( O O
d O O
) O O
new O O
composite O O
c. O O
as O O
discussed O O
in O O
section O O
2.3.2 O O
, O O
chromaticity O O
coordinates O O
( O O
2.104 O O
) O O
or O O
even O O
simpler O O
color B B
ra- O O
tios O O
( O O
2.116 O O
) O O
can O O
ﬁrst O O
be O O
computed O O
and O O
then O O
used O O
after O O
manipulating O O
( O O
e.g. O O
, O O
brightening O O
) O O
the O O
luminance O O
y O O
to O O
re-compute O O
a O O
valid O O
rgb O O
image B O
with O O
the O O
same O O
hue B B
and O O
saturation O O
. O O
to O O
model O O
shapes O O
more O O
accurately O O
, O O
zhang O O
, O O
curless O O
, O O
and O O
seitz O O
( O O
2003 O O
) O O
model O O
the O O
linear B B
disparity O O
variation O O
within O O
the O O
space–time O O
window O O
and O O
show O O
that O O
bet- O O
ter O O
results O O
can O O
be O O
obtained O O
by O O
globally O O
optimizing O O
disparity O O
and O O
disparity O O
gradient O O
estimates O O
over O O
video O B
volumes O O
( O O
zhang O O
, O O
snavely O O
, O O
curless O O
et O O
al O O
. O O
in O O
the O O
context B B
of O O
image B B
segmentation O O
, O O
ma O O
, O O
derksen O O
, O O
hong O O
et O O
al O O
. O O
aliasing B B
, O O
since O O
it O O
avoids O O
one O O
downsampling O O
and O O
upsampling O O
round-trip O O
, O O
but O O
it O O
is O O
not O O
self- O O
inverting O O
, O O
since O O
the O O
laplacian O O
images O O
are O O
no O O
longer O O
adequate O O
to O O
reproduce O O
the O O
original O O
image B B
. O O
the O O
spatial O O
bins O O
are O O
of O O
radius O O
6 O O
, O O
224 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
( O O
a O O
) O O
image B B
gradients O O
( O O
b O O
) O O
keypoint O O
descriptor O O
figure O O
4.18 O O
a O O
schematic O O
representation O O
of O O
lowe O O
’ O O
s O O
( O O
2004 O O
) O O
scale O O
invariant O O
feature B B
transform O O
( O O
sift O O
) O O
: O O
( O O
a O O
) O O
gradient O B
orientations O O
and O O
magnitudes O O
are O O
computed O O
at O O
each O O
pixel O O
and O O
weighted B B
by O O
a O O
gaussian O O
fall-off O O
function O O
( O O
blue O O
circle O O
) O O
. O O
recognition B B
( O O
cvpr O O
2010 O O
) O O
, O O
san O O
francisco O O
, O O
ca O O
. O O
anisotropic B B
ﬁltering I O
an O O
alternative O O
approach O O
to O O
ﬁltering O O
oriented B B
textures O I
, O O
which O O
is O O
sometimes O O
implemented O O
in O O
graphics O O
hardware O O
( O O
gpus O O
) O O
, O O
is O O
to O O
use O O
anisotropic B O
ﬁltering I O
( O O
barkans O O
1997 O O
; O O
akenine-m¨oller O O
and O O
haines O O
2002 O O
) O O
. O O
the O O
biggest O O
difference B B
between O O
part-based B B
and O O
context B B
models O O
is O O
that O O
the O O
latter O O
combine O O
objects O O
into O O
scenes O O
and O O
the O O
number O O
of O O
constituent O O
objects O O
from O O
each O O
class O O
is O O
not O O
known O O
in O O
advance O O
. O O
a O O
large O O
number O O
of O O
customized O O
iterative B O
techniques O O
have O O
been O O
proposed O O
. O O
note O O
that O O
when O O
top-down O O
maps O O
of O O
the O O
buildings O O
being O O
mod- O O
eled O O
are O O
available O O
, O O
these O O
can O O
be O O
used O O
to O O
further O O
constrain O O
the O O
3d O O
modeling B B
process O O
( O O
robertson O O
and O O
cipolla O O
2002 O O
, O O
2009 O O
) O O
. O O
figure O O
12.8 O O
shows O O
one O O
such O O
approach O O
, O O
the O O
volumetric B B
range O O
image B B
processing O O
( O O
vrip O O
) O O
technique O O
developed O O
by O O
curless O O
and O O
levoy O O
( O O
1996 O O
) O O
, O O
which O O
ﬁrst O O
computes O O
a O O
weighted B B
signed O I
distance O O
function O O
from O O
each O O
range O O
image O O
and O O
then O O
merges O O
them O O
using O O
a O O
weighted B B
averaging O O
process O O
. O O
multiplied O O
by O O
its O O
corresponding O O
gaussian O O
mask B O
and O O
the O O
sum O O
of O O
these O O
two O O
weighted O O
pyramids O O
is O O
then O O
used O O
to O O
construct O O
the O O
ﬁnal O O
image B B
( O O
figure O O
3.42 O O
, O O
right O O
column O O
) O O
. O O
multiple B B
view O O
geometry O O
. O O
articulated O O
mesh O O
animation O O
from O O
multi-view B B
silhouettes O O
. O O
b.5 O O
markov O O
random O O
ﬁelds O O
767 O O
( O O
a O O
) O O
( O O
b O O
) O O
figure O O
b.2 O O
dynamic B O
programming I I
over O O
a O O
tree O O
drawn O O
as O O
a O O
factor O O
graph O O
. O O
a O O
reﬂectance B B
model O O
for O O
computer O O
graphics O O
. O O
7.4 O O
bundle B B
adjustment I I
369 O O
( O O
a O O
) O O
( O O
b O O
) O O
figure O O
7.10 O O
3d O O
augmented B B
reality I I
: O O
( O O
a O O
) O O
darth O O
vader O O
and O O
a O O
horde O O
of O O
ewoks O O
battle O O
it O O
out O O
on O O
a O O
table-top O O
recovered O O
using O O
real-time O O
, O O
keyframe-based O O
structure B O
from I I
motion I I
( O O
klein O O
and O O
murray O O
2007 O O
) O O
c O O
( O O
cid:13 O O
) O O
2007 O O
ieee O O
; O O
( O O
b O O
) O O
a O O
virtual O O
teapot O O
is O O
ﬁxed O O
to O O
the O O
top O O
of O O
a O O
real-world O O
coffee O O
cup O O
, O O
whose O O
pose O O
is O O
re-recognized O O
at O O
each O O
time O O
frame O O
( O O
gordon O O
and O O
lowe O O
2006 O O
) O O
c O O
( O O
cid:13 O O
) O O
2007 O O
springer O O
. O O
notice O O
that O O
the O O
image B B
in O O
figure O O
3.7a O O
has O O
both O O
an O O
excess O O
of O O
dark O O
values O O
and O O
light O O
values O O
, O O
but O O
that O O
the O O
mid-range O O
values O O
are O O
largely O O
under-populated O O
. O O
( O O
note O O
that O O
[ O O
e O O
] O O
× O O
annihilates O O
any O O
multiple B B
of O O
e. O O
) O O
any O O
one O O
of O O
these O O
valid O O
homographies O B
˜h O O
maps O O
some O O
plane O O
in O O
the O O
scene O O
from O O
one O O
image B B
to O O
the O O
other O O
. O O
itsol O O
, O O
miqr O O
, O O
and O O
other O O
sparse B B
solvers O O
, O O
http O O
: O O
//www-users.cs.umn.edu/∼saad/software/ O O
( O O
saad O O
2003 O O
) O O
. O O
( O O
another O O
name O O
for O O
the O O
inverse B B
covariance O O
matrix O O
, O O
which O O
is O O
equal O O
to O O
the O O
hessian O O
in O O
such O O
simple O O
cases O O
, O O
is O O
the O O
information O O
matrix O O
. O O
( O O
11.4 O O
) O O
however O O
, O O
it O O
is O O
also O O
possible O O
to O O
compute O O
alternative O O
statistics O O
such O O
as O O
robust B B
variance O O
, O O
focus B B
, O O
or O O
entropy O O
( O O
section O O
11.3.1 O O
) O O
( O O
vaish O O
, O O
szeliski O O
, O O
zitnick O O
et O O
al O O
. O O
666 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
( O O
a O O
) O O
( O O
b O O
) O O
( O O
c O O
) O O
( O O
d O O
) O O
( O O
e O O
) O O
( O O
f O O
) O O
( O O
g O O
) O O
figure O O
14.8 O O
pedestrian B O
detection O O
using O O
histograms O O
of O O
oriented B B
gradients O O
( O O
dalal O O
and O O
triggs O O
2005 O O
) O O
c O O
( O O
cid:13 O O
) O O
2005 O O
ieee O O
: O O
( O O
a O O
) O O
the O O
average O O
gradient O O
image O O
over O O
the O O
training O O
examples B B
; O O
( O O
b O O
) O O
each O O
“ O O
pixel O O
” O O
shows O O
the O O
maximum O O
positive O O
svm O O
weight O O
in O O
the O O
block O O
centered O O
on O O
the O O
pixel O O
; O O
( O O
c O O
) O O
like- O O
wise O O
, O O
for O O
the O O
negative O O
svm O O
weights O O
; O O
( O O
d O O
) O O
a O O
test O O
image O O
; O O
( O O
e O O
) O O
the O O
computed O O
r-hog O O
( O O
rectangular O O
histogram B B
of O O
gradients O O
) O O
descriptor O O
; O O
( O O
f O O
) O O
the O O
r-hog O O
descriptor O O
weighted B B
by O O
the O O
positive O O
svm O O
weights O O
; O O
( O O
g O O
) O O
the O O
r-hog O O
descriptor O O
weighted B B
by O O
the O O
negative O O
svm O O
weights O O
. O O
is O O
modiﬁed O O
so O O
that O O
the O O
smoothness B B
terms O O
sx O O
( O O
x O O
, O O
y O O
) O O
and O O
sy O O
( O O
x O O
, O O
y O O
) O O
in O O
figure O O
3.56 O O
and O O
( O O
3.113 O O
) O O
depend O O
on O O
the O O
magnitude O O
of O O
the O O
gradient O O
between O O
adjacent O O
pixels.25 O O
since O O
the O O
smoothness B B
term O O
now O O
depends O O
on O O
the O O
data O O
, O O
bayes O O
’ O O
rule O O
( O O
3.117 O O
) O O
no O O
longer O O
ap- O O
plies O O
. O O
684 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
( O O
a O O
) O O
( O O
b O O
) O O
figure O O
14.25 O O
person O O
detection B B
and O O
re-recognition O O
using O O
a O O
combined O O
face B B
, O O
hair O O
, O O
and O O
torso O O
model O O
( O O
sivic O O
, O O
zitnick O O
, O O
and O O
szeliski O O
2006 O O
) O O
c O O
( O O
cid:13 O O
) O O
2006 O O
springer O O
. O O
2008 O O
) O O
, O O
which O O
contain O O
tens O O
of O O
thousands O O
of O O
labeled O O
examples B B
. O O
the O O
number O O
of O O
sub-octave O O
levels O O
was O O
determined O O
, O O
after O O
careful O O
empirical O O
investigation O O
, O O
to O O
be O O
three O O
, O O
which O O
corresponds O O
to O O
a O O
quarter-octave O O
pyramid B O
, O O
which O O
is O O
the O O
same O O
as O O
used O O
by O O
triggs O O
( O O
2004 O O
) O O
. O O
they O O
are O O
set O O
to O O
zero O O
when O O
just O O
discretizing O O
the O O
conventional O O
ﬁrst-order O O
smoothness B B
functional O O
( O O
3.94 O O
) O O
. O O
using O O
vanishing O O
points B I
for O O
camera B O
calibration O O
. O O
when O O
performing O O
feature B B
detection O O
, O O
we O O
do O O
not O O
know O O
which O O
other O O
image B B
locations O O
the O O
feature B B
will O O
end O O
up O O
being O O
matched O O
against O O
. O O
the O O
two O O
foundational O O
papers O O
in O O
image-based B B
rendering I I
are O O
light B O
ﬁeld I I
rendering O O
by O O
levoy O O
and O O
hanrahan O O
( O O
1996 O O
) O O
and O O
the O O
lumigraph O O
by O O
gortler O O
, O O
grzeszczuk O O
, O O
szeliski O O
et O O
al O O
. O O
if O O
gamma B O
is O O
applied O O
separately O O
to O O
each O O
channel O O
( O O
figure O O
10.20b O O
) O O
, O O
the O O
colors O O
become O O
muted O O
( O O
less O O
saturated O O
) O O
, O O
since O O
higher-valued O O
color B B
channels O O
contribute O O
less O O
( O O
pro- O O
portionately O O
) O O
to O O
the O O
ﬁnal O O
color B B
. O O
the O O
image B B
processing O O
handbook O O
. O O
( O O
a O O
) O O
( O O
c O O
) O O
( O O
b O O
) O O
( O O
d O O
) O O
figure O O
10.6 O O
simultaneous O O
estimation B B
of O O
vignetting B B
, O O
exposure O O
, O O
and O O
radiometric B B
response O O
( O O
goldman O O
2011 O O
) O O
c O O
( O O
cid:13 O O
) O O
2011 O O
ieee O O
: O O
( O O
a O O
) O O
original O O
average O O
of O O
the O O
input O O
images O O
; O O
( O O
b O O
) O O
after O O
compen- O O
sating O O
for O O
vignetting O O
; O O
( O O
c O O
) O O
using O O
gradient O O
domain O O
blending B O
only O O
( O O
note O O
the O O
remaining O O
mottled O O
look O O
) O O
; O O
( O O
d O O
) O O
after O O
both O O
vignetting B B
compensation O O
and O O
blending B B
. O O
each O O
of O O
these O O
, O O
in O O
turn O O
, O O
is O O
a O O
simple O O
product O O
between O O
a O O
relative O O
power B O
spectrum I O
c O O
( O O
λ O O
) O O
, O O
which O O
depends O O
only O O
on O O
wavelength O O
, O O
and O O
a O O
magnitude O O
m O O
( O O
ˆvr O O
, O O
ˆvi O O
, O O
ˆn O O
) O O
, O O
which O O
depends O O
only O O
on O O
geometry O O
. O O
9.2 O O
global B B
alignment I O
443 O O
where O O
the O O
˜xik O O
function O O
is O O
the O O
predicted O O
location O O
of O O
feature B B
i O O
in O O
frame O O
k O O
given O O
by O O
( O O
9.27 O O
) O O
, O O
ˆxij O O
is O O
the O O
observed O O
location O O
, O O
and O O
the O O
“ O O
2d O O
” O O
in O O
the O O
subscript O O
indicates O O
that O O
an O O
image-plane O O
error O O
is O O
being O O
minimized O O
( O O
shum O O
and O O
szeliski O O
2000 O O
) O O
. O O
( O O
schmid O O
, O O
mohr O O
, O O
and O O
bauckhage O O
( O O
2000 O O
) O O
; O O
triggs O O
( O O
2004 O O
) O O
give O O
more O O
detailed O O
histori- O O
cal O O
reviews O O
of O O
feature B B
detection O O
algorithms O O
. O O
, O O
h21 O O
) O O
( O O
see O O
section O O
6.1.3 O O
) O O
table O O
6.1 O O
jacobians O O
of O O
the O O
2d O O
coordinate B B
transformations I I
x O O
( O O
cid:48 O O
) O O
= O O
f O O
( O O
x O O
; O O
p O O
) O O
shown O O
in O O
table O O
2.1 O O
, O O
where O O
we O O
have O O
re-parameterized O O
the O O
motions O O
so O O
that O O
they O O
are O O
identity O O
for O O
p O O
= O O
0 O O
. O O
14.5.1 O O
learning B B
and O O
large O O
image O O
collections O O
14.5.2 O O
application O O
: O O
image B B
search I I
. O O
a.4 O O
direct B B
sparse O O
matrix O O
techniques O O
. O O
while O O
the O O
parameterization O O
of O O
such O O
lenses O O
may O O
be O O
more O O
complicated O O
( O O
section O O
2.1.6 O O
) O O
, O O
the O O
general O O
approach O O
of O O
either O O
us- O O
ing O O
calibration B B
rigs O O
with O O
known O O
3d O O
positions O O
or O O
self-calibration B B
through O O
the O O
use O O
of O O
multiple B B
overlapping O O
images O O
of O O
a O O
scene O O
can O O
both O O
be O O
used O O
( O O
hartley O O
and O O
kang O O
2007 O O
; O O
tardif O O
, O O
sturm O O
, O O
and O O
roy O O
2007 O O
) O O
. O O
towards O O
model-based B O
recognition O O
of O O
human O O
movements O O
in O O
image B B
se- O O
quences O O
. O O
more O O
insight O O
into O O
the O O
problem O O
, O O
e.g. O O
, O O
the O O
dominant O O
modes O O
of O O
uncertainty B B
, O O
can O O
be O O
obtained O O
using O O
eigenvalue O O
analysis O O
( O O
szeliski O O
and O O
kang O O
1997 O O
) O O
. O O
11.5.1 O O
dynamic B B
programming I I
. O O
in O O
subsequent O O
work O O
, O O
isaksen O O
, O O
mcmillan O O
, O O
and O O
gortler O O
( O O
2000 O O
) O O
show O O
how O O
a O O
planar O O
proxy O O
for O O
the O O
scene O O
, O O
which O O
is O O
a O O
simpler O O
3d O O
model O O
, O O
can O O
be O O
used O O
to O O
simplify O O
the O O
resampling O O
equations B B
. O O
9.3 O O
compositing B B
once O O
we O O
have O O
registered O O
all O O
of O O
the O O
input O O
images O O
with O O
respect O O
to O O
each O O
other O O
, O O
we O O
need O O
to O O
decide O O
how O O
to O O
produce O O
the O O
ﬁnal O O
stitched O O
mosaic O O
image B O
. O O
( O O
g O O
) O O
an O O
analytical O O
stereo B B
plotter O O
, O O
courtesy O O
of O O
kenney O O
aerial O O
mapping O O
, O O
inc. O O
, O O
can O O
generate O O
( O O
h O O
) O O
contour O O
plots O O
. O O
( O O
the O O
response O O
curves O O
are O O
calibrated O O
separately O O
for O O
each O O
color B B
channel O O
. O O
2.3 O O
the O O
digital O O
camera O O
91 O O
( O O
a O O
) O O
rgb O O
( O O
b O O
) O O
r O O
( O O
c O O
) O O
g O O
( O O
d O O
) O O
b O O
( O O
e O O
) O O
rgb O O
( O O
f O O
) O O
r O O
( O O
g O O
) O O
g O O
( O O
h O O
) O O
b O O
( O O
i O O
) O O
l* O O
( O O
j O O
) O O
a* O O
( O O
k O O
) O O
b* O O
( O O
l O O
) O O
h O O
( O O
m O O
) O O
s O O
( O O
n O O
) O O
v O O
figure O O
2.32 O O
color B B
space O O
transformations O O
: O O
( O O
a–d O O
) O O
rgb O O
; O O
( O O
e–h O O
) O O
rgb O O
. O O
2003 O O
; O O
criminisi O O
, O O
p´erez O O
, O O
and O O
toyama O O
2004 O O
) O O
, O O
as O O
discussed O O
in O O
sections O O
5.1.4 O O
and O O
10.5.1. O O
figure O O
3.57 O O
shows O O
an O O
example O O
of O O
image B B
denoising O O
and O O
inpainting B B
( O O
hole B B
ﬁlling I I
) O O
using O O
a O O
markov O O
random O O
ﬁeld O O
. O O
multiplexing O O
for O O
optimal O O
lighting B B
. O O
in O O
the O O
case O O
of O O
full O O
360◦ O O
panoramas O O
, O O
a O O
better O O
choice O O
might O O
be O O
to O O
choose O O
the O O
middle O O
image B B
from O O
the O O
sequence O O
of O O
inputs O O
, O O
or O O
sometimes O O
the O O
ﬁrst O O
image B B
, O O
assuming O O
this O O
contains O O
the O O
object O O
of O O
greatest O O
interest O O
. O O
212 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
using O O
a O O
taylor O O
series O O
expansion O O
of O O
the O O
image B B
function O O
i0 O O
( O O
xi O O
+∆u O O
) O O
≈ O O
i0 O O
( O O
xi O O
) O O
+∇i0 O O
( O O
xi O O
) O O
· O O
∆u O O
( O O
lucas O O
and O O
kanade O O
1981 O O
; O O
shi O O
and O O
tomasi O O
1994 O O
) O O
, O O
we O O
can O O
approximate O O
the O O
auto-correlation B O
surface O O
as O O
eac O O
( O O
∆u O O
) O O
= O O
( O O
cid:88 O O
) O O
i O O
≈ O O
( O O
cid:88 O O
) O O
i O O
= O O
( O O
cid:88 O O
) O O
i O O
w O O
( O O
xi O O
) O O
[ O O
i0 O O
( O O
xi O O
+ O O
∆u O O
) O O
− O O
i0 O O
( O O
xi O O
) O O
] O O
2 O O
w O O
( O O
xi O O
) O O
[ O O
i0 O O
( O O
xi O O
) O O
+ O O
∇i0 O O
( O O
xi O O
) O O
· O O
∆u O O
− O O
i0 O O
( O O
xi O O
) O O
] O O
2 O O
w O O
( O O
xi O O
) O O
[ O O
∇i0 O O
( O O
xi O O
) O O
· O O
∆u O O
] O O
2 O O
= O O
∆ut O O
a∆u O O
, O O
where O O
∇i0 O O
( O O
xi O O
) O O
= O O
( O O
∂i0 O O
∂x O O
, O O
∂i0 O O
∂y O O
) O O
( O O
xi O O
) O O
( O O
4.3 O O
) O O
( O O
4.4 O O
) O O
( O O
4.5 O O
) O O
( O O
4.6 O O
) O O
( O O
4.7 O O
) O O
( O O
4.8 O O
) O O
is O O
the O O
image B B
gradient O O
at O O
xi O O
. O O
how O O
do O O
we O O
ﬁnd O O
the O O
maximum O O
likelihood O O
estimate O O
? O O
if O O
the O O
measurement O O
noise B B
is O O
gaussian O O
, O O
we O O
can O O
minimize O O
the O O
quadratic O O
objective O O
function O O
( O O
b.13 O O
) O O
. O O
however O O
, O O
if O O
we O O
capture O O
a O O
two-dimensional B B
spherical O I
im- O O
age O O
around O O
each O O
possible O O
camera B B
location O O
, O O
we O O
can O O
re-render O O
any O O
view O O
from O O
this O O
information.4 O O
thus O O
, O O
taking O O
the O O
cross-product O O
of O O
the O O
three-dimensional O O
space O O
of O O
camera B B
positions O O
with O O
the O O
2d O O
space O O
of O O
spherical B B
images O O
, O O
we O O
obtain O O
the O O
5d O O
plenoptic O O
function O O
of O O
adelson O O
and O O
bergen O O
( O O
1991 O O
) O O
, O O
which O O
forms O O
the O O
basis O O
of O O
the O O
image-based B B
rendering I I
system O O
of O O
mcmillan O O
and O O
bishop O O
( O O
1995 O O
) O O
. O O
however O O
, O O
this O O
problem O O
can O O
suffer O O
from O O
extended O O
low-frequency O O
ambiguities O O
, O O
especially O O
if O O
either O O
of O O
the O O
layers B B
lacks O O
dark O O
( O O
black O O
) O O
pixels O O
or O O
the O O
motion B B
is O O
uni-directional O O
. O O
for O O
example O O
, O O
if O O
there O O
are O O
parallel O O
lines B B
in O O
the O O
scene O O
( O O
usually O O
, O O
having O O
several O O
lines B B
converge O O
on O O
the O O
same O O
vanishing O B
point O O
is O O
good O O
evidence O O
) O O
, O O
three O O
or O O
more O O
vanishing B B
points I I
, O O
which O O
are O O
the O O
images O O
of O O
points B B
at O O
inﬁnity O O
, O O
can O O
be O O
used O O
to O O
establish O O
the O O
ho- O O
mography O O
for O O
the O O
plane O O
at O O
inﬁnity O O
, O O
from O O
which O O
focal O O
lengths O O
and O O
rotations O O
can O O
be O O
recovered O O
. O O
one O O
popular O O
approach O O
used O O
generalized B B
cylinders O O
, O O
i.e. O O
, O O
solids O O
of O O
revolution O O
and O O
swept O O
closed O O
curves O O
( O O
agin O O
and O O
binford O O
1976 O O
; O O
nevatia O O
and O O
binford O O
1977 O O
) O O
, O O
of- O O
ten O O
arranged O O
into O O
parts O O
relationships7 O O
( O O
hinton O O
1977 O O
; O O
marr O O
1982 O O
) O O
( O O
figure O O
1.7c O O
) O O
. O O
the O O
resulting O O
prior B B
image O O
model O O
is O O
a O O
gaussian O O
markov O O
random O O
ﬁeld O O
( O O
gmrf O O
) O O
, O O
which O O
can O O
be O O
extended O O
to O O
other O O
( O O
e.g. O O
, O O
diagonal O O
) O O
differences O O
, O O
as O O
in O O
( O O
capel O O
2004 O O
) O O
( O O
figure O O
10.31 O O
) O O
. O O
a O O
multiresolution O O
spline B O
with O O
applications O O
to O O
image B B
mosaics O O
. O O
ex O O
6.10 O O
: O O
radial B B
distortion I I
with O O
plumb O O
lines B B
mine O O
the O O
radial B B
distortion I I
parameters O O
. O O
in O O
ieee O O
computer O O
society O O
conference O O
on O O
computer O O
vision O O
and O O
pattern O O
recognition B B
( O O
cvpr O O
’ O O
2005 O O
) O O
, O O
pp O O
. O O
the O O
ﬁrst O O
is O O
called O O
natural B B
vignetting O O
and O O
is O O
due O O
to O O
the O O
foreshortening O O
in O O
the O O
object O O
surface B B
, O O
projected O O
pixel O O
, O O
and O O
lens O O
aperture O O
, O O
as O O
shown O O
in O O
figure O O
2.22. O O
consider O O
the O O
light O O
leaving O O
the O O
object O O
surface B B
patch O O
of O O
size O O
δo O O
located O O
at O O
an O O
off-axis O O
angle O O
α. O O
because O O
this O O
patch B B
is O O
foreshortened O O
with O O
respect O O
to O O
the O O
camera B B
lens O O
, O O
the O O
amount O O
of O O
light O O
reaching O O
the O O
lens O O
is O O
reduced O O
by O O
a O O
factor O O
cos O O
α. O O
the O O
amount O O
of O O
light O O
reaching O O
the O O
lens O O
is O O
also O O
subject O O
to O O
the O O
usual O O
1/r2 O O
fall-off O O
; O O
in O O
this O O
case O O
, O O
the O O
distance O O
ro O O
= O O
zo/ O O
cos O O
α. O O
the O O
actual O O
area O O
of O O
the O O
aperture O O
through O O
which O O
the O O
light O O
passes O O
is O O
foreshortened O O
by O O
an O O
additional O O
factor O O
cos O O
α O O
, O O
i.e. O O
, O O
the O O
aperture O O
as O O
seen O O
from O O
point O O
o O O
is O O
an O O
ellipse O O
of O O
dimensions O B
d× O O
d O O
cos O O
α. O O
putting O O
all O O
of O O
these O O
factors O O
together O O
, O O
we O O
see O O
that O O
the O O
amount O O
of O O
light O O
leaving O O
o O O
and O O
passing O O
through O O
the O O
aperture O O
on O O
its O O
way O O
to O O
the O O
image B B
pixel O O
located O O
at O O
i O O
is O O
proportional O O
to O O
δo O O
cos O O
α O O
r2 O O
o O O
π O O
( O O
cid:18 O O
) O O
d O O
2 O O
( O O
cid:19 O O
) O O
2 O O
cos O O
α O O
= O O
δo O O
π O O
4 O O
d2 O O
z2 O O
o O O
cos4 O O
α O O
. O O
modeling B B
from O O
reality O O
, O O
kluwer O O
academic O O
publish- O O
ers O O
, O O
boston O O
. O O
3.7.1 O O
regularization B B
the O O
theory O O
of O O
regularization B B
was O O
ﬁrst O O
developed O O
by O O
statisticians O O
trying O O
to O O
ﬁt O O
models O O
to O O
data O O
that O O
severely O O
underconstrained O O
the O O
solution O O
space O O
( O O
tikhonov O O
and O O
arsenin O O
1977 O O
; O O
engl O O
, O O
hanke O O
, O O
and O O
neubauer O O
1996 O O
) O O
. O O
figure O O
10.27 O O
shows O O
how O O
such O O
a O O
scale B O
selection I I
operator O O
can O O
determine O O
a O O
radius O O
( O O
scale O O
) O O
that O O
only O O
includes O O
logexpdiffint.compress2500:17.5:1h O O
( O O
x O O
) O O
i O O
( O O
x O O
) O O
h O O
’ O O
( O O
x O O
) O O
g O O
( O O
x O O
) O O
10.2 O O
high B O
dynamic I I
range I I
imaging O O
493 O O
( O O
a O O
) O O
( O O
b O O
) O O
figure O O
10.26 O O
gradient B O
domain I I
tone O B
mapping O O
( O O
fattal O O
, O O
lischinski O O
, O O
and O O
werman O O
2002 O O
) O O
c O O
( O O
cid:13 O O
) O O
2002 O O
acm O O
: O O
( O O
a O O
) O O
attenuation O O
map O O
, O O
with O O
darker O O
values O O
corresponding O O
to O O
more O O
attenuation O O
; O O
( O O
b O O
) O O
ﬁnal O O
tone-mapped O O
image B B
. O O
( O O
2008 O O
) O O
show O O
how O O
to O O
mitigate O O
quantization B B
problems O O
in O O
visual B O
words I I
selection O I
using O O
soft O O
assignment O O
, O O
where O O
each O O
feature B B
descriptor O O
is O O
mapped O O
to O O
a O O
number O O
of O O
visual B B
words I I
based O O
on O O
its O O
distance O O
from O O
the O O
cluster O O
prototypes O O
. O O
as O O
each O O
input O O
image B B
is O O
warped O O
onto O O
the O O
current O O
planes B B
parameterized O O
by O O
disparity O O
d O O
, O O
it O O
can O O
be O O
stacked O O
into O O
a O O
generalized B B
disparity O O
space O O
image O O
˜i O O
( O O
x O O
, O O
y O O
, O O
d O O
, O O
k O O
) O O
for O O
further O O
processing O O
( O O
figure O O
11.6b O O
) O O
( O O
szeliski O O
and O O
golland O O
1999 O O
) O O
. O O
this O O
is O O
because O O
larger O O
values O O
of O O
k O O
alias O O
with O O
lower O O
for O O
values O O
in O O
the O O
range O O
k O O
∈ O O
[ O O
− O O
n O O
frequencies O O
and O O
hence O O
provide O O
no O O
additional O O
information O O
, O O
as O O
explained O O
in O O
the O O
discussion O O
on O O
aliasing B B
in O O
section O O
2.3.1 O O
. O O
ieee O O
transactions O O
on O O
pattern O O
analysis O O
and O O
machine O O
intelligence O O
, O O
24 O O
( O O
5 O O
) O O
:603– O O
619. O O
references B B
813 O O
comaniciu O O
, O O
d. O O
and O O
meer O O
, O O
p. O O
( O O
2003 O O
) O O
. O O
the O O
one O O
spe- O O
cial O O
case O O
where O O
it O O
is O O
easy O O
to O O
obtain O O
a O O
simple O O
description O O
for O O
this O O
distribution O O
is O O
linear B B
estimation O O
problems O O
with O O
gaussian O O
noise B B
, O O
where O O
the O O
joint B B
energy O O
function O O
( O O
negative O O
log O O
likelihood O O
of O O
the O O
posterior O B
estimate O O
) O O
is O O
a O O
quadratic O O
. O O
( O O
note O O
that O O
we O O
have O O
also O O
replaced O O
f O O
( O O
i O O
, O O
j O O
) O O
with O O
l O O
( O O
i O O
, O O
j O O
) O O
to O O
make O O
it O O
clearer O O
that O O
these O O
are O O
labels O O
rather O O
than O O
discrete B B
function O O
samples O O
. O O
first O O
, O O
a O O
block-based O O
quadratic O O
transfer B B
function O O
is O O
ﬁt O O
between O O
each O O
source O O
image B B
and O O
an O O
initial O O
feathered O O
composite O O
. O O
pattern O O
recognition B B
letters O O
, O O
9 O O
( O O
4 O O
) O O
:279–286 O O
. O O
references B B
905 O O
sun O O
, O O
j. O O
, O O
yuan O O
, O O
l. O O
, O O
jia O O
, O O
j. O O
, O O
and O O
shum O O
, O O
h.-y O O
. O O
automatic B O
retrieval O O
of O O
visual O B
continuity O O
errors O O
in O O
movies O O
. O O
1.2 O O
a O O
brief O O
history O O
17 O O
multi-view B B
stereo I I
algorithms O O
( O O
figure O O
1.9c O O
) O O
that O O
produce O O
complete O O
3d O O
surfaces O O
( O O
see O O
sec- O O
tion B B
11.6 O O
) O O
were O O
also O O
an O O
active O O
topic O O
of O O
research O O
( O O
seitz O O
and O O
dyer O O
1999 O O
; O O
kutulakos O O
and O O
seitz O O
2000 O O
) O O
that O O
continues O O
to O O
be O O
active O O
today O O
( O O
seitz O O
, O O
curless O O
, O O
diebel O O
et O O
al O O
. O O
as O O
we O O
discussed O O
in O O
section O O
3.7.2 O O
, O O
the O O
prior B B
probability O O
p O O
( O O
x O O
) O O
for O O
a O O
markov O O
random O O
ﬁeld O O
is O O
a O O
gibbs O O
or O O
boltzmann O O
distribution O O
, O O
whose O O
negative O O
log O O
likelihood O O
( O O
according O O
to O O
the O O
hammer- O O
5 O O
alternative O O
formulations O O
include O O
power O O
spectra O O
( O O
section O O
3.4.3 O O
) O O
and O O
non-local O O
means O O
( O O
buades O O
, O O
coll O O
, O O
and O O
morel O O
2008 O O
) O O
. O O
it O O
is O O
also O O
possible O O
to O O
replace O O
the O O
quadratic O O
penalties O O
used O O
in O O
the O O
poisson O O
equations B B
with O O
l1 O O
( O O
total B B
variation I O
) O O
constraints O O
and O O
still O O
obtain O O
a O O
convex O O
optimization O O
problem O O
, O O
which O O
can O O
be O O
solved O O
using O O
either O O
continuous O O
( O O
zach O O
, O O
pock O O
, O O
and O O
bischof O O
2007b O O
; O O
zach O O
2008 O O
) O O
or O O
discrete B B
graph O O
cut O I
( O O
lempitsky O O
and O O
boykov O O
2007 O O
) O O
techniques O O
. O O
over O O
the O O
years O O
, O O
a O O
large O O
number O O
of O O
self-calibration B B
( O O
or O O
auto-calibration O O
) O O
techniques O O
have O O
been O O
de- O O
veloped O O
for O O
converting O O
a O O
projective B B
reconstruction O O
into O O
a O O
metric O O
one O O
, O O
which O O
is O O
equivalent O O
to O O
recovering O O
the O O
unknown O O
calibration B B
matrices O O
kj O O
associated O O
with O O
each O O
image B B
( O O
hartley O O
and O O
zisserman O O
2004 O O
; O O
moons O O
, O O
van O O
gool O O
, O O
and O O
vergauwen O O
2010 O O
) O O
. O O
in O O
the O O
formulation O O
originally O O
developed O O
by O O
criminisi O O
, O O
reid O O
, O O
and O O
zisserman O O
( O O
2000 O O
) O O
, O O
the O O
system O O
produces O O
an O O
afﬁne B B
reconstruction O O
, O O
i.e. O O
, O O
one O O
that O O
is O O
only O O
known O O
up O O
to O O
a O O
set O O
of O O
indepen- O O
dent O O
scaling O O
factors O O
along O O
each O O
axis O O
. O O
objcut O O
: O O
efﬁcient O O
segmenta- O O
tion B B
using O O
top-down O O
and O O
bottom-up O O
cues O O
. O O
paris O O
and O O
durand O O
( O O
2007 O O
) O O
provide O O
a O O
nice O O
review O O
of O O
such O O
applications O O
, O O
as O O
well O O
as O O
techniques O O
for O O
more O O
efﬁciently O O
solving O O
the O O
mean-shift O O
equations B B
and O O
producing O O
hierarchical B B
segmentations O O
. O O
in O O
ieee O O
computer O O
society O O
conference O O
on O O
computer O O
vision O O
and O O
pattern O O
recognition B B
( O O
cvpr O O
2008 O O
) O O
, O O
anchorage O O
, O O
ak O O
. O O
of O O
thresholds O O
can O O
vary O O
a O O
lot O O
as O O
we O O
move O O
to O O
different O O
parts O O
of O O
the O O
feature B B
space O O
( O O
lowe O O
2004 O O
; O O
mikolajczyk O O
and O O
schmid O O
2005 O O
) O O
. O O
the O O
resulting O O
homography B B
matrix O O
˜h O O
10 O O
( O O
the O O
upper O O
left O O
3 O O
× O O
3 O O
sub-matrix O O
of O O
m O O
10 O O
) O O
describes O O
the O O
mapping O O
between O O
pixels O O
in O O
the O O
two O O
images O O
, O O
˜x1 O O
∼ O O
˜h O O
10 O O
˜x0 O O
. O O
13.6 O O
additional O O
reading O O
two O O
good O O
recent O O
surveys B B
of O O
image-based B B
rendering I I
are O O
by O O
kang O O
, O O
li O O
, O O
tong O O
et O O
al O O
. O O
active B O
contours I I
without O O
edges O O
. O O
efﬁcient O O
image B B
matching O O
with O O
distributions O O
of O O
lo- O O
cal O O
invariant O O
features O O
. O O
hierarchical B B
images O O
caching O O
for O O
accelerated O O
walkthroughs B O
of O O
complex O O
environments O O
. O O
the O O
simplest O O
way O O
to O O
compress O O
a O O
high B O
dynamic I I
range I I
radiance O O
image B B
into O O
a O O
low O O
dynamic B O
range O O
gamut O O
is O O
to O O
use O O
a O O
global B B
transfer O O
curve O O
( O O
larson O O
, O O
rushmeier O O
, O O
and O O
piatko O O
1997 O O
) O O
. O O
once O O
an O O
initial O O
set O O
of O O
correspondences O O
has O O
been O O
established O O
, O O
some O O
systems O O
look O O
for O O
additional O O
matches O O
, O O
e.g. O O
, O O
by O O
looking O O
for O O
additional O O
correspondences O O
along O O
epipolar O B
lines O O
( O O
section O O
11.1 O O
) O O
or O O
in O O
the O O
vicinity O O
of O O
estimated O O
locations O O
based O O
on O O
the O O
global B B
transform O O
. O O
rotation O O
and O O
zooming O O
in O O
image B B
mosaic- O O
in O O
ieee O O
workshop O O
on O O
applications O O
of O O
computer O O
vision O O
( O O
wacv O O
’ O O
98 O O
) O O
, O O
pp O O
. O O
pattern O O
recognition B B
, O O
13 O O
( O O
2 O O
) O O
:111–122 O O
. O O
for O O
example O O
, O O
consider O O
the O O
problem O O
of O O
image B B
denoising O O
( O O
sections O O
3.4.4 O O
and O O
3.7.3 O O
) O O
. O O
acm O O
computing O O
surveys B B
, O O
40 O O
( O O
2 O O
) O O
. O O
in O O
order B B
to O O
make O O
such O O
a O O
technique O O
practical O O
, O O
a O O
number O O
issues O O
need O O
to O O
be O O
addressed O O
: O O
• O O
the O O
amount O O
of O O
blur O O
increase O O
in O O
both O O
directions O O
as O O
you O O
move O O
away O O
from O O
the O O
focus B B
plane O O
. O O
orthography O O
and O O
para-perspective B O
an O O
orthographic B O
projection O O
simply O O
drops O O
the O O
z O O
component O O
of O O
the O O
three-dimensional O O
coordi- O O
nate O O
p O O
to O O
obtain O O
the O O
2d O O
point O O
x O O
. O O
ex O O
11.8 O O
: O O
multi-frame B B
stereo O B
extend O O
one O O
of O O
your O O
previous O O
techniques O O
to O O
use O O
multiple B B
input O O
frames O O
( O O
section O O
11.6 O O
) O O
and O O
try O O
to O O
improve O O
the O O
results O O
you O O
obtained O O
with O O
just O O
two O O
views O O
. O O
each O O
matching B B
feature O I
votes O O
for O O
the O O
nearest O B
24 O O
bins O O
and O O
peaks O O
in O O
the O O
transform B B
are O O
then O O
selected O O
for O O
a O O
more O O
careful O O
afﬁne B B
motion O O
ﬁt O O
. O O
bayesian O O
model O O
estimation B B
and O O
selection O O
for O O
epipolar O O
geometry O I
and O O
generic O O
manifold O O
ﬁtting O O
. O O
however O O
, O O
in O O
terms O O
of O O
the O O
physics O O
of O O
the O O
underlying O O
image B B
formation O O
and O O
sensing O O
, O O
it O O
may O O
be O O
a O O
questionable O O
strategy B B
. O O
belief B I
propagation I I
algorithm O O
computes O O
a O O
slightly O O
lower O O
energy O O
and O O
also O O
a O O
smoother O O
image B B
than O O
the O O
alpha-expansion O O
graph B O
cut I I
algorithm O O
. O O
probabilistic B B
robotics O O
. O O
curvature-preserving O O
regularization B B
of O O
multi-valued O O
images O O
using O O
pdes O O
. O O
joshi O O
, O O
n. O O
, O O
zitnick O O
, O O
c. O O
l. O O
, O O
szeliski O O
, O O
r. O O
, O O
and O O
kriegman O O
, O O
d. O O
j. O O
image B B
deblurring O O
and O O
denoising O O
using O O
color O O
priors O O
. O O
) O O
while O O
light O O
is O O
scattered O O
uniformly O O
in O O
all O O
directions O O
, O O
i.e. O O
, O O
the O O
brdf O O
is O O
constant O O
, O O
fd O O
( O O
ˆvi O O
, O O
ˆvr O O
, O O
ˆn O O
; O O
λ O O
) O O
= O O
fd O O
( O O
λ O O
) O O
, O O
( O O
2.86 O O
) O O
the O O
amount O O
of O O
light O O
depends O O
on O O
the O O
angle O O
between O O
the O O
incident O O
light O O
direction O O
and O O
the O O
surface B B
normal O O
θi O O
. O O
stereo B B
reconstruction O O
from O O
multiperspective O O
panora- O O
mas O O
. O O
2. O O
detect O O
the O O
squares O O
, O O
lines B B
, O O
or O O
dots O O
in O O
your O O
calibration B B
target O O
. O O
in O O
other O O
words O O
, O O
there O O
are O O
many O O
unusual O O
photographs O O
in O O
the O O
world. O O
” O O
he O O
does O O
, O O
however O O
agree O O
that O O
in O O
computational O O
photography O O
, O O
as O O
in O O
many O O
other O O
applications O O
such O O
as O O
speech O O
recognition B B
, O O
synthesis O O
, O O
and O O
translation B B
, O O
“ O O
simple O O
machine O O
learning O O
algorithms O O
often O O
outperform O O
more O O
sophisticated O O
ones O O
if O O
trained O O
on O O
large O O
enough O O
databases. O O
” O O
he O O
also O O
goes O O
on O O
to O O
point O O
out O O
both O O
the O O
potential O O
advantages O O
of O O
such O O
systems O O
, O O
such O O
as O O
better O O
automatic B B
color O O
balancing O O
, O O
and O O
potential O O
issues O O
and O O
pitfalls O O
with O O
the O O
kind O O
of O O
image B B
fakery O O
that O O
these O O
new O O
approaches O O
enable O O
. O O
in O O
many O O
cases O O
, O O
this O O
operation O O
can O O
be O O
signiﬁcantly O O
sped O O
up O O
by O O
ﬁrst O O
performing O O
a O O
one-dimensional O O
horizontal O O
convolution O O
followed O O
by O O
a O O
one-dimensional O O
vertical O O
convolution O O
( O O
which O O
requires O O
a O O
total B B
of O O
2k O O
operations O O
per O O
pixel O O
) O O
. O O
motion B B
es- O O
timation O O
can O O
be O O
cast O O
as O O
a O O
global B B
energy O O
minimization O O
problem O O
that O O
simultaneously O O
minimizes O O
brightness O O
compatibility O O
and O O
ﬂow O O
compatibility O O
terms O O
between O O
keyframes O O
and O O
other O O
frames O O
, O O
in O O
addition O O
to O O
using O O
robust O O
smoothness B B
terms O O
. O O
the O O
proﬁle B B
and O O
locations O O
of O O
such O O
edges O O
can O O
be O O
estimated O O
to O O
sub-pixel O O
precision O O
, O O
which O O
makes O O
it O O
possible O O
to O O
estimate O O
the O O
psf O O
at O O
sub-pixel O O
resolutions O O
( O O
reichenbach O O
, O O
park O O
, O O
and O O
narayanswamy O O
1991 O O
; O O
burns O O
and O O
williams O O
1999 O O
; O O
williams O O
and O O
burns O O
2001 O O
; O O
goesele O O
, O O
fuchs O O
, O O
and O O
seidel O O
2003 O O
) O O
. O O
representations O O
such O O
as O O
view- O O
dependent O O
texture B B
maps O O
and O O
lumigraphs O O
still O O
use O O
a O O
single O O
global O O
geometric B B
model O O
, O O
but O O
select O O
the O O
colors O O
to O O
map O O
onto O O
these O O
surfaces O O
from O O
nearby O O
images O O
. O O
dai O O
, O O
baker O O
, O O
and O O
kang O O
( O O
2009 O O
) O O
review O O
this O O
literature O O
and O O
propose O O
their O O
own O O
algorithm B B
, O O
which O O
selects O O
among O O
seven O O
different O O
interpolation B B
functions O O
at O O
each O O
pixel O O
using O O
an O O
mrf O O
framework O O
. O O
humaneva O O
: O O
baseline O O
code O O
for O O
the O O
tracking O O
of O O
articulated O O
human B O
motion I I
, O O
http O O
: O O
//vision O O
. O O
5.5.1 O O
application O O
: O O
medical B B
image I I
segmentation O O
. O O
( O O
3.5 O O
) O O
( O O
we O O
will O O
have O O
more O O
to O O
say O O
about O O
linear B B
shift O O
invariant O O
operators O O
in O O
section O O
3.2 O O
. O O
a O O
lot O O
of O O
current O O
3d O O
reconstruction O O
and O O
recognition B B
techniques O O
are O O
built O O
on O O
extracting O O
and O O
matching B B
feature O I
points B B
( O O
section O O
4.1 O O
) O O
, O O
so O O
this O O
is O O
a O O
fundamental O O
technique O O
required O O
by O O
many O O
subsequent O O
chapters O O
( O O
chapters O O
6 O O
, O O
7 O O
, O O
9 O O
and O O
14 O O
) O O
. O O
therefore O O
, O O
a O O
number O O
of O O
approximations O O
to O O
this O O
ﬁlter O O
are O O
used O O
in O O
practice O O
, O O
include O O
mip-mapping O O
, O O
elliptically O O
weighted B O
gaussian O O
averaging O O
, O O
and O O
anisotropic B B
ﬁltering I O
( O O
akenine-m¨oller O O
and O O
haines O O
2002 O O
) O O
. O O
arc-length O O
parameterization O O
can O O
also O O
be O O
used O O
to O O
smooth O O
curves O O
in O O
order B B
to O O
remove O O
digiti- O O
zation O O
noise B O
. O O
14.1 O O
object O O
detection B B
if O O
we O O
are O O
given O O
an O O
image B B
to O O
analyze O O
, O O
such O O
as O O
the O O
group O O
portrait O O
in O O
figure O O
14.2 O O
, O O
we O O
could O O
try O O
to O O
apply O O
a O O
recognition B B
algorithm O O
to O O
every O O
possible O O
sub-window O O
in O O
this O O
image B B
. O O
( O O
1999 O O
) O O
review O O
difference B O
matting O O
. O O
( O O
a.25 O O
) O O
a.2 O O
linear B B
least O O
squares O O
743 O O
note O O
that O O
the O O
function O O
being O O
ﬁtted O O
need O O
not O O
itself O O
be O O
linear B B
to O O
use O O
linear B B
least O O
squares O O
. O O
robust B O
regularization I O
while O O
regularization B B
is O O
most O O
commonly O O
formulated O O
using O O
quadratic O O
( O O
l2 O O
) O O
norms O O
( O O
compare O O
with O O
the O O
squared O O
derivatives O O
in O O
( O O
3.92–3.95 O O
) O O
and O O
squared O O
differences O O
in O O
( O O
3.100–3.101 O O
) O O
) O O
, O O
it O O
can O O
f O O
( O O
i O O
, O O
j O O
) O O
sx O O
( O O
i O O
, O O
j O O
) O O
f O O
( O O
i O O
, O O
j+1 O O
) O O
sy O O
( O O
i O O
, O O
j O O
) O O
w O O
( O O
i O O
, O O
j O O
) O O
d O O
( O O
i O O
, O O
j O O
) O O
f O O
( O O
i+1 O O
, O O
j O O
) O O
f O O
( O O
i+1 O O
, O O
j+1 O O
) O O
3.7 O O
global B B
optimization I I
179 O O
also O O
be O O
formulated O O
using O O
non-quadratic O O
robust B B
penalty O O
functions O O
( O O
appendix O O
b.3 O O
) O O
. O O
all O O
of O O
these O O
are O O
examples B B
of O O
good O O
reordering O O
techniques O O
. O O
a O O
segmentation B B
based O O
variational O O
model O O
for O O
accurate O O
in O O
tenth O O
european O O
conference O O
on O O
computer O O
vision O O
( O O
eccv O O
optical B O
ﬂow I I
estimation O O
. O O
extract- O O
ing O O
layers B B
and O O
analyzing O O
their O O
specular B B
properties O O
using O O
epipolar-plane-image O O
analysis O O
. O O
to O O
steer O O
any O O
order B B
of O O
derivative O O
with O O
a O O
relatively O O
small O O
number O O
of O O
basis O O
functions O O
. O O
its O O
fourier O O
transform B B
can O O
be O O
written O O
as O O
f O O
{ O O
essd O O
( O O
u O O
) O O
} O O
= O O
f O O
( O O
cid:40 O O
) O O
( O O
cid:88 O O
) O O
i O O
= O O
δ O O
( O O
ω O O
) O O
( O O
cid:88 O O
) O O
i O O
[ O O
i1 O O
( O O
xi O O
+ O O
u O O
) O O
− O O
i0 O O
( O O
xi O O
) O O
] O O
2 O O
( O O
cid:41 O O
) O O
[ O O
i O O
2 O O
0 O O
( O O
xi O O
) O O
+ O O
i O O
2 O O
1 O O
( O O
xi O O
) O O
] O O
− O O
2i0 O O
( O O
ω O O
) O O
i∗1 O O
( O O
ω O O
) O O
. O O
patch-based B B
multi-view O O
stereo B B
software O O
( O O
pmvs O O
version O O
2 O O
) O O
, O O
http O O
: O O
//grail.cs.washington O O
. O O
( O O
2003 O O
) O O
augment O O
their O O
earlier O O
technique O O
by O O
adding O O
synthetic O O
texture B B
to O O
the O O
inﬁlled O O
regions O O
. O O
you O O
can O O
clearly O O
see O O
the O O
woman O O
’ O O
s O O
portrait O O
inside O O
the O O
picture O O
frame O O
superimposed O O
with O O
the O O
reﬂection O O
of O O
a O O
man O O
’ O O
s O O
face B B
off O O
the O O
glass O O
. O O
8.2 O O
parametric B B
motion O O
. O O
porter O O
and O O
duff O O
( O O
1984 O O
) O O
describe O O
a O O
number O O
of O O
additional O O
operations O O
that O O
can O O
be O O
useful O O
in O O
photo O O
editing O O
and O O
visual B B
effects I I
applications O O
. O O
texture B B
and O O
reﬂection O O
in O O
computer O O
generated O O
images O O
. O O
such O O
problems O O
can O O
then O O
be O O
solved O O
using O O
sparse O O
system O O
solving O O
techniques O O
, O O
such O O
as O O
multigrid O O
( O O
briggs O O
, O O
henson O B
, O O
and O O
mccormick O O
2000 O O
) O O
or O O
hierarchically O O
preconditioned B O
conjugate O O
gradient O B
( O O
szeliski O O
2006b O O
) O O
. O O
8.2 O O
parametric B B
motion O O
the O O
parametric B B
incremental O O
motion B O
update O O
rule O O
now O O
becomes O O
elk−pm O O
( O O
p O O
+ O O
∆p O O
) O O
= O O
( O O
cid:88 O O
) O O
i O O
≈ O O
( O O
cid:88 O O
) O O
i O O
= O O
( O O
cid:88 O O
) O O
i O O
[ O O
i1 O O
( O O
x O O
( O O
cid:48 O O
) O O
( O O
xi O O
; O O
p O O
+ O O
∆p O O
) O O
) O O
− O O
i0 O O
( O O
xi O O
) O O
] O O
2 O O
[ O O
i1 O O
( O O
x O O
( O O
cid:48 O O
) O O
i O O
) O O
+ O O
j O O
1 O O
( O O
x O O
( O O
cid:48 O O
) O O
i O O
) O O
∆p O O
− O O
i0 O O
( O O
xi O O
) O O
] O O
2 O O
[ O O
j O O
1 O O
( O O
x O O
( O O
cid:48 O O
) O O
i O O
) O O
∆p O O
+ O O
ei O O
] O O
2 O O
, O O
where O O
the O O
jacobian O O
is O O
now O O
j O O
1 O O
( O O
x O O
( O O
cid:48 O O
) O O
i O O
) O O
= O O
∂i1 O O
∂p O O
= O O
∇i1 O O
( O O
x O O
( O O
cid:48 O O
) O O
i O O
) O O
∂x O B
( O O
cid:48 O O
) O O
∂p O O
( O O
xi O O
) O O
, O O
399 O O
( O O
8.49 O O
) O O
( O O
8.50 O O
) O O
( O O
8.51 O O
) O O
( O O
8.52 O O
) O O
i.e. O O
, O O
the O O
product O O
of O O
the O O
image B B
gradient O O
∇i1 O O
with O O
the O O
jacobian O O
of O O
the O O
correspondence B B
ﬁeld O O
, O O
j O O
x O O
( O O
cid:48 O O
) O O
= O O
∂x O B
( O O
cid:48 O O
) O O
/∂p O O
. O O
5.5.1 O O
application O O
: O O
medical B B
image I I
segmentation O O
one O O
of O O
the O O
most O O
promising O O
applications O O
of O O
image B B
segmentation O O
is O O
in O O
the O O
medical B B
imaging I I
domain O O
, O O
where O O
it O O
can O O
be O O
used O O
to O O
segment O O
anatomical O O
tissues O O
for O O
later O O
quantitative O O
analysis O O
. O O
we O O
also O O
present O O
applications O O
of O O
location B O
recognition I I
( O O
section O O
14.3.3 O O
) O O
. O O
the O O
cascaded B O
hough O O
transform B B
. O O
however O O
, O O
unlike O O
simple O O
coarse-to-ﬁne B B
techniques O O
, O O
which O O
use O O
the O O
coarse O O
solutions O O
to O O
initialize O O
the O O
ﬁne O O
solution O O
, O O
multigrid O O
techniques O O
only O O
correct O O
the O O
low-frequency O O
component O O
of O O
the O O
current O O
solu- O O
tion B B
and O O
use O O
multiple B B
rounds O O
of O O
coarsening O O
and O O
reﬁnement O O
( O O
in O O
what O O
are O O
often O O
called O O
“ O O
v O O
” O O
and O O
“ O O
w O O
” O O
patterns B O
of O O
motion B B
across O O
the O O
pyramid B B
) O O
to O O
obtain O O
rapid O O
convergence O O
. O O
before O O
comparing O O
your O O
techniques O O
, O O
predict O O
which O O
one O O
will O O
be O O
the O O
most O O
accurate O O
( O O
normalize O O
your O O
results O O
by O O
the O O
square B O
root I O
of O O
the O O
number O O
of O O
points B B
used O O
) O O
. O O
( O O
a O O
) O O
structure B B
from I I
motion I I
algorithms O O
can O O
reconstruct O O
a O O
sparse B B
3d O O
point O O
model O O
of O O
a O O
large O O
complex O O
scene O O
from O O
hundreds O O
of O O
partially O O
overlapping O O
photographs O O
( O O
snavely O O
, O O
seitz O O
, O O
and O O
szeliski O O
2006 O O
) O O
c O O
( O O
cid:13 O O
) O O
2006 O O
acm O O
. O O
12.1.1 O O
shape O O
from O O
shading B B
and O O
photometric B B
stereo I I
when O O
you O O
look O O
at O O
images O O
of O O
smooth O O
shaded O O
objects O O
, O O
such O O
as O O
the O O
ones O O
shown O O
in O O
figure O O
12.2 O O
, O O
you O O
can O O
clearly O O
see O O
the O O
shape O O
of O O
the O O
object O O
from O O
just O O
the O O
shading B B
variation O O
. O O
you O O
can O O
get O O
a O O
good O O
sense O O
of O O
the O O
range O O
of O O
operations O O
possible O O
by O O
opening O O
up O O
any O O
photo O O
manipulation O O
tool O O
and O O
trying O O
out O O
a O O
variety O O
of O O
contrast O O
, O O
brightness O O
, O O
and O O
color B B
manipulation O O
options O O
, O O
as O O
shown O O
in O O
figures O O
3.2 O O
and O O
3.7. O O
exercises O O
3.1 O O
, O O
3.5 O O
, O O
and O O
3.6 O O
have O O
you O O
implement O O
some O O
of O O
these O O
operations O O
, O O
in O O
order B B
to O O
become O O
familiar O O
with O O
basic O O
image B B
processing O O
operators O O
. O O
in O O
ieee O O
computer O O
society O O
conference O O
on O O
computer O O
vision O O
and O O
pattern O O
recognition B B
( O O
cvpr O O
’ O O
2001 O O
) O O
, O O
pp O O
. O O
in O O
symposium O O
on O O
interactive B B
3d O O
graphics O O
, O O
pp O O
. O O
fortunately O O
, O O
there O O
exists O O
a O O
faster O O
algorithm B B
called O O
the O O
fast O O
fourier O O
transform B B
( O O
fft O O
) O O
, O O
which O O
requires O O
only O O
o O O
( O O
n O O
log2 O O
n O O
) O O
operations O O
( O O
bracewell O O
1986 O O
; O O
oppenheim O O
, O O
schafer O O
, O O
and O O
buck O O
1999 O O
) O O
. O O
in O O
ieee O O
com- O O
puter O O
society O O
conference O O
on O O
computer O O
vision O O
and O O
pattern O O
recognition B B
( O O
cvpr O O
’ O O
2005 O O
) O O
, O O
pp O O
. O O
the O O
additional O O
colored O O
edges O O
show O O
how O O
combinations O O
of O O
unknown O O
values O O
( O O
say O O
, O O
in O O
a O O
sharp O O
image B B
) O O
produce O O
the O O
measured O O
values O O
( O O
a O O
noisy O O
blurred O O
image B B
) O O
. O O
distinctive O O
image B B
features O O
from O O
scale-invariant O O
keypoints O O
. O O
stereo B B
matching I I
with O O
color-weighted O O
correlation O O
, O O
hierarchical B B
belief O O
propagation O O
and O O
occlusion O O
handling O O
. O O
a O O
closely O O
related O O
topic O O
to O O
multi-frame B O
stereo O B
estimation B B
is O O
scene O O
ﬂow O O
, O O
in O O
which O O
multiple B B
cameras O O
are O O
used O O
to O O
capture O O
a O O
dynamic B B
scene O O
. O O
if O O
they O O
are O O
trying O O
to O O
match O O
door O O
and O O
window O O
edges O O
in O O
a O O
building O O
for O O
the O O
purpose O O
of O O
3d O O
reconstruction O O
, O O
i O O
tell O O
them O O
that O O
edges O O
are O O
a O O
ﬁne O O
idea O O
but O O
it O O
is O O
better O O
to O O
tune O O
the O O
edge O O
detector O O
for O O
long O O
edges O O
( O O
see O O
sections O O
3.2.3 O O
and O O
4.2 O O
) O O
and O O
link O O
them O O
together O O
into O O
straight O O
lines B B
with O O
common O O
vanishing B B
points I I
before O O
matching B B
( O O
see O O
section O O
4.3 O O
) O O
. O O
the O O
spatial O O
matching B B
of O O
image B B
features O O
and O O
regions O O
performed O O
by O O
photo O O
tourism O O
can O O
also O O
be O O
used O O
to O O
infer O O
more O O
information O O
from O O
large O O
image O O
collections O O
. O O
if O O
we O O
introduce O O
a O O
weight O O
function O O
, O O
w O O
( O O
r O O
) O O
= O O
ψ O O
( O O
r O O
) O O
/r O O
, O O
we O O
observe O O
that O O
ﬁnding O O
the O O
stationary O O
point O O
of O O
( O O
6.25 O O
) O O
using O O
( O O
6.26 O O
) O O
is O O
equivalent O O
to O O
minimizing O O
the O O
iteratively B O
reweighted I I
least O O
squares O O
( O O
irls O O
) O O
problem O O
eirls O O
= O O
( O O
cid:88 O O
) O O
i O O
w O O
( O O
( O O
cid:107 O O
) O O
ri O O
( O O
cid:107 O O
) O O
) O O
( O O
cid:107 O O
) O O
ri O O
( O O
cid:107 O O
) O O
2 O O
, O O
( O O
6.27 O O
) O O
where O O
the O O
w O O
( O O
( O O
cid:107 O O
) O O
ri O O
( O O
cid:107 O O
) O O
) O O
play O O
the O O
same O O
local B B
weighting O O
role O O
as O O
σ−2 O O
in O O
( O O
6.10 O O
) O O
. O O
a O O
multiple B B
hypothesis I O
approach O O
to O O
ﬁgure O O
tracking O O
. O O
once O O
the O O
global B B
energy O O
has O O
been O O
deﬁned O O
, O O
a O O
variety O O
of O O
algorithms O O
can O O
be O O
used O O
to O O
ﬁnd O O
a O O
( O O
local B B
) O O
minimum O O
. O O
ex O O
11.9 O O
: O O
volumetric B B
stereo O O
implement O O
voxel B B
coloring I O
( O O
seitz O O
and O O
dyer O O
1999 O O
) O O
as O O
a O O
simple O O
extension O O
to O O
the O O
plane B O
sweep I O
algorithm O O
you O O
implemented O O
in O O
exercise O O
11.4 O O
. O O
instead O O
, O O
a O O
smaller O O
n O O
× O O
n O O
matrix O O
con- O O
sisting O O
of O O
the O O
inner O O
products O O
between O O
all O O
the O O
signed B B
deviations O O
( O O
xi−m O O
) O O
is O O
accumulated O O
instead O O
. O O
a.5 O O
iterative B B
techniques O O
751 O O
conjugategradient O O
( O O
c O O
, O O
d O O
, O O
x0 O O
) O O
conjugategradientls O O
( O O
a O O
, O O
b O O
, O O
x0 O O
) O O
1. O O
r0 O B
= O O
d O O
− O O
cx0 O O
2. O O
p0 O O
= O O
r0 O O
3. O O
for O O
k O O
= O O
0 O O
. O O
mosaicing O O
on O O
adaptive B B
mani- O O
folds O O
. O O
3. O O
these O O
two O O
approaches O O
are O O
fundamentally O O
different O O
, O O
even O O
though O O
projective B B
duality O O
tells O O
us O O
that O O
points B B
and O O
lines B B
are O O
interchangeable O O
. O O
( O O
2003 O O
) O O
, O O
who O O
estimate O O
locally O O
varying O O
brdfs O O
and O O
reﬁne O O
their O O
shape O O
models O O
using O O
local O O
estimates O O
of O O
surface B B
normals O O
. O O
412 O B
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
figure O O
8.12 O O
evaluation B B
of O O
the O O
results O O
of O O
24 O O
optical B O
ﬂow I I
algorithms O O
, O O
october O O
2009 O O
, O O
http O O
: O O
//vision.middlebury.edu/ﬂow/ O O
, O O
( O O
baker O O
, O O
scharstein O O
, O O
lewis O O
et O O
al O O
. O O
the O O
weighted B B
mean O O
also O O
has O O
deep O O
connections O O
to O O
other O O
methods O O
in O O
robust B B
statistics O O
( O O
see O O
ap- O O
pendix O O
b.3 O O
) O O
, O O
such O O
as O O
inﬂuence O O
functions O O
( O O
huber O O
1981 O O
; O O
hampel O O
, O O
ronchetti O O
, O O
rousseeuw O O
et O O
al O O
. O O
we O O
can O O
also O O
compute O O
the O O
fourier O O
transforms O O
for O O
the O O
small O O
discrete B B
kernels O O
shown O O
in O O
fig- O O
ure O O
3.14 O O
( O O
see O O
table O O
3.3 O O
) O O
. O O
in O O
ieee O O
computer O O
society O O
conference O O
on O O
com- O O
puter O O
vision O O
and O O
pattern O O
recognition B B
( O O
cvpr O O
’ O O
2006 O O
) O O
, O O
pp O O
. O O
this O O
convergence O O
is O O
not O O
guaranteed O O
for O O
regular O O
gradient B O
descent I I
unless O O
appropriate O O
step O O
size O O
control O O
is O O
used O O
. O O
3.3.4 O O
connected B B
components I I
. O O
while O O
all O O
of O O
these O O
color B B
systems O O
may O O
sound O O
confusing O O
, O O
in O O
the O O
end O O
, O O
it O O
often O O
may O O
not O O
mat- O O
ter O O
that O O
much O O
which O O
one O O
you O O
use O O
. O O
once O O
again O O
, O O
however O O
, O O
this O O
euclidean O O
distance O O
ignores O O
the O O
fact O O
that O O
we O O
have O O
more O O
information O O
about O O
face B B
likelihoods O O
available O O
in O O
the O O
distribution O O
of O O
training O O
images O O
. O O
( O O
4.19 O O
) O O
the O O
local B B
gradient O O
vector O O
j O O
points B B
in O O
the O O
direction O O
of O O
steepest O O
ascent O O
in O O
the O O
intensity O O
function O O
. O O
2001 O O
) O O
, O O
which O O
are O O
both O O
examples B B
of O O
non-photorealistic B B
rendering I I
( O O
gooch O O
and O O
gooch O O
2001 O O
) O O
. O O
this O O
can O O
be O O
quite O O
convenient O O
in O O
many O O
cases O O
since O O
, O O
for O O
cameras O O
moving O O
around O O
outdoors O O
, O O
the O O
inverse B B
depth O O
to O O
the O O
camera B B
is O O
often O O
a O O
more O O
well-conditioned O O
parameterization O O
than O O
direct B B
3d O O
distance O O
. O O
section O O
14.3 O O
: O O
instance B B
recognition O O
fastann O O
and O O
fastcluster O O
for O O
approximate O O
k-means B B
( O O
akm O O
) O O
, O O
http O O
: O O
//www.robots O O
. O O
similarly O O
, O O
the O O
parameters B B
of O O
the O O
prior B B
distribution I O
can O O
often O O
be O O
learned B B
by O O
observing O O
samples O O
from O O
the O O
class O O
we O O
are O O
modeling B B
( O O
roth O O
and O O
black O O
2007a O O
; O O
tappen O O
2007 O O
; O O
li O O
and O O
huttenlocher O O
2008 O O
) O O
. O O
consider O O
, O O
for O O
example O O
, O O
where O O
one O O
image B B
i0 O O
is O O
all O O
sky O O
blue O O
, O O
i.e. O O
, O O
i0 O O
( O O
p O O
) O O
= O O
i0 O O
( O O
q O O
) O O
= O O
b O O
, O O
while O O
the O O
other O O
image B B
i1 O O
has O O
a O O
transition O O
from O O
sky O O
blue O O
, O O
i1 O O
( O O
p O O
) O O
= O O
b O O
, O O
to O O
forest O O
green O O
, O O
i1 O O
( O O
q O O
) O O
= O O
g. O O
i0 O O
: O O
: O O
i1 O O
in O O
this O O
case O O
, O O
vp O O
, O O
q O O
( O O
1 O O
, O O
0 O O
) O O
= O O
0 O O
( O O
the O O
colors O O
agree O O
) O O
, O O
while O O
vp O O
, O O
q O O
( O O
0 O O
, O O
1 O O
) O O
> O O
0 O O
( O O
the O O
colors O O
disagree O O
) O O
. O O
the O O
idea O O
of O O
manipulating O O
real-world O O
imagery O O
directly O O
to O O
create O O
new O O
animations O O
ﬁrst O O
came O O
to O O
prominence O O
with O O
image O O
morphing B O
techniques O O
( O O
figure1.5c O O
) O O
( O O
see O O
section O O
3.6.3 O O
and O O
beier O O
and O O
neely O O
1992 O O
) O O
and O O
was O O
later O O
applied O O
to O O
view B O
interpolation I I
( O O
chen O O
and O O
williams O O
1993 O O
; O O
seitz O O
and O O
dyer O O
1996 O O
) O O
, O O
panoramic O O
image B B
stitching I I
( O O
figure1.5a O O
) O O
( O O
see O O
chapter O O
9 O O
and O O
mann O O
and O O
picard O O
1994 O O
; O O
chen O O
1995 O O
; O O
szeliski O O
1996 O O
; O O
szeliski O O
and O O
shum O O
1997 O O
; O O
szeliski O O
2006a O O
) O O
, O O
and O O
full O O
light-ﬁeld O O
rendering B B
( O O
figure O O
1.10a O O
) O O
( O O
see O O
section O O
13.3 O O
and O O
gortler O O
, O O
grzeszczuk O O
, O O
szeliski O O
et O O
al O O
. O O
points B B
above O O
the O O
ground O O
plane O O
, O O
when O O
paired O O
with O O
their O O
ground O O
plane O O
projections O B
, O O
can O O
also O O
be O O
recovered O O
. O O
7.4.3 O O
uncertainty B B
and O O
ambiguities O O
. O O
fast O O
, O O
robust B B
image O O
registration B B
for O O
compositing B O
high O O
dynamic B I
range O I
photographs O O
from O O
hand-held O O
exposures O O
. O O
human O O
detection O O
based O O
on O O
a O O
prob- O O
abilistic O O
assembly O O
of O O
robust B B
part O O
detectors O O
. O O
) O O
can O O
be O O
estimated O O
from O O
a O O
set O O
of O O
overlapping O O
ﬁsheye O O
images O O
using O O
a O O
direct B B
( O O
intensity-based B B
) O O
non-linear B B
minimization O O
algorithm B B
. O O
) O O
in O O
fact O O
, O O
equation B B
( O O
3.14 O O
) O O
can O O
be O O
interpreted O O
as O O
the O O
superposition B O
( O O
addition O O
) O O
of O O
shifted O O
im- O O
pulse O O
response O O
functions O O
h O O
( O O
i− O O
k O O
, O O
j O O
− O O
l O O
) O O
multiplied O O
by O O
the O O
input O O
pixel O O
values O O
f O O
( O O
k O O
, O O
l O O
) O O
. O O
seamless O O
image B B
stitching I I
in O O
the O O
gradient B O
domain I I
. O O
a00 O O
a01 O O
a02 O O
a03 O O
a10 O O
a11 O O
a12 O O
a13 O O
0 O O
1 O O
0 O O
0 O O
( O O
2.49 O O
) O O
note O O
how O O
parallel O O
lines B B
in O O
3d O O
remain O O
parallel O O
after O O
projection O O
in O O
figure O O
2.7b–d O O
. O O
206 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
( O O
a O O
) O O
( O O
c O O
) O O
( O O
b O O
) O O
( O O
d O O
) O O
figure O O
4.1 O O
a O O
variety O O
of O O
feature B B
detectors O O
and O O
descriptors O O
can O O
be O O
used O O
to O O
analyze O O
, O O
describe O O
and O O
match O O
images O O
: O O
( O O
a O O
) O O
point-like O O
interest O O
operators O O
( O O
brown O O
, O O
szeliski O O
, O O
and O O
winder O O
2005 O O
) O O
c O O
( O O
cid:13 O O
) O O
2005 O O
ieee O O
; O O
( O O
b O O
) O O
region-like O O
interest O O
operators O O
( O O
matas O O
, O O
chum O O
, O O
urban O O
et O O
al O O
. O O
geometric B B
camera O O
calibration B B
using O O
systems O O
of O O
linear B B
equations O O
. O O
can O O
you O O
think O O
of O O
a O O
way O O
to O O
enhance O O
it O O
( O O
exercise O O
3.29 O O
) O O
? O O
2. O O
shift O O
drag O O
( O O
rubber-band O O
) O O
to O O
crop O O
a O O
subregion O O
( O O
or O O
select O O
whole O O
image B B
) O O
. O O
note O O
that O O
the O O
colors O O
for O O
the O O
ﬂower O O
garden O O
sequence O O
are O O
incorrect O O
; O O
the O O
correct O O
colors O O
( O O
yellow O O
ﬂowers O O
) O O
are O O
shown O O
in O O
figure O O
8.15. O O
o O O
of O O
course O O
, O O
layers B B
are O O
not O O
the O O
only O O
way O O
to O O
introduce O O
segmentation B B
into O O
motion B B
estimation I I
. O O
9.1 O O
motion B B
models I I
431 O O
( O O
a O O
) O O
translation B B
[ O O
2 O O
dof O O
] O O
( O O
b O O
) O O
afﬁne B B
[ O O
6 O O
dof O O
] O O
( O O
c O O
) O O
perspective B B
[ O O
8 O O
dof O O
] O O
( O O
d O O
) O O
3d O O
rotation O O
[ O O
3+ O O
dof O O
] O O
figure O O
9.2 O O
two-dimensional B B
motion O O
models O O
and O O
how O O
they O O
can O O
be O O
used O O
for O O
image O O
stitching O O
. O O
chapter O O
4 O O
: O O
feature B B
detection O O
and O O
matching B B
vlfeat O O
, O O
an O O
open O O
and O O
portable O O
library O O
of O O
computer O O
vision O O
algorithms O O
, O O
http O O
: O O
//vlfeat.org/ O O
( O O
vedaldi O O
and O O
fulkerson O O
2008 O O
) O O
. O O
note O O
that O O
in O O
this O O
section O O
, O O
we O O
use O O
the O O
variables O O
x O O
and O O
y O O
to O O
denote O O
the O O
spatial O O
coordinates O O
of O O
an O O
image B B
, O O
rather O O
than O O
i O O
and O O
j O O
as O O
in O O
the O O
previous O O
sections O O
. O O
section O O
14.1.1 O O
: O O
face B B
detection O O
sample O O
face B B
detection O O
code O O
and O O
evaluation B B
tools O O
, O O
http O O
: O O
//vision.ai.uiuc.edu/mhyang/face-detection-survey.html O O
. O O
( O O
5.15 O O
) O O
in O O
most O O
cases O O
, O O
the O O
likely O O
appearance O O
of O O
the O O
points B B
can O O
be O O
modeled O O
using O O
only O O
a O O
few O O
eigen- O O
vectors O O
with O O
the O O
largest O O
eigenvalues B B
. O O
recognition B I
( O O
cvpr O O
’ O O
91 O O
) O O
, O O
pp O O
. O O
14.4.4 O O
application O O
: O O
intelligent B B
photo I I
editing I O
recent O O
advances O O
in O O
object O O
recognition B B
and O O
scene B O
understanding I I
have O O
greatly O O
increased O O
the O O
power O B
of O O
intelligent O B
( O O
semi-automated O O
) O O
photo O O
editing O O
applications O O
. O O
recognition B B
( O O
cvpr O O
’ O O
2005 O O
) O O
, O O
pp O O
. O O
solving O O
random-dot O O
stereograms O O
using O O
the O O
heat O O
equa- O O
tion B B
. O O
the O O
number O O
of O O
bins O O
to O O
use O O
along O O
each O O
axis O O
depends O O
on O O
the O O
accuracy B B
of O O
the O O
position O O
and O O
orientation O O
estimate O O
available O O
at O O
each O O
edgel O O
and O O
the O O
expected O O
line O O
density O O
, O O
and O O
is O O
best O O
set O O
experimentally O O
with O O
some O O
test O O
runs O O
on O O
sample O O
imagery O O
. O O
under O O
favorable O O
conditions O O
, O O
super-resolution O O
and O O
related O O
upsampling O O
techniques O O
can O O
in- O O
crease O O
the O O
resolution O O
of O O
a O O
well-photographed O O
image B B
or O O
image B B
collection O O
. O O
figure O O
12.10 O O
shows O O
details O O
from O O
this O O
project O O
, O O
including O O
a O O
sample O O
photograph O O
, O O
a O O
detailed O O
3d O O
( O O
sculptural O O
) O O
head B B
model O O
scanned O O
from O O
ground O O
level O B
, O O
and O O
an O O
aerial O O
overview O O
of O O
the O O
ﬁnal O O
merged O O
3d O O
site O O
model O O
, O O
which O O
was O O
acquired O O
using O O
a O O
balloon O O
. O O
for O O
scattered O O
data O O
interpolation O B
( O O
nielson O O
1993 O O
) O O
, O O
the O O
data O O
term O O
measures O O
the O O
dis- O O
tance O O
between O O
the O O
function O O
f O O
( O O
x O O
, O O
y O O
) O O
and O O
a O O
set O O
of O O
data O O
points O O
di O O
= O O
d O O
( O O
xi O O
, O O
yi O O
) O O
, O O
to O O
obtain O O
a O O
global B B
energy O O
that O O
can O O
be O O
minimized O O
, O O
the O O
two O O
energy O O
terms O O
are O O
usually O O
added O O
together O O
, O O
e O O
= O O
ed O O
+ O O
λes O O
, O O
( O O
3.98 O O
) O O
where O O
es O O
is O O
the O O
smoothness B B
penalty O O
( O O
e1 O O
, O O
e2 O O
or O O
some O O
weighted B B
blend O O
) O O
and O O
λ O O
is O O
the O O
regulariza- O O
tion B B
parameter O O
, O O
which O O
controls O O
how O O
smooth O O
the O O
solution O O
should O O
be O O
. O O
each O O
transformation O O
also O O
preserves O O
the O O
properties B B
listed O O
in O O
the O O
rows O O
below O O
it O O
, O O
i.e. O O
, O O
similarity B B
preserves O O
not O O
only O O
angles O O
but O O
also O O
parallelism O O
and O O
straight O O
lines B B
. O O
machine O O
learning O B
techniques O O
can O O
be O O
used O O
to O O
create O O
the O O
probabilistic B B
models I I
in O O
the O O
ﬁrst O O
place O O
. O O
lucas-kanade O O
without O O
iterative B B
warping O O
. O O
370 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
7.4.3 O O
uncertainty B B
and O O
ambiguities O O
because O O
structure B O
from I I
motion I I
involves O O
the O O
estimation B B
of O O
so O O
many O O
highly O O
coupled O O
parameters B B
, O O
often O O
with O O
no O O
known O O
“ O O
ground O O
truth O O
” O O
components O O
, O O
the O O
estimates O O
produced O O
by O O
structure O O
from O O
motion B B
algorithms O O
can O O
often O O
exhibit O O
large O O
amounts O O
of O O
uncertainty B B
( O O
szeliski O O
and O O
kang O O
1997 O O
) O O
. O O
convolving O O
the O O
linear B B
tent O O
function O O
with O O
itself O O
yields O O
the O O
cubic B B
approximating O O
spline B B
, O O
which O O
is O O
called O O
the O O
“ O O
gaussian O O
” O O
kernel B B
( O O
figure O O
3.14c O O
) O O
in O O
burt O O
and O O
adelson O O
’ O O
s O O
( O O
1983a O O
) O O
lapla- O O
cian O O
pyramid B B
representation O O
( O O
section O O
3.5 O O
) O O
. O O
( O O
3.32 O O
) O O
a O O
potential O O
disadvantage O O
of O O
summed O O
area O O
tables O O
is O O
that O O
they O O
require O O
log O O
m O O
+ O O
log O O
n O O
extra O O
bits O O
in O O
the O O
accumulation O O
image B B
compared O O
to O O
the O O
original O O
image B B
, O O
where O O
m O O
and O O
n O O
are O O
the O O
image B B
width O O
and O O
height O O
. O O
meshes O O
are O O
the O O
standard O O
representation O O
used O O
in O O
computer O O
graphics O O
and O O
also O O
readily O O
support O O
the O O
computation O O
of O O
visibility B B
and O O
occlusions O O
. O O
in O O
addition O O
to O O
modeling B B
people O O
, O O
we O O
also O O
discuss O O
techniques O O
for O O
tracking O O
them O O
. O O
similarly O O
, O O
color B B
balancing O O
( O O
e.g. O O
, O O
to O O
compensate O O
for O O
incandescent O O
lighting B B
) O O
can O O
be O O
per- O O
formed O O
either O O
by O O
multiplying O O
each O O
channel O O
with O O
a O O
different O O
scale O O
factor O O
or O O
by O O
the O O
more O O
com- O O
plex O O
process O O
of O O
mapping O O
to O O
xyz O O
color B B
space O O
, O O
changing O O
the O O
nominal O O
white O O
point O O
, O O
and O O
mapping O O
back O O
to O O
rgb O O
, O O
which O O
can O O
be O O
written O O
down O O
using O O
a O O
linear B B
3 O O
× O O
3 O O
color B B
twist O O
transform B B
matrix O O
. O O
puter O O
society O O
conference O O
on O O
computer O O
vision O O
and O O
pattern O O
recognition B B
( O O
cvpr O O
2008 O O
) O O
, O O
anchorage O O
, O O
ak O O
. O O
while O O
originally O O
bright O O
blue O O
was O O
the O O
preferred O O
color B B
, O O
bright O O
green O O
is O O
now O O
more O O
com- O O
monly O O
used O O
( O O
wright O O
2006 O O
; O O
brinkmann O O
2008 O O
) O O
. O O
in O O
ieee O O
computer O O
society O O
conference O O
on O O
computer O O
vision O O
and O O
pattern O O
recognition B B
( O O
cvpr O O
2007 O O
) O O
, O O
minneapolis O O
, O O
mn O O
. O O
an O O
efﬁcient O O
line O O
search O O
for O O
nonlinear O O
least B B
squares I I
. O O
another O O
possibility O O
is O O
to O O
compute O O
a O O
weighted B B
median O O
, O O
in O O
which O O
each O O
pixel O O
is O O
used O O
a O O
num- O O
ber O O
of O O
times O O
depending O O
on O O
its O O
distance O O
from O O
the O O
center O O
. O O
however O O
, O O
in O O
general O O
, O O
we O O
can O O
not O O
be O O
sure O O
that O O
we O O
have O O
a O O
reasonable O O
algorithm B B
unless O O
we O O
make O O
a O O
model O O
of O O
the O O
likely O O
sources O O
of O O
error O O
and O O
devise O O
an O O
algorithm B B
that O O
performs O O
as O O
well O O
as O O
possible O O
given O O
these O O
potential O O
errors O O
. O O
in O O
principle O O
, O O
summed O O
area O O
tables O O
could O O
also O O
be O O
used O O
to O O
compute O O
the O O
sums O O
in O O
the O O
sum O O
of O O
squared O O
differences O O
( O O
ssd O O
) O O
stereo B B
and O O
motion B B
algorithms O O
( O O
section O O
11.4 O O
) O O
. O O
634 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
the O O
decomposition O O
into O O
a O O
diffuse B B
and O O
specular B B
component O O
can O O
also O O
be O O
used O O
to O O
perform O O
editing O O
or O O
manipulation O O
operations O O
, O O
such O O
as O O
re-painting O O
the O O
surface B B
, O O
changing O O
the O O
specular B B
component O O
of O O
the O O
reﬂection O O
( O O
e.g. O O
, O O
by O O
blurring O O
or O O
sharpening O O
the O O
specular B B
lumispheres O O
) O O
, O O
or O O
even O O
geometrically O O
deforming O O
the O O
object O O
while O O
preserving O O
detailed O O
surface B B
appearance O O
. O O
hornung O O
, O O
a. O O
, O O
zeng O O
, O O
b. O O
, O O
and O O
kobbelt O O
, O O
l. O O
image B B
selection O O
for O O
improved O O
multi- O O
view O O
stereo O O
. O O
as O O
an O O
alternative O O
, O O
generate O O
synthetic O O
3d O O
points B B
and O O
cameras O O
and O O
add O O
noise B B
to O O
the O O
2d O O
point O O
measurements O O
. O O
• O O
shifted O O
impulse O O
: O O
the O O
shifted O O
impulse O O
has O O
unit O O
magnitude O O
and O O
linear B B
phase O O
. O O
12.7.1 O O
estimating O O
brdfs O O
a O O
more O O
ambitious O O
approach O O
to O O
the O O
problem O O
of O O
view-dependent B O
appearance O O
modeling B B
is O O
to O O
estimate O O
a O O
general O O
bidirectional O O
reﬂectance B B
distribution O O
function O O
( O O
brdf O O
) O O
for O O
each O O
point O O
on O O
an O O
object O O
’ O O
s O O
surface B B
. O O
zi O O
’ O O
=103mmf O O
’ O O
= O O
101mmzo=5mpdc O O
72 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
figure O O
2.22 O O
the O O
amount O O
of O O
light O O
hitting O O
a O O
pixel O O
of O O
surface B B
area O O
δi O O
depends O O
on O O
the O O
square O O
of O O
the O O
ratio O O
of O O
the O O
aperture O O
diameter O O
d O O
to O O
the O O
focal O O
length O O
f O O
, O O
as O O
well O O
as O O
the O O
fourth O O
power O O
of O O
the O O
off-axis O O
angle O O
α O O
cosine O O
, O O
cos4 O O
α O O
. O O
please O O
note O O
that O O
most O O
mathematical O O
textbooks B B
and O O
papers O O
use O O
1-based O O
indexing O O
, O O
so O O
you O O
need O O
to O O
be O O
aware O O
of O O
the O O
differences O O
when O O
you O O
read O O
this O O
book O O
. O O
( O O
11.14 O O
) O O
the O O
advantage O O
of O O
this O O
scanline B O
optimization I O
algorithm O O
is O O
that O O
it O O
computes O O
the O O
same O O
represen- O O
tation O O
and O O
minimizes O O
a O O
reduced O O
version O O
of O O
the O O
same O O
energy O O
function O O
as O O
the O O
full O O
2d O O
energy O O
function O O
( O O
11.8 O O
) O O
. O O
the O O
responses O O
are O O
then O O
ﬁltered O O
using O O
offset O O
rectangular O O
regions O O
trained O O
with O O
joint O O
boosting B O
( O O
viola O O
and O O
jones O O
2004 O O
) O O
to O O
produce O O
the O O
texton-layout O O
features O O
used O O
as O O
unary O O
potentials O O
. O O
markov O O
random O O
field O O
modeling B B
in O O
computer O O
vision O O
. O O
if O O
the O O
measurements O O
have O O
comparable O O
noise B B
, O O
the O O
terms O O
that O O
are O O
products O O
of O O
measurements O O
have O O
their O O
noise B B
ampliﬁed O O
by O O
the O O
other O O
element O O
in O O
the O O
product O O
, O O
which O O
can O O
lead O O
to O O
very O O
poor O O
scaling O O
, O O
e.g. O O
, O O
an O O
inordinately O O
large O O
inﬂuence O O
of O O
points B B
with O O
large O O
coordinates O O
( O O
far O O
away O O
from O O
the O O
image B B
center O O
) O O
. O O
performance O O
of O O
optical B B
ﬂow I I
techniques O O
. O O
other O O
kinds O O
of O O
edges O O
correspond O O
to O O
shadow B O
boundaries O O
or O O
crease O O
edges O O
, O O
where O O
surface B B
orientation O O
changes O O
rapidly O O
. O O
while O O
video B B
stitching O O
is O O
in O O
many O O
ways O O
a O O
straightforward O O
generalization O O
of O O
multiple-image O O
stitching O O
( O O
steedly O O
, O O
pal O O
, O O
and O O
szeliski O O
2005 O O
; O O
baudisch O O
, O O
tan O O
, O O
steedly O O
et O O
al O O
. O O
this O O
includes O O
approaches O O
that O O
use O O
bags O O
of O O
features O O
( O O
section O O
14.4.1 O O
) O O
, O O
parts O O
( O O
section O O
14.4.2 O O
) O O
, O O
and O O
segmentation B B
( O O
section O O
14.4.3 O O
) O O
. O O
3d O O
shape O O
and O O
light O O
source O O
location O O
from O O
depth O O
and O O
in O O
ieee O O
computer O O
society O O
conference O O
on O O
computer O O
vision O O
and O O
pattern O O
reﬂectance B B
. O O
image B O
processing O O
is O O
often O O
taught O O
in O O
electrical O O
engineering O O
departments O O
as O O
a O O
follow-on O O
course O O
to O O
an O O
introductory O O
course O O
in O O
signal O O
processing O O
( O O
oppenheim O O
and O O
schafer O O
1996 O O
; O O
oppenheim O O
, O O
schafer O O
, O O
and O O
buck O O
1999 O O
) O O
. O O
however O O
, O O
when O O
video B B
is O O
being O O
captured O O
for O O
display O O
, O O
some O O
motion B B
blur O O
may O O
be O O
desirable O O
to O O
avoid O O
stroboscopic O O
effects O O
. O O
structure- O O
and O O
motion-adaptive O O
in O O
twelfth O O
international O O
conference O O
on O O
regularization B B
for O O
high O O
accuracy O O
optic O O
ﬂow O O
. O O
how O O
do O O
these O O
quan- O O
tities O O
relate O O
to O O
the O O
more O O
familiar O O
focal O O
lengths O O
used O O
by O O
photographers O O
? O O
figure O O
2.10 O O
illustrates O O
the O O
relationship O O
between O O
the O O
focal O O
length O O
f O O
, O O
the O O
sensor B B
width O O
w O O
, O O
and O O
the O O
ﬁeld O O
of O O
view O O
θ O O
, O O
which O O
obey O O
the O O
formula O O
tan O O
θ O O
2 O O
= O O
w O O
2f O O
or O O
f O O
= O O
w O O
2 O O
( O O
cid:20 O O
) O O
tan O O
θ O O
2 O O
( O O
cid:21 O O
) O O
−1 O O
. O O
ex O O
4.14 O O
: O O
vanishing B O
points I I
compute O O
the O O
vanishing B B
points I I
in O O
an O O
image B B
using O O
one O O
of O O
the O O
tech- O O
niques O O
described O O
in O O
section O O
4.3.3 O O
and O O
optionally O O
reﬁne O O
the O O
original O O
line O O
equations O O
associated O O
with O O
each O O
vanishing O O
point O O
. O O
in O O
the O O
absence O O
of O O
inter-reﬂections O O
( O O
e.g. O O
, O O
a O O
convex O O
object O O
in O O
a O O
large O O
open O O
space O O
) O O
, O O
each O O
surface B B
point O O
simply O O
reﬂects O O
the O O
far-ﬁeld O O
environment O O
map O O
( O O
section O O
2.2.1 O B
) O O
, O O
which O O
again O O
is O O
two-dimensional B B
. O O
computer O O
vision O O
, O O
graphics O O
, O O
and O O
image B B
processing O O
, O O
22:39–69 O O
. O O
a.3 O O
non-linear B B
least O O
squares O O
. O O
to O O
deal O O
with O O
in-plane O O
rotations O O
of O O
faces B B
, O O
rowley O O
, O O
baluja O O
, O O
and O O
kanade O O
( O O
1998b O O
) O O
train O O
a O O
router O O
network O O
to O O
estimate O O
likely O O
rotation O O
angles O O
from O O
input O O
patches O O
and O O
then O O
apply O O
the O O
estimated O O
rotation O O
to O O
each O O
patch B B
before O O
running O O
the O O
result O O
through O O
their O O
upright O O
face B B
detector O O
. O O
these O O
ﬁlters O O
are O O
of O O
odd O O
length O O
, O O
are O O
sym- O O
metric O O
, O O
and O O
are O O
normalized B B
to O O
have O O
unit O O
dc O O
gain O O
( O O
sum O O
up O O
to O O
1 O O
) O O
. O O
we O O
close O O
with O O
an O O
example O O
appli- O O
cation O O
that O O
manipulates O O
tonal O O
values O O
( O O
exposure O O
and O O
contrast O O
) O O
to O O
improve O O
image B B
appearance O O
. O O
a O O
different O O
connection O O
to O O
continuous O O
segmentation B B
techniques O O
, O O
this O O
time O O
to O O
the O O
literature O O
on O O
level B O
sets I I
( O O
section O O
5.1.4 O O
) O O
, O O
is O O
made O O
by O O
boykov O O
, O O
kolmogorov O O
, O O
cremers O O
et O O
al O O
. O O
when O O
fewer O O
images O O
are O O
available O O
, O O
it O O
becomes O O
necessary O O
to O O
fall O O
back O O
on O O
aggregation O O
tech- O O
niques O O
such O O
as O O
sliding O O
windows O O
or O O
global B B
optimization I I
. O O
for O O
the O O
data O O
penalty O O
, O O
ρd O O
can O O
be O O
quadratic O O
( O O
to O O
model O O
gaussian O O
noise B B
) O O
or O O
the O O
log O O
of O O
a O O
contaminated O O
gaussian O O
( O O
appendix O O
b.3 O O
) O O
. O O
for O O
example O O
, O O
nene O O
and O O
nayar O O
( O O
1997 O O
) O O
developed O O
a O O
technique O O
they O O
call O O
slicing O O
that O O
uses O O
a O O
series O O
of O O
1d O O
binary O O
searches O O
on O O
the O O
point O O
list O O
sorted O O
along O O
different O O
dimen- O O
sions O O
to O O
efﬁciently O O
cull O O
down O O
a O O
list O O
of O O
candidate O O
points B B
that O O
lie O O
within O O
a O O
hypercube O O
of O O
the O O
query O O
point O O
. O O
2004 O O
) O O
can O O
sometimes O O
be O O
used O O
to O O
retain O O
multiple B B
copies O O
of O O
a O O
moving O O
object O O
( O O
figure O O
9.17 O O
) O O
. O O
8.3.1 O O
application O O
: O O
medical B B
image I I
registration O O
. O O
can O O
we O O
tell O O
what O O
spectral O O
sensitivities O O
the O O
cameras O O
actually O O
have O O
? O O
unless O O
the O O
camera B B
manufacturer O O
provides O O
us O O
with O O
this O O
data O O
or O O
we O O
observe O O
the O O
response O O
of O O
the O O
camera B B
to O O
a O O
whole O O
spectrum O O
of O O
monochromatic O O
lights O O
, O O
these O O
sensitivities O O
are O O
not O O
speciﬁed O O
by O O
a O O
standard O O
such O O
as O O
bt.709 O O
. O O
section O O
12.6.1 O O
describes O O
other O O
, O O
potentially O O
multi-view B B
, O O
approaches O O
to O O
architectural O O
reconstruction O O
, O O
including O O
an O O
interactive B B
piecewise-planar O O
modeling B B
system O O
that O O
uses O O
vanishing B B
points I I
to O O
establish O O
3d O O
line O O
directions O O
and O O
plane O O
normals O O
( O O
sinha O O
, O O
steedly O O
, O O
szeliski O O
et O O
al O O
. O O
exact O O
maximum O O
a O O
posteriori O O
estimation B B
for O O
binary O O
images O O
. O O
references B B
873 O O
nagel O O
, O O
h. O O
h. O O
( O O
1986 O O
) O O
. O O
( O O
2004 O O
) O O
extended O O
this O O
idea O O
to O O
a O O
multi-source O O
formu- O O
lation O O
, O O
where O O
it O O
no O O
longer O O
makes O O
sense O O
to O O
talk O O
of O O
a O O
destination O O
image B B
whose O O
exact O O
pixel O O
values O O
must O O
be O O
matched O O
at O O
the O O
seam O O
. O O
in O O
eighth O O
international O O
joint B B
conference O O
on O O
artiﬁcial O O
intelligence O O
( O O
ijcai-83 O O
) O O
, O O
pp O O
. O O
interactive B B
volume O O
rendering B B
. O O
combining O O
object O O
recognition B B
with O O
scene O O
segmentation O B
can O O
yield O O
strong O O
beneﬁts O O
. O O
from O O
projective B B
to O O
euclidean O O
space O O
under O O
any O O
practical O O
situation O O
, O O
a O O
criticism O O
of O O
self-calibration B O
. O O
-0.50.00.51.0-1.0000-0.50000.00000.50001.0000-0.50.00.51.0-0.50000.00000.5000-0.50.00.51.0-1.0000-0.50000.00000.50001.0000-0.50.00.51.0-0.50000.00000.5000-0.50.00.51.0-1.0000-0.50000.00000.50001.0000-0.50.00.51.0-0.50000.00000.5000-0.50.00.51.0-1.0000-0.50000.00000.50001.0000-0.50.00.51.0-0.50000.00000.5000-0.50.00.51.0-1.0000-0.50000.00000.50001.0000-0.50.00.51.0-0.50000.00000.5000-0.50.00.51.0-1.0000-0.50000.00000.50001.0000-0.50.00.51.0-0.50000.00000.5000-0.50.00.51.0-1.0000-0.50000.00000.50001.0000-0.50.00.51.0-0.50000.00000.5000-0.50.00.51.01.5-1.0000-0.50000.00000.50001.0000-0.50.00.51.01.5-0.50000.00000.5000-0.50.00.51.0-1.0000-0.50000.00000.50001.0000-0.50.00.51.0-0.50000.00000.5000 O O
138 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
• O O
laplacian O O
of O O
gaussian O O
: O O
the O O
second O O
derivative O O
of O O
a O O
gaussian O O
of O O
width O O
σ O O
, O O
log O O
( O O
x O O
; O O
σ O O
) O O
= O O
( O O
x2 O O
σ4 O O
− O O
1 O O
σ2 O O
) O O
g O O
( O O
x O O
; O O
σ O O
) O O
has O O
a O O
band-pass B B
response O O
of O O
√2π O O
σ O O
− O O
ω2g O O
( O O
ω O O
; O O
σ−1 O O
) O O
( O O
3.59 O O
) O O
( O O
3.60 O O
) O O
as O O
its O O
fourier O O
transform B B
. O O
the O O
point B O
spread I O
function I O
( O O
blur O O
kernel O B
) O O
bk O O
is O O
either O O
inferred O O
from O O
knowledge O O
of O O
the O O
image B B
formation O O
process O O
( O O
e.g. O O
, O O
the O O
amount O O
of O O
motion B B
or O O
defocus O O
blur O O
and O O
the O O
camera B B
sensor O O
optics B B
) O O
or O O
calibrated O O
from O O
a O O
test O O
image O O
or O O
the O O
observed O O
images O O
{ O O
ok O O
} O O
using O O
one O O
of O O
the O O
techniques O O
described O O
in O O
section O O
10.1.4. O O
the O O
problem O O
of O O
simultaneously O O
inferring O O
the O O
blur O O
kernel O O
and O O
the O O
sharp O O
image B B
is O O
known O O
as O O
blind O O
image B O
deconvolution O O
( O O
kundur O O
and O O
hatzinakos O O
1996 O O
; O O
levin O O
2006 O O
) O O
.18 O O
given O O
an O O
estimate O O
of O O
ˆhk O O
and O O
bk O O
( O O
x O O
) O O
, O O
( O O
10.27 O O
) O O
can O O
be O O
re-written O O
using O O
matrix/vector O O
notation O O
as O O
a O O
large O O
sparse O O
least B O
squares I O
problem O O
in O O
the O O
unknown O O
values O O
of O O
the O O
super-resolved O O
pixels O O
s O O
, O O
( O O
cid:88 O O
) O O
k O O
( O O
cid:107 O O
) O O
ok O O
− O O
dbkw O O
ks O O
( O O
cid:107 O O
) O O
2 O O
. O O
probabilistic B O
latent O O
semantic O O
indexing O O
. O O
of O O
course O O
, O O
the O O
above O O
formula O O
( O O
3.113 O O
) O O
for O O
the O O
smoothness B B
term O O
ep O O
( O O
i O O
, O O
j O O
) O O
just O O
shows O O
the O O
simplest O O
case O O
. O O
3. O O
estimate O O
the O O
lumisphere O O
for O O
each O O
surface B B
point O O
on O O
the O O
object O O
. O O
stereo B B
for O O
image-based B O
rendering I B
using O O
image B B
over-segmentation O O
. O O
segmentation-based B O
adaptive O I
support O O
in O O
paciﬁc-rim O O
symposium O O
on O O
image B B
and O O
video B B
for O O
accurate O O
stereo B B
correspondence O O
. O O
as O O
with O O
dynamic O O
programming O I
, O O
belief B B
propagation I I
techniques O O
also O O
become O O
less O O
efﬁcient O O
as O O
the O O
order B B
of O O
each O O
factor O O
clique O O
increases O O
. O O
one O O
of O O
the O O
key O O
advances O O
in O O
this O O
community O O
was O O
the O O
development O O
of O O
bundle B B
adjustment I I
al- O O
gorithms O O
( O O
section O O
7.4 O O
) O O
, O O
which O O
could O O
simultaneously O O
solve O O
for O O
the O O
locations O O
of O O
all O O
of O O
the O O
cam- O O
era O O
positions O O
, O O
thus O O
yielding O O
globally O O
consistent O O
solutions O O
( O O
triggs O O
, O O
mclauchlan O O
, O O
hartley O O
et O O
al O O
. O O
if O O
we O O
want O O
the O O
function O O
f O O
( O O
x O O
) O O
to O O
exactly O O
interpolate O O
the O O
data O O
points O O
, O O
the O O
kernel B B
functions O O
must O O
either O O
be O O
singular O O
at O O
the O O
origin O O
, O O
limr→0 O O
k O O
( O O
r O O
) O O
→ O O
∞ O O
( O O
nielson O O
1993 O O
) O O
, O O
or O O
a O O
dense O O
linear O O
system O O
must O O
be O O
solved O O
to O O
determine O O
the O O
magnitude O O
associated O O
with O O
each O O
basis O O
function O O
( O O
boult O O
and O O
kender O O
1986 O O
) O O
. O O
12.5 O O
volumetric B B
representations O O
. O O
edge-preserving B B
decom- O O
positions O O
for O O
multi-scale O O
tone O B
and O O
detail O O
manipulation O O
. O O
the O O
random O O
selection O O
process O O
is O O
repeated O O
s O O
times O O
and O O
the O O
sample O O
set O O
with O O
the O O
largest O O
number O O
of O O
inliers B B
( O O
or O O
with O O
the O O
smallest O O
median B B
residual O O
) O O
is O O
kept O O
as O O
the O O
ﬁnal O O
solution O O
. O O
“ O O
who O O
are O O
you O O
? O O
” O O
—learning O O
person O O
in O O
ieee O O
computer O O
society O O
conference O O
on O O
computer O O
speciﬁc O O
classiﬁers O O
from O O
video B B
. O O
( O O
2.43 O O
) O O
in O O
particular O O
, O O
if O O
we O O
want O O
to O O
determine O O
a O O
rotation O O
that O O
is O O
partway O O
between O O
two O O
given O O
rota- O O
tions O O
, O O
we O O
can O O
compute O O
the O O
incremental B B
rotation O O
, O O
take O O
a O O
fraction O O
of O O
the O O
angle O O
, O O
and O O
compute O O
the O O
new O O
rotation O O
. O O
this O O
kind O O
of O O
approach O O
is O O
suitable O O
when O O
the O O
images O O
being O O
matched O O
do O O
not O O
undergo O O
large B O
scale I O
changes O O
, O O
e.g. O O
, O O
when O O
matching B B
successive O I
aerial O O
images O O
taken O O
from O O
an O O
airplane O O
or O O
stitching O O
panoramas O O
taken O O
with O O
a O O
ﬁxed-focal-length O O
camera B B
. O O
another O O
example O O
, O O
this O O
time O O
related O O
to O O
face B B
contours O I
, O O
is O O
shown O O
in O O
figure O O
5.5a O O
. O O
handbook O O
of O O
computer O O
vision O O
algorithms O O
in O O
image B B
algebra O O
. O O
these O O
are O O
then O O
used O O
to O O
guide O O
the O O
user O O
drawing O O
axis-aligned O O
planes B B
, O O
which O O
are O O
automatically O O
ﬁtted O O
to O O
the O O
recovered O O
3d O O
point O O
cloud O O
. O O
3.2.1 O O
3.2.2 O O
examples B B
of O O
linear B B
ﬁltering O O
. O O
global B B
illumination I O
( O O
ray O O
tracing O O
and O O
radiosity B B
) O O
the O O
simple O O
shading B B
model O O
presented O O
thus O O
far O O
assumes O O
that O O
light O O
rays O O
leave O O
the O O
light O O
sources O O
, O O
bounce O O
off O O
surfaces O O
visible O O
to O O
the O O
camera B B
, O O
thereby O O
changing O O
in O O
intensity O O
or O O
color B B
, O O
and O O
arrive O O
at O O
the O O
camera B B
. O O
6.2.2 O O
iterative B B
algorithms O O
the O O
most O O
accurate O O
( O O
and O O
ﬂexible O O
) O O
way O O
to O O
estimate O O
pose O O
is O O
to O O
directly O O
minimize O O
the O O
squared O O
( O O
or O O
robust B B
) O O
reprojection O O
error O O
for O O
the O O
2d O O
points B B
as O O
a O O
function O O
of O O
the O O
unknown O O
pose O O
parameters B B
in O O
( O O
r O O
, O O
t O O
) O O
and O O
optionally O O
k O O
using O O
non-linear O O
least B B
squares I I
( O O
tsai O O
1987 O O
; O O
bogart O O
1991 O O
; O O
gleicher O O
and O O
witkin O O
1992 O O
) O O
. O O
non-rigid B B
structure-from-motion O O
: O O
estimating O O
shape O O
and O O
motion B B
with O O
hierarchical B B
priors O O
. O O
self-calibrating O O
cameras O O
in O O
video B B
surveillance O O
. O O
the O O
differences O O
between O O
pairs B B
that O O
are O O
in O O
the O O
same O O
class O O
( O O
the O O
same O O
person O O
) O O
are O O
used O O
to O O
estimate O O
the O O
intrapersonal O O
covariance O O
matrix O O
σi O O
, O O
while O O
differences O O
between O O
different O O
people O O
are O O
used O O
to O O
estimate O O
the O O
extrapersonal O O
covariance O O
σe.12 O O
the O O
principal O O
components O O
( O O
eigenfaces O O
) O O
corresponding O O
to O O
these O O
two O O
classes O O
are O O
shown O O
in O O
figure O O
14.17. O O
at O O
recognition B B
time O O
, O O
we O O
can O O
compute O O
the O O
distance O O
∆i O O
between O O
a O O
new O O
face B B
x O O
and O O
a O O
stored O O
training O O
image B B
xi O O
and O O
evaluate O O
its O O
intrapersonal O O
likelihood O O
as O O
pi O O
( O O
∆i O O
) O O
= O O
pn O O
( O O
∆i O O
; O O
σi O O
) O O
= O O
1 O O
|2πσi|1/2 O O
exp− O O
( O O
cid:107 O O
) O O
∆i O O
( O O
cid:107 O O
) O O
2 O O
σ−1 O O
i O O
, O O
( O O
14.24 O O
) O O
12 O O
note O O
that O O
the O O
difference B B
distributions O O
are O O
zero O O
mean O O
because O O
for O O
every O O
∆ij O O
there O O
corresponds O O
a O O
negative O O
∆ji O O
. O O
the O O
likelihood O O
in O O
one O O
trial O O
that O O
all O O
k O O
random O O
samples O O
are O O
inliers B B
is O O
pk O O
. O O
city-scale O O
location B O
recognition I I
. O O
a O O
burst O O
of O O
activity O O
in O O
using O O
projective O O
invariants O O
for B O
recognition I I
( O O
mundy O O
and O O
zisserman O O
1992 O O
) O O
evolved O O
into O O
a O O
concerted O O
effort O O
to O O
solve O O
the O O
structure B O
from I I
motion I I
problem O O
( O O
see O O
chap- O O
ter O O
7 O O
) O O
. O O
while O O
the O O
above O O
computations O O
can O O
yield O O
the O O
correct O O
( O O
fractional O O
) O O
pixel O O
addresses O O
in O O
each O O
input O O
image B B
, O O
we O O
still O O
need O O
to O O
pay O O
attention O O
to O O
sampling B B
issues O O
. O O
how O O
does O O
this O O
compare O O
to O O
the O O
multi-image O O
technique O O
, O O
and O O
how O O
stable O O
are O O
your O O
estimates O O
from O O
image B B
to O O
image B B
? O O
ex O O
10.3 O O
: O O
vignetting B B
estimate O O
the O O
amount O O
of O O
vignetting B B
in O O
some O O
of O O
your O O
lenses O O
using O O
one O O
of O O
the O O
following O O
three O O
techniques O O
( O O
or O O
devise O O
one O O
of O O
your O O
choosing O O
) O O
: O O
1. O O
take O O
an O O
image B B
of O O
a O O
large O O
uniform O O
intensity O O
region B B
( O O
well-illuminated O O
wall O O
or O O
blue O O
sky— O O
but O O
be O O
careful O O
of O O
brightness O O
gradients O O
) O O
and O O
ﬁt O O
a O O
radial B B
polynomial O O
curve O O
to O O
estimate O O
the O O
vignetting B B
. O O
inferring O O
surface B B
trace O O
and O O
differential O O
structure O O
from O I
3-d O O
images O O
. O O
on O O
in O O
ieee O O
computer O O
society O O
benchmarking O O
camera B B
calibration O O
and O O
multi-view B B
stereo I I
. O O
in O O
their O O
journal O O
paper O O
, O O
sivic O O
and O O
zisserman O O
( O O
2009 O O
) O O
compare O O
this O O
690 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
1. O O
vocabulary O O
construction O O
( O O
off-line O O
) O O
( O O
a O O
) O O
extract O O
afﬁne B B
covariant O O
regions O O
from O O
each O O
database O O
image B B
. O O
how O O
can O O
we O O
map O O
a O O
particular O O
grade O O
to O O
its O O
corresponding O O
percentile O O
, O O
so O O
that O O
students O O
at O O
the O O
75 O O
% O O
percentile O O
range O O
scored O O
better O O
than O O
3/4 O O
of O O
their O O
classmates O O
? O O
the O O
answer O O
is O O
to O O
integrate O O
the O O
distribution O O
h O O
( O O
i O O
) O O
to O O
obtain O O
the O O
cumulative O O
distribution O O
c O O
( O O
i O O
) O O
, O O
c O O
( O O
i O O
) O O
= O O
1 O O
n O O
h O O
( O O
i O O
) O O
= O O
c O O
( O O
i O O
− O O
1 O O
) O O
+ O O
1 O O
n O O
h O O
( O O
i O O
) O O
, O O
( O O
3.9 O O
) O O
i O O
( O O
cid:88 O O
) O O
i=0 O O
where O O
n O O
is O O
the O O
number O O
of O O
pixels O O
in O O
the O O
image B B
or O O
students O O
in O O
the O O
class O O
. O O
image B B
segmentation O O
( O O
see O O
chapter O O
5 O O
) O O
( O O
figure O O
1.9e O O
) O O
, O O
a O O
topic O O
which O O
has O O
been O O
active O O
since O O
the O O
earliest O O
days O O
of O O
computer O O
vision O O
( O O
brice O O
and O O
fennema O O
1970 O O
; O O
horowitz O O
and O O
pavlidis O O
1976 O O
; O O
riseman O O
and O O
arbib O O
1977 O O
; O O
rosenfeld O O
and O O
davis O O
1979 O O
; O O
haralick O O
and O O
shapiro O O
1985 O O
; O O
pavlidis O O
and O O
liow O O
1990 O O
) O O
, O O
was O O
also O O
an O O
active O O
topic O O
of O O
research O O
, O O
producing O O
techniques O O
based O O
on O O
min- O O
imum O O
energy O O
( O O
mumford O O
and O O
shah O O
1989 O O
) O O
and O O
minimum O O
description O O
length O O
( O O
leclerc O O
1989 O O
) O O
, O O
normalized B B
cuts I I
( O O
shi O O
and O O
malik O O
2000 O O
) O O
, O O
and O O
mean B B
shift I I
( O O
comaniciu O O
and O O
meer O O
2002 O O
) O O
. O O
this O O
corresponds O O
roughly O O
to O O
the O O
within-class B O
scatter O O
matrix O O
( O O
14.17 O O
) O O
we O O
studied O O
in O O
section O O
14.2.1. O O
d O O
( O O
x0 O O
, O O
x1 O O
) O O
= O O
( O O
cid:107 O O
) O O
x0 O O
− O O
x1 O O
( O O
cid:107 O O
) O O
σ−1 O O
= O O
( O O
cid:113 O O
) O O
( O O
x0 O O
− O O
x1 O O
) O O
t O O
σ−1 O O
( O O
x0 O O
− O O
x1 O O
) O O
. O O
finally O O
, O O
test O O
the O O
algorithm B B
on O O
real-world O O
data O O
, O O
preferably O O
drawn O O
from O O
a O O
wide O O
variety O O
of O O
sources O O
, O O
such O O
as O O
photos O O
found O O
on O O
the O O
web O O
. O O
( O O
2.61 O O
) O O
this O O
has O O
the O O
advantage O O
that O O
the O O
focal O O
length O O
f O O
and O O
optical O O
center O O
( O O
cx O O
, O O
cy O O
) O O
become O O
independent O O
of O O
the O O
image B B
resolution O O
, O O
which O O
can O O
be O O
useful O O
when O O
using O O
multi-resolution O O
, O O
image-processing O O
algorithms O O
, O O
such O O
as O O
image B B
pyramids O O
( O O
section O O
3.5 O O
) O O
.2 O O
the O O
use O O
of O O
s O O
instead O O
of O O
w O O
also O O
makes O O
the O O
focal O O
length O O
the O O
same O O
for O O
landscape O O
( O O
horizontal O O
) O O
and O O
portrait O O
( O O
vertical O O
) O O
pictures O O
, O O
as O O
is O O
the O O
case O O
in O O
35mm O O
photography O O
. O O
probabilistic B B
aggregation I I
. O O
figure O O
3.13 O O
shows O O
the O O
effects O O
of O O
padding O O
an O O
image B B
with O O
each O O
of O O
the O O
above O O
mechanisms O O
and O O
then O O
blurring O O
the O O
resulting O O
padded O O
image B B
. O O
the O O
basic O O
observation O O
that O O
these O O
linear B B
pnp O O
( O O
perspective B B
n-point O O
) O O
algorithms O O
employ O O
is O O
that O O
the O O
visual O O
angle O O
between O O
any O O
9 O O
because O O
p O O
is O O
unknown O O
up O O
to O O
a O O
scale O O
, O O
we O O
can O O
either O O
ﬁx O O
one O O
of O O
the O O
entries O O
, O O
e.g. O O
, O O
p23 O O
= O O
1 O O
, O O
or O O
ﬁnd O O
the O O
smallest O O
singular O O
vector O O
of O O
the O O
set O O
of O O
linear B B
equations O O
. O O
criminisi O O
, O O
p´erez O O
, O O
and O O
toyama O O
( O O
2004 O O
) O O
use O O
exemplar-based O O
texture B B
synthesis O O
where O O
the O O
order B B
of O O
synthesis O O
is O O
determined O O
by O O
the O O
strength O O
of O O
the O O
gradient O O
along O O
the O O
region B B
boundary O O
( O O
figures O O
10.1d O O
and O O
10.52c–d O O
) O O
. O O
in O O
fact O O
, O O
in O O
the O O
absence O O
of O O
any O O
prior B B
model O O
for O O
x O O
( O O
appendix O O
b.4 O O
) O O
, O O
we O O
have O O
l O O
= O O
p O O
( O O
y|x O O
) O O
= O O
p O O
( O O
y O O
, O O
x O O
) O O
= O O
p O O
( O O
x|y O O
) O O
. O O
1. O O
take O O
a O O
still O O
or O O
video B B
sequence O O
of O O
images O O
with O O
and O O
without O O
some O O
intermittent O O
smoke B B
and O O
shadows O O
. O O
the O O
eigenvalues B B
and O O
eigenvectors O O
of O O
c O O
and O O
the O O
singular O O
values O O
and O O
singular O O
vectors O O
of O O
a O O
are O O
closely O O
related O O
. O O
note O O
that O O
if O O
the O O
two O O
images O O
have O O
very O O
different O O
exposures O O
, O O
which O O
can O O
happen O O
when O O
performing O O
view B O
interpolation I I
on O O
real O O
images O O
, O O
the O O
hole-ﬁlled O O
regions O O
and O O
the O O
blended O O
regions O O
will O O
have O O
different O O
exposures O O
, O O
leading O O
13.1 O O
view B O
interpolation I I
to O O
subtle O O
artifacts O O
. O O
( O O
b O O
) O O
the O O
relative O O
positions O O
of O O
each O O
feature B B
can O O
be O O
detected O O
at O O
recognition B B
time O O
, O O
thus O O
allowing O O
for O O
more O O
ﬂexibility O O
in O O
viewpoint O O
and O O
expression O O
. O O
6.1.1 O O
6.1.2 O O
application O O
: O O
panography B B
. O O
the O O
classic O O
ﬁve O O
seidel O O
aberrations O O
, O O
which O O
arise O O
when O O
using O O
third-order O O
optics B B
, O O
include O O
spherical B B
aberration O O
, O O
coma O O
, O O
astigmatism O O
, O O
curvature O O
of O O
ﬁeld O O
, O O
and O O
distortion O O
( O O
m¨oller O O
1988 O O
; O O
hecht O O
2001 O O
; O O
ray O O
2002 O O
) O O
. O O
in O O
ieee O O
com- O O
puter O O
society O O
conference O O
on O O
computer O O
vision O O
and O O
pattern O O
recognition B B
( O O
cvpr O O
’ O O
2006 O O
) O O
, O O
pp O O
. O O
variable O O
base- O O
line/resolution O O
stereo B B
. O O
as O O
we O O
saw O O
in O O
our O O
discussion O O
of O O
plane B O
sweep I O
( O O
section O O
11.1.2 O O
) O O
, O O
it O O
is O O
possible O O
to O O
resample O O
all O O
neighboring O O
k O O
images O O
at O O
each O O
disparity O O
hypothesis O O
d O O
into O O
a O O
generalized B B
disparity O O
space O O
volume O O
˜i O O
( O O
x O O
, O O
y O O
, O O
d O O
, O O
k O O
) O O
. O O
5.3 O O
mean B B
shift I I
and O O
mode O O
ﬁnding O O
291 O O
based O O
on O O
their O O
statistics O O
, O O
and O O
for O O
accelerating O O
the O O
process O O
of O O
ﬁnding O O
the O O
nearest O B
mean O I
center O O
( O O
bishop O O
2006 O O
) O O
. O O
in O O
fact O O
, O O
if O O
the O O
object O O
is O O
totally O O
diffuse B B
, O O
ignoring O O
occlusions O O
, O O
which O O
can O O
be O O
handled O O
using O O
3d O O
graphics O O
algorithms O O
or O O
z-buffering O O
, O O
all O O
rays O O
passing O O
through O O
a O O
given O O
surface B B
point O O
will O O
have O O
the O O
same O O
color B B
value O O
. O O
light B O
ﬁeld I O
mi- O O
levoy O O
, O O
m. O O
, O O
pulli O O
, O O
k. O O
, O O
curless O O
, O O
b. O O
, O O
rusinkiewicz O O
, O O
s. O O
, O O
koller O O
, O O
d. O O
et O O
al O O
. O O
figure O O
8.6b O O
shows O O
the O O
temporal O O
evolution B B
of O O
the O O
basis O O
coefﬁcients O O
as O O
well O O
as O O
a O O
few O O
of O O
the O O
recovered O O
parametric B B
motion O O
ﬁelds O O
. O O
some O O
approaches O O
to O O
location B O
recognition I O
assume O O
that O O
the O O
photos O O
consist O O
of O O
architectural O O
scenes O O
for O O
which O O
vanishing O B
directions O O
can O O
be O O
used O O
to O O
pre-rectify O O
the O O
images O O
for O O
easier O O
match- O O
ing O O
( O O
robertson O O
and O O
cipolla O O
2004 O O
) O O
. O O
interactively O O
modify O O
the O O
object O O
or O O
camera B B
transform O O
. O O
for O O
your O O
data O O
, O O
you O O
can O O
use O O
synthetic O O
ray O O
tracing O O
, O O
a O O
layered B B
reconstructed O O
model O O
, O O
or O O
a O O
volumetric B B
reconstruction O O
. O O
their O O
paper O O
also O O
contains O O
extensive O O
references B B
to O O
previ- O O
ous O O
work O O
in O O
these O O
areas O O
. O O
once O O
an O O
initial O O
pair O O
has O O
been O O
reconstructed O O
, O O
the O O
pose O O
of O O
cameras O O
that O O
see O O
a O O
sufﬁcient O O
num- O O
ber O O
of O O
the O O
resulting O O
3d O O
points B B
can O O
be O O
estimated O O
( O O
section O O
6.2 O O
) O O
and O O
the O O
complete O O
set O O
of O O
cameras O O
and O O
feature B B
correspondences O O
can O O
be O O
used O O
to O O
perform O O
another O O
round O O
of O O
bundle B B
adjustment I I
. O O
23 O O
in O O
numerical O O
analysis O O
, O O
a O O
is O O
called O O
the O O
coefﬁcient O O
matrix O O
( O O
saad O O
2003 O O
) O O
; O O
in O O
ﬁnite O O
element O O
analysis O O
( O O
bathe O O
2007 O O
) O O
, O O
it O O
is O O
called O O
the O O
stiffness B O
matrix I O
. O O
the O O
plane B O
sweep I I
algorithm O O
was O O
ﬁrst O O
popular- O O
ized O O
by O O
collins O O
( O O
1996 O O
) O O
and O O
then O O
generalized B O
to O O
a O O
full O O
arbitrary O O
projective B B
setting O O
by O O
szeliski O O
and O O
golland O O
( O O
1999 O O
) O O
and O O
saito O O
and O O
kanade O O
( O O
1999 O O
) O O
. O O
there O O
are O O
also O O
several O O
courses O O
on O O
computational O O
photography O O
where O O
the O O
instructors O O
have O O
provided O O
extensive O O
on-line O O
materials O O
, O O
e.g. O O
, O O
fr´edo O O
durand O O
’ O O
s O O
computation O O
photography O O
course O O
at O O
mit,3 O O
alyosha O O
efros O O
’ O O
class O O
at O O
carnegie O O
mellon,4 O O
marc O O
levoy O O
’ O O
s O O
class O O
at O O
stanford,5 O O
and O O
a O O
series O O
of O O
siggraph O O
courses O O
on O O
computational O O
photography.6 O O
10.1 O O
photometric B B
calibration O O
before O O
we O O
can O O
successfully O O
merge O O
multiple B B
photographs O O
, O O
we O O
need O O
to O O
characterize O O
the O O
func- O O
tions O O
that O O
map O O
incoming O O
irradiance O O
into O O
pixel O O
values O O
and O O
also O O
the O O
amounts O O
of O O
noise B B
present O O
in O O
each O O
image B B
. O O
the O O
key O O
to O O
their O O
approach O O
is O O
to O O
use O O
the O O
pl¨ucker O O
coor- O O
dinates O O
( O O
2.12 O O
) O O
to O O
parameterize O O
lines B O
and O O
to O O
directly O O
minimize O O
reprojection O O
errors O O
. O O
on O O
3d O O
scene O O
ﬂow O O
and O O
structure O O
recovery O B
from O I
ieee O O
transactions O O
on O O
systems O O
, O O
man O O
, O O
and O O
cybernetics O O
, O O
multiview O O
image B B
sequences O O
. O O
spectral O O
segmentation B B
with O O
multiscale O O
graph O B
decomposition O O
. O O
bias B O
and I O
gain I I
, O O
weighting B B
, O O
and O O
robust B B
error O O
metrics O O
. O O
vision O O
and O O
pattern O O
recognition B B
( O O
cvpr O O
2009 O O
) O O
, O O
miami O O
, O O
fl O O
. O O
10.3.2 O O
application O O
: O O
colorization B B
. O O
) O O
2. O O
compute O O
your O O
in-between O O
camera B O
positions O O
and O O
orientations O O
. O O
what O O
happens O O
if O O
the O O
glass O O
is O O
tinted O O
, O O
especially O O
to O O
a O O
non-gray O O
hue B B
? O O
how O O
about O O
if O O
the O O
glass O O
is O O
dirty O O
or O O
smudged O O
? O O
how O O
could O O
you O O
model O O
wavy O O
glass O O
or O O
other O O
kinds O O
of O O
refractive O O
objects O O
? O O
ex O O
3.3 O O
: O O
blue B B
screen I I
matting O B
set O O
up O O
a O O
blue O O
or O O
green O O
background O O
, O O
e.g. O O
, O O
by O O
buying O O
a O O
large O O
piece O O
of O O
colored O O
posterboard O O
. O O
symmetry-seeking B O
models O O
and O O
3d O O
object O O
reconstruction O O
. O O
a O O
variational O O
method O O
for O O
scene O O
ﬂow O O
estimation B O
from O O
in O O
eleventh O O
international O O
conference O O
on O O
computer O O
vision O O
( O O
iccv O O
stereo B O
sequences O O
. O O
in O O
advances O O
in O O
neural O O
informa- O O
tion B B
processing O O
systems O O
. O O
( O O
imagine O O
how O O
the O O
3d O O
points B B
need O O
to O O
“ O O
shift O O
” O O
each O O
time O O
some O O
rotation O O
matrices O O
are O O
updated O O
. O O
while O O
the O O
2d O O
optimization O O
of O O
equation B B
( O O
11.8 O O
) O O
can O O
be O O
shown O O
to O O
be O O
np-hard O O
for O O
common O O
classes O O
of O O
smoothness B B
functions O O
( O O
veksler O O
1999 O O
) O O
, O O
dynamic B B
programming I I
can O O
ﬁnd O O
the O O
global B B
mini- O O
mum O O
for O O
independent O O
scanlines O O
in O O
polynomial O O
time O O
. O O
a O O
good O O
way O O
to O O
determine O O
if O O
the O O
calibration B B
has O O
been O O
successfully O O
performed O O
is O O
to O O
estimate O O
the O O
covariance O O
in O O
the O O
param- O O
eters O O
( O O
section O O
6.1.4 O O
) O O
and O O
then O O
project O O
3d O O
points B B
from O O
various O O
points B B
in O O
the O O
workspace O O
into O O
the O O
image B B
in O O
order B B
to O O
estimate O O
their O O
2d O O
positional O O
uncertainty B B
. O O
while O O
these O O
early O O
approaches O O
used O O
afﬁne B B
motion O O
models O O
and O O
were O O
therefore O O
restricted B B
to O O
long O O
focal O O
lengths O O
, O O
the O O
techniques O O
were O O
generalized B O
by O O
lee O O
, O O
ge O O
chen O O
, O O
lung O O
bruce O O
lin O O
et O O
al O O
. O O
note O O
that O O
the O O
reﬂected O O
layers B B
in O O
( O O
c O O
) O O
and O O
( O O
e O O
) O O
are O O
doubled O O
in O O
intensity O O
to O O
better O O
show O O
their O O
structure O O
. O O
4. O O
compare O O
your O O
results O O
against O O
those O O
presented O O
by O O
chakrabarti O O
, O O
scharstein O O
, O O
and O O
zickler O O
( O O
2009 O O
) O O
or O O
use O O
the O O
data O O
available O O
in O O
their O O
database O O
of O O
color B B
images.26 O O
26 O O
http O O
: O O
//vision.middlebury.edu/color/ O O
. O O
multi-perspective O O
images O O
( O O
rademacher O O
and O O
bishop O O
1998 O O
) O O
and O O
manifold O O
projections B O
( O O
peleg O O
and O O
herman O O
1997 O O
) O O
, O O
although O O
not O O
true O O
light O O
ﬁelds O O
, O O
are O O
also O O
closely O O
related O O
to O O
these O O
ideas O O
. O O
in O O
computer O O
vision O O
, O O
splines B B
are O O
often O O
used O O
for O O
elastic O O
image B B
deformations O O
( O O
section O O
3.6.2 O O
) O O
, O O
motion B B
estimation I I
( O O
section O O
8.3 O O
) O O
, O O
and O O
surface B B
interpolation O O
( O O
section O O
12.3 O O
) O O
. O O
the O O
actual O O
pixel O O
values O O
for O O
the O O
copied O O
area O O
are O O
then O O
computed O O
by O O
solving O O
a O O
poisson O O
equation B B
that O O
locally O O
matches O O
the O O
gradients O O
while O O
obeying O O
the O O
ﬁxed O O
dirichlet O O
( O O
exact O O
matching B B
) O O
conditions O O
at O O
the O O
seam O O
bound- O O
ary O O
. O O
236 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
figure O O
4.28 O O
feature B B
tracking O O
using O O
an O O
afﬁne B B
motion O O
model O O
( O O
shi O O
and O O
tomasi O O
1994 O O
) O O
c O O
( O O
cid:13 O O
) O O
1994 O O
ieee O O
, O O
top O O
row O O
: O O
image B B
patch O O
around O O
the O O
tracked O O
feature B B
location O O
. O O
in O O
addition O O
, O O
it O O
is O O
common O O
to O O
add O O
a O O
stage O O
for O O
radial O O
distortion O O
parameter O O
estimation B B
( O O
2.78 O O
) O O
, O O
f O O
rd O O
( O O
x O O
) O O
= O O
( O O
1 O O
+ O O
κ1r2 O O
+ O O
κ2r4 O O
) O O
x O O
, O O
( O O
7.50 O O
) O O
if O O
the O O
cameras O O
being O O
used O O
have O O
not O O
been O O
pre-calibrated O O
, O O
as O O
shown O O
in O O
figure O O
7.7 O O
. O O
determining O O
optical B O
ﬂow I I
. O O
exercise O O
8.7 O O
lists O O
some O O
of O O
the O O
steps O O
required O O
, O O
which O O
include O O
the O O
ability O O
to O O
determine O O
if O O
the O O
8.5 O O
layered B B
motion O O
415 O O
current O O
motion B B
estimate O O
is O O
accurate O O
enough O O
to O O
permit O O
averaging O O
with O O
other O O
frames O O
. O O
figure O O
12.4 O O
shows O O
an O O
example O O
of O O
a O O
real-time O O
depth O O
from O O
defocus O O
sensor B B
, O O
which O O
employs O O
two O O
imaging O O
chips O O
at O O
slightly O O
different O O
depths O O
sharing O O
a O O
common O O
optical O O
path O O
, O O
as O O
well O O
as O O
an O O
active B B
illumination I I
system O O
that O O
projects O O
a O O
checkerboard O O
pattern O O
from O O
the O O
same O O
direction O O
. O O
( O O
2008 O O
) O O
develop O O
such O O
a O O
model O O
, O O
which O O
can O O
be O O
thought O O
of O O
as O O
a O O
two-level O O
constellation B O
model I O
. O O
markerless O O
tracking O O
of O O
complex O O
human O O
motions O O
from O O
multiple B B
views O O
. O O
intelligent B O
scissors I O
for O O
image B O
composition O O
. O O
fourier O O
transform B B
pairs O O
. O O
exploiting O O
the O O
sparse B B
derivative O I
prior B B
for O O
super-resolution O O
and O O
image B B
demosaicing O O
. O O
dur- O O
ing O O
synthesis O O
, O O
image B B
morphing O O
techniques O O
are O O
used O O
to O O
blend O O
and O O
stitch O O
adjacent O O
mouth O O
shapes O O
into O O
a O O
more O O
coherent O O
whole O O
. O O
demetri O O
terzopoulos O O
was O O
my O O
mentor O O
at O O
my O O
ﬁrst O O
industrial B B
research O O
job O O
and O O
taught O O
me O O
the O O
ropes O O
of O O
successful O O
publishing O O
. O O
an O O
alternative O O
to O O
directly O O
matching B B
gray-level O O
images O O
or O O
patches O O
is O O
to O O
use O O
non-linear B B
local O O
transforms O O
such O O
as O O
local O B
binary O O
patterns O O
( O O
ahonen O O
, O O
hadid O O
, O O
and O O
pietik¨ainen O O
2006 O O
; O O
zhao O O
and O O
pietik¨ainen O O
2007 O O
; O O
cao O O
, O O
yin O O
, O O
tang O O
et O O
al O O
. O O
p O O
( O O
j O O
) O O
px1x0r0c0c1r1v0v1d0d1q0^^q1 O O
7.2 O O
two-frame B B
structure O O
from O O
motion B B
347 O O
we O O
use O O
homogeneous B O
coordinates I O
p O O
= O O
( O O
x O O
, O O
y O O
, O O
z O O
, O O
w O O
) O O
, O O
the O O
resulting O O
set O O
of O O
equations B B
is O O
homo- O O
geneous O O
and O O
is O O
best O O
solved O O
as O O
a O O
singular O O
value O O
decomposition O O
( O O
svd O O
) O O
or O O
eigenvalue O O
problem O O
( O O
looking O O
for O O
the O O
smallest O O
singular O O
vector O O
or O O
eigenvector O O
) O O
. O O
the O O
concept O O
of O O
the O O
disparity O O
space O O
( O O
x O O
, O O
y O O
, O O
d O O
) O O
dates O O
back O O
to O O
early O O
work O O
in O O
stereo B B
matching I I
( O O
marr O O
and O O
poggio O O
1976 O O
) O O
, O O
while O O
the O O
concept O O
of O O
a O O
disparity O O
space O O
image O O
( O O
volume O O
) O O
is O O
generally O O
associated O O
with O O
yang O O
, O O
yuille O O
, O O
and O O
lu O O
( O O
1993 O O
) O O
and O O
intille O O
and O O
bobick O O
( O O
1994 O O
) O O
. O O
478 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
( O O
a O O
) O O
( O O
b O O
) O O
( O O
c O O
) O O
figure O O
10.8 O O
point B O
spread I O
function I O
estimation O B
using O O
a O O
calibration B B
target O O
( O O
joshi O O
, O O
szeliski O O
, O O
and O O
kriegman O O
2008 O O
) O O
c O O
( O O
cid:13 O O
) O O
2008 O O
ieee O O
. O O
2000 O O
; O O
matusik O O
, O O
buehler O O
, O O
and O O
mcmillan O O
2001 O O
) O O
, O O
and O O
free-viewpoint O O
video B B
( O O
carranza O O
, O O
theobalt O O
, O O
magnor O O
et O O
al O O
. O O
( O O
2001 O O
) O O
look O O
for O O
intervening O O
contours O O
between O O
pixels O O
i O O
and O O
j O O
and O O
deﬁne O O
an O O
intervening B O
contour I O
weight O O
ij O O
= O O
1 O O
− O O
max O O
wic O O
x∈lij O O
pcon O O
( O O
x O O
) O O
, O O
( O O
5.49 O O
) O O
where O O
lij O O
is O O
the O O
image B B
line O O
joining O O
pixels O O
i O O
and O O
j O O
and O O
pcon O O
( O O
x O O
) O O
is O O
the O O
probability O O
of O O
an O O
inter- O O
vening O O
contour O O
perpendicular O O
to O O
this O O
line O O
, O O
which O O
is O O
deﬁned O O
as O O
the O O
negative O O
exponential O O
of O O
the O O
oriented B B
energy O O
in O O
the O O
perpendicular O O
direction O O
. O O
in O O
practice O O
, O O
only O O
the O O
location O O
of O O
the O O
front O O
nodal B B
point I O
is O O
of O O
interest O O
when O O
performing O O
careful O O
camera B O
calibration O O
, O O
e.g. O O
, O O
when O O
determining O O
the O O
point O O
around O O
which O O
to O O
rotate O O
to O O
capture O O
a O O
parallax-free O O
panorama O O
( O O
see O O
section O O
9.1.3 O O
) O O
. O O
5.2 O O
split O O
and O O
merge O O
as O O
mentioned O O
in O O
the O O
introduction O O
to O O
this O O
chapter O O
, O O
the O O
simplest O O
possible O O
technique O O
for O O
seg- O O
menting O O
a O O
grayscale O O
image B B
is O O
to O O
select O O
a O O
threshold O O
and O O
then O O
compute O O
connected B B
components I I
( O O
section O O
3.3.2 O O
) O O
. O O
for O O
more O O
ﬂexible O O
surface B B
modeling O O
, O O
we O O
can O O
either O O
rep- O O
resent O O
the O O
surface B B
as O O
a O O
collection O O
of O O
oriented B B
points O O
( O O
section O O
12.4 O O
) O O
or O O
use O O
3d O O
implicit O O
functions O O
( O O
section O O
12.5.1 O O
) O O
, O O
which O O
can O O
also O O
be O O
combined O O
with O O
elastic O O
3d O O
surface B B
models O O
( O O
mcinerney O O
and O O
terzopoulos O O
1993 O O
) O O
. O O
ieee O O
transactions O O
on O O
image B B
processing O O
, O O
15 O O
( O O
5 O O
) O O
:1120–1129 O O
. O O
conditional O O
random O O
ﬁelds O O
in O O
a O O
classic O O
bayesian O O
model O O
( O O
3.106–3.108 O O
) O O
, O O
p O O
( O O
x|y O O
) O O
∝ O O
p O O
( O O
y|x O O
) O O
p O O
( O O
x O O
) O O
, O O
( O O
3.117 O O
) O O
the O O
prior B B
distribution I O
p O O
( O O
x O O
) O O
is O O
independent O O
of O O
the O O
observations O O
y. O O
sometimes O O
, O O
however O O
, O O
it O O
is O O
useful O O
to O O
modify O O
our O O
prior B B
assumptions O O
, O O
say O O
about O O
the O O
smoothness B B
of O O
the O O
ﬁeld O O
we O O
are O O
trying O O
to O O
estimate O O
, O O
in O O
response O O
to O O
the O O
sensed O O
data O O
. O O
additive O O
logistic O O
regression O O
: O O
a O O
statistical O O
view O O
of O O
boosting B B
. O O
through O O
what O O
process O O
is O O
it O O
possible O O
for O O
two O O
different O O
colors O O
, O O
such O O
as O O
red O O
and O O
green O O
, O O
to O O
interact O O
to O O
produce O O
a O O
third O O
color B B
like O O
yellow O O
? O O
are O O
the O O
wavelengths O O
somehow O O
mixed O O
up O O
to O O
produce O O
a O O
new O O
wavelength O O
? O O
you O O
probably O O
know O O
that O O
the O O
correct O O
answer O O
has O O
nothing O O
to O O
do O O
with O O
physically O O
mixing O O
wavelengths O O
. O O
the O O
distinctiveness O O
, O O
detectability O O
, O O
and O O
robustness O O
of O O
local B B
image O O
features O O
. O O
an O O
alternative O O
approach O O
is O O
to O O
estimate O O
local B B
color O O
statistics O O
in O O
regions O O
around O O
each O O
pixel O O
( O O
ruzon O O
and O O
tomasi O O
2001 O O
; O O
martin O O
, O O
fowlkes O O
, O O
and O O
malik O O
2004 O O
) O O
. O O
some O O
of O O
the O O
early O O
work O O
in O O
this O O
area O O
handles O O
transparent B B
motion O O
by O O
either O O
just O O
estimating O O
the O O
component O O
motions O O
( O O
shizawa O O
and O O
mase O O
1991 O O
; O O
bergen O O
, O O
burt O O
, O O
hingorani O O
et O O
al O O
. O O
for O O
every O O
destina- O O
tion B B
pixel O O
x O O
( O O
cid:48 O O
) O O
, O O
the O O
ellipsoidal O O
projection O O
of O O
a O O
small O O
pixel O O
grid O O
in O O
x O O
( O O
cid:48 O O
) O O
onto O O
x O O
is O O
computed O O
( O O
fig- O O
ure O O
3.48b O O
) O O
. O O
1992 O O
; O O
girod O O
, O O
greiner O O
, O O
and O O
niemann O O
2000 O O
) O O
, O O
x O O
( O O
cid:48 O O
) O O
= O O
a0 O O
+ O O
a1x O O
+ O O
a2y O O
+ O O
a6x2 O O
+ O O
a7xy O O
y O O
( O O
cid:48 O O
) O O
= O O
a3 O O
+ O O
a4x O O
+ O O
a5y O O
+ O O
a7x2 O O
+ O O
a6xy O O
, O O
arises O O
when O O
a O O
planar O O
surface O O
undergoes O O
a O O
small O O
3d O O
motion B B
. O O
( O O
eds O O
) O O
, O O
bayesian O O
inference B B
in O O
wavelet O O
based O O
models O O
, O O
pp O O
. O O
( O O
2007 O O
) O O
present O O
a O O
nice O O
review O O
of O O
segmentation B B
using O O
mixtures O O
of O O
gaussians O O
and O O
develop O O
their O O
own O O
extension O O
based O O
on O O
minimum O O
description O O
length O O
( O O
mdl O O
) O O
coding O O
, O O
which O O
they O O
show O O
produces O O
good O O
results O O
on O O
the O O
berkeley O O
segmentation B B
database O O
. O O
3. O O
determine O O
a O O
back-to-front O O
order B B
based O O
on O O
expected O O
visibility B O
or O O
add O O
a O O
z-buffer O O
to O O
your O O
rendering B B
algorithm O O
to O O
handle O O
occlusions O O
. O O
figure O O
3.29 O O
shows O O
the O O
a O O
= O O
−1 O O
and O O
a O O
= O O
−0.5 O O
cubic B O
interpolating O O
kernel B B
along O O
with O O
their O O
fourier O O
transforms O O
; O O
figure O O
3.28b O O
and O O
c O O
shows O O
them O O
being O O
applied O O
to O O
two-dimensional B B
interpolation O I
. O O
all O O
of O O
these O O
properties B B
are O O
relatively O O
straightforward O O
to O O
prove O O
( O O
see O O
exercise O O
3.15 O B
) O O
and O O
they O O
will O O
come O O
in O O
handy O O
later O O
in O O
the O O
book O O
, O O
e.g. O O
, O O
when O O
designing O O
optimum O O
wiener O O
ﬁlters O O
( O O
section O O
3.4.3 O O
) O O
or O O
performing O O
fast O O
image O O
correlations O O
( O O
section O O
8.1.2 O O
) O O
. O O
6.3.5 O O
radial B B
distortion I I
. O O
3d O O
facial B O
animation I O
is O O
often O O
matched O O
to O O
the O O
performance O O
of O O
an O O
actor O O
, O O
in O O
what O O
is O O
known O O
as O O
performance-driven B B
animation I O
( O O
section O O
4.1.5 O O
) O O
( O O
williams O O
1990 O O
) O O
. O O
as O O
the O O
shadow B B
falls O O
across O O
two O O
background O O
planes B B
whose O O
orientation O O
relative O O
to O O
the O O
cam- O O
era O O
is O O
known O O
( O O
or O O
inferred O O
during O O
pre-calibration O O
) O O
, O O
the O O
plane O O
equation O O
for O O
each O O
stripe O O
can O O
be O O
inferred O O
from O O
the O O
two O O
projected O O
lines B B
, O O
whose O O
3d O O
equations B B
are O O
known O O
( O O
figure O O
12.6b O O
) O O
. O O
( O O
a O O
more O O
detailed O O
analysis O O
using O O
a O O
more O O
realistic O O
model O O
of O O
image B B
noise O O
is O O
given O O
by O O
steele O O
and O O
jaynes O O
( O O
2005 O O
) O O
. O O
learning B B
a O O
sparse B B
representation O O
for O O
object O O
detection B B
. O O
one O O
way O O
around O O
this O O
is O O
to O O
use O O
stochastic B O
gradient I I
descent I I
or O O
markov O O
chain O O
monte O O
carlo O O
( O O
mcmc O O
) O O
( O O
metropolis O O
, O O
rosenbluth O O
, O O
rosen- O O
bluth O O
et O O
al O O
. O O
the O O
book O O
begins O O
in O O
chapter O O
2 O O
with O O
a O O
review O O
of O O
the O O
image B B
formation O O
processes O O
that O O
create O O
the O O
images O O
that O O
we O O
see O O
and O O
capture O O
. O O
2006 O O
) O O
, O O
and O O
video B B
compression I I
( O O
irani O O
, O O
hsu O O
, O O
and O O
anandan O O
1995 O O
; O O
lee O O
, O O
ge O O
chen O O
, O O
lung O O
bruce O O
lin O O
et O O
al O O
. O O
3.2.1 O O
separable B O
ﬁltering O O
the O O
process O O
of O O
performing O O
a O O
convolution O O
requires O O
k O O
2 O O
( O O
multiply-add O O
) O O
operations O O
per O O
pixel O O
, O O
where O O
k O O
is O O
the O O
size O O
( O O
width O O
or O O
height O O
) O O
of O O
the O O
convolution O O
kernel B B
, O O
e.g. O O
, O O
the O O
box O O
ﬁlter O O
in O O
fig- O O
116 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
1 O O
k2 O O
1 O O
1 O O
... O O
1 O O
1 O O
1 O O
... O O
1 O O
··· O O
··· O O
1 O O
··· O O
1 O O
1 O O
... O O
1 O O
1 O O
16 O O
1 O O
2 O O
1 O O
2 O O
4 O O
2 O O
1 O O
2 O O
1 O O
1 O O
256 O O
4 O O
6 O O
4 O O
1 O O
1 O O
4 O O
16 O O
24 O O
16 O O
4 O O
6 O O
24 O O
36 O O
24 O O
6 O O
4 O O
16 O O
24 O O
16 O O
4 O O
1 O O
1 O O
4 O O
6 O O
4 O O
1 O O
8 O O
−1 O O
0 O O
1 O O
−2 O O
0 O O
2 O O
−1 O O
0 O O
1 O O
1 O O
4 O O
1 O O
−2 O O
−2 O O
1 O O
−2 O O
1 O O
4 O O
−2 O O
1 O O
1 O O
k O O
1 O O
1 O O
··· O O
1 O O
1 O O
4 O O
1 O O
2 O O
1 O O
1 O O
16 O O
1 O O
4 O O
6 O O
4 O O
1 O O
1 O O
2 O O
−1 O O
0 O O
1 O O
1 O O
2 O O
1 O O
−2 O O
1 O O
( O O
a O O
) O O
box O O
, O O
k O O
= O O
5 O O
( O O
b O O
) O O
bilinear B B
( O O
c O O
) O O
“ O O
gaussian O O
” O O
( O O
d O O
) O O
sobel O O
( O O
e O O
) O O
corner O O
figure O O
3.14 O O
separable B B
linear O O
ﬁlters O O
: O O
for O O
each O O
image B B
( O O
a O O
) O O
– O O
( O O
e O O
) O O
, O O
we O O
show O O
the O O
2d O O
ﬁlter O O
kernel B B
( O O
top O O
) O O
, O O
the O O
corresponding O O
horizontal O O
1d O O
kernel B O
( O O
middle O O
) O O
, O O
and O O
the O O
ﬁltered O O
image B B
( O O
bottom O O
) O O
. O O
in O O
image B B
understanding O O
workshop O O
, O O
pp O O
. O O
by O O
replacing O O
the O O
rightmost O O
two O O
transformations O O
in O O
figure O O
7.7 O O
with O O
the O O
transformations O O
shown O O
in O O
figure O O
7.8b O O
, O O
we O O
can O O
simultaneously O O
recover O O
the O O
position O O
of O O
the O O
robot O O
at O O
each O O
time O O
and O O
the O O
calibration B B
of O O
each O O
camera B B
with O O
respect O O
to O O
the O O
rig O O
, O O
in O O
addition O O
to O O
the O O
3d O O
structure O O
of O O
the O O
world O O
. O O
( O O
in O O
fact O O
, O O
it O O
can O O
interpolate O O
the O O
motion B B
of O O
any O O
four O O
non-collinear O O
points B B
. O O
this O O
calibration B B
will O O
be O O
useful O O
in O O
a O O
number O O
of O O
different O O
applications O O
, O O
such O O
as O O
stitching O O
images O O
or O O
stereo B B
matching I I
with O O
different O O
exposures O O
and O O
shape O O
from O O
shading B B
. O O
( O O
2008 O O
) O O
show O O
how O O
accurately O O
locating O O
facial O O
features O O
using O O
an O O
active O O
shape O O
model O O
( O O
cootes O O
, O O
edwards O O
, O O
and O O
taylor O O
2001 O O
; O O
zhou O O
, O O
gu O O
, O O
and O O
zhang O O
2003 O O
) O O
can O O
be O O
used O O
to O O
warp O O
such O O
features O O
( O O
and O O
hence O O
the O O
image B B
) O O
towards O O
conﬁgurations O O
resembling O B
those O O
found O O
in O O
images O O
whose O O
facial O O
attractiveness O O
was O O
highly O O
rated O O
, O O
thereby O O
“ O O
beautifying O O
” O O
the O O
image B B
without O O
completely O O
losing O O
a O O
person O O
’ O O
s O O
identity O O
. O O
chapter O O
6 O O
: O O
feature-based B B
alignment O O
and O O
calibration B B
non-iterative O O
pnp O O
algorithm B B
, O O
http O O
: O O
//cvlab.epﬂ.ch/software/epnp/ O O
( O O
moreno-noguer O O
, O O
lep- O O
etit O O
, O O
and O O
fua O O
2007 O O
) O O
. O O
13 O O
in O O
computer O O
games O O
, O O
restricting O O
a O O
player O O
to O O
forward B B
and O O
backward O O
motion B B
along O O
predetermined O O
paths O O
is O O
called O O
rail-based O O
gaming O O
. O O
the O O
second O O
major O O
problem O O
with O O
forward O O
warping O O
is O O
the O O
appearance O O
of O O
cracks O O
and O O
holes O O
, O O
especially O O
when O O
magnifying O O
an O O
image B B
. O O
an O O
accurately O O
calibrated O O
light O O
at O O
the O O
top O O
controls O O
the O O
amount O O
of O O
radiance O O
inside O O
the O O
sphere O O
( O O
which O O
is O O
constant O O
everywhere O O
because O O
of O O
the O O
sphere O O
’ O O
s O O
radiometry O O
) O O
and O O
a O O
small O O
opening B O
at O O
the O O
side O O
allows O O
for O O
a O O
camera/lens O O
combination O O
to O O
be O O
mounted O O
. O O
poisson O O
matting B B
( O O
sun O O
, O O
jia O O
, O O
tang O O
et O O
al O O
. O O
splines B B
are O O
widely O O
used O O
in O O
geometric B B
modeling O O
and O O
computer-aided O O
design O O
( O O
cad O O
) O O
applications O O
, O O
although O O
they O O
have O O
14 O O
the O O
term O O
“ O O
spline B B
” O O
comes O O
from O O
the O O
draughtsman O O
’ O O
s O O
workshop O O
, O O
where O O
it O O
was O O
the O O
name O O
of O O
a O O
ﬂexible O O
piece O O
of O O
wood O O
or O O
metal O O
used O O
to O O
draw O O
smooth O O
curves O O
. O O
some O O
commonly O O
used O O
spline B B
basis O O
functions O O
are O O
shown O O
in O O
figure O O
8.8. O O
substituting O O
the O O
formula O O
for O O
the O O
individual O O
per-pixel O O
ﬂow O O
vectors O O
ui O O
( O O
8.68 O O
) O O
into O O
the O O
ssd O O
error O O
metric O O
( O O
8.67 O O
) O O
yields O O
a O O
parametric B B
motion O O
formula O O
similar O O
to O O
equation B B
( O O
8.50 O O
) O O
. O O
14.3.2 O O
large O O
databases O O
as O O
the O O
number O O
of O O
objects O O
in O O
the O O
database O O
starts O O
to O O
grow O O
large O O
( O O
say O O
, O O
millions O O
of O O
objects O O
or O O
video B B
frames O O
being O O
searched O O
) O O
, O O
the O O
time O O
it O O
takes O O
to O O
match O O
a O O
new O O
image B B
against O O
each O O
database O O
image B B
can O O
become O O
prohibitive O O
. O O
( O O
one O O
variant O O
is O O
to O O
show O O
the O O
adjusted O O
image B O
10.7 O O
exercises O O
527 O O
inside O O
a O O
window O O
around O O
the O O
mouse O O
. O O
while O O
fourier-based O O
alignment B B
is O O
mostly O O
used O O
to O O
estimate O O
transla- O O
tional O O
shifts O O
between O O
images O O
, O O
it O O
can O O
, O O
under O O
certain O O
limited O O
conditions O O
, O O
also O O
be O O
used O O
to O O
estimate O O
in-plane O O
rotations O O
and O O
scales O O
. O O
96 O O
bits O O
/ O O
pixelsignexponentmantissa O O
( O O
a O O
) O O
32 O B
bits O O
/ O O
pixelredgreenblueexponent O O
( O O
b O O
) O O
48 O O
bits O O
/ O O
pixelsignexponentmantissa O O
( O O
c O O
) O O
488 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
( O O
a O O
) O O
( O O
b O O
) O O
( O O
c O O
) O O
figure O O
10.20 O O
global B B
tone O O
mapping O O
: O O
( O O
a O O
) O O
input O O
hdr O O
image B B
, O O
linearly O O
mapped O O
; O O
( O O
b O O
) O O
gamma B B
applied O O
to O O
each O O
color B B
channel O O
independently O O
; O O
( O O
c O O
) O O
gamma B B
applied O O
to O O
intensity O O
( O O
colors O O
are O O
less O O
washed O O
out O O
) O O
. O O
fig- O O
ure O O
10.20 O O
shows O O
one O O
such O O
example O O
, O O
where O O
a O O
gamma B B
curve O O
is O O
used O O
to O O
map O O
an O O
hdr O O
image B B
back O O
12 O O
http O O
: O O
//www.openexr.net/ O O
. O O
ruzon O O
and O O
tomasi O O
’ O O
s O O
algorithm B B
locally O O
models O O
foreground O O
and O O
background O O
colors O O
and O O
variances O O
. O O
9 O O
the O O
condition O O
number O O
κ O O
( O O
c O O
) O O
is O O
the O O
ratio O O
of O O
the O O
largest O O
and O O
smallest O O
eigenvalues B B
of O O
c. O O
the O O
actual O O
convergence O O
rate O O
depends O O
on O O
the O O
clustering O O
of O O
the O O
eigenvalues B B
, O O
as O O
discussed O O
in O O
the O O
references B B
cited O O
in O O
this O O
section O O
. O O
these O O
kinds O O
of O O
approaches O O
produce O O
good O O
results O O
when O O
the O O
lighting B B
stays O O
ﬁxed O O
with O O
respect O O
to O O
the O O
object O O
, O O
i.e. O O
, O O
when O O
the O O
camera B B
moves O O
around O O
the O O
object O O
or O O
space O O
. O O
in O O
ieee O O
computer O O
society O O
conference O O
on O O
computer O O
vision O O
and O O
pattern O O
recognition B B
( O O
cvpr O O
’ O O
2006 O O
) O O
, O O
pp O O
. O O
in O O
their O O
bayesian O O
matting B B
paper O O
, O O
chuang O O
, O O
curless O O
, O O
salesin O O
et O O
al O O
. O O
figure O O
10.6 O O
shows O O
an O O
example O O
of O O
simultaneously O O
estimating O O
the O O
vignetting B B
, O O
exposure O O
, O O
and O O
radiometric B B
response O O
function O O
from O O
a O O
set O O
of O O
overlapping O O
photographs O O
( O O
goldman O O
2011 O O
) O O
. O O
higher-order O O
cliques B B
can O O
also O O
be O O
used O O
to O O
develop O O
more O O
sophisticated O O
models O O
( O O
potetz O O
and O O
lee O O
2008 O O
; O O
kohli O O
, O O
ladick´y O O
, O O
and O O
torr O O
2009 O O
; O O
kohli O O
, O O
kumar O O
, O O
and O O
torr O O
2009 O O
) O O
. O O
128 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
( O O
a O O
) O O
( O O
b O O
) O O
( O O
c O O
) O O
( O O
d O O
) O O
( O O
e O O
) O O
( O O
f O O
) O O
figure O O
3.21 O O
binary O O
image O O
morphology O O
: O O
( O O
a O O
) O O
original O O
image B B
; O O
( O O
b O O
) O O
dilation B O
; O O
( O O
c O O
) O O
erosion B O
; O O
( O O
d O O
) O O
majority O O
; O O
( O O
e O O
) O O
opening B O
; O O
( O O
f O O
) O O
closing B O
. O O
scale O O
invariant O O
feature B B
transform O O
( O O
sift O O
) O O
. O O
simultaneous O O
structure O O
and O O
texture B B
image O O
inpainting B B
. O O
880 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
peleg O O
, O O
s. O O
and O O
herman O O
, O O
j. O O
in O O
ieee O O
computer O O
society O O
conference O O
on O O
computer O O
vision O O
and O O
pattern O O
recognition B B
( O O
cvpr O O
’ O O
97 O O
) O O
, O O
pp O O
. O O
signal O O
processing O O
: O O
image B B
communication O O
, O O
7:529–552 O O
. O O
the O O
color-dependent O O
blurring O O
caused O O
by O O
chromatic O O
aberration O O
( O O
figure O O
2.21 O O
) O O
can O O
also O O
be O O
removed O O
using O O
the O O
de-blurring O O
techniques O O
discussed O O
in O O
10 O O
this O O
process O O
confounds O O
the O O
distinction O O
between O O
geometric B B
and O O
photometric B B
calibration O O
. O O
in O O
fact O O
, O O
it O O
is O O
possible O O
to O O
combine O O
part-based B B
and O O
context B B
models O O
into O O
the O O
same O O
19 O O
http O O
: O O
//www.internetvisioner.org/ O O
. O O
when O O
large O O
numbers O O
of O O
closely O O
spaced O O
cameras O O
are O O
available O O
, O O
as O O
in O O
the O O
stanford O O
light O O
field O O
camera B B
( O O
wilburn O O
, O O
joshi O O
, O O
vaish O O
et O O
al O O
. O O
hoiem O O
, O O
efros O O
, O O
and O O
hebert O O
( O O
2005a O O
) O O
on O O
the O O
other O O
hand O O
, O O
work O O
with O O
more O O
“ O O
organic O O
” O O
scenes O O
such O O
as O O
the O O
one O O
shown O O
in O O
figure O O
14.47. O O
their O O
system O O
uses O O
a O O
variety O O
of O O
classiﬁers O O
and O O
statistics O O
learned B B
from O O
labeled O O
images O O
to O O
classify O O
each O O
pixel O O
as O O
either O O
ground O O
, O O
vertical O O
, O O
or O O
sky O O
( O O
figure O O
14.47d O O
) O O
. O O
figure O O
12.3 O O
shows O O
an O O
example O O
of O O
such O O
a O O
pattern O O
, O O
along O O
with O O
the O O
estimated O O
local B B
surface O O
orientations O O
. O O
a O O
similar O O
process O O
has O O
been O O
occurring O O
in O O
computer O O
vision O O
, O O
with O O
some O O
of O O
the O O
most O O
exciting O O
new O O
work O O
occurring O O
at O O
the O O
intersection O O
of O O
the O O
object O O
recognition B B
and O O
machine O O
learning O O
ﬁelds O O
. O O
b.1 O O
estimation B O
theory O O
. O O
however O O
, O O
such O O
conditions O O
rarely O O
arise O O
in O O
image B B
registration I I
. O O
11.8 O O
exercises O O
575 O O
merge O O
these O O
depth O O
maps O O
into O O
a O O
coherent O O
3d O O
model O O
, O O
e.g. O O
, O O
using O O
poisson O O
surface B B
reconstruc- O I
tion B B
( O O
kazhdan O O
, O O
bolitho O O
, O O
and O O
hoppe O O
2006 O O
) O O
. O O
6. O O
alternatively O O
, O O
since O O
you O O
already O O
know O O
the O O
rotation O O
, O O
simply O O
estimate O O
the O O
unknown O O
trans- O O
lation O O
from O O
the O O
known O O
3d O O
corner O O
points B B
on O O
the O O
cube O B
and O O
their O O
measured O O
2d O O
locations O O
using O O
either O O
linear B B
or O O
non-linear B B
least O O
squares O O
. O O
more O O
recent O O
examples B B
include O O
( O O
heisele O O
, O O
ho O O
, O O
wu O O
et O O
al O O
. O O
an O O
alternative O O
formulation O O
would O O
be O O
to O O
have O O
one O O
general O O
function O O
f O O
( O O
x O O
, O O
pi O O
) O O
and O O
to O O
use O O
a O O
per-measurement O O
parameter O O
vector O O
pi O O
to O O
distinguish O O
between O O
different O O
measurements O O
, O O
e.g. O O
, O O
( O O
xi O O
, O O
yi O O
, O O
zi O O
) O O
in O O
equation B B
( O O
b.1 O O
) O O
. O O
locally B O
adaptive I I
learning O O
for O O
translation-variant O O
mrf O O
image B B
priors O O
. O O
some O O
of O O
the O O
notable O O
papers O O
in O O
this O O
area O O
include O O
the O O
constellation B O
model I O
of O O
fergus O O
, O O
perona O O
, O O
and O O
zisserman O O
( O O
2007 O O
) O O
( O O
figure O O
1.10e O O
) O O
and O O
the O O
pictorial O O
structures O O
of O O
felzenszwalb O O
and O O
huttenlocher O O
( O O
2005 O O
) O O
. O O
references B B
841 O O
hogg O O
, O O
d. O O
( O O
1983 O O
) O O
. O O
more O O
recent O O
ap- O O
proaches O O
sometimes O O
simultaneously O O
compute O O
both O O
the O O
unknown O O
intrinsic B B
parameters O O
and O O
the O O
radial B B
distortion I I
coefﬁcients O O
, O O
which O O
may O O
include O O
higher-order O O
terms O O
or O O
more O O
complex O O
rational O O
or O O
non-parametric B B
forms O O
( O O
claus O O
and O O
fitzgibbon O O
2005 O O
; O O
sturm O O
2005 O O
; O O
thirthala O O
and O O
pollefeys O O
2005 O O
; O O
barreto O O
and O O
daniilidis O O
2005 O O
; O O
hartley O O
and O O
kang O O
2005 O O
; O O
steele O O
and O O
jaynes O O
2006 O O
; O O
tardif O O
, O O
sturm O O
, O O
trudeau O O
et O O
al O O
. O O
this O O
, O O
indeed O O
, O O
is O O
the O O
“ O O
classic O O
” O O
approach O O
to O O
camera B B
calibration O O
used O O
in O O
both O O
the O O
photogrammetry B B
( O O
slama O O
1980 O O
) O O
and O O
the O O
com- O O
puter O O
vision O O
( O O
tsai O O
1987 O O
) O O
communities O O
. O O
using O O
inhomogeneous O O
coordinates O O
, O O
this O O
can O O
be O O
written O O
as O O
in O O
homogeneous B O
coordinates I O
, O O
the O O
projection O O
has O O
a O O
simple O O
linear B B
form O O
, O O
x/z O O
y/z O O
1 O O
¯x O O
= O O
pz O O
( O O
p O O
) O O
= O O
˜x O O
= O O
1 O O
0 O O
0 O O
0 O O
0 O O
1 O O
0 O O
0 O O
0 O O
0 O O
1 O O
0 O O
 O O
. O O
2007 O O
) O O
, O O
full O O
afﬁne B B
invariance I O
is O O
preferred O O
. O O
2008 O O
) O O
, O O
video B B
footage O O
can O O
now O O
often O O
be O O
used O O
directly O O
to O O
control O O
the O O
animation O O
( O O
buck O O
, O O
finkelstein O O
, O O
jacobs O O
et O O
al O O
. O O
for O O
example O O
, O O
the O O
change O O
in O O
scale O O
of O O
an O O
object O O
viewed O O
through O O
a O O
zoom O O
telephoto O O
lens O O
can O O
either O O
be O O
due O O
to O O
a O O
zoom O O
change O O
or O O
a O O
motion B B
towards O O
the O O
user O O
. O O
( O O
8.9 O O
) O O
rather O O
than O O
taking O O
a O O
simple O O
squared O O
difference B B
between O O
corresponding O O
patches O O
, O O
it O O
becomes O O
necessary O O
to O O
perform O O
a O O
linear B B
regression O O
( O O
appendix O O
a.2 O O
) O O
, O O
which O O
is O O
somewhat O O
more O O
costly O O
. O O
in O O
addition O O
to O O
fully O O
automated B B
stereo O O
tech- O O
niques O O
, O O
it O O
is O O
also O O
possible O O
to O O
paint O O
in O O
depth O O
layers O O
( O O
kang O O
1998 O O
; O O
oh O O
, O O
chen O O
, O O
dorsey O O
et O O
al O O
. O O
a.2.1 O O
total B B
least O O
squares O O
. O O
figure O O
5.22 O O
shows O O
the O O
segmen- O O
tations O O
produced O O
by O O
this O O
algorithm B B
compared O O
to O O
other O O
popular O O
segmentation B B
algorithms O O
. O O
finding O O
faces B B
in O O
cluttered O O
scenes O O
using O O
random O O
labeled O O
graph O O
matching O O
. O O
consensus O O
surfaces O O
for O O
modeling O O
3d O O
in O O
sixth O O
international O O
conference O O
on O O
computer O O
objects O O
from O O
multiple B B
range O O
images O O
. O O
references B B
861 O O
lindeberg O O
, O O
t. O O
( O O
1994 O O
) O O
. O O
inferring O O
the O O
values O O
of O O
the O O
joint B B
angles O O
from O O
the O O
locations O O
of O O
the O O
visible O O
surface B B
points O O
is O O
called O O
inverse B B
kinematics O O
( O O
ik O O
) O O
and O O
is O O
widely O O
studied O O
in O O
computer O O
graphics O O
. O O
( O O
a O O
) O O
afﬁne B B
covariant O O
regions O O
are O O
extracted O O
from O O
each O O
frame O O
and O O
clustered O O
into O O
visual B O
words I I
using O O
k-means B O
clustering O O
on O O
sift O O
descriptors O O
with O O
a O O
learned B B
mahalanobis O O
distance O O
. O O
furthermore O O
, O O
nearby O O
images O O
in O O
both O O
3d O O
position O O
and O O
viewing O O
direction O O
can O O
be O O
linked O O
to O O
create O O
“ O O
virtual O O
paths O O
” O O
, O O
which O O
can O O
then O O
be O O
used O O
to O O
navigate O O
between O O
arbitrary O O
pairs B B
of O O
images O O
, O O
such O O
as O O
those O O
you O O
might O O
take O O
yourself O O
while O O
walking O O
around O O
a O O
popular O O
tourist O O
site O O
( O O
snavely O O
, O O
garg O O
, O O
seitz O O
et O O
al O O
. O O
given O O
the O O
line O O
parameterization O O
, O O
the O O
hough O O
transform B B
proceeds O O
as O O
shown O O
in O O
algorithm B B
4.2. O O
θiriθ O O
( O O
xi O O
, O O
yi O O
) O O
03600rmaxr-rmaxxy O O
( O O
a O O
) O O
( O O
b O O
) O O
yxdθnl^ O O
4.3 O O
lines B B
253 O O
procedure O O
hough O O
( O O
{ O O
( O O
x O O
, O O
y O O
, O O
θ O O
) O O
} O O
) O O
: O O
1. O O
clear O O
the O O
accumulator O O
array O O
. O O
a O O
simpler O O
approach O O
, O O
which O O
does O O
not O O
re- O O
quire O O
the O O
evaluation B B
of O O
extrapersonal O O
probabilities O O
, O O
is O O
to O O
simply O O
choose O O
the O O
training O O
image B B
with O O
678 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
( O O
a O O
) O O
( O O
b O O
) O O
figure O O
14.18 O O
modular O O
eigenspace O O
for O O
face O O
recognition B B
( O O
moghaddam O O
and O O
pentland O O
1997 O O
) O O
c O O
( O O
cid:13 O O
) O O
1997 O O
ieee O O
. O O
r0 O O
= O O
rt O O
r. O O
( O O
a.21 O O
) O O
( O O
a.22 O O
) O O
algorithm B B
a.1 O O
provides O O
a O O
more O O
procedural O O
deﬁnition O O
, O O
which O O
can O O
store O O
the O O
upper-triangular O O
matrix O O
r O O
in O O
the O O
same O O
space O O
as O O
c O O
, O O
if O O
desired O O
. O O
the O O
feature-based B B
matching O O
stage O O
ﬁrst O O
ex- O O
tracts O O
scale O O
invariant O O
feature B B
transform O O
( O O
sift O O
) O O
feature B B
locations O O
and O O
feature B B
descriptors O O
( O O
lowe O O
2004 O O
) O O
from O O
all O O
the O O
input O O
images O O
and O O
places O O
them O O
in O O
an O O
indexing O O
structure O O
, O O
as O O
described O O
in O O
sec- O O
tion B B
4.1.3. O O
for O O
each O O
image B B
pair O O
under O O
consideration O O
, O O
the O O
nearest O B
matching O I
neighbor O I
is O O
found O O
for O O
each O O
feature B B
in O O
the O O
ﬁrst O O
image B B
, O O
using O O
the O O
indexing O O
structure O O
to O O
rapidly O O
ﬁnd O O
candidates O O
and O O
then O O
comparing O O
feature B O
descriptors O O
to O O
ﬁnd O O
the O O
best O O
match O O
. O O
3d O O
to O O
2d O O
projections B B
. O O
content- O O
based O O
image B B
retrieval O O
at O O
the O O
end O O
of O O
the O O
early O O
years O O
. O O
in O O
ieee O O
computer O O
society O O
conference O O
on O O
computer O O
vision O O
and O O
pattern O O
recognition B B
( O O
cvpr O O
’ O O
2000 O O
) O O
, O O
pp O O
. O O
figure O O
10.24 O O
local B B
tone O O
mapping O O
using O O
bilateral O B
ﬁlter O O
( O O
durand O O
and O O
dorsey O O
2002 O O
) O O
: O O
sum- O O
mary O O
of O O
algorithm B B
workﬂow O O
. O O
7.5 O O
constrained B O
structure O O
and O O
motion B B
375 O O
figure O O
7.14 O O
two O O
images O O
of O O
a O O
toy O O
house O O
along O O
with O O
their O O
matched O O
3d O O
line O O
segments O O
( O O
schmid O O
and O O
zisserman O O
1997 O O
) O O
c O O
( O O
cid:13 O O
) O O
1997 O O
springer O O
. O O
linear B B
multi-view O O
reconstruction O O
of O O
points B B
, O O
lines B B
, O O
planes B B
and O O
cameras O O
using O O
a O O
reference O O
plane O O
. O O
) O O
we O O
then O O
turn O O
our O O
attention O O
to O O
more O O
local B B
general O O
deformations O O
such O O
as O O
those O O
deﬁned O O
on O O
meshes O O
( O O
section O O
3.6.2 O O
) O O
. O O
in O O
ieee O O
computer O O
society O O
conference O O
on O O
computer O O
vision O O
and O O
pattern O O
recogni- O O
tion B B
( O O
cvpr O O
’ O O
2003 O O
) O O
, O O
pp O O
. O O
rigid O O
, O O
afﬁne B B
, O O
and O O
locally O O
afﬁne O B
registration B O
of O O
free-form O O
surfaces O O
. O O
figure O O
3.53 O O
shows O O
the O O
essence O O
of O O
image B B
morphing O O
. O O
a O O
three-frame O O
algorithm B B
for O O
estimating O O
two-component O O
image B B
motion O O
. O O
this O O
can O O
be O O
“ O O
broken O O
” O O
either O O
using O O
structural O O
assumptions O O
about O O
the O O
sharp O O
image B B
, O O
e.g. O O
, O O
the O O
presence O O
of O O
edges O O
( O O
joshi O O
, O O
szeliski O O
, O O
and O O
kriegman O O
2008 O O
) O O
or O O
prior B B
models O O
for O O
the O O
image B B
, O O
such O O
as O O
edge O O
sparsity O O
( O O
fergus O O
, O O
singh O O
, O O
hertzmann O O
et O O
al O O
. O O
recursive O O
ﬁltering O O
the O O
incremental B B
formula O O
( O O
3.31 O O
) O O
for O O
the O O
summed O O
area O O
is O O
an O O
example O O
of O O
a O O
recursive O O
ﬁlter O O
, O O
i.e. O O
, O O
one O O
whose O O
values O O
depends O O
on O O
previous O O
ﬁlter O O
outputs O O
. O O
ws O O
= O O
( O O
10.22 O O
) O O
494 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
figure O O
10.27 O O
scale B O
selection I I
for O O
tone B O
mapping I O
( O O
reinhard O O
, O O
stark O O
, O O
shirley O O
et O O
al O O
. O O
( O O
8.28 O O
) O O
the O O
desired O O
rotation O O
can O O
then O O
be O O
estimated O O
using O O
a O O
fast O O
fourier O O
transform B B
( O O
fft O O
) O O
shift-based O O
technique O O
. O O
a O O
different O O
application O O
of O O
image B B
recognition O O
and O O
segmentation B B
is O O
to O O
infer O O
3d O O
structure O O
from O I
a O O
single O O
photo O O
by O O
recognizing O O
certain O O
scene O O
structures O O
. O O
a O O
closely O O
related O O
concept O O
is O O
that O O
of O O
wavelets O O
, O O
which O O
are O O
a O O
special O O
kind O O
of O O
pyramid B B
with O O
higher O O
frequency O O
selectivity B O
and O O
other O O
useful O O
properties B O
( O O
section O O
3.5.4 O O
) O O
. O O
b.6 O O
uncertainty B B
estimation O O
( O O
error O O
analysis O O
) O O
. O O
such O O
techniques O O
are O O
used O O
not O O
only O O
to O O
remove O O
unwanted O O
people O O
or O O
interlopers O O
from O O
photographs O O
( O O
king O O
1997 O O
) O O
but O O
also O O
to O O
ﬁx O O
small O O
defects O O
in O O
old O O
photos O O
and O O
movies O O
( O O
scratch B O
removal I O
) O O
or O O
to O O
remove O O
wires O O
holding O O
props O O
or O O
actors O O
in O O
mid-air O O
during O O
ﬁlming O O
( O O
wire O O
removal O O
) O O
. O O
the O O
afﬁne B B
transformation O O
is O O
written O O
as O O
x O O
( O O
cid:48 O O
) O O
= O O
a¯x O O
, O O
where O O
a O O
is O O
an O O
arbitrary O O
2 O O
× O O
3 O O
matrix O O
, O O
i.e. O O
, O O
x O O
( O O
cid:48 O O
) O O
= O O
( O O
cid:34 O O
) O O
a00 O O
a01 O O
a02 O O
a10 O O
a11 O O
a12 O O
( O O
cid:35 O O
) O O
¯x O O
. O O
recognition B B
( O O
cvpr O O
2008 O O
) O O
, O O
anchorage O O
, O O
ak O O
. O O
rendering B B
with O O
coherent O O
layers B B
. O O
in O O
ieee O O
com- O O
puter O O
society O O
conference O O
on O O
computer O O
vision O O
and O O
pattern O O
recognition B B
( O O
cvpr O O
2007 O O
) O O
, O O
minneapolis O O
, O O
mn O O
. O O
3.3 O O
more O O
neighborhood B B
operators O O
. O O
ex O O
8.7 O O
: O O
video B B
denoising I O
implement O O
the O O
algorithm B B
sketched O O
in O O
application O O
8.4.2. O O
your O O
al- O O
gorithm O O
should O O
contain O O
the O O
following O O
steps O O
: O O
1. O O
compute O O
accurate O O
per-pixel O O
ﬂow O O
. O O
parametric B O
transformations O O
. O O
in O O
ieee O O
computer O O
society O O
conference O O
on O O
computer O O
vision O O
and O O
pattern O O
recognition B B
( O O
cvpr O O
’ O O
2000 O O
) O O
, O O
pp O O
. O O
) O O
in O O
addition O O
to O O
its O O
location O O
, O O
a O O
point O O
light O O
source O O
has O O
an O O
intensity O O
and O O
a O O
color B B
spectrum O O
, O O
i.e. O O
, O O
a O O
distribution O O
over O O
2.2 O O
photometric B B
image O O
formation O O
61 O O
figure O O
2.14 O O
a O O
simpliﬁed O O
model O O
of O O
photometric B B
image O O
formation O O
. O O
motorized O O
rotation O O
heads O O
are O O
also O O
6 O O
note O O
that O O
these O O
are O O
not O O
the O O
usual O O
spherical B B
coordinates O O
, O O
ﬁrst O O
presented O O
in O O
equation B B
( O O
2.8 O O
) O O
. O O
estimating O O
the O O
local B B
displacement O O
vectors O O
around O O
a O O
current O O
estimate O O
xk O O
results O O
in O O
the O O
mean-shift O O
vector O O
m O O
( O O
xk O O
) O O
, O O
which O O
, O O
in O O
a O O
multi-dimensional O O
setting O O
, O O
point O O
in O O
the O O
same O O
direction O O
as O O
the O O
function O O
gradient O O
∇f O O
( O O
xk O O
) O O
. O O
finally O O
, O O
during O O
rendering B B
, O O
images O O
from O O
different O O
viewpoints O O
are O O
warped O O
and O O
blended O O
together O O
as O O
the O O
camera B B
moves O O
around O O
the O O
scene O O
, O O
using O O
a O O
process O O
( O O
re- O O
lated O O
to O O
light B O
ﬁeld I I
and O O
lumigraph O O
rendering B B
, O O
see O O
section O O
13.3 O O
) O O
called O O
view-dependent O B
texture O O
mapping O O
( O O
figure O O
12.14d O O
) O O
. O O
the O O
resulting O O
homogeneous O O
coordinate O I
˜x O O
( O O
cid:48 O O
) O O
must O O
be O O
normalized B O
in O O
order B B
to O O
obtain O O
an O O
inhomogeneous O O
result O O
x O O
, O O
i.e. O O
, O O
x O O
( O O
cid:48 O O
) O O
= O O
h00x O O
+ O O
h01y O O
+ O O
h02 O O
h20x O O
+ O O
h21y O O
+ O O
h22 O O
and O O
y O O
( O O
cid:48 O O
) O O
= O O
h10x O O
+ O O
h11y O O
+ O O
h12 O O
h20x O O
+ O O
h21y O O
+ O O
h22 O O
. O O
unfortunately O O
, O O
these O O
downhill O O
methods O O
tend O O
to O O
get O O
easily O O
stuck O O
in O O
local B B
minima O O
. O O
these O O
techniques O O
are O O
most O O
often O O
implemented O O
within O O
a O O
coarse-to-ﬁne B B
hierarchical O O
reﬁnement O O
framework O O
( O O
quam O O
1984 O O
; O O
bergen O O
, O O
anandan O O
, O O
hanna O O
et O O
al O O
. O O
texture B B
gradients O O
( O O
figure O O
12.1b O O
) O O
, O O
i.e. O O
, O O
the O O
foreshortening O O
of O O
regular O O
patterns B B
as O O
the O O
surface B B
slants O O
or O O
bends O O
away O O
from O O
the O O
camera B B
, O O
can O O
provide O O
similar O O
cues O O
on O O
local B B
surface O O
orientation O O
( O O
section O O
12.1.2 O O
) O O
. O O
fragment-based O O
image B B
completion O O
. O O
in O O
defense O O
of O O
nearest-neighbor O O
based O O
image B B
classiﬁcation O O
. O O
while O O
it O O
is O O
easy O O
to O O
convince O O
yourself O O
that O O
the O O
two O O
forms O O
are O O
mathematically O O
equivalent O O
, O O
the O O
least B B
squares I I
form O O
is O O
preferable O O
if O O
rounding O O
errors O O
start O O
to O O
affect O O
the O O
results O O
because O O
of O O
poor O O
conditioning O O
. O O
examples B B
of O O
such O O
problems O O
include O O
surface B B
interpolation O O
from O O
scattered O O
data O O
( O O
figure O O
3.54 O O
) O O
, O O
image B B
denoising O O
and O O
the O O
restoration O O
of O O
missing O O
regions O O
( O O
figure O O
3.57 O O
) O O
, O O
and O O
the O O
segmentation B B
of O O
images O O
into O O
foreground O O
and O O
background O O
regions O O
( O O
figure O O
3.61 O O
) O O
. O O
however O O
, O O
despite O O
all O O
of O O
these O O
advances O O
, O O
the O O
dream O O
of O O
having O O
a O O
computer O O
interpret O O
an O O
image B B
at O O
the O O
same O O
level O O
as O O
a O O
two-year O O
old O O
( O O
for O O
example O O
, O O
counting O O
all O O
of O O
the O O
animals O O
in O O
a O O
picture O O
) O O
remains O O
elusive O O
. O O
10.5.1 O O
application O O
: O O
hole B B
ﬁlling I I
and O O
inpainting B B
. O O
many O O
global B B
methods O I
are O O
formulated O O
in O O
an O O
energy-minimization O O
framework O O
, O O
where O O
, O O
as O O
we O O
saw O O
in O O
sections O O
3.7 O O
( O O
3.100–3.102 O O
) O O
and O O
8.4 O O
, O O
the O O
objective O O
is O O
to O O
ﬁnd O O
a O O
solution O O
d O O
that O O
minimizes O O
a O O
global B B
energy O O
, O O
e O O
( O O
d O O
) O O
= O O
ed O O
( O O
d O O
) O O
+ O O
λes O O
( O O
d O O
) O O
. O O
12.6.4 O O
whole O O
body B B
modeling O O
and O O
tracking O O
. O O
775 O O
756 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
the O O
following O O
problem O O
commonly O O
recurs O O
in O O
this O O
book O O
: O O
given O O
a O O
number O O
of O O
measurements O O
( O O
images O O
, O O
feature B B
positions O O
, O O
etc O O
. O O
( O O
optional O O
) O O
add O O
the O O
ability O O
to O O
supply O O
a O O
target O O
( O O
reference O O
) O O
image B B
( O O
efros O O
and O O
freeman O O
2001 O O
) O O
or O O
to O O
provide O O
sample O O
ﬁltered O O
or O O
unﬁltered O O
( O O
reference O O
and O O
rendered O O
) O O
images O O
( O O
hertz- O O
mann O O
, O O
jacobs O O
, O O
oliver O O
et O O
al O O
. O O
5. O O
repeat O O
your O O
calibration B B
experiments O O
under O O
different O O
conditions O O
, O O
e.g. O O
, O O
indoors O O
under O O
in- O O
candescent O O
light O O
, O O
to O O
get O O
a O O
sense O O
for O O
the O O
range O O
of O O
color B B
balancing O O
effects O O
that O O
your O O
camera B B
imposes O O
. O O
754 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
appendix O O
b O O
bayesian O O
modeling B B
and O O
inference B B
. O O
9.1.5 O O
application O O
: O O
video B B
summarization I I
and O O
compression B B
an O O
interesting O O
application O O
of O O
image B B
stitching I I
is O O
the O O
ability O O
to O O
summarize O O
and O O
compress O O
videos O O
taken O O
with O O
a O O
panning O O
camera B B
. O O
pattern O O
recognition B B
( O O
cvpr O O
2008 O O
) O O
, O O
anchorage O O
, O O
ak O O
. O O
in O O
addition O O
to O O
computing O O
the O O
weight O O
matrix O O
using O O
interpolation-based O O
coarsening O O
, O O
additional O O
region B B
statistics O O
are O O
used O O
to O O
modulate O O
the O O
weights O O
. O O
a O O
generalized B B
ordering O O
constraint B O
for O O
stereo B O
corre- O O
spondence O O
. O O
level O B
set O O
techniques O O
( O O
section O O
5.1.4 O O
) O O
also O O
operate O O
on O O
a O O
uniform O O
grid O O
but O O
, O O
instead O O
of O O
representing O O
a O O
binary O O
occupancy O O
map O O
, O O
they O O
represent O O
the O O
signed B B
distance O O
to O O
the O O
surface B B
( O O
faugeras O O
and O O
keriven O O
1998 O O
; O O
pons O O
, O O
keriven O O
, O O
and O O
faugeras O O
2007 O O
) O O
, O O
which O O
can O O
encode O O
a O O
ﬁner O O
level O O
of O O
detail O O
. O O
given O O
two O O
quaternions O B
q0 O O
= O O
( O O
v0 O O
, O O
w0 O O
) O O
and O O
q1 O O
= O O
( O O
v1 O O
, O O
w1 O O
) O O
, O O
the O O
quaternion O O
multiply O O
operator O O
is O O
deﬁned O O
as O O
q2 O O
= O O
q0q1 O O
= O O
( O O
v0 O O
× O O
v1 O O
+ O O
w0v1 O O
+ O O
w1v0 O O
, O O
w0w1 O O
− O O
v0 O O
· O O
v1 O O
) O O
, O O
( O O
2.42 O O
) O O
zxw║q║=1yq0q1q2-q2 O O
2.1 O O
geometric B B
primitives O O
and O O
transformations O O
45 O O
with O O
the O O
property O O
that O O
r O O
( O O
q2 O O
) O O
= O O
r O O
( O O
q0 O O
) O O
r O O
( O O
q1 O O
) O O
. O O
10.5 O O
texture B B
analysis O O
and O O
synthesis O O
while O O
texture B B
analysis O O
and O O
synthesis O O
may O O
not O O
at O O
ﬁrst O O
seem O O
like O O
computational O O
photography O O
techniques O O
, O O
they O O
are O O
, O O
in O O
fact O O
, O O
widely O O
used O O
to O O
repair O O
defects O O
, O O
such O O
as O O
small O O
holes O O
, O O
in O O
images O O
or O O
to O O
create O O
non-photorealistic O B
painterly O O
renderings O O
from O O
regular O O
photographs O O
. O O
in O O
ieee O O
computer O O
society O O
conference O O
on O O
computer O O
vision O O
and O O
pattern O O
recognition B B
( O O
cvpr O O
’ O O
97 O O
) O O
, O O
pp O O
. O O
this O O
material O O
, O O
which O O
is O O
described O O
in O O
appendix O O
c O O
, O O
includes O O
: O O
• O O
pointers O O
to O O
commonly O O
used O O
data B O
sets I I
for O O
the O O
problems O O
, O O
which O O
can O O
be O O
found O O
on O O
the O O
web O O
• O O
pointers O O
to O O
software O O
libraries O O
, O O
which O O
can O O
help O O
students O O
get O O
started O O
with O O
basic O O
tasks O O
such O O
as O O
reading/writing O O
images O O
or O O
creating O O
and O O
manipulating O O
images O O
• O O
slide O O
sets O O
corresponding O O
to O O
the O O
material O O
covered O O
in O O
this O O
book O O
• O O
a O O
bibtex O O
bibliography O O
of O O
the O O
papers O O
cited O O
in O O
this O O
book O O
. O O
shakhnarovich O O
, O O
viola O O
, O O
and O O
darrell O O
( O O
2003 O O
) O O
extend O O
this O O
technique O O
to O O
be O O
more O O
sensitive O O
to O O
the O O
distribution O O
of O O
points B B
in O O
parameter O O
space O O
, O O
which O O
they O O
call O O
parameter-sensitive O O
hashing B B
. O O
8.1 O O
translational B B
alignment O O
385 O O
however O O
, O O
since O O
this O O
function O O
is O O
not O O
differentiable O O
at O O
the O O
origin O O
, O O
it O O
is O O
not O O
well O O
suited O O
to O O
gradient- O O
descent O O
approaches O O
such O O
as O O
the O O
ones O O
presented O O
in O O
section O O
8.1.3. O O
instead O O
, O O
a O O
smoothly O O
varying O O
function O O
that O O
is O O
quadratic O O
for O O
small O O
values O O
but O O
grows O O
more O O
slowly O O
away O O
from O O
the O O
origin O O
is O O
often O O
used O O
. O O
efﬁciently O O
registering O O
video B B
into O O
panoramic O O
in O O
tenth O O
international O O
conference O O
on O O
computer O O
vision O O
( O O
iccv O O
2005 O O
) O O
, O O
mosaics O O
. O O
600 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
( O O
a O O
) O O
( O O
b O O
) O O
figure O O
12.15 O O
interactive B B
3d O O
modeling B B
from O O
panoramas O O
( O O
shum O O
, O O
han O O
, O O
and O O
szeliski O O
1998 O O
) O O
c O O
( O O
cid:13 O O
) O O
1998 O O
ieee O O
: O O
( O O
a O O
) O O
wide-angle O O
view O O
of O O
a O O
panorama O O
with O O
user-drawn O O
vertical O O
and O O
horizontal O O
( O O
axis-aligned O O
) O O
lines B B
; O O
( O O
b O O
) O O
single-view O O
reconstruction O O
of O O
the O O
corridors O O
. O O
the O O
terms O O
in O O
es O O
can O O
also O O
be O O
made O O
to O O
depend O O
on O O
the O O
intensity O O
differences O O
, O O
e.g. O O
, O O
ρd O O
( O O
d O O
( O O
x O O
, O O
y O O
) O O
− O O
d O O
( O O
x O O
+ O O
1 O O
, O O
y O O
) O O
) O O
· O O
ρi O O
( O O
( O O
cid:107 O O
) O O
i O O
( O O
x O O
, O O
y O O
) O O
− O O
i O O
( O O
x O O
+ O O
1 O O
, O O
y O O
) O O
( O O
cid:107 O O
) O O
) O O
, O O
( O O
11.11 O O
) O O
where O O
ρi O O
is O O
some O O
monotonically O O
decreasing O O
function O O
of O O
intensity O O
differences O O
that O O
lowers O O
smoothness B B
costs O O
at O O
high-intensity O O
gradients O O
. O O
recognition B B
( O O
cvpr O O
2008 O O
) O O
, O O
anchorage O O
, O O
ak O O
. O O
the O O
error O O
metrics O O
above O O
ignore O O
that O O
fact O O
that O O
for O O
a O O
given O O
align- O O
ment O O
, O O
some O O
of O O
the O O
pixels O O
being O O
compared O O
may O O
lie O O
outside O O
the O O
original O O
image B B
boundaries O O
. O O
determining O O
the O O
epipolar B O
geometry I I
and O O
its O O
uncertainty B B
: O O
a O O
review O O
. O O
( O O
2008 O O
) O O
use O O
this O O
model O O
, O O
along O O
with O O
an O O
empirical O O
database O O
of O O
camera B B
response O O
functions O O
( O O
crfs O O
) O O
obtained O O
by O O
grossberg O O
and O O
nayar O O
( O O
2004 O O
) O O
, O O
to O O
estimate O O
the O O
noise B B
level O O
function O O
( O O
nlf O O
) O O
for O O
a O O
given O O
image B B
, O O
which O O
predicts O O
the O O
overall O O
noise B B
variance O O
at O O
a O O
given O O
pixel O O
as O O
a O O
function O O
of O O
its O O
brightness O O
( O O
a O O
separate O O
nlf O O
is O O
estimated O O
for O O
each O O
color B B
channel O O
) O O
. O O
the O O
shifted O O
window O O
centered O O
on O O
the O O
black O O
pixel O O
in O O
region B B
b O O
matches O O
correctly O O
in O O
the O O
left O O
image B B
, O O
but O O
requires O O
temporal O O
selection O O
to O O
disable O O
matching B B
the O O
right O O
image B B
. O O
1997 O O
) O O
.14 O O
of O O
all O O
these O O
techniques O O
, O O
the O O
active O O
appearance O O
models O O
( O O
aams O O
) O O
of O O
cootes O O
, O O
edwards O O
, O O
and O O
taylor O O
( O O
2001 O O
) O O
are O O
among O O
the O O
most O O
widely O O
used O O
for O O
face O O
recognition B B
and O O
tracking O O
. O O
if O O
the O O
scene O O
is O O
composed O O
mostly O O
of O O
uniform O O
albedo O O
simple O O
geometry O O
illuminators O O
and O O
surfaces O O
, O O
radiosity B O
( O O
global B B
illumination I O
) O O
techniques O O
are O O
preferred O O
( O O
cohen O O
and O O
wallace O O
1993 O O
; O O
sillion O O
and O O
puech O O
1994 O O
; O O
glassner O O
1995 O O
) O O
. O O
11.4.2 O O
application O O
: O O
stereo-based O O
head B B
tracking I O
. O O
furthermore O O
, O O
these O O
primitives O O
are O O
often O O
arranged O O
in O O
particular O O
relationships O O
, O O
i.e. O O
, O O
many O O
lines B B
and O O
planes B B
are O O
either O O
parallel O O
or O O
orthogonal O O
to O O
each O O
other O O
. O O
interactive B B
3-d O O
video B B
representation O O
and O O
coding O O
technolo- O O
gies O O
. O O
a O O
generic O O
concept O O
for O O
camera O O
calibration B B
. O O
( O O
14.3 O O
) O O
( O O
14.4 O O
) O O
for O O
any O O
given O O
fj O O
function O O
, O O
the O O
optimal O O
values O O
of O O
( O O
θj O O
, O O
sj O O
) O O
can O O
be O O
found O O
in O O
linear B B
time O O
using O O
a O O
variant O O
of O O
weighted B B
median O O
computation O O
( O O
exercise O O
14.2 O O
) O O
. O O
image B B
and O O
vision O O
computing O O
, O O
10 O O
( O O
3 O O
) O O
:132–144 O O
. O O
the O O
information O O
available O O
to O O
a O O
moving O O
observer O O
from O O
specularities B O
. O O
the O O
simplest O O
such O O
model O O
is O O
a O O
covariance O O
matrix O O
, O O
which O O
captures O O
the O O
expected O O
variance O O
in O O
the O O
motion B B
estimate O O
in O O
all O O
possible O O
directions O O
. O O
sophisticated O O
machine O O
learning O O
techniques O O
are O O
also O O
becoming O O
a O O
key O O
component O O
of O O
suc- O O
cessful O O
object O O
detection B B
and O O
recognition B B
algorithms O O
( O O
varma O O
and O O
ray O O
2007 O O
; O O
felzenszwalb O O
, O O
mcallester O O
, O O
and O O
ramanan O O
2008 O O
; O O
fritz O O
and O O
schiele O O
2008 O O
; O O
sivic O O
, O O
russell O O
, O O
zisserman O O
et O O
al O O
. O O
use O O
an O O
alter- O O
native O O
step O O
size O O
estimation B B
algorithm O O
from O O
the O O
optimization O O
literature O O
to O O
see O O
if O O
you O O
can O O
make O O
the O O
algorithm B B
converge O O
faster O O
. O O
to O O
counteract O O
this O O
bias O O
, O O
the O O
windowed B B
ssd O O
score O O
can O O
be O O
divided O O
by O O
the O O
overlap O O
area O O
w0 O O
( O O
xi O O
) O O
w1 O O
( O O
xi O O
+ O O
u O O
) O O
( O O
8.6 O O
) O O
to O O
compute O O
a O O
per-pixel O O
( O O
or O O
mean O O
) O O
squared O O
pixel O O
error O O
ewssd/a O O
. O O
translation B B
. O O
references B O
797 O O
bar-shalom O O
, O O
y. O O
and O O
fortmann O O
, O O
t. O O
e. O O
( O O
1988 O O
) O O
. O O
object O O
mining O O
using O O
a O O
matching B B
graph O I
on O O
very O O
large O O
in O O
indian O O
conference O O
on O O
computer O O
vision O O
, O O
graphics O O
and O O
image B B
image O O
collections O O
. O O
optimal O O
seam B O
selection I O
. O O
feathering B O
and O O
center-weighting O O
. O O
snakes B B
: O O
active O O
contour O O
models O O
. O O
5.2.1 O O
watershed B B
. O O
computer O O
vision O O
and O O
image B B
understanding O O
, O O
104 O O
( O O
2-3 O O
) O O
:178–189 O O
. O O
it O O
is O O
also O O
possible O O
to O O
reconstruct O O
sparser O O
representations O O
, O O
such O O
as O O
3d O O
points B B
and O O
lines B B
, O O
and O O
to O O
interpolate O O
them O O
to O O
full O O
3d O O
surfaces O O
( O O
section O O
12.3.1 O O
) O O
( O O
taylor O O
2003 O O
) O O
. O O
( O O
optional O O
) O O
do O O
your O O
image B B
spectra O O
have O O
a O O
lot O O
of O O
energy O O
concentrated O O
along O O
the O O
horizontal O O
and O O
vertical O O
axes O O
( O O
fx O O
= O O
0 O O
and O O
fy O O
= O O
0 O O
) O O
? O O
can O O
you O O
think O O
of O O
an O O
explanation O O
for O O
this O O
? O O
does O O
rotating O O
your O O
image B B
samples O O
by O O
45◦ O O
move O O
this O O
energy O O
to O O
the O O
diagonals O O
? O O
if O O
not O O
, O O
could O O
it O O
be O O
due O O
to O O
edge O O
effects O O
in O O
the O O
fourier O O
transform B B
? O O
can O O
you O O
suggest O O
some O O
techniques O O
for O O
reducing O O
such O O
effects O O
? O O
ex O O
3.17 O O
: O O
deblurring O O
using O O
wiener O O
ﬁltering O O
use O O
wiener O O
ﬁltering O O
to O O
deblur O O
some O O
images O O
. O O
proceedings O O
of O O
the O O
3dtv O O
conference O O
: O O
the O O
true O O
vision—capture O O
, O O
transmission O O
and O O
display O O
of O O
3d O O
video B B
, O O
ieee O O
computer O O
society O O
press O O
. O O
4. O O
reconstruct O O
the O O
ﬁnal O O
image B B
from O O
the O O
blended O O
laplacian O O
pyramid B B
. O O
acm O O
computing O O
surveys B B
, O O
38 O O
( O O
4 O O
) O O
. O O
this O O
gets O O
even O O
more O O
complicated O O
for O O
the O O
case O O
of O O
general O O
afﬁne B B
or O O
perspective B B
transforms O O
. O O
black O O
and O O
rangarajan O O
( O O
1996 O O
) O O
showed O O
how O O
independent O O
line O O
processes O O
could O O
be O O
replaced O O
with O O
robust O O
pairwise O O
potentials O O
; O O
boykov O O
, O O
veksler O O
, O O
and O O
zabih O O
( O O
2001 O O
) O O
devel- O O
oped O O
iterative B B
binary O O
, O O
graph B B
cut I I
algorithms O O
for O O
optimizing O O
multi-label O O
mrfs O O
; O O
kolmogorov O O
and O O
zabih O O
( O O
2004 O O
) O O
characterized O O
the O O
class O O
of O O
binary O O
energy O O
potentials O O
required O O
for O O
these O O
tech- O O
niques O O
to O O
work O O
; O O
and O O
freeman O O
, O O
pasztor O O
, O O
and O O
carmichael O O
( O O
2000 O O
) O O
popularized O O
the O O
use O O
of O O
loopy B B
belief I I
propagation I I
for O O
mrf O O
inference B B
. O O
photometric B B
image O O
formation O O
( O O
section O O
2.2 O O
) O O
covers O O
radiometry O O
, O O
which O O
describes O O
how O O
light O O
interacts O O
with O O
surfaces O O
in O O
the O O
world O O
, O O
and O O
optics B B
, O O
which O O
projects O O
light O O
onto O O
the O O
sensor B B
plane O O
. O O
closely O O
related O O
to O O
this O O
idea O O
are O O
view-dependent B O
texture I O
maps I O
( O O
section O O
13.1.1 O O
) O O
, O O
which O O
blend O O
multiple B B
texture O O
maps O O
on O O
a O O
3d O O
model O O
’ O O
s O O
surface B B
. O O
augmented B O
reality I O
( O O
isar O O
2000 O O
) O O
. O O
one O O
of O O
the O O
oldest O O
, O O
and O O
simplest O O
, O O
is O O
the O O
one O O
proposed O O
( O O
a O O
) O O
( O O
b O O
) O O
( O O
c O O
) O O
4.3 O O
lines B B
251 O O
figure O O
4.41 O O
original O O
hough O O
transform B B
: O O
( O O
a O O
) O O
each O O
point O O
votes O O
for O O
a O O
complete O O
family O O
of O O
poten- O O
tial O O
lines B B
ri O O
( O O
θ O O
) O O
= O O
xi O O
cos O O
θ O O
+ O O
yi O O
sin O O
θ O O
; O O
( O O
b O O
) O O
each O O
pencil O O
of O O
lines B B
sweeps O O
out O O
a O O
sinusoid O O
in O O
( O O
r O O
, O O
θ O O
) O O
; O O
their O O
intersection O O
provides O O
the O O
desired O O
line O O
equation O O
. O O
video B B
cutout O O
. O O
a O O
number O O
of O O
good O O
surveys B B
have O O
been O O
written O O
over O O
the O O
years O O
( O O
marr O O
and O O
poggio O O
1976 O O
; O O
barnard O O
and O O
fischler O O
1982 O O
; O O
dhond O O
and O O
aggarwal O O
1989 O O
; O O
scharstein O O
and O O
szeliski O O
2002 O O
; O O
brown O O
, O O
burschka O O
, O O
and O O
hager O O
2003 O O
; O O
seitz O O
, O O
curless O O
, O O
diebel O O
et O O
al O O
. O O
com- O O
puter O O
vision O O
and O O
image B B
understanding O O
, O O
104 O O
( O O
2-3 O O
) O O
:221–231 O O
. O O
feature-based B B
correspondence O O
techniques O O
have O O
been O O
used O O
since O O
the O O
early O O
days O O
of O O
stereo B B
208 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
figure O O
4.2 O O
two O O
pairs O B
of O O
images O O
to O O
be O O
matched O O
. O O
in O O
many O O
cases O O
, O O
however O O
, O O
the O O
scene O O
contains O O
higher-level O O
geometric B B
primitives O O
, O O
such O O
as O O
lines B B
and O O
planes B B
. O O
) O O
today O O
, O O
it O O
is O O
more O O
common O O
to O O
use O O
the O O
l1 O O
( O O
p O O
= O O
1 O O
) O O
norm O O
, O O
which O O
is O O
often O O
called O O
total B B
variation I O
( O O
chan O O
, O O
osher O O
, O O
and O O
shen O O
2001 O O
; O O
tschumperl´e O O
and O O
deriche O O
2005 O O
; O O
tschumperl´e O O
2006 O O
; O O
kaftory O O
, O O
schechner O O
, O O
and O O
zeevi O O
2007 O O
) O O
. O O
for O O
two-frame O O
reconstruction O O
, O O
hartley O O
( O O
1997a O O
) O O
wrote O O
a O O
highly O O
cited O O
paper O O
on O O
the O O
“ O O
eight-point B O
algorithm I O
” O O
for O O
computing O O
an O O
essential O O
or O O
fundamental O O
ma- O O
trix O O
with O O
reasonable O O
point O O
normalization O O
. O O
the O O
topic O O
of O O
active B O
contours I I
has O O
a O O
long O O
history O O
, O O
beginning O O
with O O
the O O
seminal O O
work O O
on O O
snakes B B
and O O
other O O
energy-minimizing O O
variational O O
methods O O
( O O
kass O O
, O O
witkin O O
, O O
and O O
terzopoulos O O
1988 O O
; O O
cootes O O
, O O
cooper O O
, O O
taylor O O
et O O
al O O
. O O
references B B
877 O O
opelt O O
, O O
a. O O
, O O
pinz O O
, O O
a. O O
, O O
and O O
zisserman O O
, O O
a O O
. O O
the O O
overall O O
set O O
of O O
steps O O
used O O
to O O
perform O O
the O O
direct B B
solution O O
of O O
sparse B B
least O O
squares O O
problems O O
are O O
summarized O O
in O O
algorithm B B
a.2 O O
, O O
which O O
is O O
a O O
modiﬁed O O
version O O
of O O
algorithm B B
6.6.1 O O
by O O
bj¨orck O O
( O O
1996 O O
, O O
section O O
6.6 O O
) O O
) O O
. O O
2d O O
points B B
. O O
journal O I
of O O
visual O O
communication O O
and O O
image B B
represen- O O
tation O O
, O O
5 O O
( O O
1 O O
) O O
:10–28 O O
. O O
the O O
3d O O
planar O B
proxies O O
used O O
in O O
photo O O
tourism O O
and O O
the O O
related O O
photosynth O O
system O O
from O O
microsoft O O
result O O
in O O
non-photorealistic O B
transitions O O
reminiscent O O
of O O
visual B O
effects I I
such O O
as O O
“ O O
page O O
ﬂips O O
” O O
. O O
ex O O
9.9 O O
: O O
feathering B O
and O O
blending B B
compute O O
a O O
feather O O
( O O
distance O O
) O O
map O O
for O O
each O O
warped O O
source O O
image B B
and O O
use O O
these O O
maps O O
to O O
blend O O
the O O
warped O O
images O O
. O O
articulated O O
body B B
motion O O
capture O O
by O O
stochastic O O
search O O
. O O
lorusso O O
, O O
eggert O O
, O O
and O O
fisher O O
( O O
1995 O O
) O O
experimentally O O
compare O O
these O O
two O O
techniques O O
to O O
two O O
additional O O
techniques O O
proposed O O
in O O
the O O
literature O O
, O O
but O O
ﬁnd O O
that O O
the O O
difference B B
in O O
accuracy B O
is O O
negligible O O
( O O
well O O
below O O
the O O
effects O O
of O O
measurement O O
noise B B
) O O
. O O
nearby O O
lumispheres O O
can O O
then O O
be O O
compressed O O
using O O
predictive O O
coding O O
, O O
vector O O
quantization B B
, O O
or O O
principal O O
component O O
analysis O O
. O O
for O O
ﬁgures O O
( O O
c O O
) O O
– O O
( O O
d O O
) O O
, O O
the O O
image B B
was O O
ﬁrst O O
converted O O
to O O
grayscale O O
. O O
another O O
color B B
space O O
you O O
may O O
come O O
across O O
is O O
hue B O
, O O
saturation O O
, O O
value O O
( O O
hsv O O
) O O
, O O
which O O
is O O
a O O
pro- O O
jection O O
of O O
the O O
rgb O O
color B B
cube O O
onto O O
a O O
non-linear B B
chroma O O
angle O O
, O O
a O O
radial B B
saturation O O
percentage O O
, O O
and O O
a O O
luminance-inspired O O
value O O
. O O
to O O
make O O
the O O
optimization O O
computationally O O
tractable O O
, O O
the O O
smoothness B B
term O O
is O O
often O O
restricted B O
11.5 O O
global B B
optimization I I
553 O O
to O O
measuring O O
only O O
the O O
differences O O
between O O
neighboring O O
pixels O O
’ O O
disparities O O
, O O
es O O
( O O
d O O
) O O
= O O
( O O
cid:88 O O
) O O
( O O
x O O
, O O
y O O
) O O
ρ O O
( O O
d O O
( O O
x O O
, O O
y O O
) O O
− O O
d O O
( O O
x O O
+ O O
1 O O
, O O
y O O
) O O
) O O
+ O O
ρ O O
( O O
d O O
( O O
x O O
, O O
y O O
) O O
− O O
d O O
( O O
x O O
, O O
y O O
+ O O
1 O O
) O O
) O O
, O O
( O O
11.10 O O
) O O
where O O
ρ O O
is O O
some O O
monotonically O O
increasing O O
function O O
of O O
disparity O O
difference B B
. O O
picture O O
segmentation B B
using O O
a O O
recursive O O
region B B
splitting O O
method O O
. O O
median B B
ﬁltering O O
is O O
used O O
to O O
produce O O
sharp O O
composite O O
layers B B
that O O
are O O
robust B B
to O O
small O O
intensity O O
variations O O
, O O
as O O
well O O
as O O
to O O
infer O O
occlusion O O
relationships O O
between O O
the O O
layers B B
. O O
during O O
the O O
matching B B
structure O O
construction O O
, O O
each O O
8 O O
× O O
8 O O
scaled O B
, O O
oriented B B
, O O
and O O
normalized B B
mops O O
patch B B
is O O
converted O O
into O O
a O O
three-element O O
index O O
by O O
perform- O O
ing O O
sums O O
over O O
different O O
quadrants O O
of O O
the O O
patch B B
( O O
figure O O
4.26 O O
) O O
. O O
2009 O O
) O O
c O O
( O O
cid:13 O O
) O O
2009 O O
springer O O
: O O
( O O
a O O
) O O
successful O O
recognition B B
results O O
; O O
( O O
b O O
) O O
less O O
suc- O O
cessful O O
results O O
. O O
in O O
order B B
to O O
keep O O
the O O
system O O
from O O
jumping O O
around O O
unpredictably O O
, O O
the O O
system O O
will O O
“ O O
freeze O O
” O O
the O O
curve O O
to O O
date O O
( O O
reset O O
the O O
seed O O
point O O
) O O
after O O
a O O
period O O
of O O
inactivity O O
. O O
11.1.2 O O
plane B O
sweep I I
. O O
after O O
each O O
weak O O
classiﬁer O O
( O O
decision B O
stump I O
or O O
hyperplane O O
) O O
is O O
selected O O
, O O
data O O
points O I
that O O
are O O
erroneously O O
classiﬁed O O
have O O
their O O
weights O O
in- O O
creased O O
. O O
for O O
problems O O
where O O
the O O
posterior O B
energy O O
is O O
non-quadratic O O
, O O
e.g. O O
, O O
in O O
non-linear B B
or O O
robustiﬁed O O
least B B
squares I I
, O O
it O O
is O O
still O O
often O O
possible O O
to O O
obtain O O
an O O
estimate O O
of O O
the O O
hessian O O
in O O
the O O
vicinity O O
of O O
the O O
optimal O O
solution O O
. O O
these O O
can O O
provide O O
information O O
complementary O O
to O O
interest O O
points B B
and O O
also O O
serve O O
as O O
useful O O
building O O
blocks O O
for O O
3d O O
modeling B B
and O O
visualization O O
. O O
motion B B
competition O O
: O O
a O O
variational O O
framework O O
for O O
piecewise O O
parametric B B
motion O O
segmentation B B
. O O
the O O
difﬁculty O O
in O O
matching B B
proﬁle O O
curves O O
is O O
that O O
in O O
general O O
, O O
the O O
locations O O
of O O
proﬁle B B
curves O O
vary O O
as O O
a O O
function O O
of O O
camera B B
viewpoint O O
. O O
in O O
fact O O
, O O
all O O
of O O
the O O
parametric B B
transforms O O
listed O O
in O O
table O O
3.5 O O
have O O
closed O O
form O O
solutions O O
for O O
the O O
inverse B B
transform O O
: O O
simply O O
take O O
the O O
inverse B B
of O O
the O O
3 O O
× O O
3 O O
matrix O O
specifying O O
the O O
transform B B
. O O
in O O
fact O O
, O O
one O O
of O O
the O O
two O O
variants O O
of O O
belief O B
prop- O O
agation O O
, O O
the O O
max-product O O
rule O O
, O O
performs O O
the O O
exact O O
same O O
computation O O
( O O
inference B B
) O O
as O O
dynamic B B
programming I I
, O O
albeit O O
using O O
probabilities O O
instead O O
of O O
energies O O
. O O
since O O
the O O
seam B O
selection I O
is O O
performed O O
sequentially O O
as O O
new O O
images O O
are O O
added O O
in O O
, O O
some O O
artifacts O O
can O O
occur O O
. O O
( O O
the O O
image B B
on O O
the O O
right O O
is O O
scaled O B
up O O
for O O
better O O
visibility B B
. O O
2.2.2 O O
reﬂectance B B
and O O
shading B B
. O O
figure O O
13.6d O O
shows O O
the O O
results O O
of O O
applying O O
such O O
a O O
two-pass O O
rendering B O
algorithm O O
. O O
) O O
in O O
order B B
to O O
add O O
a O O
scale B O
selection I I
mechanism O O
to O O
the O O
harris O O
corner O O
detector O O
, O O
mikolajczyk O O
and O O
schmid O O
( O O
2004 O O
) O O
evaluate O O
the O O
laplacian O O
of O O
gaussian O O
function O O
at O O
each O O
detected O O
harris O O
point O O
( O O
in O O
a O O
multi-scale O O
pyramid B B
) O O
and O O
keep O O
only O O
those O O
points B B
for O O
which O O
the O O
laplacian O O
is O O
extremal O O
( O O
larger O O
or O O
smaller O O
than O O
both O O
its O O
coarser O O
and O O
ﬁner-level O O
values O O
) O O
. O O
direct B B
recovery O B
of O O
shape O O
from O O
multiple B B
in O O
twelfth O O
international O O
conference O O
on O O
pattern O O
views O O
: O O
a O O
parallax O O
based O O
approach O O
. O O
11.3 O O
dense B O
correspondence I I
while O O
sparse B B
matching O I
algorithms O O
are O O
still O O
occasionally O O
used O O
, O O
most O O
stereo B B
matching I I
algo- O O
rithms O O
today O O
focus B B
on O O
dense B B
correspondence I I
, O O
since O O
this O O
is O O
required O O
for O O
applications O O
such O O
as O O
image-based B B
rendering I I
or O O
modeling B B
. O O
the O O
partial O O
surface B B
models O O
obtained O O
using O O
such O O
techniques O O
( O O
or O O
passive O O
image-based B B
stereo O O
) O O
can O O
then O O
be O O
merged O O
into O O
more O O
coherent O O
3d O O
surface B B
models O O
( O O
figure O O
12.1e O O
) O O
, O O
as O O
discussed O O
in O O
section O O
12.2.1. O O
such O O
techniques O O
have O O
been O O
used O O
to O O
construct O O
highly O O
detailed O O
and O O
accurate O O
models O O
of O O
cultural O O
heritage O O
such O O
as O O
historic O O
sites O O
( O O
section O O
12.2.2 O O
) O O
. O O
2. O O
database O O
construction O O
( O O
off-line O O
) O O
( O O
a O O
) O O
compute O O
term O O
frequencies O O
for O O
the O O
visual O O
word O O
in O O
each O O
image B B
, O O
document O O
fre- O O
quencies O O
for O O
each O O
word O O
, O O
and O O
normalized B B
tf-idf O O
vectors O O
for O O
each O O
document O O
. O O
for O O
a O O
desktop O O
application O O
, O O
a O O
grid O O
of O O
dots O O
printed O O
on O O
a O O
mouse O O
pad O O
can O O
be O O
tracked O O
by O O
a O O
camera B B
embedded O O
in O O
an O O
augmented O O
mouse O O
to O O
give O O
the O O
user O O
control O O
of O O
a O O
full O O
six O O
degrees O O
of O O
freedom O O
over O O
their O O
position O O
and O O
orientation O O
in O O
a O O
3d O O
space O O
( O O
hinckley O O
, O O
sinclair O O
, O O
hanson O O
et O O
al O O
. O O
8.1 O O
translational B B
alignment O O
397 O O
uncertainty B B
modeling I O
. O O
if O O
both O O
curves O O
are O O
normalized B B
to O O
unit O O
length O O
, O O
s O O
∈ O O
[ O O
0 O O
, O O
1 O O
] O O
and O O
centered O O
around O O
their O O
centroid O O
x0 O O
, O O
they O O
will O O
have O O
the O O
same O O
descriptor O O
up O O
to O O
an O O
overall O O
“ O O
temporal O O
” O O
shift O O
( O O
due O O
to O O
different O O
starting O O
points B B
for O O
s O O
= O O
0 O O
) O O
and O O
a O O
phase O O
( O O
x-y O O
) O O
shift O O
( O O
due O O
to O O
rotation O O
) O O
. O O
unfortunately O O
, O O
shape O O
from O O
shading B B
is O O
susceptible O O
to O O
local B B
minima O O
in O O
the O O
search O O
space O O
and O O
, O O
like O O
other O O
variational O O
problems O O
that O O
involve O O
the O O
simultaneous O O
estimation B B
of O O
many O O
variables O O
, O O
can O O
also O O
suffer O O
from O O
slow O O
convergence O O
. O O
13.2.1 O O
impostors B O
, O O
sprites B B
, O O
and O O
layers B B
. O O
this O O
can O O
come O O
in O O
particularly O O
handy O O
when O O
setting O O
up O O
multi-view O B
stereo B I
reconstruction O O
algorithms O O
, O O
since O O
it O O
allows O O
us O O
to O O
sweep O O
a O O
series O O
of O O
planes B B
( O O
section O O
11.1.2 O O
) O O
through O O
space O O
with O O
a O O
variable O O
( O O
projective B B
) O O
sampling B B
that O O
best O O
matches O O
the O O
sensed O O
image B B
mo- O O
tions O O
( O O
collins O O
1996 O O
; O O
szeliski O O
and O O
golland O O
1999 O O
; O O
saito O O
and O O
kanade O O
1999 O O
) O O
. O O
detect- O O
ing O O
and O O
matching B B
repeated O O
patterns B O
for O O
automatic B O
geo-tagging O O
in O O
urban O O
environments O O
. O O
overconstrained O O
linear B B
estimation O O
of O O
radial B B
distortion I I
and O O
multi-view B B
geometry O O
. O O
b.5.4 O O
graph B B
cuts I I
. O O
( O O
2.90 O O
) O O
( O O
2.91 O O
) O O
larger O O
exponents O O
ke O O
( O O
or O O
inverse B B
gaussian O O
widths O O
cs O O
) O O
correspond O O
to O O
more O O
specular B B
surfaces O O
with O O
distinct O O
highlights O O
, O O
while O O
smaller O O
exponents O O
better O O
model O O
materials O O
with O O
softer O O
gloss O O
. O O
shape O O
modeling O O
with O O
front O O
propaga- O O
tion B B
. O O
additional O O
optional O O
steps O O
could O O
include O O
: O O
1. O O
compute O O
the O O
detections O O
on O O
a O O
sub-octave O O
pyramid B B
and O O
ﬁnd O O
3d O O
maxima O O
. O O
face B B
detection O O
and O O
localization O O
can O O
also O O
be O O
used O O
in O O
a O O
variety O O
of O O
photo O O
editing O O
applications O O
( O O
in O O
addition O O
to O O
being O O
used O O
in-camera O O
to O O
provide O O
better O O
focus B B
, O O
exposure O O
, O O
and O O
ﬂash B B
settings O O
) O O
. O O
a O O
better O O
strategy B O
in O O
such O O
cases O O
is O O
to O O
simply O O
match O O
the O O
nearest B B
neighbor I I
in O O
feature B B
space O O
. O O
interactive B B
graph O O
cuts O O
for O O
optimal O O
boundary O O
and O O
re- O O
in O O
eighth O O
international O O
conference O O
on O O
gion O O
segmentation B B
of O O
objects O O
in O O
n-d O O
images O O
. O O
2000 O O
) O O
or O O
borrowing O O
pixels O O
from O O
other O O
parts O O
of O O
the O O
image B B
( O O
efros O O
and O O
leung O O
1999 O O
; O O
criminisi O O
, O O
p´erez O O
, O O
and O O
toyama O O
2004 O O
; O O
efros O O
and O O
freeman O O
2001 O O
) O O
. O O
) O O
, O O
handbook O O
of O O
geometric B B
computing O O
, O O
pp O O
. O O
3.4.3 O O
wiener O O
ﬁltering O O
while O O
the O O
fourier O O
transform B B
is O O
a O O
useful O O
tool O O
for O O
analyzing O O
the O O
frequency O O
characteristics O O
of O O
a O O
ﬁlter O O
kernel B B
or O O
image B B
, O O
it O O
can O O
also O O
be O O
used O O
to O O
analyze O O
the O O
frequency O O
spectrum O O
of O O
a O O
whole O O
class O O
of O O
images O O
. O O
in O O
order B B
to O O
do O O
this O O
, O O
however O O
, O O
full O O
hilbert O O
transform B B
pairs O O
need O O
to O O
be O O
used O O
for O O
second-order O O
and O O
higher O O
ﬁlters O O
, O O
as O O
described O O
in O O
( O O
freeman O O
and O O
adelson O O
1991 O O
) O O
. O O
when O O
measuring O O
the O O
effectiveness O O
of O O
image B B
denoising O O
algorithms O O
, O O
it O O
is O O
common O O
to O O
report O O
the O O
results O O
as O O
a O O
peak O O
signal-to-noise O O
ratio O O
( O O
psnr O O
) O O
measurement O O
( O O
2.119 O O
) O O
, O O
where O O
i O O
( O O
x O O
) O O
is O O
the O O
original O O
( O O
noise-free O O
) O O
image B B
and O O
ˆi O O
( O O
x O O
) O O
is O O
the O O
image B B
after O O
denoising O O
; O O
this O O
is O O
for O O
the O O
case O O
where O O
the O O
noisy O O
image B B
has O O
been O O
synthetically O O
generated O O
, O O
so O O
that O O
the O O
clean O O
image B B
is O O
known O O
. O O
because O O
the O O
point O O
samples O O
represent O O
and O O
propagate O O
conditional O O
estimates O O
of O O
the O O
multi-modal O O
density O O
, O O
isard O O
and O O
blake O O
( O O
1998 O O
) O O
dubbed O O
their O O
algorithm B B
condi- O O
tional O O
density O O
propagation O O
or O O
condensation O O
. O O
learning B B
for O O
optical B O
ﬂow I I
using O O
stochastic O O
optimiza- O O
tion B B
. O O
5.5 O O
graph B B
cuts I I
and O O
energy-based B B
methods O O
. O O
3. O O
match O O
features O O
in O O
this O O
area O O
with O O
each O O
new O O
image B B
frame O O
. O O
612 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
( O O
a O O
) O O
( O O
b O O
) O O
( O O
c O O
) O O
figure O O
12.22 O O
estimating O O
the O O
diffuse B B
albedo O O
and O O
reﬂectance B B
parameters O O
for O O
a O O
scanned O O
3d O O
model O O
( O O
sato O O
, O O
wheeler O O
, O O
and O O
ikeuchi O O
1997 O O
) O O
c O O
( O O
cid:13 O O
) O O
1997 O O
acm O O
: O O
( O O
a O O
) O O
set O O
of O O
input O O
images O O
projected O O
onto O O
the O O
model O O
; O O
( O O
b O O
) O O
the O O
complete O O
diffuse B B
reﬂection O O
( O O
albedo O O
) O O
model O O
; O O
( O O
c O O
) O O
rendering B B
from O O
the O O
reﬂectance B B
model O O
including O O
the O O
specular B B
component O O
. O O
references B B
903 O O
steedly O O
, O O
d. O O
, O O
pal O O
, O O
c. O O
, O O
and O O
szeliski O O
, O O
r. O O
( O O
2005 O O
) O O
. O O
projective B B
( O O
uncalibrated O O
) O O
reconstruction O O
. O O
statistical O O
learning B B
techniques O O
started O O
appearing O O
, O O
ﬁrst O O
in O O
the O O
application O O
of O O
principal O O
com- O O
ponent O O
eigenface B O
analysis O O
to O O
face B B
recognition O O
( O O
figure O O
1.9f O O
) O O
( O O
see O O
section O O
14.2.1 O O
and O O
turk O O
and O O
pentland O O
1991a O O
) O O
and O O
linear B B
dynamical O O
systems O O
for O O
curve O O
tracking O O
( O O
see O O
section O O
5.1.1 O O
and O O
blake O O
and O O
isard O O
1998 O O
) O O
. O O
to O O
reconstruct O O
the O O
3d O O
location O O
of O O
an O O
individual O O
edgel O O
, O O
along O O
with O O
its O O
local B B
in-plane O O
normal O O
and O O
curvature O O
, O O
we O O
project O O
the O O
viewing O O
rays O O
corresponding O O
to O O
its O O
neighbors O O
onto O O
the O O
instanta- O O
neous O O
epipolar O B
plane O O
deﬁned O O
by O O
the O O
camera B B
center O O
, O O
the O O
viewing O O
ray O O
, O O
and O O
the O O
camera B B
velocity O O
, O O
as O O
shown O O
in O O
figure O O
11.7a O O
. O O
( O O
in O O
some O O
computer O O
graphics O O
textbooks B B
and O O
systems O O
, O O
normalized B B
device O O
coordinates O O
go O O
from O O
[ O O
−1 O O
, O O
1 O O
] O O
× O O
[ O O
−1 O O
, O O
1 O O
] O O
, O O
which O O
requires O O
the O O
use O O
of O O
two O O
different O O
focal O O
lengths O O
to O O
describe O O
the O O
camera B B
intrinsics O O
( O O
watt O O
1995 O O
; O O
opengl-arb O O
1997 O O
) O O
. O O
a O O
model-based B B
approach O O
for O O
estimating O O
human O O
3d O O
poses O O
ieee O O
transactions O O
on O O
pattern O O
analysis O O
and O O
machine O O
intelligence O O
, O O
in O O
static O O
images O O
. O O
learning B B
with O O
kernels O O
: O O
support B O
vector I I
machines I I
, O O
regularization B B
, O O
optimization O O
and O O
beyond O O
. O O
often O O
, O O
however O O
, O O
we O O
may O O
wish O O
to O O
change O O
the O O
resolution O O
of O O
an O O
image B B
before O O
proceeding O O
further O O
. O O
4.3.1 O O
successive B O
approximation I O
as O O
we O O
saw O O
in O O
section O O
4.2.2 O O
, O O
describing O O
a O O
curve O O
as O O
a O O
series O O
of O O
2d O O
locations O O
xi O O
= O O
x O O
( O O
si O O
) O O
provides O O
a O O
general O O
representation O O
suitable O O
for O O
matching O O
and O O
further O O
processing O O
. O O
temporal O O
motion B B
models I O
for O O
monocular O O
and O O
multiview O O
3d O O
human B O
body I I
tracking O O
. O O
the O O
resulting O O
4 O O
× O O
4 O O
system O O
of O O
equations B B
can O O
be O O
solved O O
to O O
simultaneously O O
estimate O O
the O O
translational B B
displacement O O
update O B
∆u O O
and O O
the O O
bias B O
and I O
gain I O
parameters O B
β O O
and O O
α. O O
a O O
similar O O
formulation O O
can O O
be O O
derived O O
for O O
images O O
( O O
templates O O
) O O
that O O
have O O
a O O
linear B B
appearance I O
variation I O
, O O
i1 O O
( O O
x O O
+ O O
u O O
) O O
≈ O O
i0 O O
( O O
x O O
) O O
+ O O
( O O
cid:88 O O
) O O
j O O
λjbj O O
( O O
x O O
) O O
, O O
( O O
8.46 O O
) O O
where O O
the O O
bj O O
( O O
x O O
) O O
are O O
the O O
basis O O
images O O
and O O
the O O
λj O O
are O O
the O O
unknown O O
coefﬁcients O O
( O O
hager O O
and O O
belhumeur O O
1998 O O
; O O
baker O O
, O O
gross O O
, O O
ishikawa O O
et O O
al O O
. O O
eigenfaces O O
vs. O O
fisher- O O
faces B B
: O O
recognition B B
using O O
class O O
speciﬁc O O
linear B B
projection O O
. O O
feature-based B B
techniques O O
also O O
dominate O O
other O O
recognition B B
tasks O O
, O O
such O O
as O O
scene O O
recognition O O
( O O
zhang O O
, O O
marszalek O O
, O O
lazebnik O O
et O O
al O O
. O O
phase B B
correlation I I
has O O
also O O
been O O
studied O O
by O O
fleet O O
and O O
jepson O O
( O O
1990 O O
) O O
as O O
a O O
method O O
for O O
estimating O O
general O O
optical B B
ﬂow I I
and O O
stereo B B
disparity O O
. O O
12.6.4 O O
whole O O
body B B
modeling O O
and O O
tracking O O
. O O
764 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
figure O O
b.1 O O
graphical O O
model O O
for O O
an O O
n4 O O
neighborhood B B
markov O O
random O O
ﬁeld O O
. O O
once O O
the O O
face B B
and O O
non-face O O
patterns B O
have O O
been O O
pre-processed O O
, O O
sung O O
and O O
poggio O O
( O O
1998 O O
) O O
cluster O O
each O O
of O O
these O O
datasets O O
into O O
six O O
separate O O
clusters O O
using O O
k-means O O
and O O
then O O
ﬁt O O
pca O O
subspaces O O
to O O
each O O
of O O
the O O
resulting O O
12 O O
clusters O O
( O O
figure O O
14.4 O O
) O O
. O O
the O O
process O O
of O O
selecting O O
good O O
features O O
to O O
track O O
is O O
closely O O
related O O
to O O
selecting O O
good O O
features O O
for O O
more O O
general O O
recognition B B
applications O O
. O O
( O O
the O O
one O O
exception O O
to O O
this O O
normalization O O
is O O
the O O
line O O
at O O
inﬁnity O O
˜l O O
= O O
( O O
0 O O
, O O
0 O O
, O O
1 O O
) O O
, O O
which O O
includes O O
all O O
( O O
ideal O O
) O O
points B B
at O O
inﬁnity O O
. O O
10 O O
even O O
for O O
one O O
dimension O O
, O O
if O O
the O O
space O O
is O O
extremely O O
sparse B B
, O O
it O O
may O O
be O O
inefﬁcient O O
. O O
2003 O O
) O O
, O O
as O O
shown O O
in O O
figure O O
12.13. O O
further O O
improvements O O
can O O
be O O
obtained O O
using O O
local O O
sphere O O
ﬁtting O O
( O O
guennebaud O O
and O O
gross O O
2007 O O
) O O
, O O
faster O O
and O O
more O O
accu- O O
rate O O
re-sampling O O
( O O
guennebaud O O
, O O
germann O O
, O O
and O O
gross O O
2008 O O
) O O
, O O
and O O
kernel B B
regression O O
to O O
better O O
tolerate O O
outliers O O
( O O
oztireli O O
, O O
guennebaud O O
, O O
and O O
gross O O
2008 O O
) O O
. O O
we O O
can O O
re-write O O
the O O
gradient O O
of O O
the O O
density O O
function O O
as O O
where O O
the O O
vector O O
g O O
( O O
x O O
− O O
xi O O
) O O
( O O
cid:35 O O
) O O
m O O
( O O
x O O
) O O
, O O
∇f O O
( O O
x O O
) O O
= O O
( O O
cid:34 O O
) O O
( O O
cid:88 O O
) O O
i O O
m O O
( O O
x O O
) O O
= O O
( O O
cid:80 O O
) O O
i O O
xig O O
( O O
x O O
− O O
xi O O
) O O
( O O
cid:80 O O
) O O
i O O
g O O
( O O
x O O
− O O
xi O O
) O O
− O O
x O O
( O O
5.37 O O
) O O
( O O
5.38 O O
) O O
is O O
called O O
the O O
mean B O
shift I I
, O O
since O O
it O O
is O O
the O O
difference B B
between O O
the O O
weighted B B
mean O O
of O O
the O O
neighbors O O
xi O O
around O O
x O O
and O O
the O O
current O O
value O O
of O O
x O O
. O O
chapter O O
12 O O
: O O
3d O O
reconstruction O O
scanalyze O O
: O O
a O O
system O O
for O O
aligning O O
and O O
merging B B
range O O
data O O
, O O
http O O
: O O
//graphics.stanford.edu/ O O
software/scanalyze/ O O
( O O
curless O O
and O O
levoy O O
1996 O O
) O O
. O O
• O O
statistical O O
: O O
use O O
probabilistic B B
models I I
to O O
quantify O O
the O O
prior B B
likelihood O O
of O O
your O O
unknowns O O
and O O
the O O
noisy O O
measurement O O
processes O O
that O O
produce O O
the O O
input O O
images O O
, O O
then O O
infer O O
the O O
best O O
possible O O
estimates O O
of O O
your O O
desired O O
quantities O O
and O O
analyze O O
their O O
resulting O O
uncertainties O O
. O O
1999 O O
) O O
c O O
( O O
cid:13 O O
) O O
1999 O O
ieee O O
: O O
shaded O O
images O O
, O O
( O O
a–b O O
) O O
with O O
light O O
from O O
in O O
front O O
( O O
0 O O
, O O
0 O O
, O O
1 O O
) O O
and O O
( O O
c–d O O
) O O
with O O
light O O
the O O
front O O
right O O
( O O
1 O O
, O O
0 O O
, O O
1 O O
) O O
; O O
( O O
e–f O O
) O O
corresponding O O
shape O O
from O O
shading B B
reconstructions O O
using O O
the O O
technique O O
of O O
tsai O O
and O O
shah O O
( O O
1994 O O
) O O
. O O
7.2 O O
two-frame B B
structure O O
from O O
motion B B
. O O
recent O O
advances O O
in O O
highly O O
accurate O O
real-time O O
stereo B B
matching I I
, O O
however O O
, O O
now O O
make O O
it O O
possible O O
to O O
perform O O
z-keying B B
on O O
regular O O
pcs O O
, O O
enabling O O
desktop O O
videoconferencing O O
applications O O
such O O
as O O
those O O
shown O O
in O O
fig- O O
ure O O
11.14 O O
( O O
kolmogorov O O
, O O
criminisi O O
, O O
blake O O
et O O
al O O
. O O
instead O O
of O O
pre-segmenting O O
the O O
image B B
, O O
zheng O O
, O O
yu O O
, O O
kang O O
et O O
al O O
. O O
( O O
14.15 O O
) O O
this O O
whitening O O
transformation O O
then O O
means O O
that O O
euclidean O O
distances O O
in O O
feature B B
( O O
face B B
) O O
space O O
now O O
correspond O O
directly O O
to O O
log O O
likelihoods O O
( O O
moghaddam O O
, O O
jebara O O
, O O
and O O
pentland O O
2000 O O
) O O
. O O
the O O
advantage O O
of O O
the O O
arc-length O O
parameterization O O
is O O
that O O
it O O
makes O O
matching B B
and O O
processing O O
( O O
e.g. O O
, O O
smoothing B B
) O O
operations O O
much O O
easier O O
. O O
a O O
variety O O
of O O
smoothness B B
and O O
radial B B
symmetry O O
forces O O
are O O
used O O
to O O
constrain O O
the O O
model O O
while O O
it O O
is O O
ﬁtted O O
to O O
image-based B B
silhouette O O
curves O O
. O O
zheng O O
, O O
y. O O
, O O
lin O O
, O O
s. O O
, O O
and O O
kang O O
, O O
s. O O
b. O O
in O O
ieee O O
computer O O
society O O
conference O O
on O O
computer O O
vision O O
and O O
pattern O O
recognition B B
( O O
cvpr O O
’ O O
2006 O O
) O O
, O O
pp O O
. O O
2.3.3 O O
compression B B
. O O
a O O
space-sweep O O
approach O O
to O O
true O O
multi-image O O
matching B B
. O O
( O O
a O O
principled O O
way O O
to O O
do O O
this O O
is O O
to O O
establish O O
a O O
coordinate O O
frame O O
for O O
each O O
plane O O
, O O
e.g. O O
, O O
at O O
one O O
of O O
the O O
feature B B
points O O
, O O
and O O
to O O
use O O
2d O O
in-plane O O
parameterizations O O
for O O
the O O
other O O
points B B
. O O
8.7 O O
exercises O O
425 O O
ex O O
8.6 O O
: O O
motion-based O O
user O O
interaction O O
write O O
a O O
program O O
to O O
compute O O
a O O
low-resolution O O
mo- O O
tion B B
ﬁeld O O
in O O
order B B
to O O
interactively O O
control O O
a O O
simple O O
application O O
( O O
cutler O O
and O O
turk O O
1998 O O
) O O
. O O
( O O
optional O O
) O O
perform O O
a O O
complete O O
bundle B B
adjustment I I
in O O
the O O
rotation O O
matrices O O
and O O
focal O O
length O O
to O O
obtain O O
the O O
highest O O
quality O O
estimate O O
( O O
section O O
9.2.1 O O
) O O
. O O
we O O
also O O
look O O
at O O
special O O
cases O O
that O O
arise O O
when O O
there O O
are O O
higher-level O O
structures O O
, O O
such O O
as O O
lines B B
and O O
planes B B
, O O
in O O
the O O
scene O O
( O O
section O O
7.5 O O
) O O
. O O
more O O
recent O O
approaches O O
have O O
focused O O
on O O
the O O
dense O O
( O O
intensity-based B O
) O O
scanline O O
match- O O
ing O O
problem O O
( O O
belhumeur O O
1996 O O
; O O
geiger O O
, O O
ladendorf O O
, O O
and O O
yuille O O
1992 O O
; O O
cox O O
, O O
hingorani O O
, O O
rao O O
et O O
al O O
. O O
matching B B
strategy O O
and O O
error B O
rates I O
determining O O
which O O
feature B B
matches O O
are O O
reasonable O O
to O O
process O O
further O O
depends O O
on O O
the O O
context B B
in O O
which O O
the O O
matching B B
is O O
being O O
performed O O
. O O
conditional O O
random O O
ﬁelds O O
continue O O
to O O
be O O
widely O O
used O O
and O O
extended O O
for O O
simultaneous O O
recognition B B
and O O
segmentation B B
applications O O
( O O
kumar O O
and O O
hebert O O
2006 O O
; O O
he O O
, O O
zemel O O
, O O
and O O
ray O O
2006 O O
; O O
levin O O
and O O
weiss O O
2006 O O
; O O
verbeek O O
and O O
triggs O O
2007 O O
; O O
yang O O
, O O
meer O O
, O O
and O O
foran O O
2007 O O
; O O
rabi- O O
novich O O
, O O
vedaldi O O
, O O
galleguillos O O
et O O
al O O
. O O
multi-resolution O O
surface B B
modeling O O
from O O
multiple B B
range O O
views O O
. O O
this O O
suggests O O
that O O
it O O
might O O
be O O
prudent O O
before O O
computing O O
a O O
full O O
essential O O
matrix O O
to O O
ﬁrst O O
compute O O
a O O
rotation O O
estimate O O
r O O
using O O
( O O
6.32 O O
) O O
, O O
potentially O O
with O O
just O O
a O O
small O O
number O O
of O O
points B B
, O O
and O O
then O O
compute O O
the O O
residuals O O
after O O
rotating O O
the O O
points B B
before O O
proceeding O O
with O O
a O O
full O O
e O O
computation O O
. O O
6.1.5 O O
3d O O
alignment B B
instead O O
of O O
aligning O O
2d O O
sets O O
of O O
image B B
features O O
, O O
many O O
computer O O
vision O O
applications O O
require O O
the O O
alignment B B
of O O
3d O O
points B B
. O O
3. O O
tone O B
map O I
the O O
resulting O O
high B O
dynamic I I
range I I
( O O
hdr O O
) O O
image B B
back O O
into O O
a O O
displayable O O
gamut O O
. O O
figure O O
a.2b O O
shows O O
a O O
line O O
ﬁtting O O
problem O O
where O O
, O O
in O O
this O O
case O O
, O O
the O O
measurement O O
errors O O
are O O
assumed O O
to O O
be O O
isotropic B O
in O O
( O O
x O O
, O O
y O O
) O O
. O O
while O O
simple O O
linear B B
interpolation O O
can O O
be O O
used O O
( O O
representing O O
rotations O O
as O O
quaternions B O
( O O
section O O
2.1.4 O O
) O O
) O O
, O O
a O O
more O O
pleasing O O
effect O O
is O O
obtained O O
by O O
easing O O
in O O
and O O
easing O O
out O O
the O O
camera B B
parameters O O
, O O
e.g. O O
, O O
using O O
a O O
raised O O
cosine O O
, O O
as O O
well O O
as O O
moving O O
the O O
camera B B
along O O
a O O
more O O
circular O O
trajectory O O
( O O
snavely O O
, O O
seitz O O
, O O
and O O
szeliski O O
2006 O O
) O O
. O O
instead O O
of O O
modeling B B
the O O
4d O O
space O O
of O O
rays O O
emanating O O
from O O
a O O
scene O O
, O O
we O O
now O O
need O O
to O O
model O O
how O O
each O O
pixel O O
in O O
our O O
view O O
of O O
this O O
object O O
refracts O O
incident O O
light O O
coming O O
from O O
its O O
environment O O
. O O
similarly O O
, O O
when O O
correcting O O
for O O
radial O O
distortion O O
( O O
section O O
2.1.6 O O
) O O
, O O
we O O
calibrate O O
the O O
lens O O
by O O
computing O O
for O O
each O O
pixel O O
in O O
the O O
ﬁnal O O
( O O
undistorted O O
) O O
image B B
the O O
corresponding O O
pixel O O
location O O
in O O
the O O
original O O
( O O
distorted O O
) O O
image B B
. O O
( O O
it O O
is O O
often O O
safe O O
for O O
rough O O
3d O O
modeling B B
to O O
assume O O
that O O
the O O
optical O O
center O O
is O O
at O O
the O O
center O O
of O O
the O O
image B B
, O O
that O O
the O O
aspect O O
ratio O O
is O O
1 O O
, O O
and O O
that O O
there O O
is O O
no O O
skew O O
. O O
coded O B
aperture O O
pairs B B
for O O
depth O O
from O O
defocus O O
. O O
today O O
, O O
most O O
image B B
search I O
engines O O
rely O O
mostly O O
on O O
textual O O
keywords O O
found O O
in O O
captions O O
, O O
nearby O O
text O O
, O O
and O O
ﬁlenames O O
, O O
augmented O O
by O O
user O O
click-through O O
data O O
( O O
craswell O O
and O O
szummer O O
2007 O O
) O O
. O O
( O O
b O O
) O O
the O O
actual O O
computation O O
of O O
the O O
high-pass O O
ﬁlter O O
involves O O
ﬁrst O O
interpolating O O
the O O
downsampled O O
low-pass B B
image O O
and O O
then O O
subtracting O O
it O O
. O O
figure O O
8.16 O O
shows O O
the O O
ﬁnal O O
results O O
obtained O O
with O O
this O O
algorithm B B
. O O
a O O
tree O O
topology O O
enables O O
the O O
use O O
of O O
a O O
recursive O O
viterbi O O
( O O
dynamic B B
programming I I
) O O
algorithm B B
( O O
pearl O O
1988 O O
; O O
bishop O O
2006 O O
) O O
, O O
in O O
which O O
leaf O O
nodes O O
are O O
ﬁrst O O
optimized O O
as O O
a O O
function O O
of O O
their O O
parents O O
, O O
and O O
the O O
resulting O O
values O O
are O O
then O O
plugged O O
in O O
and O O
eliminated O O
from O O
the O O
energy O O
function—see O O
ap- O O
pendix O O
b.5.2 O O
. O O
a O O
feature-based B B
, O O
robust B B
, O O
hierarchical B B
algorithm O O
for O O
registering O O
pairs B B
of O O
images O O
of O O
the O O
curved O O
human O O
retina O O
. O O
medical B O
imaging I O
, O O
16 O O
( O O
2 O O
) O O
:199–209 O O
. O O
in O O
the O O
image- O O
processing O O
community O O
, O O
half-octave B O
pyramids O O
combined O O
with O O
checkerboard O O
sampling B B
grids O O
are O O
known O O
as O O
quincunx O O
sampling B B
( O O
feilner O O
, O O
van O O
de O O
ville O O
, O O
and O O
unser O O
2005 O O
) O O
. O O
546 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
for O O
example O O
, O O
local B B
( O O
window-based B B
) O O
algorithms O O
( O O
section O O
11.4 O O
) O O
, O O
where O O
the O O
disparity O O
com- O O
putation O O
at O O
a O O
given O O
point O O
depends O O
only O O
on O O
intensity O O
values O O
within O O
a O O
ﬁnite O O
window O O
, O O
usually O O
make O O
implicit O O
smoothness B B
assumptions O O
by O O
aggregating O O
support O O
. O O
13.5.3 O O
application O O
: O O
animating B B
pictures I I
. O O
) O O
this O O
is O O
the O O
same O O
computation O O
that O O
is O O
performed O O
by O O
freeman O O
and O O
adelson O O
’ O O
s O O
( O O
1991 O O
) O O
ﬁrst-order O O
steerable B B
ﬁlter I O
, O O
which O O
we O O
already O O
covered O O
in O O
section O O
3.2.3. O O
for O O
many O O
applications O O
, O O
however O O
, O O
we O O
wish O O
to O O
thin B O
such O O
a O O
continuous O O
gradient O O
image O O
to O O
only O O
return O O
isolated O O
edges O O
, O O
i.e. O O
, O O
as O O
single O O
pixels O O
at O O
discrete B B
locations O O
along O O
the O O
edge O O
contours O O
. O O
( O O
pixels O O
exactly O O
on O O
the O O
uv O O
plane O O
appear O O
“ O O
vertical O O
” O O
, O O
i.e. O O
, O O
they O O
do O O
not O O
move O O
as O O
the O O
camera B B
moves O O
along O O
s. O O
) O O
furthermore O O
, O O
pixel O O
tracks O O
occlude O O
one O O
another O O
as O O
their O O
corresponding O O
3d O O
surface B B
elements O O
occlude O O
. O O
( O O
eds O O
) O O
, O O
toward O O
category-level O O
object O O
recognition B B
, O O
pp O O
. O O
as O O
we O O
discussed O O
in O O
( O O
section O O
11.3.1 O O
) O O
, O O
a O O
variety O O
of O O
similarity B B
measures O O
can O O
be O O
used O O
to O O
compare O O
pixel O O
values O O
in O O
different O O
images O O
, O O
including O O
measures O O
that O O
try O O
to O O
discount O O
illumination O O
effects O O
or O O
be O O
less O O
sensitive O O
to O O
outliers O O
. O O
in O O
this O O
section O O
, O O
we O O
highlight O O
some O O
of O O
the O O
main O O
ideas O O
, O O
representations O O
, O O
and O O
modeling B B
algo- O O
rithms O O
used O O
for O O
these O O
three O O
cases O O
. O O
scale O O
variant O O
image B B
pyramids O O
. O O
automatic B B
reconstruction O O
of O O
stationary O O
3-d O O
objects O O
from O O
multiple B B
uncalibrated O O
camera B B
views O O
. O O
chakrabarti O O
, O O
scharstein O O
, O O
and O O
zickler O O
( O O
2009 O O
) O O
develop O O
a O O
sophisti- O O
cated O O
24-parameter O O
model O O
that O O
is O O
a O O
good O O
match O O
to O O
the O O
processing O O
performed O O
by O O
today O O
’ O O
s O O
digital O O
cameras O O
; O O
they O O
also O O
provide O O
a O O
database O O
of O O
color B B
images O O
you O O
can O O
use O O
for O O
your O O
own O O
testing.23 O O
for O O
other O O
vision O O
applications O O
, O O
however O O
, O O
such O O
as O O
feature B B
detection O O
or O O
the O O
matching B B
of O O
sig- O O
nals O O
in O O
stereo B B
and O O
motion B B
estimation I I
, O O
this O O
linearization O O
step O O
is O O
often O O
not O O
necessary O O
. O O
n O O
( O O
x|µk O O
, O O
σk O O
) O O
= O O
e−d O O
( O O
x O O
, O O
µk O O
; O O
σk O O
) O O
( O O
5.28 O O
) O O
to O O
iteratively O O
compute O O
( O O
a O O
local B B
) O O
maximum O O
likely O O
estimate O O
for O O
the O O
unknown O O
mixture O O
pa- O O
rameters O O
{ O O
πk O O
, O O
µk O O
, O O
σk O O
} O O
, O O
the O O
expectation O O
maximization O O
( O O
em O O
) O O
algorithm B B
( O O
dempster O O
, O O
laird O O
, O O
and O O
rubin O O
1977 O O
) O O
proceeds O O
in O O
two O O
alternating O O
stages O O
: O O
1. O O
the O O
expectation O O
stage O O
( O O
e O O
step O O
) O O
estimates O O
the O O
responsibilities O O
zik O O
= O O
1 O O
zi O O
πk O O
n O O
( O O
x|µk O O
, O O
σk O O
) O O
with O O
( O O
cid:88 O O
) O O
k O O
zik O O
= O O
1 O O
, O O
( O O
5.29 O O
) O O
which O O
are O O
the O O
estimates O O
of O O
how O O
likely O O
a O O
sample O O
xi O O
was O O
generated O O
from O O
the O O
kth O O
gaussian O O
cluster O O
. O O
the O O
multi-view B B
reconstruction O O
problem O O
can O O
be O O
formulated O O
as O O
the O O
simultaneous O O
estimation B B
of O O
depth O O
maps O O
at O O
key O O
frames O O
( O O
figure O O
8.13c O O
) O O
while O O
maximizing O O
not O O
only O O
photoconsistency B B
and O O
piecewise O O
disparity O O
smoothness B B
but O O
also O O
the O O
consistency O O
between O O
disparity O O
estimates O O
at O O
different O O
frames O O
. O O
2001 O O
; O O
13.2 O O
layered O O
depth O O
images O O
627 O O
figure O O
13.5 O O
a O O
variety O O
of O O
image-based B B
rendering I I
primitives O O
, O O
which O O
can O O
be O O
used O O
depending O O
on O O
the O O
distance O O
between O O
the O O
camera B B
and O O
the O O
object O O
of O O
interest O O
( O O
shade O O
, O O
gortler O O
, O O
he O O
et O O
al O O
. O O
a O O
more O O
direct B B
derivation O O
of O O
the O O
foe O O
estimate O O
can O O
be O O
obtained O O
by O O
minimizing O O
the O O
triple O O
product O O
( O O
( O O
xi0 O O
× O O
xi1 O O
) O O
· O O
e O O
) O O
2 O O
, O O
which O O
is O O
equivalent O O
to O O
ﬁnding O O
the O O
null O O
space O O
for O O
the O O
set O O
of O O
equations B B
( O O
cid:88 O O
) O O
i O O
( O O
xi0 O O
, O O
xi1 O O
, O O
e O O
) O O
2 O O
= O O
( O O
cid:88 O O
) O O
i O O
( O O
yi0 O O
− O O
yi1 O O
) O O
e0 O O
+ O O
( O O
xi1 O O
− O O
xi0 O O
) O O
e1 O O
+ O O
( O O
xi0yi1 O O
− O O
yi0xi1 O O
) O O
e2 O O
= O O
0 O O
. O O
456098127132133137133466598123126128131133476596115119123135137476391107113122138134505980971101231331344953688397113128133505058708410211612650505258698610112013579111315s1s2s3s4s5s6s7s8s9s10s11s12s13s14s15s16020406080100120140160rangedomaindomain O O
104 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
bias B O
and I O
gain I O
parameters O B
can O O
also O O
be O O
spatially O O
varying O O
, O O
g O O
( O O
x O O
) O O
= O O
a O O
( O O
x O O
) O O
f O O
( O O
x O O
) O O
+ O O
b O O
( O O
x O O
) O O
, O O
( O O
3.4 O O
) O O
e.g. O O
, O O
when O O
simulating O O
the O O
graded O O
density O O
ﬁlter O O
used O O
by O O
photographers O O
to O O
selectively O O
darken O O
the O O
sky O O
or O O
when O O
modeling B B
vignetting O O
in O O
an O O
optical O B
system O O
. O O
the O O
ﬁnal O O
desired O O
value O O
for O O
v O O
is O O
computed O O
as O O
the O O
least O B
eigenvector O O
of O O
m. O O
pi1pi0vmi^d1a O O
4.4 O O
additional O O
reading O O
257 O O
while O O
the O O
technique O O
described O O
above O O
proceeds O O
in O O
two O O
discrete O O
stages O O
, O O
better O O
results O O
may O O
be O O
obtained O O
by O O
alternating O O
between O O
assigning O O
lines B B
to O O
vanishing B B
points I I
and O O
reﬁtting O O
the O O
van- O O
ishing O O
point O O
locations O O
( O O
antone O O
and O O
teller O O
2002 O O
; O O
koˇseck´a O O
and O O
zhang O O
2005 O O
; O O
pﬂugfelder O O
2008 O O
) O O
. O O
12 O O
in O O
some O O
applications O O
, O O
you O O
can O O
use O O
the O O
exif O O
tags O O
associated O O
with O O
a O O
jpeg O O
image B B
to O O
obtain O O
a O O
rough O O
estimate O O
of O O
a O O
camera B B
’ O O
s O O
focal O O
length O O
but O O
this O O
technique O O
should O O
be O O
used O O
with O O
caution O O
as O O
the O O
results O O
are O O
often O O
inaccurate O O
. O O
( O O
such O O
a O O
transformation O O
is O O
called O O
parametric B B
because O O
it O O
is O O
controlled O O
by O O
a O O
small O O
number O O
of O O
parameters B B
. O O
in O O
ieee O O
computer O O
society O O
conference O O
on O O
computer O O
vision O O
and O O
pattern O O
recognition B B
( O O
cvpr O O
’ O O
2005 O O
) O O
, O O
pp O O
. O O
as O O
you O O
can O O
see O O
from O O
table O O
6.2 O O
, O O
the O O
number O O
of O O
trials O O
grows O O
quickly O O
with O O
the O O
number O O
of O O
sample O O
points B B
used O O
. O O
( O O
2.6 O O
) O O
quadric O O
equations B B
play O O
useful O O
roles O O
in O O
the O O
study O O
of O O
multi-view B B
geometry O O
and O O
camera B B
calibra- O O
tion B B
( O O
hartley O O
and O O
zisserman O O
2004 O O
; O O
faugeras O O
and O O
luong O O
2001 O O
) O O
but O O
are O O
not O O
used O O
extensively O O
in O O
this O O
book O O
. O O
distance O O
transforms O O
: O O
properties B B
and O O
machine O O
vision O O
applications O O
. O O
an O O
interesting O O
application O O
that O O
is O O
closer O O
to O O
computer O O
animation O O
and O O
visual B B
effects I I
is O O
ro- O O
toscoping O O
, O O
which O O
uses O O
the O O
tracked O O
contours O O
to O O
deform O O
a O O
set O O
of O O
hand-drawn O O
animations O O
( O O
or O O
to O O
modify O O
or O O
replace O O
the O O
original O O
video B B
frames O O
) O O
.7 O O
agarwala O O
, O O
hertzmann O O
, O O
seitz O O
et O O
al O O
. O O
the O O
early O O
work O O
in O O
simultaneously O O
recovering O O
3d O O
structure O O
and O O
camera B B
motion O O
( O O
see O O
chapter O O
7 O O
) O O
also O O
began O O
around O O
this O O
time O O
( O O
ullman O O
1979 O O
; O O
longuet-higgins O O
1981 O O
) O O
. O O
ex O O
7.3 O O
: O O
view B O
morphing I I
and O O
interpolation B B
implement O O
automatic B B
view O O
morphing B I
, O O
i.e. O O
, O O
com- O O
pute O O
two-frame B B
structure O O
from O O
motion B B
and O O
then O O
use O O
these O O
results O O
to O O
generate O O
a O O
smooth O O
anima- O O
tion B B
from O O
one O O
image B B
to O O
the O O
next O O
( O O
section O O
7.2.3 O O
) O O
. O O
in O O
many O O
cases O O
, O O
the O O
small O O
number O O
of O O
spline B B
vertices O O
results O O
in O O
a O O
motion B B
estimation I I
problem O O
that O O
is O O
well O O
conditioned O O
. O O
many O O
algorithms O O
also O O
use O O
more O O
than O O
a O O
single O O
represen- O O
tation O O
, O O
e.g. O O
, O O
they O O
may O O
start O O
by O O
computing O O
multiple B B
depth O O
maps O O
and O O
then O O
merge O O
them O O
into O O
a O O
3d O O
object O O
model O O
( O O
narayanan O O
, O O
rander O O
, O O
and O O
kanade O O
1998 O O
; O O
furukawa O O
and O O
ponce O O
2009 O O
; O O
goesele O O
, O O
curless O O
, O O
and O O
seitz O O
2006 O O
; O O
goesele O O
, O O
snavely O O
, O O
curless O O
et O O
al O O
. O O
as O O
you O O
can O O
see O O
, O O
the O O
attachment O O
points B B
between O O
the O O
ﬁngers O O
and O O
the O O
thumb O O
have O O
two O O
degrees O O
of O O
freedom O O
, O O
while O O
the O O
ﬁnger O O
joints O O
themselves O O
have O O
only O O
one O O
. O O
6. O O
re-insert O O
the O O
smoke B B
or O O
shadow B O
matte O O
, O O
along O O
with O O
any O O
other O O
foreground O O
objects O O
you O O
may O O
have O O
extracted O O
. O O
non-linear B B
gaussian O O
ﬁlters O O
performing O O
edge O O
preserving O O
diffusion O O
. O O
image B B
snapping O O
. O O
boykov O O
and O O
funka-lea O O
( O O
2006 O O
) O O
present O O
a O O
good O O
survey O O
of O O
various O O
energy-based B O
techniques O O
for O O
binary O O
object O O
segmentation B B
. O O
a O O
more O O
efﬁcient O O
algorithm B O
can O O
be O O
obtained O O
by O O
ﬁrst O O
rectifying O O
( O O
i.e O O
, O O
warping O O
) O O
the O O
input O O
images O O
so O O
that O O
corresponding O O
horizontal O O
scanlines O O
are O O
epipolar O O
lines O O
( O O
loop O O
and O O
zhang O O
1999 O O
; O O
faugeras O O
and O O
luong O O
2001 O O
; O O
hartley O O
and O O
zisserman O O
2004 O O
) O O
.2 O O
afterwards O O
, O O
it O O
is O O
possible O O
to O O
match O O
horizontal O O
scanlines O O
independently O O
or O O
to O O
shift O O
images O O
horizontally O O
while O O
computing O O
matching B B
scores O O
( O O
figure O O
11.4 O O
) O O
. O O
the O O
normalized B B
zero O O
image B I
is O O
the O O
result O O
of O O
dividing O O
( O O
normalizing B O
) O O
the O O
blurred O O
zero- O O
padded O O
rgba O O
image B B
by O O
its O O
corresponding O O
soft O O
alpha O O
value O O
. O O
extraction O O
, O O
matching B B
and O O
pose O O
recovery B B
based O O
on O O
dom- O O
inant O O
rectangular O O
structures O O
. O O
the O O
above O O
correlation O O
operator O O
can O O
be O O
more O O
compactly O O
notated O O
as O O
g O O
= O O
f O O
⊗ O O
h. O O
( O O
3.13 O O
) O O
a O O
common O O
variant O O
on O O
this O O
formula O O
is O O
g O O
( O O
i O O
, O O
j O O
) O O
= O O
( O O
cid:88 O O
) O O
k O O
, O O
l O O
f O O
( O O
i O O
− O O
k O O
, O O
j O O
− O O
l O O
) O O
h O O
( O O
k O O
, O O
l O O
) O O
= O O
( O O
cid:88 O O
) O O
k O O
, O O
l O O
f O O
( O O
k O O
, O O
l O O
) O O
h O O
( O O
i O O
− O O
k O O
, O O
j O O
− O O
l O O
) O O
, O O
( O O
3.14 O O
) O O
112 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
figure O O
3.10 O O
neighborhood B B
ﬁltering O O
( O O
convolution O O
) O O
: O O
the O O
image B B
on O O
the O O
left O O
is O O
convolved O O
with O O
the O O
ﬁlter O O
in O O
the O O
middle O O
to O O
yield O O
the O O
image B B
on O O
the O O
right O O
. O O
deformable O O
curve O O
and O O
surface B B
ﬁnite-elements O O
for O O
free-form O O
shape O O
design O O
. O O
photogrammetry B B
& O O
remote O O
sensing O O
, O O
26 O O
( O O
3 O O
) O O
:150–166 O O
. O O
it O O
is O O
then O O
convenient O O
to O O
be O O
able O O
to O O
map O O
from O O
a O O
sensor-based O O
depth O O
or O O
disparity O O
value O O
d O O
directly O O
back O O
to O O
a O O
3d O O
location O O
using O O
the O O
inverse B B
of O O
a O O
4 O O
× O O
4 O O
matrix O O
( O O
section O O
2.1.5 O O
) O O
. O O
in O O
this O O
case O O
, O O
bayesian O O
meth- O O
ods O O
such O O
as O O
mrfs O O
, O O
which O O
can O O
model O O
spatially O O
varying O O
per-pixel O O
measurement O O
noise B B
, O O
can O O
be O O
used O O
instead O O
. O O
9.4 O O
additional O O
reading O O
the O O
literature O O
on O O
image B B
stitching I I
dates O O
back O O
to O O
work O O
in O O
the O O
photogrammetry B B
community O O
in O O
the O O
1970s O O
( O O
milgram O O
1975 O O
, O O
1977 O O
; O O
slama O O
1980 O O
) O O
. O O
figure O O
10.46 O O
shows O O
a O O
result O O
for O O
an O O
even O O
more O O
recent O O
algorithm B B
( O O
rhemann O O
, O O
rother O O
, O O
rav-acha O O
et O O
al O O
. O O
9.2 O O
global B B
alignment I O
pole O O
lies O O
along O O
the O O
optical O O
axis O O
rather O O
than O O
the O O
vertical O O
axis O O
, O O
( O O
cos O O
θ O O
sin O O
φ O O
, O O
sin O O
θ O O
sin O O
φ O O
, O O
cos O O
φ O O
) O O
= O O
s O O
( O O
x O O
, O O
y O O
, O O
z O O
) O O
. O O
3.2.2 O O
examples B B
of O O
linear B B
ﬁltering O O
now O O
that O O
we O O
have O O
described O O
the O O
process O O
for O O
performing O O
linear B B
ﬁltering O O
, O O
let O O
us O O
examine O O
a O O
number O O
of O O
frequently O O
used O O
ﬁlters O O
. O O
consider O O
, O O
for O O
example O O
, O O
ﬁnding O O
a O O
smooth O O
surface B B
that O O
passes O O
through O O
( O O
or O O
near O O
) O O
a O O
set O O
of O O
measured O O
data O O
points O O
( O O
figure O O
3.54 O O
) O O
. O O
( O O
5.9 O O
) O O
this O O
energy O O
derives O O
its O O
name O O
from O O
the O O
fact O O
that O O
, O O
unlike O O
a O O
regular O O
spring O O
, O O
which O O
couples O O
a O O
given O O
snake O O
point O O
to O O
a O O
given O O
constraint B O
( O O
5.6 O O
) O O
, O O
this O O
alternative O O
energy O O
deﬁnes O O
a O O
slippery B O
spring I O
that O O
allows O O
the O O
association O O
between O O
constraints O O
( O O
cities O O
) O O
and O O
curve O O
( O O
tour O O
) O O
points B B
to O O
evolve O O
over O O
time O O
( O O
szeliski O O
1989 O O
) O O
. O O
a O O
topological O O
approach O O
to O O
hierarchical B B
segmentation O O
using O O
in O O
ieee O O
computer O O
society O O
conference O O
on O O
computer O O
vision O O
and O O
pattern O O
mean B B
shift I I
. O O
non-parametric B O
local O B
transforms O O
for O O
computing O O
vi- O O
sual O O
correspondence B B
. O O
in O O
many O O
cases O O
, O O
however O O
, O O
better O O
performance O O
can O O
be O O
obtained O O
by O O
using O O
a O O
non-linear B B
com- O O
bination O O
of O O
neighboring O O
pixels O O
. O O
13.4 O O
environment O O
mattes O O
637 O O
figure O O
13.11 O O
the O O
geometry-image O O
continuum O O
in O O
image-based B B
rendering I I
( O O
kang O O
, O O
szeliski O O
, O O
and O O
anandan O O
2000 O O
) O O
c O O
( O O
cid:13 O O
) O O
2000 O O
ieee O O
. O O
for O O
example O O
, O O
they O O
can O O
be O O
used O O
to O O
track O O
facial O O
features O O
5.1 O O
active B O
contours I I
283 O O
( O O
a O O
) O O
( O O
b O O
) O O
figure O O
5.11 O O
level O O
set O O
segmentation B B
( O O
cremers O O
, O O
rousson O O
, O O
and O O
deriche O O
2007 O O
) O O
c O O
( O O
cid:13 O O
) O O
2007 O O
springer O O
: O O
( O O
a O O
) O O
grayscale O O
image B B
segmentation O O
and O O
( O O
b O O
) O O
color B B
image O O
segmentation B B
. O O
watersheds O O
in O O
digital O O
spaces O O
: O O
an O O
efﬁcient O O
algorithm B B
based O O
on O O
immersion O O
simulations O O
. O O
this O O
is O O
then O O
used O O
to O O
ﬁlter O O
the O O
source O O
image B B
g O O
( O O
x O O
) O O
with O O
a O O
gaussian O O
whose O O
inverse B B
covariance O O
matrix O O
is O O
this O O
ellipsoid O O
. O O
the O O
basic O O
problem O O
is O O
to O O
compute O O
the O O
appropriate O O
pre-ﬁlter O O
, O O
which O O
depends O O
on O O
the O O
distance O O
( O O
and O O
arrangement O O
) O O
between O O
neighboring O O
samples O O
in O O
a O O
source O O
image B B
. O O
fast O O
texture O B
segmentation B O
using O O
the O O
shape O O
operator O O
and O O
active O O
contour O O
. O O
local B B
invariant O O
feature B B
detectors O O
. O O
6.3 O O
geometric B B
intrinsic O O
calibration B B
. O O
let O O
us O O
also O O
assume O O
a O O
simpliﬁed O O
form O O
for O O
the O O
calibration B B
matrix I O
k O O
where O O
only O O
the O O
focal O O
length O O
is O O
unknown O O
( O O
2.59 O O
) O O
. O O
scene B O
representation I O
. O O
7.3.2 O O
application O O
: O O
sparse B B
3d O O
model O O
extraction O O
once O O
a O O
multi-view B O
3d O O
reconstruction O O
of O O
the O O
scene O O
has O O
been O O
estimated O O
, O O
it O O
then O O
becomes O O
possi- O O
ble O O
to O O
create O O
a O O
texture-mapped O O
3d O O
model O O
of O O
the O O
object O O
and O O
to O O
look O O
at O O
it O O
from O O
new O O
directions O O
. O O
in O O
order B B
to O O
avoid O O
cracks O O
in O O
the O O
resulting O O
motion B B
ﬁeld O I
( O O
fig- O O
408 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
( O O
a O O
) O O
( O O
b O O
) O O
( O O
c O O
) O O
figure O O
8.10 O O
elastic O O
brain O O
registration B B
( O O
kybic O O
and O O
unser O O
2003 O O
) O O
c O O
( O O
cid:13 O O
) O O
2003 O O
ieee O O
: O O
( O O
a O O
) O O
original O O
brain O O
atlas O O
and O O
patient O O
mri O O
images O O
overlaid O O
in O O
red–green O O
; O O
( O O
b O O
) O O
after O O
elastic O O
registration O B
with O O
eight O O
user-speciﬁed O O
landmarks O O
( O O
not O O
shown O O
) O O
; O O
( O O
c O O
) O O
a O O
cubic B B
b-spline O O
deformation O O
ﬁeld O O
, O O
shown O O
as O O
a O O
deformed O O
grid O O
. O O
10 O O
computational O O
photography O O
469 O O
stitching O O
multiple B B
images O O
into O O
wide O O
ﬁeld O O
of O O
view O O
panoramas O O
, O O
which O O
we O O
covered O O
in O O
chapter O O
9 O O
, O O
allows O O
us O O
create O O
photographs O O
that O O
could O O
not O O
be O O
captured O O
with O O
a O O
regular O O
camera B B
. O O
poisson O O
image B B
editing O O
. O O
evaluate O O
your O O
algorithm B B
by O O
running O O
it O O
on O O
the O O
middlebury O O
stereo B B
data O O
sets O I
. O O
( O O
a O O
) O O
( O O
b O O
) O O
figure O O
12.18 O O
head B B
and O O
expression O O
tracking O O
and O O
re-animation O O
using O O
deformable O O
3d O O
models O O
. O O
real-time O O
rendering B B
. O O
the O O
radial B B
trifocal O O
tensor O O
: O O
a O O
tool O O
for O O
calibrating O O
the O O
radial B B
distortion I I
of O O
wide-angle O O
cameras O O
. O O
while O O
the O O
original O O
view B O
interpolation I I
paper O O
describes O O
how O O
to O O
generate O O
novel O O
views O O
based O O
on O O
similar O O
pre-computed O B
( O O
linear B B
perspective O O
) O O
images O O
, O O
the O O
plenoptic O O
modeling B B
paper O O
of O O
mcmil- O O
lan O O
and O O
bishop O O
( O O
1995 O O
) O O
argues O O
that O O
cylindrical B B
images O O
should O O
be O O
used O O
to O O
store O O
the O O
pre-computed O O
rendering B I
or O O
real-world O O
images O O
. O O
) O O
in O O
this O O
case O O
, O O
the O O
eigenvalues B B
can O O
be O O
both O O
positive O O
and O O
negative.2 O O
λ0 O O
≥ O O
λ1 O O
≥ O O
··· O O
≥ O O
λn−1 O O
( O O
a.7 O O
) O O
a O O
special O O
case O O
of O O
the O O
symmetric O O
matrix O O
c O O
occurs O O
when O O
it O O
is O O
constructed O O
as O O
the O O
sum O O
of O O
a O O
number O O
of O O
outer O O
products O O
aiat O O
i O O
= O O
aat O O
, O O
( O O
a.8 O O
) O O
c O O
= O O
( O O
cid:88 O O
) O O
i O O
which O O
often O O
occurs O O
when O O
solving O O
least B B
squares I I
problems O O
( O O
appendix O O
a.2 O O
) O O
, O O
where O O
the O O
matrix O O
a O O
consists O O
of O O
all O O
the O O
ai O O
column O O
vectors O O
stacked O O
side-by-side O O
. O O
both O O
distances O O
can O O
be O O
turned O O
into O O
mahalanobis O O
distances O O
and O O
given O O
probabilistic B B
interpretations O O
. O O
the O O
ﬁrst O O
, O O
which O O
is O O
often O O
called O O
regularization B B
or O O
variational O O
methods O O
( O O
section O O
3.7.1 O O
) O O
, O O
con- O O
structs O O
a O O
continuous O O
global B B
energy O O
function O O
that O O
describes O O
the O O
desired O O
characteristics O O
of O O
the O O
solution O O
and O O
then O O
ﬁnds O O
a O O
minimum O O
energy O O
solution O O
using O O
sparse O O
linear B O
systems O O
or O O
related O O
iterative B B
techniques O O
. O O
seam O O
penalties O O
are O O
widely O O
used O O
in O O
other O O
computer O O
vision O O
applications O O
such O O
as O O
stereo B B
matching I I
( O O
boykov O O
, O O
veksler O O
, O O
and O O
zabih O O
2001 O O
) O O
to O O
give O O
the O O
labeling O O
function O O
its O O
coherence O O
or O O
smoothness B B
. O O
figure O O
3.45 O O
shows O O
a O O
few O O
ex- O O
fxhffghghhgxfxgxyxsimilarityeuclideanaffineprojectivetranslation O O
164 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
transformation O O
matrix O O
# O O
dof O O
preserves O O
icon O O
translation B B
rigid O O
( O O
euclidean O O
) O O
similarity B B
afﬁne O O
projective B B
( O O
cid:104 O O
) O O
i O O
t O O
( O O
cid:105 O O
) O O
2×3 O O
( O O
cid:104 O O
) O O
r O O
t O O
( O O
cid:105 O O
) O O
2×3 O O
( O O
cid:104 O O
) O O
sr O O
t O O
( O O
cid:105 O O
) O O
2×3 O O
( O O
cid:104 O O
) O O
a O O
( O O
cid:105 O O
) O O
2×3 O O
( O O
cid:104 O O
) O O
˜h O O
( O O
cid:105 O O
) O O
3×3 O O
2 O O
3 O O
4 O O
6 O O
8 O O
orientation O O
lengths O O
angles O O
 O O
ss O O
ss O O
 O O
 O O
s O O
s O O
 O O
 O O
 O O
straight O O
lines B B
`` O O
parallelism O O
table O O
3.5 O O
hierarchy B B
of O O
2d O O
coordinate B B
transformations I I
. O O
the O O
resulting O O
b-snake O O
can O O
be O O
written O O
as O O
f O O
( O O
s O O
) O O
= O O
( O O
cid:88 O O
) O O
k O O
bk O O
( O O
s O O
) O O
xk O O
f O O
= O O
bx O O
or O O
in O O
discrete B B
form O O
as O O
with O O
f O O
= O O
f O O
t O O
( O O
0 O O
) O O
... O O
f O O
t O O
( O O
n O O
) O O
 O O
, O O
b O O
= O O
b0 O O
( O O
s0 O O
) O O
... O O
b0 O O
( O O
sn O O
) O O
. O O
an O O
evaluation B B
of O O
some O O
of O O
the O O
best O O
performing O O
recognition B B
algorithms O O
can O O
be O O
found O O
on O O
the O O
pascal O O
visual O O
object O O
classes O O
( O O
voc O O
) O O
challenge O O
web O O
site O O
at O O
http O O
: O O
//pascallin.ecs.soton.ac.uk/challenges/voc/ O O
. O O
the O O
term O O
“ O O
dc O O
” O O
comes O O
from O O
“ O O
direct B B
current O O
” O O
, O O
i.e. O O
, O O
the O O
non-sinusoidal O O
or O O
non-alternating O O
part O O
of O O
a O O
signal O O
. O O
an O O
alternative O O
approach O O
to O O
global B B
optimization I I
is O O
to O O
sweep O O
through O O
the O O
3d O O
volume O O
while O O
computing O O
both O O
photoconsistency B B
and O O
visibility B B
simultaneously O O
. O O
2010 O O
) O O
, O O
can O O
require O O
solving O O
non-linear B O
least O O
squares O O
problems O O
with O O
millions O O
of O O
measurements O O
( O O
feature B B
matches O O
) O O
and O O
tens O O
of O O
thousands O O
of O O
unknown O O
parameters B B
( O O
3d O O
point O O
positions O O
and O O
cam- O O
era O O
poses O O
) O O
. O O
templates O O
for O O
the O O
solution O O
of O O
linear B B
systems O O
, O O
http O O
: O O
//www.netlib.org/linalg/html O O
templates/ O O
templates.html O O
( O O
barrett O O
, O O
berry O O
, O O
chan O O
et O O
al O O
. O O
5.3.1 O O
k-means B B
and O O
mixtures O O
of O O
gaussians O O
while O O
k-means B B
implicitly O O
models O O
the O O
probability O O
density O O
as O O
a O O
superposition B B
of O O
spherically O O
symmetric O O
distributions O O
, O O
it O O
does O O
not O O
require O O
any O O
probabilistic B B
reasoning O O
or O O
modeling B B
( O O
bishop O O
2006 O O
) O O
. O O
the O O
log-luminance O O
image B B
is O O
differentiated O O
to O O
obtain O O
a O O
gradient O B
image O O
this O O
gradient O O
image O O
is O O
then O O
attenuated O O
by O O
a O O
spatially O O
varying O O
attenuation O O
function O O
φ O O
( O O
x O O
, O O
y O O
) O O
, O O
h O O
( O O
cid:48 O O
) O O
( O O
x O O
, O O
y O O
) O O
= O O
∇h O O
( O O
x O O
, O O
y O O
) O O
. O O
in O O
image B B
understanding O O
workshop O O
, O O
pp O O
. O O
2004 O O
) O O
c O O
( O O
cid:13 O O
) O O
2004 O O
ieee O O
; O O
( O O
g O O
) O O
simultaneous O O
recognition B B
and O O
segmentation B B
( O O
shotton O O
, O O
winn O O
, O O
rother O O
et O O
al O O
. O O
many O O
of O O
these O O
techniques O O
take O O
the O O
results O O
of O O
the O O
sparse B B
feature O I
matching B B
and O O
structure B O
from I I
motion I I
computation O O
and O O
then O O
compute O O
dense O O
3d O O
surface B B
models O O
using O O
multi-view O O
stereo B B
techniques O O
( O O
section O O
11.6 O O
) O O
( O O
koch O O
, O O
pollefeys O O
, O O
and O O
van O O
gool O O
2000 O O
; O O
pollefeys O O
and O O
van O O
gool O O
2002 O O
; O O
pollefeys O O
, O O
nist´er O O
, O O
frahm O O
et O O
al O O
. O O
note O O
how O O
the O O
detail O O
layer O O
has O O
visible O O
halos B B
around O O
the O O
high- O O
contrast O O
edges O O
, O O
which O O
are O O
visible O O
in O O
the O O
ﬁnal O O
tone-mapped O O
image B B
. O O
deformable O O
models O O
in O O
medical B B
image I I
analysis O O
: O O
a O O
survey O O
. O O
we O O
can O O
now O O
write O O
˜xji O O
= O O
m O O
jpi O O
, O O
( O O
7.42 O O
) O O
10 O O
in O O
this O O
section O O
, O O
we O O
index O O
the O O
2d O O
point O O
positions O O
as O O
xji O O
instead O O
of O O
xij O O
, O O
since O O
this O O
is O O
the O O
convention O O
adopted O O
by O O
factorization O B
papers O O
( O O
tomasi O O
and O O
kanade O O
1992 O O
) O O
and O O
is O O
consistent O O
with O O
the O O
factorization B B
given O O
in O O
( O O
7.43 O O
) O O
. O O
while O O
projecting O O
multiple B O
patterns O O
usually O O
requires O O
the O O
scene O O
or O O
object O O
to O O
remain O O
still O O
, O O
ad- O O
ditional O O
processing O O
can O O
enable O O
the O O
production O O
of O O
real-time O O
depth O O
maps O O
for O O
dynamic O O
scenes O O
. O O
in O O
principle O O
, O O
we O O
could O O
apply O O
a O O
face B B
recognition O O
algorithm B B
at O O
every O O
pixel O O
and O O
scale O O
( O O
moghaddam O O
and O O
pentland O O
1997 O O
) O O
but O O
such O O
a O O
process O O
would O O
be O O
too O O
slow O O
in O O
practice O O
. O O
as O O
we O O
continue O O
to O O
capture O O
and O O
manipulate O O
increasingly O O
larger O O
quan- O O
tities O O
of O O
visual O O
data O I
, O O
research O O
into O O
these O O
aspects O O
of O O
image-based B B
modeling O O
and O O
rendering B B
will O O
continue O O
to O O
evolve O O
. O O
an O O
ade- O O
quate O O
model O O
of O O
3d O O
lines B B
can O O
be O O
obtained O O
by O O
estimating O O
their O O
direction O O
( O O
which O O
may O O
be O O
known O O
ahead O O
of O O
time O O
, O O
e.g. O O
, O O
for O O
architecture O O
) O O
and O O
some O O
point O O
within O O
the O O
visible O O
portion O O
of O O
the O O
line O O
( O O
see O O
section O O
7.5.1 O O
) O O
or O O
by O O
using O O
the O O
two O O
endpoints O O
, O O
since O O
lines B B
are O O
most O O
often O O
visible O O
as O O
ﬁnite O O
line O O
segments O O
. O O
in O O
multi-view B B
stereo I I
, O O
algo- O O
rithms O O
have O O
a O O
choice O O
of O O
computing O O
these O O
measures O O
directly O O
on O O
the O O
surface B B
of O O
the O O
model O O
, O O
i.e. O O
, O O
in O O
scene O O
space O O
, O O
or O O
projecting O O
pixel O O
values O O
from O O
one O O
image B B
( O O
or O O
from O O
a O O
textured O O
model O O
) O O
back O O
into O O
another O O
image B B
, O O
i.e. O O
, O O
in O O
image B B
space O O
. O O
it O O
is O O
easy O O
to O O
show O O
that O O
the O O
two-dimensional B B
kernel O O
k O O
corresponding O O
to O O
successive O O
con- O O
volution O O
with O O
a O O
horizontal O O
kernel B B
h O O
and O O
a O O
vertical O O
kernel B B
v O O
is O O
the O O
outer O O
product O O
of O O
the O O
two O O
kernels O O
, O O
k O O
= O O
vht O O
( O O
3.20 O O
) O O
( O O
see O O
figure O O
3.14 O O
for O O
some O O
examples B B
) O O
. O O
interactive B B
control O O
of O O
avatars O O
animated O O
with O O
human O O
motion B B
data O I
. O O
homogeneous O O
points O I
whose O O
last O O
element O O
is O O
˜w O O
= O O
0 O O
are O O
called O O
ideal O O
points B O
or O O
points B B
at O O
inﬁnity O O
and O O
do O O
not O O
have O O
an O O
equivalent O O
inhomogeneous O O
representation O O
. O O
photometric B B
stereo I I
. O O
notice O O
how O O
all O O
three O O
spectra O O
( O O
color B B
matching O O
functions O O
) O O
now O O
have O O
only O O
positive O O
values O O
and O O
how O O
the O O
¯y O O
( O O
λ O O
) O O
curve O O
matches O O
that O O
of O O
the O O
luminance O O
perceived O O
by O O
humans O O
. O O
splitting B B
the O O
image B B
up O O
into O O
its O O
luminance O O
and O O
chrominance O O
( O O
say O O
, O O
l*a*b* O O
) O O
components O O
( O O
section O O
2.3.2 O O
) O O
, O O
applying O O
the O O
global B B
mapping O O
to O O
the O O
luminance O O
channel O O
, O O
and O O
then O O
reconstituting O O
a O O
color B B
image O O
works O O
better O O
( O O
figure O O
10.20c O O
) O O
. O O
what O O
is O O
needed O O
in O O
this O O
case O O
is O O
to O O
curve O O
the O O
corners O O
of O O
the O O
mouth O O
upwards O O
while O O
leaving O O
the O O
rest O O
of O O
the O O
face B B
intact.19 O O
to O O
perform O O
such O O
a O O
transformation O O
, O O
different O O
amounts O O
of O O
motion B B
are O O
required O O
in O O
different O O
parts O O
of O O
the O O
image B B
. O O
5.1 O O
active B O
contours I I
279 O O
( O O
a O O
) O O
( O O
b O O
) O O
( O O
c O O
) O O
figure O O
5.8 O O
head B B
tracking I O
using O O
condensation O O
( O O
isard O O
and O O
blake O O
1998 O O
) O O
c O O
( O O
cid:13 O O
) O O
1998 O O
springer O O
: O O
( O O
a O O
) O O
sample O O
set O O
representation O O
of O O
head B B
estimate O O
distribution O O
; O O
( O O
b O O
) O O
multiple B B
measure- O O
ments O O
at O O
each O O
control O O
vertex O O
location O O
; O O
( O O
c O O
) O O
multi-hypothesis O O
tracking O O
over O O
time O O
. O O
robust B B
computation O O
of O O
optical B B
ﬂow I I
in O O
a O O
multi-scale O O
differ- O O
ential O O
framework O O
. O O
mishima O O
’ O O
s O O
method O O
produces O O
visible O O
blue O O
spill O O
( O O
color B B
fringing O O
in O O
the O O
hair O O
) O O
, O O
while O O
chuang O O
’ O O
s O O
bayesian O O
matting B B
approach O O
produces O O
accurate O O
results O O
. O O
2003 O O
) O O
and O O
inpainting B B
( O O
bertalmio O O
, O O
sapiro O O
, O O
caselles O O
et O O
al O O
. O O
toboggan-based O O
intelligent B B
scissors I O
with O O
a O O
four O O
parameter O O
edge O O
model O O
. O O
( O O
optional O O
) O O
reﬁne O O
your O O
estimates O O
using O O
an O O
iterative B B
global O I
optimization O I
technique O O
. O O
2009 O O
) O O
, O O
as O O
shown O O
in O O
figure O O
14.33. O O
it O O
is O O
now O O
even O O
possible O O
to O O
automatically O O
associate O O
object O O
tags O O
with O O
images O O
based O O
on O O
their O O
co- O O
occurrence O O
in O O
multiple B B
loosely O O
tagged O O
images O O
( O O
simon O O
and O O
seitz O O
2008 O O
; O O
gammeter O O
, O O
bossard O O
, O O
14.4 O O
category O O
recognition O O
695 O O
figure O O
14.33 O O
automatic B B
mining O O
, O O
annotation O O
, O O
and O O
localization O O
of O O
community O O
photo O O
collec- O O
tions O O
( O O
quack O O
, O O
leibe O O
, O O
and O O
van O O
gool O O
2008 O O
) O O
c O O
( O O
cid:13 O O
) O O
2008 O O
acm O O
. O O
3.6.3 O O
application O O
: O O
feature-based B B
morphing O O
. O O
11.4.1 O O
sub-pixel O O
estimation O B
and O O
uncertainty B B
. O O
the O O
octree B B
construction O O
algorithm B B
proceeds O O
in O O
a O O
coarse-to-ﬁne B B
manner O O
, O O
ﬁrst O O
building O O
an O O
octree B B
at O O
a O O
relatively O O
coarse O O
resolution O O
, O O
and O O
then O O
reﬁning O O
it O O
by O O
revisiting O O
and O O
subdividing O O
all O O
the O O
input O O
images O O
for O O
the O O
gray O O
( O O
mixed O O
) O O
cells O O
whose O O
occupancy O O
has O O
not O O
yet O O
been O O
determined O O
. O O
if O O
the O O
focal O O
plane O O
( O O
vertical O O
zo O O
gray O O
line O O
next O O
to O O
c O O
) O O
is O O
moved O O
forward B B
, O O
the O O
images O O
are O O
no O O
longer O O
in O O
focus B B
and O O
the O O
circle O O
of O O
confusion O O
c O O
( O O
small O O
thick O O
line O O
segments O O
) O O
depends O O
on O O
the O O
distance O O
of O O
the O O
image B B
plane O O
motion B B
∆zi O O
relative O O
to O O
the O O
lens O O
aperture O O
diameter O O
d. O O
the O O
ﬁeld O O
of O O
view O O
( O O
f.o.v O O
. O O
spacetime B B
stereo I O
: O O
shape O O
recovery O O
for O O
dy- O O
namic O O
scenes O O
. O O
for O O
example O O
, O O
we O O
may O O
need O O
to O O
interpolate O O
a O O
small O O
image B B
to O O
make O O
its O O
resolution O O
match O O
that O O
of O O
the O O
output O O
printer O O
or O O
computer O O
screen O O
. O O
a.1 O O
matrix B B
decompositions I I
741 O O
procedure O O
cholesky O O
( O O
c O O
, O O
r O O
) O O
: O O
r O O
= O O
c O O
for O O
i O O
= O O
0 O O
. O O
on O O
the O O
optimization O O
criteria O O
used O O
in O O
two-view O O
motion B B
analysis O O
. O O
in O O
this O O
chapter O O
, O O
we O O
describe O O
some O O
practical O O
approaches O O
to O O
detecting O O
such O O
features O O
and O O
also O O
discuss O O
how O O
feature B B
correspondences O O
can O O
be O O
established O O
across O O
different O O
images O O
. O O
consider O O
the O O
interactive B B
image O O
segmentation B B
problem O O
shown O O
in O O
figure O O
3.61 O O
( O O
boykov O O
and O O
funka-lea O O
2006 O O
) O O
. O O
unfortunately O O
, O O
when O O
such O O
a O O
depth B O
map I I
is O O
warped O O
to O O
a O O
novel O O
view O O
, O O
holes O O
and O O
cracks O O
inevitably O O
appear O O
behind O O
the O O
foreground O O
objects O O
. O O
ex O O
6.3 O O
: O O
2d O O
rigid/euclidean O O
matching B B
several O O
alternative O O
approaches O O
are O O
given O O
in O O
section O O
6.1.3 O O
for O O
estimating O O
a O O
2d O O
rigid O O
( O O
euclidean O O
) O O
alignment B B
. O O
if O O
a O O
smaller O O
calibration B B
rig O O
needs O O
to O O
be O O
used O O
, O O
e.g. O O
, O O
for O O
indoor O O
robotics O O
applications O O
or O O
for O O
mobile O O
robots O O
that O O
carry O O
their O O
own O O
calibration B B
target O O
, O O
it O O
is O O
best O O
if O O
the O O
calibration B B
object O O
can O O
span O O
as O O
much O O
of O O
the O O
workspace O O
as O O
possible O O
( O O
figure O O
6.8a O O
) O O
, O O
as O O
planar O O
targets O O
often O O
fail O O
to O O
accurately O O
predict O O
the O O
components O O
of O O
the O O
pose O O
that O O
lie O O
far O O
away O O
from O O
the O O
plane O O
. O O
5.2.4 O O
graph-based B B
segmentation O O
while O O
many O O
merging B B
algorithms O O
simply O O
apply O O
a O O
ﬁxed O O
rule O O
that O O
groups O O
pixels O O
and O O
regions O O
together O O
, O O
felzenszwalb O O
and O O
huttenlocher O O
( O O
2004b O O
) O O
present O O
a O O
merging B B
algorithm O O
that O O
uses O O
rel- O O
ative O O
dissimilarities O O
between O O
regions O O
to O O
determine O O
which O O
ones O O
should O O
be O O
merged O O
; O O
it O O
produces O O
an O O
algorithm B B
that O O
provably O O
optimizes O O
a O O
global B B
grouping O O
metric O O
. O O
also O O
possible O O
to O O
infer O O
which O O
object O O
in O O
a O O
region B B
of O O
difference B B
is O O
the O O
foreground O O
object O O
by O O
the O O
“ O O
edginess O O
” O O
( O O
pixel O O
differences O O
) O O
across O O
the O O
rod O O
boundary O O
, O O
which O O
should O O
be O O
higher O O
when O O
an O O
object O O
is O O
present O O
( O O
herley O O
2005 O O
) O O
. O O
12.9 O O
exercises O O
617 O O
1. O O
set O O
up O O
two O O
background O O
planes O B
behind O O
the O O
object O O
of O O
interest O O
and O O
calculate O O
their O O
orienta- O O
tion B B
relative O O
to O O
the O O
viewer O O
, O O
e.g. O O
, O O
with O O
ﬁducial O O
marks O O
. O O
after O O
collecting O O
each O O
of O O
the O O
three O O
color B B
values O O
, O O
reverse O O
the O O
bits O O
so O O
that O O
the O O
low-order O O
bits O O
vary O O
the O O
most O O
quickly O O
. O O
( O O
2007 O O
) O O
describe O O
their O O
videotrace O O
system O O
, O O
which O O
performs O O
automated B B
point O O
tracking O O
and O O
3d O O
structure O O
recovery O B
from O I
video B B
and O O
then O O
lets O O
the O O
user O O
draw O O
triangles O O
and O O
surfaces O O
on O O
top O O
of O O
the O O
resulting O O
point O O
cloud O O
, O O
as O O
well O O
as O O
interactively O O
adjusting O O
the O O
locations O O
of O O
model O O
vertices O O
. O O
the O O
matlab O O
image B B
processing O O
toolbox O O
, O O
http O O
: O O
//www.mathworks.com/products/image/ O O
, O O
contains O O
routines O O
for O O
spatial O O
transformations O O
( O O
rotations O O
, O O
resizing O O
) O O
, O O
normalized B B
cross-correla- O O
tion B B
, O O
image B B
analysis O O
and O O
statistics O O
( O O
edges O O
, O O
hough O O
transform B B
) O O
, O O
image B B
enhancement O O
( O O
adaptive B B
histogram O O
equalization O O
, O O
median B O
ﬁltering O O
) O O
and O O
restoration O O
( O O
deblurring O O
) O O
, O O
linear B B
ﬁltering O O
( O O
con- O O
volution O O
) O O
, O O
image B B
transforms O O
( O O
fourier O O
and O O
dct O O
) O O
, O O
and O O
morphological O O
operations O O
( O O
connected B B
components I I
and O O
distance O O
transforms O O
) O O
. O O
examples B B
of O O
octree-based O O
re- O O
construction O O
approaches O O
include O O
those O O
by O O
potmesil O O
( O O
1987 O O
) O O
, O O
noborio O O
, O O
fukada O O
, O O
and O O
arimoto O O
( O O
1988 O O
) O O
, O O
srivasan O O
, O O
liang O O
, O O
and O O
hackwood O O
( O O
1990 O O
) O O
, O O
and O O
szeliski O O
( O O
1993 O O
) O O
. O O
780 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
multi-view B B
evaluation O O
, O O
http O O
: O O
//cvlab.epﬂ.ch/∼strecha/multiview/ O O
( O O
strecha O O
, O O
von O O
hansen O O
, O O
van O O
gool O O
et O O
al O O
. O O
in O O
ieee O O
international O O
conference O O
on O O
image B B
processing O O
( O O
icip O O
’ O O
95 O O
) O O
, O O
pp O O
. O O
ex O O
6.6 O O
: O O
rotation-based O O
calibration B B
take O O
an O O
outdoor O O
or O O
indoor O O
sequence O O
from O O
a O O
rotating O O
camera B B
with O O
very O O
little O O
parallax O O
and O O
use O O
it O O
to O O
calibrate O O
the O O
focal O O
length O O
of O O
your O O
camera B B
using O O
the O O
techniques O O
described O O
in O O
section O O
6.3.4 O O
or O O
sections O O
9.1.3–9.2.1 O O
. O O
as O O
blinn O O
( O O
1994b O O
) O O
shows O O
, O O
the O O
pre-multiplied B O
rgba O O
representation O O
is O O
preferred O O
for O O
several O O
reasons O O
, O O
including O O
the O O
ability O O
to O O
blur O O
or O O
resample O O
( O O
e.g. O O
, O O
rotate O O
) O O
alpha-matted O O
images O O
without O O
any O O
additional O O
complications O O
( O O
just O O
treating O O
each O O
rgba O O
band O O
independently O O
) O O
. O O
these O O
include O O
continuous O O
mathematics O O
, O O
such O O
as O O
signal O O
processing O O
, O O
variational O O
approaches O O
, O O
three-dimensional O O
and O O
projective B B
geometry O O
, O O
linear B B
algebra O O
, O O
and O O
least B B
squares I I
. O O
( O O
2006 O O
) O O
give O O
a O O
nice O O
overview O O
of O O
the O O
three O O
major O O
stages O O
of O O
stabilization O O
, O O
namely O O
motion B B
estimation I I
, O O
motion B B
smoothing O O
, O O
and O O
image B B
warping O O
. O O
figure O O
2.32g–i O O
shows O O
some O O
color B B
ratio O O
images O O
multiplied O O
by O O
the O O
middle O O
gray O O
value O O
for O O
better O O
visual- O O
ization O O
. O O
( O O
2008 O O
) O O
, O O
vanishing O B
point O O
directions O O
are O O
used O O
to O O
guide O O
the O O
user O O
drawing O O
of O O
polygons O O
, O O
which O O
are O O
then O O
automatically O O
ﬁtted O O
to O O
sparse B B
3d O O
points B B
recovered O O
using O O
structure O O
from O O
motion B I
. O O
corresponding O O
patches O O
in O O
different O O
views O O
of O O
the O O
same O O
object O O
, O O
along O O
with O O
their O O
local B B
afﬁne O O
deformations O O
, O O
are O O
used O O
to O O
compute O O
a O O
3d O O
afﬁne B B
model O O
for O O
the O O
object O O
using O O
an O O
extension O O
of O O
the O O
factorization B B
algorithm O O
of O O
section O O
7.3 O O
, O O
which O O
can O O
then O O
be O O
upgraded O O
to O O
a O O
euclidean O O
reconstruction O O
( O O
tomasi O O
and O O
kanade O O
1992 O O
) O O
. O O
112134 O O
228 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
table O O
4.1 O O
the O O
number O O
of O O
matches O O
correctly O O
and O O
incorrectly O O
estimated O O
by O O
a O O
feature B B
matching O O
algorithm B B
, O O
showing O O
the O O
number O O
of O O
true O O
positives O O
( O O
tp O O
) O O
, O O
false O O
positives O O
( O O
fp O O
) O O
, O O
false O O
negatives O O
( O O
fn O O
) O O
and O O
true O O
negatives O O
( O O
tn O O
) O O
. O O
in O O
fact O O
, O O
the O O
low-pass B B
and O O
high-pass O O
ﬁltering O O
operations O O
can O O
be O O
interchanged O O
, O O
e.g. O O
, O O
we O O
could O O
use O O
a O O
ﬁve-tap O O
cubic B O
low-pass O O
ﬁlter O O
on O O
the O O
odd O O
sequence O O
( O O
plus O O
center O O
value O O
) O O
ﬁrst O O
, O O
followed O O
by O O
a O O
four-tap O O
cubic B O
low-pass O O
predictor O O
to O O
estimate O O
the O O
wavelet O O
, O O
although O O
i O O
have O O
not O O
seen O O
this O O
scheme O O
written O O
down O O
. O O
( O O
2.79 O O
) O O
a O O
variety O O
of O O
techniques O O
can O O
be O O
used O O
to O O
estimate O O
the O O
radial B B
distortion I I
parameters O O
for O O
a O O
given O O
lens O O
, O O
as O O
discussed O O
in O O
section O O
6.3.5. O O
sometimes O O
the O O
above O O
simpliﬁed O O
model O O
does O O
not O O
model O O
the O O
true O O
distortions O O
produced O O
by O O
complex O O
lenses O O
accurately O O
enough O O
( O O
especially O O
at O O
very O O
wide O O
angles O O
) O O
. O O
paris O O
and O O
durand O O
( O O
2007 O O
) O O
review O O
a O O
number O O
of O O
other O O
more O O
efﬁcient O O
implementations O O
of O O
mean B B
shift I I
, O O
including O O
their O O
own O O
approach O O
, O O
which O O
is O O
based O O
on O O
using O O
an O O
efﬁcient O O
low-resolution O O
estimate O O
of O O
the O O
complete O O
multi-dimensional O O
space O O
of O O
f O O
( O O
x O O
) O O
along O O
with O O
its O O
stationary O O
points B B
. O O
an O O
alternative O O
technique O O
, O O
described O O
in O O
section O O
10.1.4 O O
, O O
is O O
to O O
look O O
at O O
a O O
calibration B B
pattern O O
( O O
e.g. O O
, O O
one O O
consisting O O
of O O
slanted O O
step O O
edges O O
( O O
reichenbach O O
, O O
park O O
, O O
and O O
narayanswamy O O
1991 O O
; O O
williams O O
and O O
burns O O
2001 O O
; O O
joshi O O
, O O
szeliski O O
, O O
and O O
kriegman O O
2008 O O
) O O
) O O
whose O O
ideal O O
appearance O O
can O O
be O O
re-synthesized O O
to O O
sub-pixel O O
precision O O
. O O
stereo B B
matching I I
with O O
linear B B
superposition O O
of O O
layers B B
. O O
given O O
a O O
euclidean O O
distance O O
metric O O
, O O
the O O
simplest O O
matching B B
strategy O O
is O O
to O O
set O O
a O O
threshold O O
( O O
maximum O O
distance O O
) O O
and O O
to O O
return O O
all O O
matches O O
from O O
other O O
images O O
within O O
this O O
threshold O O
. O O
any O O
matrix O O
of O O
the O O
form O O
lq O O
or O O
qr O O
, O O
where O O
q O O
is O O
a O O
unitary O O
matrix O O
, O O
is O O
a O O
square B B
root I O
of O O
c. O O
742 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
= O O
rt O O
0 O O
c1r0 O O
, O O
which O O
, O O
through O O
recursion O O
, O O
can O O
be O O
turned O O
into O O
c O O
= O O
rt O O
0 O O
. O O
4. O O
replace O O
the O O
original O O
image B B
with O O
an O O
“ O O
advertising O O
” O O
insert O O
, O O
warping O O
the O O
new O O
image B B
with O O
the O O
appropriate O O
homography B B
. O O
recognition B O
( O O
cvpr O O
’ O O
2004 O O
) O O
, O O
pp O O
. O O
2004 O O
) O O
c O O
( O O
cid:13 O O
) O O
2004 O O
ieee O O
: O O
( O O
a O O
) O O
system O O
diagram O O
of O O
video B B
pre-processing O O
; O O
( O O
b O O
) O O
the O O
point O O
grey O O
ladybug O O
camera B B
; O O
( O O
c O O
) O O
ghost O O
removal O O
using O O
multi-perspective O O
plane B O
sweep I I
; O O
( O O
d O O
) O O
point O O
tracking O O
, O O
used O O
both O O
for O O
calibra- O O
tion B B
and O O
stabilization O O
; O O
( O O
e O O
) O O
interactive B B
garden O O
walkthrough O O
with O O
map O O
below O O
; O O
( O O
f O O
) O O
overhead O O
map O O
authoring O O
and O O
sound O O
placement O O
; O O
( O O
g O O
) O O
interactive B B
home O O
walkthrough O O
with O O
navigation O O
bar O O
( O O
top O O
) O O
and O O
icons O O
of O O
interest O O
( O O
bottom O O
) O O
. O O
9.1 O O
motion B B
models I I
9.2 O O
global B B
alignment I O
. O O
to O O
ﬁt O O
a O O
pictorial O O
structure O O
model O O
, O O
a O O
binary O O
silhouette O O
image B B
is O O
ﬁrst O O
computed O O
using O O
background O O
subtraction O O
. O O
for O O
example O O
, O O
frame-rate O O
image B B
alignment O B
is O O
widely O O
used O O
in O O
camcorders O O
and O O
digital O O
cameras O O
to O O
implement O O
their O O
image B B
stabilization O O
( O O
is O O
) O O
feature B B
. O O
mcinerney O O
, O O
t. O O
and O O
terzopoulos O O
, O O
d. O O
for O O
medical O O
image B B
volume O O
segmentation B B
. O O
1. O O
after O O
normalizing B O
face O B
images O O
to O O
a O O
canonical O O
scale O O
and O O
location O O
, O O
manually O O
segment O O
out O O
some O O
of O O
the O O
eye O O
, O O
nose O O
, O O
and O O
face B B
regions O O
. O O
one O O
of O O
the O O
simpler O O
techniques O O
to O O
implement O O
is O O
multi-dimensional O O
hashing B B
, O O
which O O
maps O O
descriptors O O
into O O
ﬁxed O O
size O O
buckets O O
based O O
on O O
some O O
function O O
applied O O
to O O
each O O
descriptor O O
vector O O
. O O
in O O
addition O O
to O O
using O O
a O O
source O O
texture B B
image O O
, O O
texture B B
transfer O O
also O O
takes O O
a O O
reference O O
( O O
or O O
target O O
) O O
image B B
, O O
and O O
tries O O
to O O
match O O
certain O O
characteristics O O
of O O
the O O
target O O
image B B
with O O
the O O
newly O O
synthesized O O
image B O
. O O
( O O
optional O O
) O O
warp O O
the O O
pixels O O
enclosed O O
by O O
the O O
quadrilateral O O
using O O
the O O
correct O O
homography B B
to O O
produce O O
a O O
texture B B
map O O
for O O
each O O
planar O O
polygon O O
. O O
in O O
this O O
case O O
, O O
the O O
trans- O O
lational O O
component O O
of O O
the O O
pose O O
becomes O O
irrelevant O O
and O O
only O O
the O O
camera B B
rotation O O
and O O
intrinsic B B
parameters O O
need O O
to O O
be O O
recovered O O
. O O
because O O
of O O
the O O
linearity B O
of O O
the O O
fourier O O
trans- O O
form O O
, O O
we O O
can O O
write O O
o O O
( O O
ωx O O
, O O
ωy O O
) O O
= O O
s O O
( O O
ωx O O
, O O
ωy O O
) O O
+ O O
n O O
( O O
ωx O O
, O O
ωy O O
) O O
, O O
( O O
3.67 O O
) O O
where O O
each O O
quantity O O
in O O
the O O
above O O
equation B B
is O O
the O O
fourier O O
transform B B
of O O
the O O
corresponding O O
image B B
. O O
in O O
their O O
video B B
google O O
system O O
, O O
afﬁne B B
invariant O O
features O O
are O O
ﬁrst O O
detected O O
in O O
all O O
the O O
video B B
frames O O
they O O
are O O
indexing O O
using O O
both O O
shape O O
adapted O O
regions O O
around O O
harris O O
feature B B
points O O
( O O
schaffalitzky O O
and O O
zisserman O O
2002 O O
; O O
mikolajczyk O O
and O O
schmid O O
2004 O O
) O O
and O O
maximally O O
stable O O
extremal O O
regions O O
( O O
matas O O
, O O
chum O O
, O O
urban O O
et O O
al O O
. O O
the O O
function O O
itself O O
is O O
represented O O
using O O
a O O
quadratic O O
tensor-product O O
b-spline O O
over O O
an O O
octree B B
, O O
which O O
provides O O
a O O
compact O O
representation O O
with O O
larger O O
cells O O
away O O
from O O
the O O
surface B B
or O O
in O O
regions O O
of O O
lower O O
point O O
density O O
, O O
and O O
also O O
admits O O
the O O
efﬁcient O O
solution O O
of O O
the O O
related O O
poisson O O
equations B B
( O O
3.100–3.102 O O
) O O
, O O
see O O
section O O
9.3.4 O O
( O O
p´erez O O
, O O
gangnet O O
, O O
and O O
blake O O
2003 O O
) O O
. O O
we O O
have O O
also O O
studied O O
topics O O
in O O
discrete B B
mathematics O O
and O O
computer O O
science O O
, O O
such O O
as O O
graph O B
algorithms O O
, O O
combinatorial O O
opti- O O
mization O O
, O O
and O O
even O O
database O O
techniques O O
for O O
information O O
retrieval O O
. O O
the O O
new O O
search O O
direction O O
pk+1 O O
is O O
then O O
set O O
to O O
the O O
residual O O
plus O O
β O O
times O O
the O O
old O O
search O O
direction O O
pk O O
, O O
which O O
keeps O O
the O O
directions O O
conjugate O O
with O O
respect O O
to O O
c. O O
it O O
turns O O
out O O
that O O
conjugate B B
gradient I I
descent O I
can O O
also O O
be O O
directly O O
applied O O
to O O
non-quadratic O O
energy O O
functions O O
, O O
e.g. O O
, O O
those O O
arising O O
from O O
non-linear B B
least O O
squares O O
( O O
appendix O O
a.3 O O
) O O
. O O
unfortunately O O
, O O
this O O
representation O O
is O O
not O O
unique O O
, O O
since O O
we O O
can O O
always O O
add O O
a O O
multiple B B
of O O
360◦ O O
( O O
2π O O
radians O O
) O O
to O O
θ O O
and O O
get O O
the O O
same O O
rotation O O
matrix O O
. O O
) O O
to O O
map O O
pixel O O
centers O O
to O O
3d O O
coordinates O O
, O O
we O O
ﬁrst O O
scale O O
the O O
( O O
xs O O
, O O
ys O O
) O O
values O O
by O O
the O O
pixel O O
spacings O O
( O O
sx O O
, O O
sy O O
) O O
( O O
sometimes O O
expressed O O
in O O
microns O O
for O O
solid-state O O
sensors O O
) O O
and O O
then O O
describe O O
the O O
orientation O O
of O O
the O O
sensor B B
array O O
relative O O
to O O
the O O
camera B B
projection O O
center O O
oc O O
with O O
an O O
origin O O
cs O O
and O O
a O O
3d O O
rotation O O
rs O O
( O O
figure O O
2.8 O O
) O O
. O O
building O O
surfaces O O
of O O
evolution B B
: O O
the O O
weaving O O
wall O O
. O O
video B B
indexing O O
based O O
on O O
mosaic O O
representations O O
. O O
180 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
3.7.2 O O
markov O O
random O O
ﬁelds O O
as O O
we O O
have O O
just O O
seen O O
, O O
regularization B B
, O O
which O O
involves O O
the O O
minimization O O
of O O
energy O O
functionals O O
deﬁned O O
over O O
( O O
piecewise O O
) O O
continuous O O
functions O O
, O O
can O O
be O O
used O O
to O O
formulate O O
and O O
solve O O
a O O
variety O O
of O O
low-level O O
computer O O
vision O O
problems O O
. O O
( O O
6.11 O O
) O O
6.1.2 O O
application O O
: O O
panography B B
one O O
of O O
the O O
simplest O O
( O O
and O O
most O O
fun O O
) O O
applications O O
of O O
image B B
alignment O O
is O O
a O O
special O O
form O O
of O O
image B B
stitching I I
called O O
panography B O
. O O
note O O
that O O
when O O
the O O
measurement O O
covariance O O
is O O
isotropic B O
( O O
the O O
same O O
in O O
all O O
directions O O
) O O
, O O
i.e. O O
, O O
when O O
σi O O
= O O
σ2 O O
i O O
i O O
, O O
the O O
likelihood O O
can O O
be O O
written O O
as O O
i O O
l O O
= O O
( O O
cid:89 O O
) O O
i O O
( O O
2πσ2 O O
i O O
) O O
−ni/2 O O
exp O O
( O O
cid:18 O O
) O O
− O O
1 O O
2σ2 O O
i O O
( O O
cid:107 O O
) O O
yi O O
− O O
f O O
i O O
( O O
x O O
) O O
( O O
cid:107 O O
) O O
2 O O
( O O
cid:19 O O
) O O
, O O
( O O
b.9 O O
) O O
where O O
ni O O
is O O
the O O
length O O
of O O
the O O
ith O O
measurement O O
vector O O
yi O O
. O O
the O O
term O O
sprite O O
originates O O
in O O
the O O
computer O O
game O O
industry O O
, O O
where O O
it O O
is O O
used O O
to O O
designate O O
ﬂat O O
animated O O
characters O O
in O O
games O O
such O O
as O O
pac- O O
man O O
or O O
mario O O
bros. O O
when O O
put O O
into O O
a O O
3d O O
setting O O
, O O
such O O
objects O O
are O O
often O O
called O O
impostors B O
, O O
because O O
they O O
use O O
a O O
piece O O
of O O
ﬂat O O
, O O
alpha-matted O O
geometry O O
to O O
represent O O
simpliﬁed O O
versions O O
of O O
3d O O
objects O O
that O O
are O O
far O O
away O O
from O O
the O O
camera B B
( O O
shade O O
, O O
lischinski O O
, O O
salesin O O
et O O
al O O
. O O
in O O
general O O
, O O
the O O
noise B B
need O O
not O O
be O O
gaussian O O
and O O
, O O
in O O
fact O O
, O O
it O O
is O O
usually O O
prudent O O
to O O
assume O O
that O O
some O O
measurements O O
may O O
be O O
outliers O O
. O O
) O O
the O O
interactive B B
rendering O I
system O O
runs O O
in O O
real O O
time O O
using O O
regular O O
graphics O O
hardware O O
. O O
computational O O
vision O O
and O O
regularization B B
theory O O
. O O
energy O O
functions O O
that O O
do O O
not O O
have O O
this O O
problem O O
are O O
called O O
discontinuity-preserving O O
and O O
are O O
based O O
on O O
robust B B
ρ O O
functions O O
( O O
terzopoulos O O
1986b O O
; O O
black O O
and O O
rangarajan O O
1996 O O
) O O
. O O
2003 O O
) O O
or O O
virtual B O
viewpoint I I
video I O
( O O
zitnick O O
, O O
kang O O
, O O
uyttendaele O O
et O O
al O O
. O O
8.4 O O
optical B B
ﬂow I I
. O O
for O O
exam- O O
ple O O
, O O
introducing O O
feature B B
matching O O
early O O
on O O
can O O
be O O
used O O
in O O
a O O
second O O
assignment O O
to O O
do O O
image B B
alignment O O
and O O
stitching O O
. O O
on O O
the O O
motion B B
and O O
appearance O O
of O O
specularities B B
in O O
image B B
sequences O O
. O O
as O O
a O O
result O O
, O O
this O O
makes O O
steerable B B
pyramids O O
a O O
much O O
more O O
useful O O
basis O O
for O O
the O O
structural O O
analysis O O
and O O
matching B B
tasks O O
commonly O O
used O O
in O O
computer O O
vision O O
. O O
in O O
ieee O O
computer O O
society O O
conference O O
on O O
com- O O
puter O O
vision O O
and O O
pattern O O
recognition B B
( O O
cvpr O O
’ O O
2006 O O
) O O
, O O
pp O O
. O O
under O O
certain O O
circumstances O O
, O O
it O O
is O O
possible O O
to O O
recover O O
the O O
global B B
illumination I O
in O O
a O O
scene O O
from O O
photographs O O
using O O
computer O O
vision O O
techniques O O
( O O
yu O O
, O O
debevec O O
, O O
malik O O
et O O
al O O
. O O
2002 O O
) O O
and O O
panoramas O O
with B O
depth I O
( O O
peleg O O
, O O
ben-ezra O O
, O O
and O O
pritch O O
2001 O O
; O O
li O O
, O O
shum O O
, O O
tang O O
et O O
al O O
. O O
) O O
the O O
assumption O O
that O O
corresponding O O
pixel O O
values O O
remain O O
the O O
same O O
in O O
the O O
two O O
images O O
is O O
often O O
called O O
the O O
brightness O O
constancy O O
constraint.2 O O
in O O
general O O
, O O
the O O
displacement O O
u O O
can O O
be O O
fractional O O
, O O
so O O
a O O
suitable O O
interpolation B B
function O O
must O O
be O O
applied O O
to O O
image B B
i1 O O
( O O
x O O
) O O
. O O
x O O
= O O
f O O
tan O O
θ O O
= O O
f O O
tan O O
x O O
( O O
cid:48 O O
) O O
s O O
y O O
= O O
h O O
( O O
cid:112 O O
) O O
x2 O O
+ O O
f O O
2 O O
= O O
y O O
( O O
cid:48 O O
) O O
s O O
, O O
f O O
( O O
cid:113 O O
) O O
1 O O
+ O O
tan2 O O
x O O
( O O
cid:48 O O
) O O
/s O O
= O O
f O O
images O O
can O O
also O O
be O O
projected O O
onto O O
a O O
spherical B B
surface O O
( O O
szeliski O O
and O O
shum O O
1997 O O
) O O
, O O
which O O
is O O
useful O O
if O O
the O O
ﬁnal O O
panorama O O
includes O O
a O O
full O O
sphere O O
or O O
hemisphere O O
of O O
views O O
, O O
instead O O
of O O
just O O
a O O
cylindrical B B
strip O O
. O O
14.4 O O
category O O
recognition O O
699 O O
( O O
a O O
) O O
( O O
b O O
) O O
figure O O
14.37 O O
comparing O O
collections O O
of O O
feature B B
vectors O O
using O O
pyramid O B
matching B B
. O O
( O O
a O O
) O O
( O O
b O O
) O O
rgbrgbrgbrgbrgbrgbrgbrgbrgbrgbrgbrgbrgbrgbrgbrgbbgbggrgrgbgrgrbg O O
504 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
figure O O
10.36 O O
two-color O O
model O O
computed O O
from O O
a O O
collection O O
of O O
local B B
5 O O
× O O
5 O O
neighborhoods O O
( O O
bennett O O
, O O
uyttendaele O O
, O O
zitnick O O
et O O
al O O
. O O
selecting O O
the O O
right O O
window O O
is O O
important O O
, O O
since O O
windows O O
must O O
be O O
large O O
enough O O
to O O
contain O O
sufﬁcient O O
texture B O
and O O
yet O O
small O O
enough O O
so O O
that O O
they O O
do O O
not O O
straddle O O
depth O O
discontinuities O O
( O O
figure O O
11.9 O O
) O O
. O O
plenoptic O O
modeling B B
: O O
an O O
image-based B B
rendering I I
system O O
. O O
the O O
resulting O O
set O O
of O O
linear B B
equations O O
can O O
be O O
solved O O
using O O
least O B
squares O I
, O O
and O O
the O O
quality O O
of O O
the O O
solution O O
( O O
residual O O
error O O
) O O
can O O
be O O
used O O
to O O
check O O
for O O
erroneous O O
correspondences O O
. O O
adaptive B B
shape I O
modeling I B
. O O
generalizing O O
epipolar-plane O O
image B O
analysis O O
on O O
the O O
spatiotemporal O O
surface B O
. O O
even O O
through O O
the O O
representation O O
is O O
overcomplete B O
, O O
i.e. O O
, O O
there O O
are O O
more O O
wavelet O O
co- O O
efﬁcients O O
than O O
input O O
pixels O O
, O O
the O O
additional O O
frequency O O
and O O
orientation O O
selectivity B O
makes O O
this O O
representation O O
preferable O O
for O O
tasks O O
such O O
as O O
texture B B
analysis O O
and O O
synthesis O O
( O O
portilla O O
and O O
simon- O O
celli O O
2000 O O
) O O
and O O
image B B
denoising O O
( O O
portilla O O
, O O
strela O O
, O O
wainwright O O
et O O
al O O
. O O
11.4 O O
local B B
methods I O
549 O O
figure O O
11.8 O O
shiftable B O
window I O
( O O
scharstein O O
and O O
szeliski O O
2002 O O
) O O
c O O
( O O
cid:13 O O
) O O
2002 O O
springer O O
. O O
2006a O O
) O O
, O O
see O O
section O O
10.2.1 O O
, O O
as O O
well O O
as O O
other O O
applications O O
of O O
the O O
weighted B B
least O O
squares O O
( O O
wls O O
) O O
formulation O O
( O O
farbman O O
, O O
fattal O O
, O O
lischinski O O
et O O
al O O
. O O
even O O
more O O
recent O O
work O O
converts O O
high-dimensional O O
descriptor O O
vectors O O
into O O
binary O O
codes O O
that O O
can O O
be O O
compared O O
using O O
hamming O O
distances O O
( O O
torralba O O
, O O
weiss O O
, O O
and O O
fergus O O
2008 O O
; O O
weiss O O
, O O
torralba O O
, O O
and O O
fergus O O
2008 O O
) O O
or O O
that O O
can O O
accommodate O O
arbitrary O O
kernel B B
functions O O
( O O
kulis O O
and O O
grauman O O
2009 O O
; O O
raginsky O O
and O O
lazebnik O O
2009 O O
) O O
. O O
( O O
optional O O
) O O
can O O
you O O
change O O
the O O
direction O O
of O O
the O O
shadow B B
, O O
i.e. O O
, O O
simulate O O
the O O
effect O O
of O O
changing O O
the O O
light O O
source O O
direction O O
? O O
ex O O
10.10 O O
: O O
texture B B
synthesis O O
rithms O O
presented O O
in O O
section O O
10.5. O O
here O O
is O O
one O O
possible O O
procedure O O
: O O
implement O O
one O O
of O O
the O O
texture B B
synthesis O O
or O O
hole B B
ﬁlling I I
algo- O O
1. O O
implement O O
the O O
basic O O
efros O O
and O O
leung O O
( O O
1999 O O
) O O
algorithm B B
, O O
i.e. O O
, O O
starting O O
from O O
the O O
outside O O
( O O
for O O
hole O O
ﬁlling O O
) O O
or O O
in O O
raster O O
order B B
( O O
for O O
texture O O
synthesis O O
) O O
, O O
search O O
for O O
a O O
similar O O
neighbor- O O
hood O O
in O O
the O O
source O O
texture B B
image O O
, O O
and O O
copy O O
that O O
pixel O O
. O O
scale B O
selection I I
and O O
blur O O
estimation O B
as O O
we O O
mentioned O O
before O O
, O O
the O O
derivative O O
, O O
laplacian O O
, O O
and O O
difference B B
of O O
gaussian O O
ﬁlters O O
( O O
4.20– O O
4.23 O O
) O O
all O O
require O O
the O O
selection O O
of O O
a O O
spatial O O
scale O O
parameter O O
σ. O O
if O O
we O O
are O O
only O O
interested O O
in O O
detecting O O
sharp O O
edges O O
, O O
the O O
width O O
of O O
the O O
ﬁlter O O
can O O
be O O
determined O O
from O O
image B B
noise O O
characteris- O O
tics O O
( O O
canny O O
1986 O O
; O O
elder O O
and O O
zucker O O
1998 O O
) O O
. O O
for O O
example O O
, O O
if O O
we O O
know O O
that O O
the O O
motion B B
is O O
due O O
to O O
a O O
camera B B
11other O O
smoothing B B
or O O
aggregation O O
ﬁlters O O
can O O
also O O
be O O
used O O
at O O
this O O
stage O O
( O O
bruhn O O
, O O
weickert O O
, O O
and O O
schn¨orr O O
2005 O O
) O O
. O O
note O O
that O O
we O O
ignore O O
here O O
the O O
possibility O O
of O O
skew O O
between O O
the O O
two O O
axes O O
on O O
the O O
image B B
plane O O
, O O
since O O
solid-state O O
manufacturing O O
techniques O O
render O O
this O O
negligible O O
. O O
however O O
, O O
modeling B B
the O O
visual O O
world O O
in O O
all O O
of O O
its O O
rich O O
complexity O O
is O O
far O O
more O O
difﬁcult O O
than O O
, O O
say O O
, O O
modeling B B
the O O
vocal O O
tract O O
that O O
produces O O
spoken O O
sounds O O
. O O
gradient B O
domain I O
blending O O
. O O
while O O
this O O
approach O O
works O O
well O O
for O O
tens O O
of O O
thousand O O
of O O
visual B O
words I I
and O O
thousands O O
of O O
keyframes O O
, O O
as O O
the O O
size O O
of O O
the O O
database O O
continues O O
to O O
increase O O
, O O
both O O
the O O
time O O
to O O
quantize O O
each O O
feature B B
and O O
to O O
ﬁnd O O
potential O O
matching B B
frames O O
or O O
images O O
can O O
become O O
prohibitive O O
. O O
700 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
( O O
a O O
) O O
( O O
b O O
) O O
( O O
c O O
) O O
( O O
d O O
) O O
( O O
e O O
) O O
figure O O
14.38 O O
a O O
one-dimensional O O
illustration O O
of O O
comparing O O
collections O O
of O O
feature B B
vectors O O
using O O
the O O
pyramid B B
match O O
kernel B B
( O O
grauman O O
and O O
darrell O O
2007b O O
) O O
: O O
( O O
a O O
) O O
distribution O O
of O O
feature B B
vectors O O
( O O
point O O
sets O O
) O O
into O O
the O O
pyramidal O O
bins O O
; O O
( O O
b–c O O
) O O
histogram B B
of O O
point O O
counts O O
in O O
bins O O
bil O O
and O O
b O O
( O O
cid:48 O O
) O O
il O O
for O O
the O O
two O O
images O O
; O O
( O O
d O O
) O O
histogram B B
intersections O O
( O O
minimum O O
values O O
) O O
; O O
( O O
e O O
) O O
per-level O O
similarity B B
scores O O
, O O
which O O
are O O
weighted B B
and O O
summed O O
to O O
form O O
the O O
ﬁnal O O
distance/similarity O O
metric O O
. O O
this O O
technique O O
has O O
been O O
used O O
to O O
produce O O
large O O
numbers O O
of O O
highly O O
accurate O O
registered O O
multi-image O O
stereo B B
pairs O O
and O O
depth O O
maps O O
for O O
the O O
purpose O O
of O O
eval- O O
uating O O
stereo B B
correspondence O O
algorithms O O
( O O
scharstein O O
and O O
szeliski O O
2002 O O
; O O
hirschm¨uller O O
and O O
scharstein O O
2009 O O
) O O
and O O
learning B B
depth O O
map O O
priors O O
and O O
parameters B B
( O O
scharstein O O
and O O
pal O O
2007 O O
) O O
. O O
these O O
include O O
: O O
• O O
stitching O O
: O O
turning O O
overlapping O O
photos O O
into O O
a O O
single O O
seamlessly O O
stitched O O
panorama O O
( O O
fig- O O
ure O O
1.5a O O
) O O
, O O
as O O
described O O
in O O
chapter O O
9 O O
; O O
• O O
exposure O O
bracketing O O
: O O
merging B B
multiple O B
exposures O O
taken O O
under O O
challenging O O
lighting B B
conditions O O
( O O
strong O O
sunlight O O
and O O
shadows O O
) O O
into O O
a O O
single O O
perfectly O O
exposed O O
image B B
( O O
fig- O O
ure O O
1.5b O O
) O O
, O O
as O O
described O O
in O O
section O O
10.2 O O
; O O
• O O
morphing B B
: O O
turning O O
a O O
picture O O
of O O
one O O
of O O
your O O
friends O O
into O O
another O O
, O O
using O O
a O O
seamless O O
morph O O
transition O O
( O O
figure O O
1.5c O O
) O O
; O O
• O O
3d O O
modeling B B
: O O
converting O O
one O O
or O O
more O O
snapshots O O
into O O
a O O
3d O O
model O O
of O O
the O O
object O O
or O O
person O O
you O O
are O O
photographing O O
( O O
figure O O
1.5d O O
) O O
, O O
as O O
described O O
in O O
section O O
12.6 O O
• O O
video B B
match O I
move O O
and O O
stabilization O O
: O O
inserting O O
2d O O
pictures O O
or O O
3d O O
models O O
into O O
your O O
videos O O
by O O
automatically O O
tracking O O
nearby O O
reference O O
points B B
( O O
see O O
section O O
7.4.2 O O
) O O
3 O O
or O O
using O O
motion O O
estimates O O
to O O
remove O O
shake O O
from O O
your O O
videos O O
( O O
see O O
section O O
8.2.1 O O
) O O
; O O
• O O
photo-based O O
walkthroughs B O
: O O
navigating O O
a O O
large O O
collection O O
of O O
photographs O O
, O O
such O O
as O O
the O O
interior O O
of O O
your O O
house O O
, O O
by O O
ﬂying O O
between O O
different O O
photos O O
in O O
3d O O
( O O
see O O
sections O O
13.1.2 O O
and O O
13.5.5 O O
) O O
• O O
face B B
detection O O
: O O
for O O
improved O O
camera B B
focusing O O
as O O
well O O
as O O
more O O
relevant O O
image B B
search- O O
ing O O
( O O
see O O
section O O
14.1.1 O O
) O O
; O O
• O O
visual O O
authentication O O
: O O
automatically O O
logging O O
family O O
members O O
onto O O
your O O
home O O
com- O O
puter O O
as O O
they O O
sit O O
down O O
in O O
front O O
of O O
the O O
webcam O O
( O O
see O O
section O O
14.2 O O
) O O
. O O
discuss O O
whether O O
the O O
weighted B B
summation O O
stage O O
( O O
step O O
3 O O
) O O
needs O O
to O O
keep O O
track O O
of O O
the O O
total B B
weight O O
for O O
renormalization O O
, O O
or O O
whether O O
the O O
math O O
just O O
works O O
out O O
. O O
we O O
must O O
therefore O O
resort O O
to O O
physics-based B O
and O O
prob- O O
abilistic O O
models O O
to O O
disambiguate O O
between O O
potential O O
solutions O O
. O O
a O O
note O O
to O O
students O O
: O O
if O O
you O O
have O O
already O O
studied O O
computer O O
graphics O O
, O O
you O O
may O O
want O O
to O O
skim O O
the O O
material O O
in O O
section O O
2.1 O O
, O O
although O O
the O O
sections O O
on O O
projective B B
depth O O
and O O
object-centered B O
projection O O
near O O
the O O
end O O
of O O
section O O
2.1.5 O O
may O O
be O O
new O O
to O O
you O O
. O O
if O O
you O O
revisited O O
this O O
topic O O
at O O
a O O
later O O
age O O
, O O
you O O
may O O
have O O
learned B B
that O O
the O O
proper O O
subtractive O O
primaries B O
are O O
actually O O
cyan O O
( O O
a O O
light O O
blue-green O O
) O O
, O O
magenta O O
( O O
pink O O
) O O
, O O
and O O
yellow O O
( O O
figure O O
2.27b O O
) O O
, O O
although O O
black O O
is O O
also O O
often O O
used O O
in O O
four-color O O
printing O O
( O O
cmyk O O
) O O
. O O
10.1 O O
photometric B B
calibration O O
471 O O
( O O
a O O
) O O
( O O
b O O
) O O
figure O O
10.2 O O
image B B
sensing O O
pipeline B B
: O O
( O O
a O O
) O O
block O O
diagram O O
showing O O
the O O
various O O
sources O O
of O O
noise B B
as O O
well O O
as O O
the O O
typical O O
digital O O
post-processing O O
steps O O
; O O
( O O
b O O
) O O
equivalent O O
signal O O
transforms O O
, O O
including O O
convolution O O
, O O
gain O O
, O O
and O O
noise B B
injection O O
. O O
13.5.4 O O
3d O O
video B B
. O O
( O O
2.27 O O
) O O
projective B B
. O O
) O O
the O O
for O O
a O O
problem O O
like O O
noise B B
removal I I
, O O
a O O
continuous O O
version O O
of O O
this O O
measure O O
can O O
be O O
used O O
, O O
[ O O
f O O
( O O
xi O O
, O O
yi O O
) O O
− O O
di O O
] O O
2. O O
ed O O
= O O
( O O
cid:88 O O
) O O
i O O
ed O O
= O O
( O O
cid:90 O O
) O O
[ O O
f O O
( O O
x O O
, O O
y O O
) O O
− O O
d O O
( O O
x O O
, O O
y O O
) O O
] O O
2 O O
dx O O
dy O O
. O O
108 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
( O O
a O O
) O O
( O O
d O O
) O O
( O O
b O O
) O O
( O O
e O O
) O O
( O O
c O O
) O O
( O O
f O O
) O O
figure O O
3.7 O O
histogram B B
analysis O O
and O O
equalization O O
: O O
( O O
a O O
) O O
original O O
image B B
( O O
b O O
) O O
color B B
channel O O
and O O
in- O O
tensity O O
( O O
luminance O O
) O O
histograms O O
; O O
( O O
c O O
) O O
cumulative O O
distribution O O
functions O O
; O O
( O O
d O O
) O O
equalization O O
( O O
trans- O O
fer O O
) O O
functions O O
; O O
( O O
e O O
) O O
full O O
histogram B B
equalization O O
; O O
( O O
f O O
) O O
partial O O
histogram B B
equalization O O
. O O
( O O
1992 O O
) O O
introduce O O
such O O
a O O
representation O O
, O O
which O O
they O O
call O O
a O O
pyramidal O O
radial O B
frequency O O
17 O O
such O O
aliasing B B
can O O
often O O
be O O
seen O O
as O O
the O O
signal O O
content O O
moving O O
between O O
bands O O
as O O
the O O
original O O
signal O O
is O O
slowly O O
shifted O O
. O O
iddan O O
and O O
yahav O O
( O O
2001 O O
) O O
describe O O
the O O
construction O O
of O O
their O O
3dv O O
zcam O O
video- O O
rate O O
depth O O
sensing O O
camera B O
, O O
which O O
projects O O
a O O
pulsed O O
plane O O
of O O
light O O
onto O O
the O O
scene O O
and O O
then O O
integrates O O
the O O
returning O O
light O O
for O O
a O O
short O O
interval O B
, O O
essentially O O
obtaining O O
time-of-ﬂight O O
mea- O O
surement O O
for O O
the O O
distance O O
to O O
individual O O
pixels O O
in O O
the O O
scene O O
. O O
in O O
ieee O O
computer O O
society O O
conference O O
on O O
computer O O
vision O O
and O O
pat- O O
tern O O
recognition B B
( O O
cvpr O O
’ O O
2000 O O
) O O
, O O
pp O O
. O O
2009 O O
) O O
c O O
( O O
cid:13 O O
) O O
2009 O O
springer O O
; O O
( O O
h O O
) O O
location B O
recognition I I
( O O
philbin O O
, O O
chum O O
, O O
isard O O
et O O
al O O
. O O
) O O
2d O O
points B B
can O O
also O O
be O O
represented O O
using O O
homogeneous O O
coordinates O O
, O O
˜x O O
= O O
( O O
˜x O O
, O O
˜y O O
, O O
˜w O O
) O O
∈ O O
p O O
2 O O
, O O
where O O
vectors O O
that O O
differ O O
only O O
by O O
scale O O
are O O
considered O O
to O O
be O O
equivalent O O
. O O
de O O
bonet O O
( O O
1997 O O
) O O
uses O O
a O O
coarse-to-ﬁne B B
strategy O O
to O O
ﬁnd O O
locations O O
in O O
the O O
source O O
texture B B
with O O
a O O
similar O O
10.5 O O
texture B O
analysis O O
and O O
synthesis O O
519 O O
radishes O O
( O O
a O O
) O O
lots O O
more O O
radishes O O
( O O
b O O
) O O
rocks O O
yogurt O O
( O O
c O O
) O O
figure O O
10.49 O O
texture B B
synthesis O O
: O O
( O O
a O O
) O O
given O O
a O O
small O O
patch B B
of O O
texture B B
, O O
the O O
task O O
is O O
to O O
synthesize O O
( O O
b O O
) O O
a O O
similar-looking O B
larger O O
patch B B
; O O
( O O
c O O
) O O
other O O
semi-structured O O
textures O O
that O O
are O O
challenging O O
to O O
synthesize O O
. O O
columbia O O
object O O
image B B
library O O
( O O
coil- O O
100 O O
) O O
. O O
in O O
ieee O O
computer O O
society O O
conference O O
on O O
computer O O
vision O O
and O O
pattern O O
recognition B B
( O O
cvpr O O
’ O O
94 O O
) O O
, O O
pp O O
. O O
12.7 O O
recovering O O
texture B B
maps O O
and O O
albedos O O
. O O
to O O
see O O
this O O
, O O
consider O O
the O O
set O O
of O O
all O O
camera B B
matrices O O
p O O
j O O
= O O
kj O O
[ O O
rj|tj O O
] O O
projecting O O
world O O
coordinates O O
pi O O
= O O
( O O
xi O O
, O O
yi O O
, O O
zi O O
, O O
wi O O
) O O
into O O
screen O O
coordinates O O
xij O O
∼ O O
p O O
jpi O O
. O O
new O O
hermite O O
cubic B O
interpolator O O
for O O
two-dimensional O O
curve O O
generation O O
. O O
a O O
stereo B B
machine O O
for O O
video-rate O O
dense O O
depth O O
mapping O O
and O O
its O O
new O O
applications O O
. O O
a O O
maximum O O
likelihood O O
stereo B B
algorithm O O
. O O
if O O
absolute O O
metric O O
accuracy B O
is O O
required O O
, O O
as O O
in O O
photogrammetry B B
applications O O
, O O
it O O
is O O
imperative O O
to O O
pre-calibrate O O
the O O
cameras O O
using O O
one O O
of O O
the O O
techniques O O
from O O
section O O
6.3 O O
and O O
to O O
use O O
ground O O
control O O
points B B
to O O
pin O O
down O O
the O O
reconstruction O O
. O O
some O O
recent O O
techniques O O
, O O
however O O
, O O
relax O O
this O O
requirement O O
and O O
allow O O
the O O
user O O
to O O
just O O
draw O O
a O O
few O O
strokes O O
or O O
scribbles O O
in O O
the O O
image B B
, O O
see O O
figures O O
10.45 O O
and O O
10.46 O O
( O O
wang O O
and O O
cohen O O
2005 O O
; O O
wang O O
, O O
agrawala O O
, O O
and O O
cohen O O
2007 O O
; O O
levin O O
, O O
lischinski O O
, O O
and O O
weiss O O
2008 O O
; O O
rhemann O O
, O O
rother O O
, O O
rav-acha O O
et O O
al O O
. O O
figure O O
2.25 O O
shows O O
a O O
high- O O
frequency O O
chirp O O
image B B
( O O
so O O
called O O
because O O
the O O
frequencies O O
increase O O
over O O
time O O
) O O
, O O
along O O
with O O
the O O
results O O
of O O
sampling B B
it O O
with O O
a O O
25 O O
% O O
ﬁll-factor O O
area O O
sensor O B
, O O
a O O
100 O O
% O O
ﬁll-factor O O
sensor B B
, O O
and O O
a O O
high- O O
quality O O
9-tap O O
ﬁlter O O
. O O
linux O O
binaries O O
for O O
afﬁne O O
region B B
detectors O O
and O O
descriptors O O
, O O
as O O
well O O
as O O
matlab O O
ﬁles O O
to O O
compute O O
repeatability B B
and O O
matching B B
scores O O
, O O
http O O
: O O
//www.robots.ox.ac.uk/∼vgg/research/ O O
afﬁne/ O O
. O O
) O O
the O O
user O O
can O O
also O O
place O O
additional O O
strokes O O
to O O
reﬁne O O
the O O
segmentation B B
as O O
the O O
solution O O
progresses O O
. O O
precomput- O O
ing O O
the O O
inner O O
product O O
between O O
the O O
gradient O O
ﬁeld O O
and O O
shifted O O
version O O
of O O
i1 O O
allows O O
the O O
iterative B B
re-computation O O
of O O
ei O O
to O O
be O O
performed O O
in O O
constant O O
time O O
( O O
independent O O
of O O
the O O
number O O
of O O
pixels O O
) O O
. O O
multiresolution O O
image B B
processing O O
and O O
analysis O O
, O O
springer- O O
verlag O O
, O O
new O O
york O O
. O O
taking O O
simultaneous O O
video B B
streams O O
focused O O
at O O
different O O
distances O O
( O O
mcguire O O
, O O
matusik O O
, O O
pﬁster O O
et O O
al O O
. O O
preemptive B O
ransac O O
for O O
live O O
structure O O
and O O
motion B B
estimation I I
. O O
( O O
2008 O O
) O O
present O O
more O O
recent O O
surveys B B
of O O
the O O
topics O O
of O O
brdf O O
modeling B B
, O O
recovery B B
, O O
and O O
rendering B B
. O O
minimizing O O
the O O
reprojection O O
error O O
in O O
surface B B
reconstruction I I
from O O
images O O
. O O
computer O O
vision O O
, O O
graphics O O
and O O
image B B
processing O O
, O O
34 O O
( O O
3 O O
) O O
:227–248 O O
. O O
use O O
of O O
the O O
hough O O
transform B B
to O O
detect O O
lines B B
and O O
curves O O
in O O
pictures O O
. O O
method O O
and O O
means O O
for O O
recognizing O O
complex O O
patterns B B
. O O
the O O
second O O
formulates O O
the O O
problem O O
using O O
bayesian O O
statistics O O
, O O
model- O O
ing O O
both O O
the O O
noisy O O
measurement O O
process O O
that O O
produced O O
the O O
input O O
images O O
as O O
well O O
as O O
prior B B
assumptions O O
about O O
the O O
solution O O
space O O
, O O
which O O
are O O
often O O
encoded O O
using O O
a O O
markov O O
random O O
ﬁeld O O
( O O
section O O
3.7.2 O O
) O O
. O O
now O O
consider O O
transforming O O
the O O
3d O O
scene O O
{ O O
pi O O
} O O
through O O
an O O
arbitrary O O
4× O O
4 O O
projective B B
transformation O O
˜h O O
, O O
yielding O O
a O O
new O O
model O O
consisting O O
of O O
points B B
p O O
( O O
cid:48 O O
) O O
i O O
= O O
˜hpi O O
. O O
7.3 O O
factorization B B
. O O
use O O
an O O
octree B B
or O O
some O O
other O O
representation O O
of O O
your O O
choosing O O
. O O
instead O O
of O O
ﬁrst O O
recovering O O
the O O
orientation O O
ﬁelds O O
( O O
p O O
, O O
q O O
) O O
and O O
integrating O O
them O O
to O O
obtain O O
a O O
surface B B
, O O
it O O
is O O
also O O
possible O O
to O O
directly O O
minimize O O
the O O
discrepancy O O
in O O
the O O
image B B
formation O O
equa- O O
tion B B
( O O
12.1 O O
) O O
while O O
ﬁnding O O
the O O
optimal O O
depth B O
map I I
z O O
( O O
x O O
, O O
y O O
) O O
( O O
horn O O
1990 O O
) O O
. O O
some O O
techniques O O
ﬁrst O O
approximate O O
each O O
silhouette O O
with O O
a O O
polygonal O O
representation O O
and O O
then O O
intersect O O
the O O
resulting O O
faceted O O
conical O O
regions O O
in O O
three-space O O
to O O
produce O O
polyhedral O O
mod- O O
els O O
( O O
baumgart O O
1974 O O
; O O
martin O O
and O O
aggarwal O O
1983 O O
; O O
matusik O O
, O O
buehler O O
, O O
and O O
mcmillan O O
2001 O O
) O O
, O O
which O O
can O O
later O O
be O O
reﬁned O O
using O O
triangular O O
splines B B
( O O
sullivan O O
and O O
ponce O O
1998 O O
) O O
. O O
optics B B
. O O
to O O
start O O
with O O
, O O
both O O
systems O O
collect O O
a O O
set O O
of O O
labeled O O
face B B
patches O O
( O O
figure O O
14.2 O O
) O O
as O O
well O O
as O O
a O O
set O O
of O O
patches O O
taken O O
from O O
images O O
that O O
are O O
known O O
not O O
to O O
contain O O
faces B B
, O O
such O O
as O O
aerial O O
images O O
or O O
vegetation O O
( O O
figure O O
14.3b O O
) O O
. O O
elliptical O O
weighted B B
average O O
the O O
elliptical O O
weighted B B
average O O
( O O
ewa O O
) O O
ﬁlter O O
invented O O
by O O
greene O O
and O O
heckbert O O
( O O
1986 O O
) O O
is O O
based O O
on O O
the O O
observation O O
that O O
the O O
afﬁne B B
mapping O O
x O O
= O O
ax O O
( O O
cid:48 O O
) O O
deﬁnes O O
a O O
skewed O O
two-dimensional B B
coordinate O O
system O O
in O O
the O O
vicinity O O
of O O
each O O
source O O
pixel O O
x O O
( O O
figure O O
3.48a O O
) O O
. O O
image B B
quilting I O
for O O
texture B O
synthesis O O
and O O
transfer B B
. O O
530 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
4. O O
use O O
triangulation B B
matting O O
( O O
smith O O
and O O
blinn O O
1996 O O
) O O
to O O
estimate O O
the O O
ground O O
truth O O
opacities O O
α O O
and O O
pre-multiplied B O
foreground O O
colors O O
αf O O
for O O
your O O
objects O O
. O O
it O O
is O O
easy O O
to O O
convince O O
yourself O O
that O O
in O O
this O O
ﬁgure O O
, O O
you O O
only O O
need O O
to O O
know O O
ˆei O O
( O O
xi O O
) O O
and O O
ˆej O O
( O O
xj O O
) O O
in O O
order B B
to O O
compute O O
this O O
value O O
. O O
adaptive B B
support-weight O O
approach O O
for O O
corre- O O
spondence O O
search O O
. O O
in O O
fact O O
, O O
the O O
adjacencies O O
of O O
these O O
various O O
kinds O O
of O O
terrain O O
each O O
have O O
different O O
likelihoods O O
, O O
so O O
it O O
makes O O
more O O
sense O O
to O O
use O O
a O O
prior B B
of O O
the O O
form O O
ep O O
( O O
i O O
, O O
j O O
) O O
= O O
sx O O
( O O
i O O
, O O
j O O
) O O
v O O
( O O
l O O
( O O
i O O
, O O
j O O
) O O
, O O
l O O
( O O
i O O
+ O O
1 O O
, O O
j O O
) O O
) O O
+ O O
sy O O
( O O
i O O
, O O
j O O
) O O
v O O
( O O
l O O
( O O
i O O
, O O
j O O
) O O
, O O
l O O
( O O
i O O
, O O
j O O
+ O O
1 O O
) O O
) O O
, O O
( O O
3.115 O O
) O O
where O O
v O O
( O O
l0 O O
, O O
l1 O O
) O O
is O O
a O O
general O O
compatibility O O
or O O
potential O O
function O O
. O O
) O O
for O O
an O O
isotropic B O
material O O
, O O
we O O
can O O
simplify O O
the O O
brdf O O
to O O
fr O O
( O O
θi O O
, O O
θr O O
, O O
|φr O O
− O O
φi| O O
; O O
λ O O
) O O
or O O
fr O O
( O O
ˆvi O O
, O O
ˆvr O O
, O O
ˆn O O
; O O
λ O O
) O O
, O O
( O O
2.82 O O
) O O
since O O
the O O
quantities O O
θi O O
, O O
θr O O
and O O
φr O O
− O O
φi O O
can O O
be O O
computed O O
from O O
the O O
directions O O
ˆvi O O
, O O
ˆvr O O
, O O
and O O
ˆn O O
. O O
a.2 O O
linear B B
least O O
squares O O
. O O
in O O
ieee O O
computer O O
society O O
conference O O
on O O
computer O O
vision O O
and O O
pattern O O
recognition B B
( O O
cvpr O O
’ O O
2000 O O
) O O
, O O
pp O O
. O O
the O O
answer O O
depends O O
largely O O
on O O
the O O
intended O O
ap- O O
plication O O
, O O
e.g. O O
, O O
whether O O
the O O
wavelets O O
are O O
being O O
used O O
for O O
compression O O
, O O
image B B
analysis O O
( O O
feature B B
ﬁnding O O
) O O
, O O
or O O
denoising O O
. O O
13.4.2 O O
the O O
modeling B B
to O O
rendering B B
continuum O O
the O O
image-based B B
rendering I I
representations O O
and O O
algorithms O O
we O O
have O O
studied O O
in O O
this O O
chapter O O
span O O
a O O
continuum O O
ranging O O
from O O
classic O O
3d O O
texture-mapped O O
models O O
all O O
the O O
way O O
to O O
pure O O
sampled O O
ray-based O O
representations O O
such O O
as O O
light O B
ﬁelds O O
( O O
figure O O
13.11 O O
) O O
. O O
ﬁve-tap O O
kernel B B
of O O
the O O
form O O
( O O
3.82 O O
) O O
with O O
b O O
= O O
1/4 O O
and O O
c O O
= O O
1/4− O O
a/2 O O
. O O
how O O
does O O
this O O
differ O O
from O O
the O O
forward B B
warping I I
algorithm O O
? O O
for O O
one O O
thing O O
, O O
since O O
ˆh O O
( O O
x O O
( O O
cid:48 O O
) O O
) O O
is O O
( O O
presumably O O
) O O
deﬁned O O
for O O
all O O
pixels O O
in O O
g O O
( O O
x O O
( O O
cid:48 O O
) O O
) O O
, O O
we O O
no O O
longer O O
have O O
holes O O
. O O
however O O
, O O
if O O
you O O
ﬁnd O O
two O O
images O O
for O O
which O O
the O O
estimates O O
of O O
( O O
f O O
2 O O
1 O O
, O O
λ O O
) O O
are O O
well O O
conditioned O O
, O O
they O O
can O O
be O O
used O O
to O O
initialize O O
a O O
more O O
complete O O
bundle B O
adjustment I I
of O O
all O O
the O O
parameters B B
( O O
section O O
7.4 O O
) O O
. O O
practical O O
super-resolution O O
from O O
dynamic B B
video O O
in O O
ieee O O
computer O O
society O O
conference O O
on O O
computer O O
vision O O
and O O
pattern O O
sequences O O
. O O
another O O
approach O O
to O O
video-based O O
rendering O O
is O O
to O O
use O O
ﬂow O O
or O O
3d O O
modeling B B
to O O
unwrap O O
surface B B
textures O O
into O O
stabilized O O
images O O
, O O
which O O
can O O
then O O
be O O
manipulated O O
and O O
re-rendered O O
onto O O
the O O
original O O
video B B
( O O
pighin O O
, O O
szeliski O O
, O O
and O O
salesin O O
2002 O O
; O O
rav-acha O O
, O O
kohli O O
, O O
fitzgibbon O O
et O O
al O O
. O O
chuang O O
et O O
al. O O
’ O O
s O O
bayesian O O
matting B B
approach O O
computes O O
a O O
map O O
estimate O O
of O O
( O O
frac- O O
tional O O
) O O
foreground O O
color B B
and O O
opacity B B
given O O
the O O
local B B
foreground O O
and O O
background O O
distributions O O
. O O
they O O
are O O
all O O
examples B B
of O O
the O O
general O O
potentials O O
vi O O
, O O
j O O
, O O
k O O
, O O
l O O
( O O
f O O
( O O
i O O
, O O
j O O
) O O
, O O
f O O
( O O
k O O
, O O
l O O
) O O
) O O
used O O
in O O
equation B B
( O O
b.24 O O
) O O
. O O
2.2 O O
photometric B B
image O O
formation O O
in O O
modeling B B
the O O
image B B
formation O O
process O O
, O O
we O O
have O O
described O O
how O O
3d O O
geometric B B
features O O
in O O
the O O
world O O
are O O
projected O O
into O O
2d O O
features O O
in O O
an O O
image B B
. O O
in O O
the O O
case O O
of O O
orthographic B B
projection O O
( O O
2.47 O O
) O O
, O O
the O O
entries O O
in O O
m O O
j O O
are O O
the O O
ﬁrst O O
two O O
rows O O
of O O
rotation O O
matrices O O
rj O O
, O O
so O O
we O O
have O O
mj0 O O
· O O
mj0 O O
= O O
u2jqqt O O
ut O O
2j O O
mj0 O O
· O O
mj1 O O
= O O
u2jqqt O O
ut O O
mj1 O O
· O O
mj1 O O
= O O
u2j+1qqt O O
ut O O
= O O
1 O O
, O O
= O O
0 O O
, O O
2j+1 O O
= O O
1 O O
, O O
2j+1 O O
( O O
7.45 O O
) O O
where O O
uk O O
are O O
the O O
3 O O
× O O
1 O O
rows O O
of O O
the O O
matrix O O
u. O O
this O O
gives O O
us O O
a O O
large O O
set O O
of O O
equations B B
for O O
the O O
entries O O
in O O
the O O
matrix O O
qqt O O
, O O
from O O
which O O
the O O
matrix O O
q O O
can O O
be O O
recovered O O
using O O
a O O
matrix O O
square O O
root O O
( O O
appendix O O
a.1.4 O O
) O O
. O O
set O O
your O O
camera B B
up O O
to O O
take O O
a O O
series O O
of O O
50 O O
% O O
overlapped O O
photos O O
and O O
then O O
use O O
the O O
following O O
steps O O
to O O
create O O
your O O
panorama O O
: O O
1. O O
estimate O O
the O O
amount O O
of O O
radial B B
distortion I I
by O O
taking O O
some O O
pictures O O
with O O
lots O O
of O O
long O O
straight O O
lines B B
near O O
the O O
edges O O
of O O
the O O
image B B
and O O
then O O
using O O
the O O
plumb-line B O
method I O
from O O
exercise O O
6.10 O O
. O O
robust B B
real-time O O
face B B
detection O O
. O O
normalized B B
descriptor O O
, O O
treating O O
each O O
x O O
= O O
( O O
x O O
, O O
y O O
) O O
value O O
as O O
a O O
complex O O
number O O
. O O
as O O
shown O O
in O O
figure O O
2.19 O O
, O O
moving O O
the O O
object O O
surface B B
away O O
from O O
the O O
focus B B
plane O O
increases O O
the O O
circle O O
of O O
confusion O O
, O O
according O O
to O O
a O O
formula O O
that O O
is O O
easy O O
to O O
establish O O
using O O
similar O O
triangles O O
( O O
exercise O O
2.4 O O
) O O
. O O
b.4 O O
prior B B
models O O
and O O
bayesian O O
inference B B
. O O
among O O
the O O
various O O
cues O O
that O O
can O O
be O O
used O O
to O O
infer O O
shape O O
, O O
the O O
shading B B
on O O
a O O
surface B B
( O O
fig- O O
ure O O
12.1a O O
) O O
can O O
provide O O
a O O
lot O O
of O O
information O O
about O O
local B B
surface O O
orientations O O
and O O
hence O O
overall O O
surface B B
shape O O
( O O
section O O
12.1.1 O O
) O O
. O O
( O O
8.23 O O
) O O
expanding O O
this O O
as O O
a O O
sum O O
of O O
correlations O O
and O O
deriving O O
the O O
appropriate O O
set O O
of O O
fourier O O
transforms O O
is O O
left O O
for O O
exercise O O
8.1. O O
the O O
same O O
kind O O
of O O
derivation O O
can O O
also O O
be O O
applied O O
to O O
the O O
bias–gain O O
corrected O O
sum O O
of O O
squared O O
difference B B
function O O
ebg O O
( O O
8.9 O O
) O O
. O O
algorithm B B
4.2 O O
outline O O
of O O
a O O
hough O O
transform B B
algorithm O O
based O O
on O O
oriented B B
edge O O
segments O O
. O O
in O O
first O O
ieee O O
international O O
conference O O
on O O
image B B
processing O O
( O O
icip-94 O O
) O O
, O O
pp O O
. O O
acm O O
computing O O
surveys B B
, O O
39 O O
( O O
4 O O
) O O
. O O
convolu- O O
tion B B
has O O
additional O O
nice O O
properties B B
, O O
e.g. O O
, O O
it O O
is O O
both O O
commutative O O
and O O
associative O O
. O O
good O O
overviews O O
on O O
part-based B B
models O O
for B O
recognition I I
can O O
be O O
found O O
in O O
the O O
course O O
notes O O
of O O
fergus O O
2007b O O
; O O
2009. O O
carneiro O O
and O O
lowe O O
( O O
2006 O O
) O O
discuss O O
a O O
number O O
of O O
graphical O O
models O O
used O O
for O O
part-based O O
recognition B B
, O O
which O O
include O O
trees O O
and O O
stars O O
( O O
felzenszwalb O O
and O O
huttenlocher O O
2005 O O
; O O
fergus O O
, O O
per- O O
ona O O
, O O
and O O
zisserman O O
2005 O O
; O O
felzenszwalb O O
, O O
mcallester O O
, O O
and O O
ramanan O O
2008 O O
) O O
, O O
k-fans O O
( O O
crandall O O
, O O
felzenszwalb O O
, O O
and O O
huttenlocher O O
2005 O O
; O O
crandall O O
and O O
huttenlocher O O
2006 O O
) O O
, O O
and O O
constellations O O
( O O
burl O O
, O O
weber O O
, O O
and O O
perona O O
1998 O O
; O O
weber O O
, O O
welling O O
, O O
and O O
perona O O
2000 O O
; O O
fergus O O
, O O
perona O O
, O O
and O O
zis- O O
serman O O
2007 O O
) O O
. O O
in O O
this O O
case O O
, O O
a O O
useful O O
heuristic O O
can O O
be O O
to O O
compare O O
the O O
nearest B B
neighbor I I
distance O O
to O O
that O O
of O O
the O O
second O O
nearest O O
neighbor O I
, O O
preferably O O
taken O O
from O O
an O O
image B B
that O O
is O O
known O O
not O O
to O O
match O O
the O O
target O O
( O O
e.g. O O
, O O
a O O
different O O
object O O
in O O
the O O
database O O
) O O
( O O
brown O O
and O O
lowe O O
2002 O O
; O O
lowe O O
2004 O O
) O O
. O O
note O O
that O O
the O O
map O O
estimate O O
may O O
not O O
always O O
be O O
desirable O O
, O O
since O O
it O O
selects O O
the O O
“ O O
peak O O
” O O
in O O
the O O
posterior B B
distribution I I
rather O O
than O O
some O O
more O O
stable O O
statistic O O
such O O
as O O
mse—see O O
the O O
discussion O O
in O O
appendix O O
b.2 O O
about O O
loss O O
functions O O
and O O
decision O O
theory O O
. O O
obtaining O O
shape O O
from O O
shading B B
information O O
. O O
computer O O
vision O O
, O O
graphics O O
, O O
and O O
image B B
processing O O
, O O
39 O O
( O O
3 O O
) O O
:355–368 O O
. O O
6.1 O O
6.2 O O
pose O O
estimation B B
. O O
under O O
these O O
conditions O O
, O O
we O O
can O O
describe O O
each O O
image B B
by O O
the O O
location O O
and O O
orientation O O
of O O
the O O
virtual O O
camera O O
( O O
6 O O
dof O O
) O O
as O O
well O O
as O O
its O O
intrinsics O O
( O O
e.g. O O
, O O
its O O
focal O O
length O O
) O O
. O O
in O O
ieee O O
computer O O
society O O
conference O O
on O O
computer O O
vision O O
and O O
pattern O O
recognition B B
( O O
cvpr O O
’ O O
93 O O
) O O
, O O
pp O O
. O O
1. O O
take O O
a O O
set O O
of O O
photographs O O
of O O
the O O
same O O
scene O O
using O O
a O O
hand-held O O
camera B B
( O O
to O O
ensure O O
that O O
there O O
is O O
some O O
jitter O O
between O O
the O O
photographs O O
) O O
. O O
692 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
( O O
a O O
) O O
( O O
b O O
) O O
figure O O
14.30 O O
scalable O O
recognition B B
using O O
a O O
vocabulary B B
tree I O
( O O
nist´er O O
and O O
stew´enius O O
2006 O O
) O O
c O O
( O O
cid:13 O O
) O O
2006 O O
ieee O O
. O O
the O O
splits O O
are O O
arranged O O
so O O
as O O
to O O
try O O
to O O
balance B B
the O O
tree O O
, O O
i.e. O O
, O O
to O O
keep O O
its O O
maximum O O
depth O B
as O O
small O O
as O O
possible O O
. O O
we O O
can O O
write O O
the O O
projection O O
equations B B
as O O
xi O O
= O O
f O O
( O O
pi O O
; O O
r O O
, O O
t O O
, O O
k O O
) O O
and O O
iteratively O O
minimize O O
the O O
robustiﬁed O O
linearized O O
reprojection O O
errors O O
enlp O O
= O O
( O O
cid:88 O O
) O O
i O O
ρ O O
( O O
cid:18 O O
) O O
∂f O O
∂r O O
∆r O O
+ O O
∂f O O
∂t O O
∆t O O
+ O O
∂f O O
∂k O O
∆k O O
− O O
ri O O
( O O
cid:19 O O
) O O
, O O
( O O
6.42 O O
) O O
( O O
6.43 O O
) O O
where O O
ri O O
= O O
˜xi O O
− O O
ˆxi O O
is O O
the O O
current O O
residual O O
vector O O
( O O
2d O O
error O O
in O O
predicted O O
position O O
) O O
and O O
the O O
partial O O
derivatives O O
are O O
with O O
respect O O
to O O
the O O
unknown O O
pose O O
parameters B B
( O O
rotation O O
, O O
translation B B
, O O
and O O
optionally O O
calibration B B
) O O
. O O
ex O O
3.16 O O
: O O
wiener O O
ﬁltering O O
estimate O O
the O O
frequency O O
spectrum O O
of O O
your O O
personal O O
photo O O
collec- O O
tion B B
and O O
use O O
it O O
to O O
perform O O
wiener O O
ﬁltering O B
on O O
a O O
few O O
images O O
with O O
varying O O
degrees O O
of O O
noise B B
. O O
a O O
component-based O O
framework O O
for O O
face O O
detection B B
and O O
identiﬁcation O O
. O O
the O O
process O O
of O O
going O O
from O O
the O O
known O O
cfa O O
pixels O O
values O O
to O O
the O O
full O O
rgb O O
image B O
is O O
quite O O
challenging O O
. O O
) O O
for O O
example O O
, O O
ρp O O
can O O
be O O
a O O
hyper-laplacian O O
penalty O O
ρp O O
( O O
d O O
) O O
= O O
|d|p O O
, O O
p O O
< O O
1 O O
, O O
( O O
3.114 O O
) O O
which O O
better O O
encodes O O
the O O
distribution O O
of O O
gradients O O
( O O
mainly O O
edges O O
) O O
in O O
an O O
image B B
than O O
either O O
a O O
quadratic O O
or O O
linear B B
( O O
total B B
variation I O
) O O
penalty.24 O O
levin O O
and O O
weiss O O
( O O
2007 O O
) O O
use O O
such O O
a O O
penalty O O
to O O
separate O O
a O O
transmitted O O
and O O
reﬂected O O
image B B
( O O
figure O O
8.17 O O
) O O
by O O
encouraging O O
gradients O O
to O O
lie O O
in O O
one O O
or O O
the O O
other O O
image B B
, O O
but O O
not O O
both O O
. O O
when O O
overlapping O O
patches O O
are O O
used O O
, O O
an O O
efﬁcient O O
implementation O O
is O O
to O O
ﬁrst O O
com- O O
pute O O
the O O
outer O O
products O O
of O O
the O O
gradients O O
and O O
intensity O O
errors O O
( O O
8.40–8.41 O O
) O O
at O O
every O O
pixel O O
and O O
then O O
perform O O
the O O
overlapping O O
window O O
sums O O
using O O
a O O
moving B O
average I O
ﬁlter.11 O O
instead O O
of O O
solving O O
for O O
each O O
motion B B
( O O
or O O
motion B B
update O O
) O O
independently O O
, O O
horn O O
and O O
schunck O O
( O O
1981 O O
) O O
develop O O
a O O
regularization-based O O
framework O O
where O O
( O O
8.69 O O
) O O
is O O
simultaneously O O
minimized O O
over O O
all O O
ﬂow O O
vectors O O
{ O O
ui O O
} O O
. O O
as O O
shown O O
in O O
equations B B
( O O
6.13–6.17 O O
) O O
, O O
this O O
results O O
in O O
enls O O
( O O
∆p O O
) O O
= O O
( O O
cid:88 O O
) O O
i O O
≈ O O
( O O
cid:88 O O
) O O
i O O
( O O
cid:107 O O
) O O
f O O
( O O
xi O O
; O O
p O O
+ O O
∆p O O
) O O
− O O
x O O
( O O
cid:48 O O
) O O
i O O
( O O
cid:107 O O
) O O
2 O O
( O O
cid:107 O O
) O O
j O O
( O O
xi O O
; O O
p O O
) O O
∆p O O
− O O
ri O O
( O O
cid:107 O O
) O O
2 O O
, O O
( O O
a.45 O O
) O O
( O O
a.46 O O
) O O
where O O
the O O
jacobians O O
j O O
( O O
xi O O
; O O
p O O
) O O
and O O
residual O O
vectors O O
ri O O
play O O
the O O
same O O
role O O
in O O
forming O O
the O O
normal O O
equations O O
as O O
ai O O
and O O
bi O O
in O O
( O O
a.28 O O
) O O
. O O
in O O
ieee O O
computer O O
society O O
conference O O
on O O
computer O O
vision O O
and O O
pattern O O
recognition B B
( O O
cvpr O O
2007 O O
) O O
, O O
minneapolis O O
, O O
mn O O
. O O
6.3 O O
geometric B B
intrinsic O O
calibration B B
. O O
the O O
ﬁeld O O
of O O
contour O O
detection B B
and O O
linking B B
continues O O
to O O
evolve O O
rapidly O O
and O O
now O O
includes O O
techniques O O
for O O
global O O
contour O O
grouping O O
, O O
boundary O O
completion O O
, O O
and O O
junction O O
detection B B
( O O
maire O O
, O O
arbelaez O O
, O O
fowlkes O O
et O O
al O O
. O O
in O O
practice O O
, O O
a O O
bilinear B B
interpolant O O
is O O
often O O
used O O
but O O
bicubic B O
inter- O O
polation O O
can O O
yield O O
slightly O O
better O O
results O O
( O O
szeliski O O
and O O
scharstein O O
2004 O O
) O O
. O O
( O O
a O O
) O O
features O O
in O O
the O O
query O O
region O O
on O O
the O O
left O O
are O O
matched O O
to O O
corresponding O O
features O O
in O O
a O O
highly O O
ranked O O
video B B
frame O O
. O O
the O O
prior B B
distribution I O
p O O
( O O
s O O
) O O
is O O
given O O
by O O
p O O
( O O
s O O
) O O
= O O
e− O O
( O O
s−µ O O
) O O
2 O O
2ps O O
, O O
( O O
3.69 O O
) O O
where O O
µ O O
is O O
the O O
expected O O
mean O O
at O O
that O O
frequency O O
( O O
0 O O
everywhere O O
except O O
at O O
the O O
origin O O
) O O
and O O
the O O
measurement O O
distribution O O
p O O
( O O
o|s O O
) O O
is O O
given O O
by O O
p O O
( O O
s O O
) O O
= O O
e− O O
( O O
s−o O O
) O O
2 O O
2pn O O
. O O
computation O O
of O O
component O O
image B B
velocity O O
from O O
local B B
phase O O
information O O
. O O
in O O
ieee O O
international O O
conference O O
on O O
image B B
processing O O
( O O
icip-96 O O
) O O
, O O
pp O O
. O O
numerical O O
linear B B
algebra O O
. O O
12.7 O O
recovering O O
texture B B
maps O O
and O O
albedos O O
613 O O
( O O
a O O
) O O
( O O
b O O
) O O
figure O O
12.23 O O
image-based B B
reconstruction O I
of O O
appearance O O
and O O
detailed O O
geometry O O
( O O
lensch O O
, O O
kautz O O
, O O
goesele O O
et O O
al O O
. O O
194 O O
100 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
( O O
a O O
) O O
( O O
c O O
) O O
( O O
e O O
) O O
( O O
b O O
) O O
( O O
d O O
) O O
( O O
f O O
) O O
figure O O
3.1 O O
some O O
common O O
image B B
processing O O
operations O O
: O O
( O O
a O O
) O O
original O O
image B B
; O O
( O O
b O O
) O O
increased O O
contrast O O
; O O
( O O
c O O
) O O
change O O
in O O
hue B B
; O O
( O O
d O O
) O O
“ O O
posterized O O
” O O
( O O
quantized O O
colors O O
) O O
; O O
( O O
e O O
) O O
blurred O O
; O O
( O O
f O O
) O O
rotated O O
. O O
planar O O
grouping O O
for O O
automatic O O
detection B B
of O O
vanishing O O
lines O I
and O O
points B B
. O O
ieee O O
transactions O O
on O O
image B B
processing O O
, O O
7 O O
( O O
3 O O
) O O
:398–410 O O
. O O
these O O
per-level O O
counts O O
are O O
then O O
summed O O
up O O
in O O
a O O
weighted B B
fashion O O
( O O
14.40 O O
) O O
( O O
14.41 O O
) O O
d∆ O O
= O O
( O O
cid:88 O O
) O O
l O O
wlnl O O
with O O
nl O O
= O O
cl O O
− O O
cl−1 O O
and O O
wl O O
= O O
1 O O
d2l O O
( O O
figure O O
14.38e O O
) O O
, O O
which O O
discounts O O
matches O O
already O O
found O O
at O O
ﬁner O O
levels O O
while O O
weighting B B
ﬁner O O
matches O O
more O O
heavily O O
. O O
3d O O
shape O O
13. O O
image-based B B
rendering I I
14. O O
recognition B B
figure O O
1.12 O O
a O O
pictorial O O
summary O O
of O O
the O O
chapter O O
contents O O
. O O
2. O O
use O O
iterative B B
non-linear O O
minimization O O
to O O
improve O O
your O O
initial O O
estimates O O
and O O
report O O
on O O
the O O
improvement O O
in O O
accuracy B O
. O O
a O O
better O O
way O O
, O O
which O O
we O O
already O O
mentioned O O
in O O
section O O
3.6.2 O O
, O O
is O O
to O O
ﬁrst O O
warp O O
the O O
depth O O
( O O
or O O
( O O
u O O
, O O
v O O
) O O
displacement O O
) O O
map O O
to O O
the O O
novel O O
view O O
, O O
ﬁll O O
in O O
the O O
cracks O O
, O O
and O O
then O O
use O O
higher-quality O O
inverse B B
warping I O
to O O
resample O O
the O O
color B B
image O O
( O O
shade O O
, O O
gortler O O
, O O
he O O
et O O
al O O
. O O
) O O
af- O O
ter O O
this O O
real-valued O O
vector O O
is O O
computed O O
, O O
the O O
variables O O
corresponding O O
to O O
positive O O
and O O
negative O O
298 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
( O O
a O O
) O O
( O O
b O O
) O O
figure O O
5.20 O O
sample O O
weight O O
table O O
and O O
its O O
second O O
smallest O O
eigenvector O O
( O O
shi O O
and O O
malik O O
2000 O O
) O O
c O O
( O O
cid:13 O O
) O O
2000 O O
ieee O O
: O O
( O O
a O O
) O O
sample O O
32 O O
× O O
32 O O
weight O O
matrix O O
w O O
; O O
( O O
b O O
) O O
eigenvector O O
corresponding O O
to O O
the O O
second O O
smallest O O
eigenvalue O O
of O O
the O O
generalized B B
eigenvalue O O
problem O O
( O O
d O O
− O O
w O O
) O O
y O O
= O O
λdy O O
. O O
post-multiplying O O
each O O
p O O
j O O
matrix O O
by O O
˜h−1 O O
still O O
produces O O
the O O
same O O
screen O O
coordinates O O
and O O
a O O
new O O
set O O
calibration B B
matrices O O
can O O
be O O
computed O O
by O O
applying O O
rq O O
decomposition O O
to O O
the O O
new O O
camera B B
matrix O O
p O O
( O O
cid:48 O O
) O O
j O O
= O O
p O O
j O O
˜h−1 O O
. O O
instead O O
of O O
reconstructing O O
3d O O
lines B B
, O O
bay O O
, O O
ferrari O O
, O O
and O O
van O O
gool O O
( O O
2005 O O
) O O
use O O
ransac O O
to O O
group O O
lines B B
into O O
likely O O
coplanar O O
subsets O O
. O O
for O O
this O O
reason O O
, O O
all O O
self-calibration B B
methods O O
assume O O
some O O
restricted B O
form O O
of O O
the O O
calibration B B
matrix I O
, O O
either O O
by O O
setting O O
or O O
equating O O
some O O
of O O
their O O
elements O O
or O O
by O O
assuming O O
that O O
they O O
do O O
not O O
vary O O
over O O
time O O
. O O
as O O
we O O
have O O
already O O
seen O O
in O O
( O O
3.68 O O
) O O
and O O
( O O
3.106 O O
) O O
, O O
bayes O O
’ O O
rule O O
states O O
that O O
a O O
posterior O B
distribu- O O
tion B B
p O O
( O O
x|y O O
) O O
over O O
the O O
unknowns O O
x O O
given O O
the O O
measurements O O
y O O
can O O
be O O
obtained O O
by O O
multiplying O O
4 O O
in O O
fact O O
, O O
the O O
maximum O O
likelihood O O
estimate O O
is O O
just O O
the O O
noisy O O
image B B
itself O O
. O O
a O O
better O O
approach O O
is O O
to O O
compute O O
the O O
oriented B B
energy O O
in O O
each O O
band O O
( O O
morrone O O
and O O
burr O O
1988 O O
; O O
perona O O
and O O
malik O O
1990a O O
) O O
, O O
e.g. O O
, O O
using O O
a O O
second-order O O
steerable B B
ﬁlter I O
( O O
section O O
3.2.3 O O
) O O
( O O
freeman O O
and O O
adelson O O
1991 O O
) O O
, O O
and O O
then O O
sum O O
up O O
the O O
orientation-weighted O O
energies O O
and O O
ﬁnd O O
their O O
joint B O
best O O
orientation O O
. O O
figure O O
14.30b O O
shows O O
some O O
typical O O
images O O
from O O
the O O
database O O
of O O
objects O O
taken O O
under O O
varying O O
viewpoints O O
and O O
illumination O O
that O O
was O O
used O O
to O O
train O O
and O O
test O O
the O O
vocabulary B B
tree I O
recognition O B
system O O
. O O
a O O
number O O
of O O
approaches O O
use O O
the O O
gist B B
of O O
a O O
scene O O
( O O
torralba O O
2003 O O
; O O
torralba O O
, O O
murphy O O
, O O
free- O O
man O O
et O O
al O O
. O O
3. O O
group O O
these O O
centers O O
into O O
lines B B
and O O
then O O
ﬁnd O O
the O O
vanishing B B
points I I
for O O
each O O
face B B
. O O
recognition B O
( O O
icpr O O
’ O O
94 O O
) O O
, O O
pp O O
. O O
if O O
helpful O O
, O O
try O O
using O O
temporal O O
selection O O
( O O
kang O O
and O O
szeliski O O
2004 O O
) O O
to O O
deal O O
with O O
the O O
increased O O
number O O
of O O
occlusions O O
in O O
multi-frame B B
data O O
sets O I
. O O
the O O
amount O O
of O O
light O O
interchanged O O
between O O
any O O
two O O
( O O
mutually O O
visible O O
) O O
areas O O
in O O
the O O
scene O O
can O O
be O O
captured O O
as O O
a O O
form O O
factor O O
, O O
which O O
depends O O
on O O
their O O
relative O O
orientation O O
and O O
surface B B
reﬂectance O O
properties B O
, O O
as O O
well O O
as O O
the O O
1/r2 O O
fall-off O O
as O O
light O O
is O O
distributed O O
over O O
a O O
larger O O
effective O O
sphere O O
the O O
further O O
away O O
it O O
is O O
( O O
cohen O O
and O O
wallace O O
1993 O O
; O O
sillion O O
and O O
puech O O
1994 O O
; O O
glassner O O
1995 O O
) O O
. O O
12.1.3 O O
shape O O
from O O
focus B B
. O O
a O O
more O O
general O O
( O O
upper-triangular O O
) O O
estimate O O
of O O
k O O
can O O
be O O
obtained O O
in O O
the O O
case O O
of O O
a O O
ﬁxed- O O
parameter O O
camera B B
ki O O
= O O
k O O
using O O
the O O
technique O O
of O O
hartley O O
( O O
1997b O O
) O O
. O O
22 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
2. O O
image B B
formation O O
3. O O
image B B
processing O O
4. O O
features O O
5. O O
segmentation B B
6-7. O O
structure B O
from I O
motion I I
8. O O
motion B B
9. O O
stitching O O
10. O O
computational O O
photography O O
11. O O
stereo B B
12 O O
. O O
in O O
three- O O
dimensional O O
image B B
capture O O
and O O
applications O O
iv O O
, O O
pp O O
. O O
( O O
the O O
advantage O O
of O O
using O O
fewer O O
correspondences O O
inside O O
a O O
ransac O O
robust B B
ﬁtting O O
stage O O
is O O
that O O
fewer O O
random O O
samples O O
need O O
to O O
be O O
generated O O
. O O
what O O
makes O O
a O O
good O O
model O O
of O O
natural B B
images O O
? O O
in O O
ieee O O
computer O O
society O O
conference O O
on O O
computer O O
vision O O
and O O
pattern O O
recognition B B
( O O
cvpr O O
2007 O O
) O O
, O O
minneapolis O O
, O O
mn O O
. O O
in O O
ieee O O
computer O O
society O O
conference O O
on O O
computer O O
vision O O
and O O
pattern O O
recognition B B
( O O
cvpr O O
2009 O O
) O O
, O O
miami O O
beach O O
, O O
fl O O
. O O
multiview O O
registration B B
for O O
large O O
data O O
sets O I
. O O
623 O O
the O O
ﬁnal O O
step O O
in O O
view B B
interpolation I I
( O O
figure O O
13.2d O O
) O O
is O O
to O O
ﬁll O O
any O O
remaining O O
holes O O
or O O
cracks O O
due O O
to O O
the O O
forward B B
warping I I
process O O
or O O
lack O O
of O O
source O O
data O O
( O O
scene O O
visibility O O
) O O
. O O
6 O O
feature-based B B
alignment O O
. O O
is O O
the O O
median B B
the O O
best O O
way O O
to O O
do O O
this O O
? O O
why O O
not O O
use O O
the O O
minimum O O
color O B
value O O
? O O
what O O
happens O O
if O O
there O O
is O O
lambertian O O
shading B O
on O O
the O O
diffuse B B
component O O
? O O
5. O O
model O O
and O O
compress O O
the O O
remaining O O
portion O O
of O O
the O O
lumisphere O O
using O O
one O O
of O O
the O O
tech- O O
niques O O
suggested O O
by O O
wood O O
, O O
azuma O O
, O O
aldinger O O
et O O
al O O
. O O
this O O
technique O O
has O O
informally O O
come O O
to O O
be O O
known O O
as O O
graph B B
cuts I I
in O O
the O O
computer O O
vision O O
community O O
( O O
boykov O O
and O O
kolmogorov O O
2010 O O
) O O
. O O
some O O
techniques O O
rely O O
purely O O
on O O
the O O
presence O O
of O O
features O O
( O O
known O O
as O O
a O O
“ O O
bag B O
of I O
words I I
” O O
model—see O O
section O O
14.4.1 O O
) O O
, O O
their O O
relative O O
positions O O
( O O
part-based B O
models O O
( O O
section O O
14.4.2 O O
) O O
) O O
, O O
figure O O
14.1e O O
, O O
while O O
others O O
involve O O
segmenting O O
the O O
image B B
into O O
semantically O O
meaningful O O
regions O O
( O O
section O O
14.4.3 O O
) O O
( O O
figure O O
14.1f O O
) O O
. O O
however O O
, O O
even O O
if O O
the O O
ﬁll O O
factor O O
is O O
100 O O
% O O
, O O
as O O
in O O
the O O
right O O
image B B
of O O
figure O O
2.24 O O
, O O
frequencies O O
above O O
the O O
nyquist O O
limit O O
( O O
half O O
the O O
sampling B B
frequency O O
) O O
still O O
produce O O
an O O
aliased O O
signal O O
, O O
although O O
with O O
a O O
smaller O O
magnitude O O
than O O
the O O
corresponding O O
band-limited O O
signals O O
. O O
ieee O O
transactions O O
on O O
image B B
processing O O
, O O
18 O O
( O O
5 O O
) O O
:956–968 O O
. O O
learning B B
the O O
discriminative O O
power-invariance O O
trade-off O O
. O O
the O O
gradients O O
for O O
this O O
function O O
are O O
set O O
to O O
lie O O
along O O
oriented B B
surface O O
normals O O
near O O
known O O
surface B B
points O O
and O O
0 O O
elsewhere O O
. O O
an O O
integrated O O
bayesian O O
approach O O
to O O
layer O O
extraction O O
from O O
image B B
sequences O O
. O O
in O O
ieee O O
computer O O
society O O
conference O O
on O O
com- O O
puter O O
vision O O
and O O
pattern O O
recognition B B
( O O
cvpr O O
2008 O O
) O O
, O O
anchorage O O
, O O
ak O O
. O O
setting O O
t0 O O
= O O
t1 O O
= O O
0 O O
, O O
we O O
get O O
the O O
simpliﬁed O O
3 O O
× O O
3 O O
homography B B
˜h O O
10 O O
= O O
k1r1r−1 O O
0 O O
k−1 O O
0 O O
= O O
k1r10k−1 O O
0 O O
, O O
where O O
kk O O
= O O
diag O O
( O O
fk O O
, O O
fk O O
, O O
1 O O
) O O
is O O
the O O
simpliﬁed O O
camera B B
intrinsic O O
matrix O O
( O O
2.59 O O
) O O
, O O
assuming O O
that O O
cx O O
= O O
cy O O
= O O
0 O O
, O O
i.e. O O
, O O
we O O
are O O
indexing O O
the O O
pixels O O
starting O O
from O O
the O O
optical O O
center O O
( O O
szeliski O O
1996 O O
) O O
. O O
2004 O O
) O O
as O O
well O O
as O O
object-level O O
video B B
editing O O
. O O
in O O
these O O
applications O O
, O O
it O O
is O O
usual O O
to O O
ﬁrst O O
specify O O
a O O
trimap B O
, O O
i.e. O O
, O O
a O O
three-way O O
labeling O O
of O O
the O O
image B B
into O O
foreground O O
, O O
back- O O
ground O O
, O O
and O O
unknown O O
regions O O
( O O
figure O O
10.39b O O
) O O
. O O
7.2 O O
two-frame B B
structure O O
from O O
motion B B
. O O
this O O
is O O
particularly O O
true O O
of O O
architectural O O
scenes O O
and O O
models O O
, O O
which O O
we O O
study O O
in O O
more O O
detail O O
in O O
section O O
12.6.1. O O
sometimes O O
, O O
instead O O
of O O
exploiting O O
regularity O O
in O O
the O O
scene O O
structure O O
, O O
it O O
is O O
possible O O
to O O
take O O
advantage O O
of O O
a O O
constrained B B
motion O O
model O O
. O O
today O O
’ O O
s O O
face B B
recognizers O O
work O O
best O O
when O O
they O O
are O O
given O O
full O O
frontal O O
images O O
of O O
faces B B
under O O
relatively O O
uniform O O
illumination O O
conditions O O
, O O
although O O
databases O O
that O O
include O O
large O O
amounts O O
of O O
pose O O
and O O
lighting B B
variation O O
have O O
been O O
collected O O
( O O
phillips O O
, O O
moon O O
, O O
rizvi O O
et O O
al O O
. O O
intel O O
math O O
kernel B B
library O O
( O O
mkl O O
) O O
, O O
http O O
: O O
//software.intel.com/en-us/intel-mkl/ O O
. O O
furthermore O O
, O O
video B B
frames O O
cap- O O
tured O O
during O O
fast O O
motion O O
are O O
often O O
blurry O O
. O O
geometric B B
modeling O O
for O O
computer O O
vision O O
. O O
) O O
the O O
shading B B
equation O B
for O O
diffuse O O
reﬂection O O
can O O
thus O O
be O O
written O O
as O O
ld O O
( O O
ˆvr O O
; O O
λ O O
) O O
= O O
( O O
cid:88 O O
) O O
i O O
where O O
specular B O
reﬂection O O
li O O
( O O
λ O O
) O O
fd O O
( O O
λ O O
) O O
[ O O
ˆvi O O
· O O
ˆn O O
] O O
+ O O
, O O
li O O
( O O
λ O O
) O O
fd O O
( O O
λ O O
) O O
cos+ O O
θi O O
= O O
( O O
cid:88 O O
) O O
i O O
[ O O
ˆvi O O
· O O
ˆn O O
] O O
+ O O
= O O
max O O
( O O
0 O O
, O O
ˆvi O O
· O O
ˆn O O
) O O
. O O
additional O O
applications O O
include O O
medical B B
image I I
segmentation O O
, O O
where O O
contours O O
can O O
be O O
tracked O O
from O O
slice O O
to O O
slice O O
in O O
computerized O O
tomography O O
( O O
3d O O
medical O B
imagery O O
) O O
( O O
cootes O O
and O O
taylor O O
2001 O O
) O O
or O O
over O O
time O O
, O O
as O O
in O O
ultrasound O O
scans O O
. O O
the O O
inverse B B
response O O
curve O O
f−1 O O
is O O
given O O
by O O
f−1 O O
( O O
zij O O
) O O
= O O
ei O O
tj O O
. O O
alpha O O
channel O O
estimation B O
in O O
high O O
resolu- O O
tion B B
images O O
and O O
image B B
sequences O O
. O O
in O O
ieee O O
computer O O
society O O
conference O O
on O O
computer O O
vision O O
and O O
pattern O O
recognition B B
( O O
cvpr O O
2007 O O
) O O
, O O
minneapolis O O
, O O
mn O O
. O O
4. O O
extend O O
any O O
of O O
the O O
above O O
algorithms O O
by O O
selecting O O
sub-blocks O O
in O O
the O O
source O O
texture B B
and O O
using O O
optimization O O
to O O
determine O O
the O O
seam O O
between O O
the O O
new O O
block O O
and O O
the O O
existing O O
image B B
that O O
it O O
overlaps O O
( O O
efros O O
and O O
freeman O O
2001 O O
) O O
. O O
178 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
figure O O
3.55 O O
graphical O O
model O O
interpretation O O
of O O
ﬁrst-order O O
regularization B B
. O O
image B O
and O O
vision O O
computing O O
, O O
3 O O
( O O
4 O O
) O O
:183–191 O O
. O O
10.5 O O
texture B B
analysis O O
and O O
synthesis O O
10.6 O O
additional O O
reading O O
. O O
a O O
very O O
simple O O
version O O
of O O
pixel-based O O
merging B O
combines O O
adjacent O O
regions O O
whose O O
average O O
color B B
difference O O
is O O
below O O
a O O
threshold O O
or O O
whose O O
regions O O
are O O
too O O
small O O
. O O
visual O O
integration O O
and O O
detection B B
of O O
discontinuities O O
: O O
the O O
key O O
role O O
of O O
intensity O O
edges O O
. O O
hierarchical B B
( O O
multi-scale O O
) O O
and O O
grammar O O
( O O
parsing O O
) O O
models O O
are O O
also O O
sometimes O O
used O O
( O O
tu O O
, O O
chen O O
, O O
yuille O O
et O O
al O O
. O O
techniques O O
that O O
se- O O
lect O O
a O O
neighboring O O
subset O O
of O O
image B B
to O O
match O O
are O O
called O O
quasi-geometric O O
( O O
narayanan O O
, O O
rander O O
, O O
and O O
kanade O O
1998 O O
; O O
kang O O
and O O
szeliski O O
2004 O O
; O O
hernandez O O
and O O
schmitt O O
2004 O O
) O O
, O O
while O O
techniques O O
that O O
use O O
traditional O O
robust B B
similarity O O
measures O O
are O O
called O O
outlier-based O O
. O O
dynamosaics O O
: O O
video B B
mo- O O
saics O O
with O O
non-chronological O O
time O O
. O O
sometimes O O
, O O
however O O
, O O
the O O
averaged O O
( O O
signed B B
) O O
gradient O O
in O O
a O O
region B B
can O O
be O O
small O O
and O O
therefore O O
an O O
unreliable O O
indicator O O
of O O
orientation O O
. O O
( O O
14.32 O O
) O O
14.3 O O
instance B B
recognition O O
689 O O
( O O
a O O
) O O
( O O
b O O
) O O
figure O O
14.29 O O
matching B B
based O O
on O O
visual B O
words I I
( O O
sivic O O
and O O
zisserman O O
2009 O O
) O O
c O O
( O O
cid:13 O O
) O O
2009 O O
ieee O O
. O O
in O O
the O O
usual O O
case O O
, O O
an O O
area O O
around O O
the O O
current O O
predicted O O
location O O
of O O
the O O
feature B B
is O O
searched O O
with O O
an O O
incremental B B
reg- O O
istration O O
algorithm B B
( O O
section O O
8.1.3 O O
) O O
. O O
) O O
the O O
segmentation-based B O
aggregation O O
method O O
of O O
tombari O O
, O O
mattoccia O O
, O O
and O O
di O O
stefano O O
( O O
2007 O O
) O O
did O O
even O O
better O O
, O O
although O O
a O O
fast O O
implementation O O
of O O
this O O
algorithm B B
does O O
not O O
yet O O
exist O O
. O O
some O O
sample O O
recognition B O
results O O
are O O
shown O O
in O O
figure O O
14.52. O O
another O O
example O O
of O O
a O O
large O O
labeled O O
database O O
of O O
images O O
is O O
imagenet O O
( O O
deng O O
, O O
dong O O
, O O
socher O O
et O O
al O O
. O O
ex O O
14.3 O O
: O O
face B B
recognition O O
using O O
eigenfaces O O
collect O B
a O O
set O O
of O O
facial O O
photographs O O
and O O
then O O
build O O
a O O
recognition B B
system O O
to O O
re-recognize O O
the O O
same O O
people O O
. O O
11.6.1 O O
volumetric B B
and O O
3d O O
surface B B
reconstruction I I
. O O
the O O
weighted B B
averages O O
then O O
become O O
dominated O O
by O O
the O O
larger O O
values O O
, O O
i.e. O O
, O O
they O O
act O O
somewhat O O
like O O
a O O
p-norm O O
. O O
in O O
those O O
cases O O
where O O
linear B B
classiﬁcation O O
boundaries O O
are O O
insufﬁcient O O
, O O
the O O
feature B B
space O O
can O O
be O O
lifted O O
into O O
higher-dimensional O O
features O O
using O O
kernels O O
( O O
hastie O O
, O O
tibshirani O O
, O O
and O O
friedman O O
2001 O O
; O O
sch¨olkopf O O
and O O
smola O O
2002 O O
; O O
bishop O O
2006 O O
) O O
. O O
in O O
practice O O
, O O
it O O
is O O
more O O
common O O
to O O
estimate O O
a O O
set O O
of O O
shape B O
priors I I
on O O
the O O
typical O O
distribution O O
of O O
the O O
control O O
points B B
{ O O
xk O O
} O O
( O O
cootes O O
, O O
cooper O O
, O O
taylor O O
et O O
al O O
. O O
on O O
the O O
other O O
hand O O
, O O
if O O
only O O
a O O
few O O
input O O
images O O
are O O
available O O
or O O
the O O
image-based B B
models O O
need O O
to O O
be O O
manipulated O O
, O O
e.g. O O
, O O
to O O
change O O
their O O
shape O O
or O O
appearance O O
, O O
more O O
abstract O O
3d O O
representations O O
such O O
as O O
geometric B B
and O O
local B B
reﬂection O O
models O O
are O O
a O O
better O O
ﬁt O O
. O O
we O O
can O O
then O O
write O O
the O O
negative O O
log O O
likelihood O O
as O O
e O B
= O O
− O O
log O O
l O O
= O O
( O O
cid:88 O O
) O O
i O O
( O O
cid:107 O O
) O O
˜yi O O
− O O
ˆyi O O
( O O
cid:107 O O
) O O
σ−1 O O
i O O
+ O O
k. O O
( O O
b.13 O O
) O O
b.2 O O
maximum O O
likelihood O O
estimation B B
and O O
least B B
squares I I
now O O
that O O
we O O
have O O
presented O O
the O O
likelihood O O
and O O
log O O
likelihood O O
functions O O
, O O
how O O
can O O
we O O
ﬁnd O O
the O O
optimal O O
value O O
for O O
our O O
state O O
estimate O O
x O O
? O O
one O O
plausible O O
choice O O
might O O
be O O
to O O
select O O
the O O
value O O
of O O
x O O
that O O
maximizes O O
l O O
= O O
p O O
( O O
y|x O O
) O O
. O O
while O O
the O O
compositing B B
operation O O
is O O
easy O O
to O O
implement O O
, O O
the O O
reverse O O
matting B B
operation O O
of O O
estimating O O
f O O
, O O
α O O
, O O
and O O
b O O
given O O
an O O
input O O
image B B
c O O
is O O
much O O
more O O
challenging O O
( O O
figure O O
10.39 O O
) O O
. O O
in O O
this O O
section O O
, O O
we O O
review O O
not O O
only O O
techniques O O
for O O
11.6 O O
multi-view B B
stereo I I
559 O O
figure O O
11.14 O O
background B O
replacement I I
using O O
z-keying B B
with O O
a O O
bi-layer O O
segmentation B B
algo- O O
rithm O O
( O O
kolmogorov O O
, O O
criminisi O O
, O O
blake O O
et O O
al O O
. O O
in O O
order B B
to O O
compensate O O
for O O
sampling O O
issues O O
, O O
i.e. O O
, O O
dramatically O O
different O O
pixel O O
values O O
in O O
548 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
high-frequency O O
areas O O
, O O
birchﬁeld O O
and O O
tomasi O O
( O O
1998 O O
) O O
proposed O O
a O O
matching B B
cost O O
that O O
is O O
less O O
sen- O O
sitive O O
to O O
shifts O O
in O O
image B B
sampling O O
. O O
2008 O O
; O O
he O O
and O O
zemel O O
2008 O O
; O O
kumar O O
, O O
torr O O
, O O
and O O
zisserman O O
2010 O O
) O O
, O O
producing O O
some O O
of O O
the O O
best O O
results O O
on O O
the O O
difﬁcult O O
pascal O O
voc O O
segmentation B B
challenge O O
( O O
shotton O O
, O O
johnson O O
, O O
and O O
cipolla O O
2008 O O
; O O
kohli O O
, O O
ladick´y O O
, O O
and O O
torr O O
2009 O O
) O O
. O O
these O O
sequential O O
updates O O
allow O O
the O O
information O O
to O O
propagate O O
much O O
more O O
quickly O O
across O O
the O O
image B B
than O O
synchronous O O
updates O O
. O O
new O O
appearance O O
models O O
for O O
natural O O
image B B
matting O B
. O O
( O O
2009 O O
) O O
have O O
developed O O
gpu O O
implementations O O
of O O
both O O
real-time O O
stereo B B
matching I I
and O O
real-time O O
rendering B B
algorithms O O
, O O
which O O
enable O O
them O O
to O O
explore O O
algorithmic O O
alternatives O O
in O O
a O O
real-time O O
setting O O
. O O
1995 O O
; O O
hoppe O O
1996 O O
) O O
, O O
splines B B
( O O
farin O O
1992 O O
, O O
1996 O O
; O O
lee O O
, O O
wolberg O O
, O O
and O O
shin O O
1996 O O
) O O
, O O
subdivision O O
surfaces O O
( O O
stollnitz O O
, O O
derose O O
, O O
and O O
salesin O O
1996 O O
; O O
zorin O O
, O O
schr¨oder O O
, O O
and O O
sweldens O O
1996 O O
; O O
warren O O
and O O
weimer O O
2001 O O
; O O
peters O O
and O O
reif O O
2008 O O
) O O
, O O
and O O
geometry O O
images O O
( O O
gu O O
, O O
gortler O O
, O O
and O O
hoppe O O
2002 O O
) O O
. O O
in O O
viola O O
and O O
jones O O
’ O O
face B B
detector O O
, O O
the O O
features O O
are O O
differences O O
of O O
rectangular O O
regions O O
in O O
the O O
input O O
patch B B
, O O
as O O
shown O O
in O O
figure O O
14.6. O O
the O O
advantage O O
of O O
using O O
these O O
features O O
is O O
that O O
, O O
while O O
they O O
are O O
more O O
discriminating O O
than O O
single O O
pixels O O
, O O
they O O
are O O
extremely O O
fast O O
to O O
compute O O
once O O
a O O
summed O O
area O O
table O O
has O O
been O O
pre-computed O O
, O O
as O O
described O O
in O O
section O O
3.2.3 O O
( O O
3.31–3.32 O O
) O O
. O O
unfortunately O O
, O O
a O O
single O O
threshold O O
is O O
rarely O O
sufﬁcient O O
for O O
the O O
whole O O
image B B
because O O
of O O
lighting B B
and O O
intra-object O O
statistical O O
variations O O
. O O
11 O O
international O O
conference O O
on O O
automatic B B
face O O
and O O
gesture O O
recognition B B
( O O
fg O O
) O O
, O O
ieee O O
workshop O O
on O O
analysis O O
and O O
modeling B B
of O O
faces B B
and O O
gestures O O
, O O
and O O
international O O
workshop O O
on O O
tracking O O
humans O O
for O O
the O O
evaluation B B
of O O
their O O
motion B B
in O O
image B B
sequences O O
( O O
themis O O
) O O
. O O
this O O
transformation O O
, O O
variously O O
known O O
as O O
a O O
3d O O
perspective B B
transform O O
, O O
homogra- O O
phy O O
, O O
or O O
collineation B O
, O O
operates O O
on O O
homogeneous B B
coordinates I O
, O O
˜x O O
( O O
cid:48 O O
) O O
= O O
˜h O O
˜x O O
, O O
( O O
2.28 O O
) O O
where O O
˜h O O
is O O
an O O
arbitrary O O
4 O O
× O O
4 O O
homogeneous O O
matrix O O
. O O
computation O O
and O O
analysis O O
of O O
image B B
motion O O
: O O
a O O
synopsis O O
of O O
current O O
problems O O
and O O
methods O O
. O O
on O O
such O O
a O O
surface B B
, O O
edges O O
occur O O
at O O
locations O O
of O O
steep O O
slopes O O
, O O
or O O
equivalently O O
, O O
in O O
regions O O
of O O
closely O O
packed O O
contour O O
lines B B
( O O
on O O
a O O
topographic O O
map O O
) O O
. O O
if O O
the O O
values O O
for O O
all O O
the O O
points B B
are O O
known O O
or O O
ﬁxed O O
, O O
the O O
equations B B
for O O
all O O
the O O
cameras O O
become O O
independent O O
, O O
and O O
vice O O
versa O O
. O O
successive B O
approximation I O
. O O
( O O
a O O
) O O
( O O
b O O
) O O
figure O O
10.22 O O
local B B
tone O O
mapping O O
using O O
bilateral O B
ﬁlter O O
( O O
durand O O
and O O
dorsey O O
2002 O O
) O O
: O O
( O O
a O O
) O O
low- O O
pass O O
and O O
high-pass O O
bilateral B B
ﬁltered O O
log O O
luminance O O
images O O
and O O
color B B
( O O
chrominance O O
) O O
image B B
; O O
( O O
b O O
) O O
resulting O O
tone-mapped O O
image B B
( O O
after O O
attenuating O O
the O O
low-pass B B
log O O
luminance O O
image B B
) O O
shows O O
no O O
halos B O
. O O
the O O
basic O O
binary O O
segmentation O O
algorithm B O
of O O
boykov O O
and O O
jolly O O
( O O
2001 O O
) O O
has O O
been O O
extended O O
in O O
a O O
number O O
of O O
directions O O
. O O
finally O O
, O O
section O O
2.3 O O
covers O O
how O O
sensors O O
work O O
, O O
including O O
topics O O
such O O
as O O
sampling B B
and O O
aliasing B B
, O O
color B B
sensing O O
, O O
and O O
in-camera O O
compression B B
. O O
does O O
context B B
or O O
whole O O
scene B O
understanding I O
perform O O
better O O
at O O
naming O O
objects O O
than O O
stand-alone O O
systems O O
? O O
14.8 O O
exercises O O
729 O O
ex O O
14.15 O O
: O O
tiny O O
images O O
download O O
the O O
tiny O O
images O O
database O O
from O O
http O O
: O O
//people.csail.mit O O
. O O
8.1 O O
translational B B
alignment O O
for O O
this O O
reason O O
, O O
normalized B B
cross-correlation O O
is O O
more O O
commonly O O
used O O
, O O
encc O O
( O O
u O O
) O O
= O O
( O O
cid:80 O O
) O O
i O O
[ O O
i0 O O
( O O
xi O O
) O O
− O O
i0 O O
] O O
[ O O
i1 O O
( O O
xi O O
+ O O
u O O
) O O
− O O
i1 O O
] O O
( O O
cid:113 O O
) O O
( O O
cid:80 O O
) O O
i O O
[ O O
i0 O O
( O O
xi O O
) O O
− O O
i0 O O
] O O
2 O O
( O O
cid:113 O O
) O O
( O O
cid:80 O O
) O O
i O O
[ O O
i1 O O
( O O
xi O O
+ O O
u O O
) O O
− O O
i1 O O
] O O
2 O O
, O O
where O O
i0 O O
= O O
i1 O O
= O O
i0 O O
( O O
xi O O
) O O
and O O
i1 O O
( O O
xi O O
+ O O
u O O
) O O
1 O O
n O O
( O O
cid:88 O O
) O O
i O O
n O O
( O O
cid:88 O O
) O O
i O O
1 O O
387 O O
( O O
8.11 O O
) O O
( O O
8.12 O O
) O O
( O O
8.13 O O
) O O
are O O
the O O
mean O O
images O O
of O O
the O O
corresponding O O
patches O O
and O O
n O O
is O O
the O O
number O O
of O O
pixels O O
in O O
the O O
patch B B
. O O
2006 O O
) O O
( O O
potentially O O
combined O O
with O O
crf O O
models O O
) O O
also O O
do O O
quite O O
well O O
: O O
csurka O O
and O O
perronnin O O
( O O
2008 O O
) O O
have O O
one O O
of O O
the O O
top O O
algorithms O O
in O O
the O O
voc O O
segmentation B B
challenge O O
. O O
this O O
kind O O
of O O
active O O
illu- O O
mination O O
has O O
been O O
used O O
from O O
the O O
earliest O O
days O O
of O O
machine O O
vision O O
to O O
construct O O
highly O O
reliable O O
surfaceccdlaser O O
( O O
a O O
) O O
direction O O
of O O
travelobjectccdccd O O
image B B
planelasercylindrical O O
lenslaser O O
sheetσzσx O O
( O O
b O O
) O O
( O O
c O O
) O O
( O O
d O O
) O O
586 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
( O O
a O O
) O O
( O O
b O O
) O O
( O O
c O O
) O O
figure O O
12.6 O O
shape O O
scanning O O
using O O
cast O O
shadows O O
( O O
bouguet O O
and O O
perona O O
1999 O O
) O O
c O O
( O O
cid:13 O O
) O O
1999 O O
springer O O
: O O
( O O
a O O
) O O
camera B B
setup O O
with O O
a O O
point O O
light O O
source O O
( O O
a O O
desk O O
lamp O O
without O O
its O O
reﬂector O O
) O O
, O O
a O O
hand-held O O
stick O O
casting O O
a O O
shadow B B
, O O
and O O
( O O
b O O
) O O
the O O
objects O O
being O O
scanned O O
in O O
front O O
of O O
two O O
planar O O
backgrounds O O
. O O
in O O
follow-on O O
work O O
, O O
grady O O
and O O
ali O O
( O O
2008 O O
) O O
use O O
a O O
precomputation O O
of O O
the O O
eigenvectors O O
of O O
the O O
linear B B
system O O
to O O
make O O
the O O
solution O O
with O O
a O O
novel O O
set O O
of O O
seeds O O
faster O O
, O O
which O O
is O O
related O O
to O O
the O O
laplacian O O
matting B B
problem O O
presented O O
in O O
section O O
10.4.3 O O
( O O
levin O O
, O O
acha O O
, O O
and O O
lischinski O O
2008 O O
) O O
. O O
we O O
can O O
express O O
ˆn O O
as O O
a O O
function O O
of O O
two O O
angles O O
( O O
θ O O
, O O
φ O O
) O O
, O O
ˆn O O
= O O
( O O
cos O O
θ O O
cos O O
φ O O
, O O
sin O O
θ O O
cos O O
φ O O
, O O
sin O O
φ O O
) O O
, O O
( O O
2.8 O O
) O O
i.e. O O
, O O
using O O
spherical O O
coordinates O O
, O O
but O O
these O O
are O O
less O O
commonly O O
used O O
than O O
polar O O
coordinates O O
since O O
they O O
do O O
not O O
uniformly O O
sample O O
the O O
space O O
of O O
possible O O
normal B O
vectors I O
. O O
718 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
in O O
more O O
recent O O
work O O
, O O
fergus O O
, O O
perona O O
, O O
and O O
zisserman O O
( O O
2004 O O
) O O
use O O
a O O
feature-based B B
learning O O
and O O
recognition B B
algorithm O O
to O O
re-rank O O
the O O
outputs O O
from O O
a O O
traditional O O
keyword-based O O
image B B
search I O
engine O O
. O O
an O O
animator O O
ﬁrst O O
extracts O O
the O O
eye O O
and O O
mouth O O
regions O O
of O O
each O O
sketch O O
and O O
draws O O
control O O
lines B B
over O O
each O O
image B B
( O O
figure O O
4.30a O O
) O O
. O O
accurate O O
, O O
dense O O
, O O
and O O
robust B B
multi-view O O
stereopsis O O
. O O
9.1.2 O O
application O O
: O O
whiteboard B B
and I I
document I I
scanning I I
the O O
simplest O O
image-stitching O O
application O O
is O O
to O O
stitch O O
together O O
a O O
number O O
of O O
image B B
scans O O
taken O O
on O O
a O O
ﬂatbed O O
scanner O O
. O O
such O O
ﬁlters O O
are O O
known O O
collectively O O
as O O
band-pass B B
ﬁlters O O
, O O
since O O
they O O
ﬁlter O O
out O O
both O O
low O O
and O O
high O B
frequencies O O
. O O
if O O
we O O
sweep O O
the O O
monochromatic O O
color B B
λ O O
pa- O O
rameter O O
in O O
figure O O
2.28b O O
from O O
λ O O
= O O
380nm O O
to O O
λ O O
= O O
800nm O O
, O O
we O O
obtain O O
the O O
familiar O O
chromaticity O O
diagram O O
shown O O
in O O
figure O O
2.29. O O
this O O
ﬁgure O O
shows O O
the O O
( O O
x O O
, O O
y O O
) O O
value O O
for O O
every O O
color B B
value O O
per- O O
ceivable O O
by O O
most O O
humans O O
. O O
alternatively O O
, O O
we O O
can O O
write O O
g O O
( O O
i O O
, O O
j O O
) O O
= O O
1 O O
r O O
( O O
cid:88 O O
) O O
k O O
, O O
l O O
f O O
( O O
k O O
, O O
l O O
) O O
h O O
( O O
i O O
− O O
k/r O O
, O O
j O O
− O O
l/r O O
) O O
( O O
3.81 O O
) O O
and O O
keep O O
the O O
same O O
kernel B B
h O O
( O O
k O O
, O O
l O O
) O O
for O O
both O O
interpolation B B
and O O
decimation O O
. O O
18 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
( O O
a O O
) O O
( O O
d O O
) O O
( O O
b O O
) O O
( O O
e O O
) O O
( O O
c O O
) O O
( O O
f O O
) O O
figure O O
1.10 O O
recent O O
examples B B
of O O
computer O O
vision O O
algorithms O O
: O O
( O O
a O O
) O O
image-based B B
rendering I I
( O O
gortler O O
, O O
grzeszczuk O O
, O O
szeliski O O
et O O
al O O
. O O
can O O
you O O
think O O
of O O
how O O
you O O
might O O
do O O
this O O
? O O
the O O
simplest O O
approach O O
is O O
to O O
match O O
frames O O
by O O
visual O O
similarity B B
( O O
e.g. O O
, O O
l2 O O
distance O O
) O O
and O O
to O O
jump O O
between O O
frames O O
that O O
appear O O
similar O O
. O O
( O O
a O O
) O O
using O O
face O O
detection B B
alone O O
, O O
( O O
b O O
) O O
the O O
combined O O
face B B
and O O
clothing O O
model O O
successfully O O
several O O
of O O
the O O
heads O O
are O O
missed O O
. O O
while O O
lowe O O
’ O O
s O O
scale O O
invariant O O
feature B B
transform O O
( O O
sift O O
) O O
performs O O
well O O
in O O
practice O O
, O O
it O O
is O O
not O O
based O O
on O O
the O O
same O O
theoretical O O
foundation O O
of O O
maximum O O
spatial O O
stability O I
as O O
the O O
auto-correlation- O O
based O O
detectors O O
. O O
spectral O O
embedding O O
and O O
min-cut O O
for O O
image O O
segmentation B B
. O O
in O O
ieee O O
computer O O
society O O
conference O O
on O O
computer O O
vision O O
and O O
pattern O O
recognition B B
( O O
cvpr O O
2007 O O
) O O
, O O
minneapolis O O
, O O
mn O O
. O O
once O O
the O O
two O O
meshes O O
have O O
been O O
speciﬁed O O
, O O
intermediate O O
warps O O
can O O
be O O
generated O O
using O O
linear O O
interpolation B O
and O O
the O O
displacements O O
at O O
mesh O O
nodes O O
can O O
be O O
interpolated O O
using O O
splines O O
. O O
machine O O
learning O B
for O O
high-speed O O
corner O O
detection B B
. O O
in O O
ieee O O
computer O O
society O O
conference O O
on O O
computer O O
vision O O
and O O
pattern O O
recognition B B
( O O
cvpr O O
’ O O
97 O O
) O O
, O O
pp O O
. O O
( O O
8.72 O O
) O O
if O O
, O O
however O O
, O O
the O O
motion B B
vectors O O
are O O
different O O
at O O
corresponding O O
locations O O
, O O
some O O
method O O
must O O
be O O
used O O
to O O
determine O O
which O O
is O O
correct O O
and O O
which O O
image B B
contains O O
colors O O
that O O
are O O
occluded O O
. O O
3.1 O O
point O O
operators O O
107 O O
figure O O
3.6 O O
an O O
example O O
of O O
light O O
reﬂecting O O
off O O
the O O
transparent B B
glass O O
of O O
a O O
picture O O
frame O O
( O O
black O O
and O O
anandan O O
1996 O O
) O O
c O O
( O O
cid:13 O O
) O O
1996 O O
elsevier O O
. O O
this O O
is O O
an O O
appropriate O O
model O O
if O O
the O O
noise B B
is O O
the O O
result O O
of O O
lots O O
of O O
tiny O O
errors O O
being O O
added O O
together O O
, O O
e.g. O O
, O O
from O O
thermal O O
noise B B
in O O
a O O
silicon O O
imager O O
. O O
thus O O
, O O
these O O
methods O O
perform O O
a O O
local B B
“ O O
winner- O O
take-all O O
” O O
( O O
wta O O
) O O
optimization O O
at O O
each O O
pixel O O
. O O
in O O
order B B
to O O
remove O O
most O O
of O O
the O O
noise B B
, O O
the O O
gaussian O O
ﬁlter O O
is O O
forced O O
to O O
smooth O O
away O O
high-frequency O O
detail O O
, O O
which O O
is O O
most O O
noticeable O O
near O O
strong O O
edges O O
. O O
by O O
merging O O
regions O O
in O O
decreasing O O
order B B
of O O
the O O
edges O O
separating O O
them O O
( O O
which O O
can O O
be O O
efﬁ- O O
ciently O O
evaluated O O
using O O
a O O
variant O O
of O O
kruskal O O
’ O O
s O O
minimum O O
spanning O O
tree O O
algorithm B B
) O O
, O O
they O O
prov- O O
ably O O
produce O O
segmentations O O
that O O
are O O
neither O O
too O O
ﬁne O O
( O O
there O O
exist O O
regions O O
that O O
could O O
have O O
been O O
merged O O
) O O
nor O O
too O O
coarse O O
( O O
there O O
are O O
regions O O
that O O
could O O
be O O
split O O
without O O
being O O
mergeable O O
) O O
. O O
when O O
different O O
imaging O O
modalities O O
are O O
being O O
registered O O
, O O
e.g. O O
, O O
computed O O
tomography O O
( O O
ct O O
) O O
scans O O
and O O
magnetic O O
resonance O O
images O O
( O O
mri O O
) O O
, O O
mutual O O
information O O
measures O O
of O O
similarity B B
are O O
often O O
necessary O O
( O O
viola O O
and O O
wells O O
iii O O
1997 O O
; O O
maes O O
, O O
collignon O O
, O O
vandermeulen O O
et O O
al O O
. O O
the O O
3d O O
positions O O
of O O
the O O
matched O O
feature B B
points O O
and O O
cameras O O
can O O
then O O
be O O
si- O O
multaneously O O
recovered O O
, O O
although O O
this O O
can O O
be O O
signiﬁcantly O O
more O O
expensive O O
than O O
parallax-free O O
image B B
registration I I
. O O
in O O
defense O O
of O O
the O O
8-point O O
algorithm B B
. O O
in O O
this O O
chapter O O
, O O
we O O
explore O O
a O O
variety O O
of O O
image-based B B
rendering I I
techniques O O
, O O
such O O
as O O
those O O
illustrated O B
in O O
figure O O
13.1. O O
we O O
begin O O
with O O
view O O
interpolation B B
( O O
section O O
13.1 O O
) O O
, O O
which O O
creates O B
a O O
seamless O O
transition O O
between O O
a O O
pair O O
of O O
reference O O
images O O
using O O
one O O
or O O
more O O
pre-computed O O
depth O O
maps O O
. O O
2. O O
extract O O
features O O
from O O
each O O
of O O
the O O
training O O
images O O
, O O
quantize O O
them O O
, O O
and O O
compute O O
the O O
tf-idf O O
vectors O O
( O O
bag B O
of I O
words I O
histograms O O
) O O
. O O
in O O
this O O
chapter O O
, O O
we O O
investigate O O
a O O
number O O
of O O
such O O
techniques O O
, O O
which O O
include O O
not O O
only O O
visual O O
cues O O
such O O
as O O
shading B B
and O O
focus B B
, O O
but O O
also O O
techniques O O
for O O
merging O O
multiple B B
range O O
or O O
depth O O
images O O
into O O
3d O O
models O O
, O O
as O O
well O O
as O O
techniques O O
for O O
reconstructing O O
specialized O O
models O O
, O O
such O O
as O O
heads O O
, O O
bodies O O
, O O
or O O
architecture B B
. O O
they O O
can O O
also O O
be O O
applied O O
to O O
video B B
sequences O O
( O O
teodosio O O
and O O
bender O O
1993 O O
; O O
irani O O
, O O
hsu O O
, O O
and O O
anandan O O
1995 O O
; O O
kumar O O
, O O
anandan O O
, O O
irani O O
et O O
al O O
. O O
let O O
us O O
assume O O
that O O
we O O
have O O
detected O O
two O O
or O O
more O O
orthogonal O O
vanishing O B
points B I
, O O
all O O
of O O
which O O
are O O
ﬁnite O O
, O O
i.e. O O
, O O
they O O
are O O
not O O
obtained O O
from O O
lines B B
that O O
appear O O
to O O
be O O
parallel O O
in O O
the O O
image B B
plane O O
( O O
figure O O
6.9a O O
) O O
. O O
once O O
the O O
intrapersonal O O
and O O
extrapersonal O O
likelihoods O O
have O O
been O O
computed O O
, O O
we O O
can O O
com- O O
pute O O
the O O
bayesian O O
likelihood O O
of O O
a O O
new O O
image B B
x O O
matching B B
a O O
training O O
image B B
xi O O
as O O
p O O
( O O
∆i O O
) O O
= O O
pi O O
( O O
∆i O O
) O O
li O O
pi O O
( O O
∆i O O
) O O
li O O
+ O O
pe O O
( O O
∆i O O
) O O
le O O
, O O
( O O
14.28 O O
) O O
where O O
li O O
and O O
le O O
are O O
the O O
prior B B
probabilities O O
of O O
two O O
images O O
being O O
in O O
the O O
same O O
or O O
in O O
different O O
classes O O
( O O
moghaddam O O
, O O
jebara O O
, O O
and O O
pentland O O
2000 O O
) O O
. O O
3. O O
compute O O
homographies O O
between O O
overlapping O O
frames O O
and O O
use O O
equations B B
( O O
6.56–6.57 O O
) O O
to O O
get O O
an O O
estimate O O
of O O
the O O
focal O O
length O O
. O O
learning B B
layered O O
motion B B
segmen- O O
tations O O
of O O
video B B
. O O
in O O
the O O
general O O
domain O O
of O O
biometrics B B
, O O
i.e. O O
, O O
identity O O
recogni- O O
tion B B
, O O
specialized O O
images O O
such O O
as O O
irises O O
and O O
ﬁngerprints O O
perform O O
even O O
better O O
( O O
jain O O
, O O
bolle O O
, O O
and O O
pankanti O O
1999 O O
; O O
pankanti O O
, O O
bolle O O
, O O
and O O
jain O O
2000 O O
; O O
daugman O O
2004 O O
) O O
. O O
however O O
, O O
for O O
applications O O
such O O
as O O
image B B
blending O O
( O O
discussed O O
later O O
in O O
this O O
section O O
) O O
, O O
this O O
aliasing B B
is O O
of O O
little O O
concern O B
. O O
the O O
ewa O O
is O O
also O O
quite O O
slow O O
, O O
although O O
faster O O
variants O O
based O O
on O O
mip- O O
mapping O O
have O O
been O O
proposed O O
( O O
szeliski O O
, O O
winder O O
, O O
and O O
uyttendaele O O
( O O
2010 O O
) O O
provide O O
some O O
addi- O O
tional O O
references B B
) O O
. O O
modeling B B
people O O
: O O
vision-based O O
understanding O O
of O O
a O O
person O O
’ O O
s O O
shape O O
, O O
appearance O O
, O O
movement O O
, O O
and O O
behaviour O O
. O O
to O O
mitigate O O
this O O
, O O
we O O
ﬁrst O O
subtract O O
the O O
mean O O
x O O
and O O
y O O
values O O
from O O
all O O
the O O
measured O O
points B B
ˆxi O O
= O O
xi O O
− O O
¯x O O
ˆyi O O
= O O
yi O O
− O O
¯y O O
and O O
then O O
ﬁt O O
the O O
2d O O
line O O
equation O O
a O O
( O O
x O O
− O O
¯x O O
) O O
+ O O
b O O
( O O
y O O
− O O
¯y O O
) O O
= O O
0 O O
by O O
minimizing O O
etls−2dm O O
= O O
( O O
cid:88 O O
) O O
i O O
( O O
aˆxi O O
+ O O
bˆyi O O
) O O
2 O O
. O O
deformed O O
lattice O O
detection B B
in O O
real-world O O
images O O
using O O
mean-shift O O
belief B B
propagation I I
. O O
computer O O
vision O O
and O O
image B B
understanding O O
, O O
63 O O
( O O
3 O O
) O O
:542–567 O O
. O O
for O O
example O O
, O O
the O O
alignment B B
of O O
images O O
based O O
on O O
matching B B
feature O I
points B B
involves O O
the O O
minimization O O
of O O
a O O
squared O O
distance O O
objective O O
function O O
( O O
6.2 O O
) O O
, O O
where O O
els O O
= O O
( O O
cid:88 O O
) O O
i O O
( O O
cid:107 O O
) O O
ri O O
( O O
cid:107 O O
) O O
2 O O
= O O
( O O
cid:88 O O
) O O
i O O
( O O
cid:107 O O
) O O
f O O
( O O
xi O O
; O O
p O O
) O O
− O O
x O O
( O O
cid:48 O O
) O O
i O O
( O O
cid:107 O O
) O O
2 O O
, O O
ri O O
= O O
f O O
( O O
xi O O
; O O
p O O
) O O
− O O
x O O
( O O
cid:48 O O
) O O
i O O
= O O
ˆx O O
( O O
cid:48 O O
) O O
i O O
− O O
˜x O O
( O O
cid:48 O O
) O O
i O O
( O O
a.23 O O
) O O
( O O
a.24 O O
) O O
is O O
the O O
residual O O
between O O
the O O
measured O O
location O O
ˆx O O
( O O
cid:48 O O
) O O
i O O
and O O
its O O
corresponding O O
current O O
predicted O O
lo- O O
cation O O
˜x O O
( O O
cid:48 O O
) O O
i O O
= O O
f O O
( O O
xi O O
; O O
p O O
) O O
. O O
when O O
image B B
stitching I I
is O O
being O O
performed O O
( O O
brown O O
and O O
lowe O O
2007 O O
) O O
, O O
the O O
motion B B
models I I
discussed O O
in O O
section O O
9.1 O O
can O O
be O O
used O O
instead O O
. O O
a O O
more O O
complex O O
, O O
but O O
more O O
widely O O
applicable O O
, O O
version O O
of O O
hashing B B
is O O
called O O
locality O O
sen- O O
sitive O O
hashing B B
, O O
which O O
uses O O
unions O O
of O O
independently O O
computed O O
hashing B B
functions O O
to O O
index O O
the O O
features O O
( O O
gionis O O
, O O
indyk O O
, O O
and O O
motwani O O
1999 O O
; O O
shakhnarovich O O
, O O
darrell O O
, O O
and O O
indyk O O
2006 O O
) O O
. O O
labeled O O
faces B B
in O O
the O O
wild O O
: O O
a O O
database O O
for O O
studying O O
face B B
recognition O O
in O O
unconstrained O O
environments O O
. O O
the O O
resampling O O
kernel B B
should O O
be O O
performing O O
regular O O
interpolation B B
along O O
the O O
x O O
dimension O O
and O O
smoothing B B
( O O
to O O
anti-alias O O
the O O
blurred O O
image B B
) O O
in O O
the O O
y O O
direction O O
. O O
( O O
10.12 O O
) O O
( O O
10.13 O O
) O O
( O O
10.14 O O
) O O
the O O
base O O
layer O O
is O O
then O O
contrast O O
reduced O O
by O O
scaling O O
to O O
the O O
desired O O
log-luminance O O
range O O
, O O
h O O
( O O
cid:48 O O
) O O
h O O
( O O
x O O
, O O
y O O
) O O
= O O
s O O
hh O O
( O O
x O O
, O O
y O O
) O O
( O O
10.15 O O
) O O
10.2 O O
high B O
dynamic I I
range I I
imaging O O
and O O
added O O
to O O
the O O
detail O O
layer O O
to O O
produce O O
the O O
new O O
log-luminance O O
image B B
i O O
( O O
x O O
, O O
y O O
) O O
= O O
h O O
( O O
cid:48 O O
) O O
h O O
( O O
x O O
, O O
y O O
) O O
+ O O
hl O O
( O O
x O O
, O O
y O O
) O O
, O O
489 O O
( O O
10.16 O O
) O O
which O O
can O O
then O O
be O O
exponentiated O O
to O O
produce O O
the O O
tone-mapped O O
( O O
compressed O O
) O O
luminance O O
im- O O
age O O
. O O
figure O O
11.18a O O
shows O O
an O O
image B B
of O O
the O O
3d O O
scene O O
ﬂow O O
for O O
the O O
tango O O
dancer O O
shown O O
in O O
figure O O
11.2h–j O O
, O O
while O O
figure O O
11.18b O O
shows O O
3d O O
scene O O
ﬂows O O
captured O O
from O O
a O O
moving O O
vehicle O O
for O O
the O O
purpose O O
of O O
obstacle O O
avoidance O O
. O O
space O O
is O O
used O O
to O O
estimate O O
this O O
foreground O O
color B B
and O O
the O O
distance O O
along O O
each O O
color B B
line O O
is O O
used O O
to O O
estimate O O
the O O
per-pixel O O
temporally O O
varying O O
alpha O O
( O O
figure O O
10.47 O O
) O O
. O O
alternative O O
approaches O O
to O O
handling O O
the O O
uncertainty B B
inherent O O
in O O
tracking O O
include O O
multiple B B
hypothesis I O
tracking O O
( O O
cham O O
and O O
rehg O O
1999 O O
) O O
and O O
inﬂated O O
covariances O O
( O O
sminchisescu O O
and O O
triggs O O
2001 O O
) O O
. O O
jim O O
blinn O O
’ O O
s O O
corner O O
: O O
compositing B B
, O O
part O O
1 O O
: O O
theory O O
. O O
sincqmf-9jpeg O O
2000 O O
3.5 O O
pyramids O O
and O O
wavelets O O
151 O O
figure O O
3.32 O O
a O O
traditional O O
image B B
pyramid O O
: O O
each O O
level O O
has O O
half O O
the O O
resolution O O
( O O
width O O
and O O
height O O
) O O
, O O
and O O
hence O O
a O O
quarter O O
of O O
the O O
pixels O O
, O O
of O O
its O O
parent O O
level O O
. O O
the O O
coarser O O
( O O
larger O O
kernel B B
) O O
gaussian O O
is O O
an O O
estimate O O
of O O
the O O
average O O
in- O O
tensity O O
over O O
a O O
larger O O
region B B
. O O
12.2.2 O O
application O O
: O O
digital B B
heritage I I
. O O
9.2.1 O O
bundle B O
adjustment I I
. O O
techniques O O
have O O
also O O
been O O
developed O O
for O O
splitting O O
or O O
merging B B
cluster O O
centers O O
290 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
( O O
a O O
) O O
( O O
c O O
) O O
( O O
b O O
) O O
( O O
d O O
) O O
( O O
e O O
) O O
figure O O
5.16 O O
mean-shift O O
image B B
segmentation O O
( O O
comaniciu O O
and O O
meer O O
2002 O O
) O O
c O O
( O O
cid:13 O O
) O O
2002 O O
ieee O O
: O O
( O O
a O O
) O O
input O O
color B B
image O O
; O O
( O O
b O O
) O O
pixels O O
plotted O O
in O O
l*u*v* O O
space O O
; O O
( O O
c O O
) O O
l*u* O O
space O O
distribution O O
; O O
( O O
d O O
) O O
clustered O O
results O O
after O O
159 O O
mean-shift O O
procedures O O
; O O
( O O
e O O
) O O
corresponding O O
trajectories O O
with O O
peaks O O
marked O O
as O O
red O O
dots O O
. O O
while O O
most O O
of O O
these O O
approaches O O
assume O O
a O O
standard O O
elastic O O
deformation O O
model O O
, O O
which O O
uses O O
quadratic O O
inter- O O
nal O O
smoothness B B
terms O O
, O O
it O O
is O O
also O O
possible O O
to O O
use O O
sub-linear O O
energy O O
models O O
in O O
order B B
to O O
better O O
preserve O O
surface B O
creases O O
( O O
diebel O O
, O O
thrun O O
, O O
and O O
br¨unig O O
2006 O O
) O O
. O O
( O O
10.8 O O
) O O
( O O
in O O
order B B
to O O
remove O O
the O O
overall O O
shift O O
ambiguity O O
in O O
the O O
response O O
curve O O
and O O
irradiance O O
values O O
, O O
the O O
middle O O
of O O
the O O
response O O
curve O O
is O O
set O O
to O O
0 O O
. O O
1 O O
introduction O O
what O O
is O O
computer O O
vision O O
? O O
• O O
a O O
brief O O
history O O
• O O
book O O
overview O O
• O O
sample O O
syllabus O O
• O O
notation O O
2 O O
image B B
formation O O
geometric B B
primitives O O
and O O
transformations O O
• O O
photometric B B
image O O
formation O O
• O O
the O O
digital O O
camera O O
3 O O
image B B
processing O O
1 O O
29 O O
99 O O
point O O
operators O O
• O O
linear B B
ﬁltering O O
• O O
more O O
neighborhood B B
operators O O
• O O
fourier O O
transforms O O
• O O
pyramids O O
and O O
wavelets O O
• O O
geometric B B
transformations O O
• O O
global B B
optimization I I
4 O O
feature B B
detection O O
and O O
matching B B
205 O O
points B B
and O O
patches O O
• O O
edges O O
• O O
lines B B
5 O O
segmentation B B
mean O O
shift O O
and O O
mode O O
ﬁnding O O
• O O
normalized B B
cuts I I
• O O
active B O
contours I I
• O O
split O O
and O O
merge O O
• O O
graph B B
cuts I I
and O O
energy-based B B
methods O O
6 O O
feature-based B B
alignment O O
2d O O
and O O
3d O O
feature-based B B
alignment O O
• O O
pose O O
estimation B B
• O O
geometric B B
intrinsic O O
calibration B B
7 O O
structure B B
from I I
motion I I
267 O O
309 O O
343 O O
triangulation B B
• O O
two-frame B B
structure O O
from O O
motion B B
• O O
factorization B B
• O O
bundle B B
adjustment I I
• O O
constrained B O
structure O O
and O O
motion B B
n^ O O
8 O O
dense O O
motion O O
estimation B B
translational O O
alignment B B
• O O
parametric B B
motion O O
• O O
spline-based B B
motion O O
• O O
optical B B
ﬂow I I
• O O
layered B B
motion O O
9 O O
image B B
stitching I I
motion O I
models O O
• O O
global B B
alignment I I
• O O
compositing B B
381 O O
427 O O
10 O O
computational O O
photography O O
467 O O
photometric B B
calibration O O
• O O
high B B
dynamic I I
range I I
imaging O O
• O O
super-resolution O O
and O O
blur B O
removal I I
• O O
image B B
matting O O
and O O
compositing B B
• O O
texture B B
analysis O O
and O O
synthesis O O
11 O O
stereo B B
correspondence O O
533 O O
epipolar B B
geometry I I
• O O
sparse B B
correspondence I I
• O O
dense B O
correspondence I O
• O O
local B B
methods I O
• O O
global B B
optimization I I
• O O
multi-view B B
stereo I I
12 O O
3d O O
reconstruction O O
577 O O
shape O O
from O O
x O O
• O O
active O O
rangeﬁnding O O
• O O
surface B B
representations O O
• O O
point-based B B
representations O O
• O O
volumetric B B
representations O O
• O O
model-based B O
reconstruction O O
• O O
619 O O
13 O O
image-based B B
rendering I I
recovering O O
texture B B
maps O O
and O O
albedos O O
view B O
interpolation I I
• O O
layered O B
depth O O
images O O
• O O
light O O
ﬁelds O O
and O O
lumigraphs O O
• O O
environment O O
mattes O O
• O O
video-based O O
rendering O O
14 O O
recognition B B
655 O O
instance B B
recognition O O
• O O
category O O
recognition O O
• O O
object O O
detection B B
• O O
face B B
recognition O O
• O O
context B B
and O O
scene B B
understanding I I
• O O
recognition B B
databases O O
and O O
test O O
sets O O
preface O O
the O O
seeds O O
for O O
this O O
book O O
were O O
ﬁrst O O
planted O O
in O O
2001 O O
when O O
steve O O
seitz O O
at O O
the O O
university O O
of O O
wash- O O
ington O O
invited O O
me O O
to O O
co-teach O O
a O O
course O O
called O O
“ O O
computer O O
vision O O
for O O
computer O O
graphics O O
” O O
. O O
px1x0 O O
( O O
r O O
, O O
t O O
) O O
p∞e1e0c0c1 O O
epipolar O O
planep∞p O O
( O O
r O O
, O O
t O O
) O O
c0c1epipolarlinesx0e0e1x1l1l0 O O
11.1 O O
epipolar B O
geometry I I
539 O O
( O O
a O O
) O O
( O O
c O O
) O O
( O O
b O O
) O O
( O O
d O O
) O O
figure O O
11.4 O O
the O O
multi-stage O O
stereo B B
rectiﬁcation O O
algorithm B O
of O O
loop O O
and O O
zhang O O
( O O
1999 O O
) O O
c O O
( O O
cid:13 O O
) O O
1999 O O
ieee O O
. O O
face B B
transfer O O
with O O
multilinear O O
models O O
. O O
one O O
possibility O O
is O O
to O O
triangulate O O
the O O
set O O
of O O
points B B
in O O
one O O
image B B
( O O
de O O
berg O O
, O O
cheong O O
, O O
van O O
kreveld O O
et O O
al O O
. O O
2008 O O
) O O
, O O
while O O
some O O
newer O O
systems O O
use O O
video B B
footage O O
to O O
control O O
the O O
animation O O
( O O
buck O O
, O O
finkelstein O O
, O O
jacobs O O
et O O
al O O
. O O
8.2.2 O O
learned B B
motion O I
models O O
. O O
factorization B B
methods O O
for O O
projective O B
structure O O
and O O
motion B B
. O O
pure B O
translation I B
( O O
known O O
rotation O O
) O O
in O O
the O O
case O O
where O O
we O O
know O O
the O O
rotation O O
, O O
we O O
can O O
pre-rotate O O
the O O
points B B
in O O
the O O
second O O
image O O
to O O
match O O
the O O
viewing O O
direction O O
of O O
the O O
ﬁrst O O
. O O
substitut- O O
ing O O
these O O
values O O
into O O
( O O
7.19 O O
) O O
to O O
obtain O O
e O O
, O O
we O O
can O O
test O O
this O O
essential O O
matrix O O
against O O
other O O
unused O O
feature B B
correspondences O O
to O O
select O O
the O O
correct O O
one O O
. O O
references B B
915 O O
ullman O O
, O O
s. O O
( O O
1979 O O
) O O
. O O
because O O
of O O
the O O
high O O
efﬁciency O O
in O O
both O O
quantizing O O
and O O
scoring O O
features O O
, O O
their O O
vocabulary- O O
tree-based O O
recognition B B
system O O
is O O
able O O
to O O
process O O
incoming O O
images O O
in O O
real O O
time O O
against O O
a O O
database O O
of O O
40,000 O O
cd O O
covers O O
and O O
at O O
1hz O O
when O O
matching B B
a O O
database O O
of O O
one O O
million O O
frames O O
taken O O
from O O
six O O
feature-length O O
movies O O
. O O
2009 O O
; O O
kolev O O
and O O
cremers O O
2009 O O
) O O
, O O
this O O
dependence O O
on O O
initialization B B
is O O
not O O
an O O
issue O O
. O O
4.1 O O
points B B
and O O
patches O O
215 O O
( O O
a O O
) O O
( O O
b O O
) O O
( O O
c O O
) O O
figure O O
4.8 O O
interest O O
operator O O
responses O O
: O O
( O O
a O O
) O O
sample O O
image B B
, O O
( O O
b O O
) O O
harris O O
response O O
, O O
and O O
( O O
c O O
) O O
dog O O
response O O
. O O
appendix O O
a O O
covers O O
linear B B
algebra O O
and O O
numerical O O
techniques O O
, O O
including O O
matrix O O
algebra O O
, O O
least B B
squares I I
, O O
and O O
iterative B B
techniques O O
. O O
the O O
radial B B
distortion I I
parameters O O
can O O
then O O
be O O
adjusted O O
until O O
all O O
of O O
the O O
lines B B
in O O
the O O
image B B
are O O
straight O O
, O O
which O O
is O O
commonly O O
called O O
the O O
plumb-line B O
method I O
( O O
brown O O
1971 O O
; O O
kang O O
2001 O O
; O O
el-melegy O O
and O O
farag O O
2003 O O
) O O
. O O
improved O O
transitions O O
can O O
also O O
be O O
obtained O O
by O O
performing O O
3d O O
graph B O
cuts I I
on O O
the O O
spatio-temporal O O
volume O O
around O O
a O O
transition O O
( O O
kwatra O O
, O O
sch¨odl O O
, O O
essa O O
et O O
al O O
. O O
another O O
important O O
class O O
of O O
global B B
operators O O
are O O
geometric B B
transformations O O
, O O
such O O
as O O
rotations O O
, O O
shears O O
, O O
and O O
perspective B B
deformations O O
( O O
section O O
3.6 O O
) O O
. O O
10.5 O O
texture B B
analysis O O
and O O
synthesis O O
10.6 O O
additional O O
reading O O
. O O
in O O
chapter O O
11 O O
, O O
we O O
turn O O
to O O
the O O
issue O O
of O O
stereo B B
correspondence O O
, O O
which O O
can O O
be O O
thought O O
of O O
as O O
a O O
special O O
case O O
of O O
motion B B
estimation I I
where O O
the O O
camera B B
positions O O
are O O
already O O
known O O
( O O
sec- O O
tion B B
11.1 O O
) O O
. O O
when O O
the O O
problem O O
involves O O
non-linear B B
least O O
squares O O
, O O
the O O
inverse B B
of O O
the O O
hessian O O
matrix O O
provides O O
the O O
cramer–rao O O
lower O O
bound O O
on O O
the O O
covariance O O
matrix O O
, O O
i.e. O O
, O O
it O O
provides O O
the O O
minimum O O
amount O O
of O O
covariance O O
in O O
a O O
given O O
solution O O
, O O
which O O
can O O
actually O O
have O O
a O O
wider O O
spread O O
( O O
“ O O
longer O O
tails O O
” O O
) O O
if O O
the O O
energy O O
ﬂattens O O
out O O
away O O
from O O
the O O
local B B
minimum O O
where O O
the O O
optimal O O
solution O O
is O O
found O O
. O O
dense O O
mirroring O O
surface B B
re- O O
covery O O
from O O
1d O O
homographies O O
and O O
sparse B B
correspondences O O
. O O
maire O O
, O O
m. O O
, O O
arbelaez O O
, O O
p. O O
, O O
fowlkes O O
, O O
c. O O
, O O
and O O
malik O O
, O O
j. O O
and O O
localize O O
junctions O O
in O O
natural B B
images O O
. O O
a.1.4 O O
cholesky O O
factorization B B
. O O
in O O
fourth O O
international O O
conference O O
on O O
3-d O O
digital O O
imaging O O
and O O
modeling B B
, O O
banff O O
. O O
consider O O
light O O
reﬂecting O O
off O O
a O O
mirrored O O
surface B O
( O O
figure O O
2.17b O O
) O O
. O O
note O O
that O O
these O O
diagrams O O
, O O
which O O
use O O
the O O
cyclopean O O
representation O O
of O O
depth O O
, O O
i.e. O O
, O O
depth O O
relative O O
to O O
a O O
camera B B
between O O
the O O
two O O
input O O
cameras O O
, O O
show O O
an O O
“ O O
unskewed O O
” O O
x-d O O
slice O O
through O O
the O O
dsi O O
. O O
this O O
transformation O O
changes O O
the O O
aspect O O
ratio O O
of O O
an O O
image B B
, O O
x O O
( O O
cid:48 O O
) O O
= O O
sxx O O
+ O O
tx O O
y O O
( O O
cid:48 O O
) O O
= O O
syy O O
+ O O
ty O O
, O O
and O O
is O O
a O O
restricted B B
form O O
of O O
an O O
afﬁne B B
transformation O O
. O O
in O O
addition O O
to O O
the O O
three O O
color B B
rgb O O
channels O O
, O O
an O O
alpha-matted O O
image B B
contains O O
a O O
fourth O O
alpha O O
channel O O
α O O
( O O
or O O
a O O
) O O
that O O
describes O O
the O O
relative O O
amount O O
of O O
opacity B B
or O O
fractional O O
coverage O O
at O O
each O O
pixel O O
( O O
figures O O
3.4c O O
and O O
3.5b O O
) O O
. O O
( O O
9.43 O O
) O O
more O O
sophisticated O O
seam O O
penalties O O
can O O
also O O
look O O
at O O
image B B
gradients O O
or O O
the O O
presence O O
of O O
image B B
edges O O
( O O
agarwala O O
, O O
dontcheva O O
, O O
agrawala O O
et O O
al O O
. O O
ex O O
12.7 O O
: O O
body B B
tracker O O
download O O
the O O
video B B
sequences O O
from O O
the O O
humaneva O O
web O O
site.16 O O
either O O
implement O O
a O O
human B O
motion I I
tracker O O
from O O
scratch O O
or O O
extend O O
the O O
code O O
on O O
that O O
web O O
site O O
( O O
sigal O O
, O O
balan O O
, O O
and O O
black O O
2010 O O
) O O
in O O
some O O
interesting O O
way O O
. O O
an O O
easier O O
to O O
understand O O
( O O
and O O
implement O O
) O O
version O O
of O O
the O O
above O O
non-linear B B
regression O O
prob- O O
lem O O
can O O
be O O
constructed O O
by O O
re-writing O O
the O O
projection O O
equations B B
as O O
a O O
concatenation O O
of O O
simpler O O
steps O O
, O O
each O O
of O O
which O O
transforms O O
a O O
4d O O
homogeneous O O
coordinate O O
pi O O
by O O
a O O
simple O O
transformation O O
6.2 O O
pose O O
estimation B B
325 O O
figure O O
6.5 O O
a O O
set O O
of O O
chained O O
transforms O O
for O O
projecting O O
a O O
3d O O
point O O
pi O O
to O O
a O O
2d O O
measurement O O
xi O O
through O O
a O O
series O O
of O O
transformations O O
f O O
( O O
k O O
) O O
, O O
each O O
of O O
which O O
is O O
controlled O O
by O O
its O O
own O O
set O O
of O O
param- O O
eters O O
. O O
computer O O
facial B O
animation I O
. O O
face B B
recognition O O
using O O
eigenfaces O O
. O O
) O O
click O O
on O O
pairs B B
of O O
points B B
( O O
one O O
on O O
the O O
ground O O
plane O O
, O O
one O O
above O O
it O O
) O O
to O O
measure O O
vertical O O
heights O B
. O O
b.5.3 O O
belief B B
propagation I I
belief O O
propagation O I
is O O
an O O
inference B B
technique O O
originally O O
developed O O
for O O
trees O O
( O O
pearl O O
1988 O O
) O O
but O O
more O O
recently O O
extended O O
to O O
“ O O
loopy O B
” O O
( O O
cyclic O O
) O O
graphs O O
such O O
as O O
mrfs O O
( O O
frey O O
and O O
mackay O O
1997 O O
; O O
freeman O O
, O O
pasztor O O
, O O
and O O
carmichael O O
2000 O O
; O O
yedidia O O
, O O
freeman O O
, O O
and O O
weiss O O
2001 O O
; O O
weiss O O
and O O
free- O O
man O O
2001a O O
, O O
b O O
; O O
yuille O O
2002 O O
; O O
sun O O
, O O
zheng O O
, O O
and O O
shum O O
2003 O O
; O O
felzenszwalb O O
and O O
huttenlocher O O
2006 O O
) O O
. O O
per- O O
formance O O
relighting O O
and O O
reﬂectance B B
transformation O O
with O O
time-multiplexed O O
illumination O O
. O O
12.3.2 O O
surface B B
simpliﬁcation O O
. O O
14.2 O O
face B B
recognition O O
679 O O
( O O
a O O
) O O
( O O
b O O
) O O
figure O O
14.19 O O
view-based O O
eigenspace O O
( O O
moghaddam O O
and O O
pentland O O
1997 O O
) O O
c O O
( O O
cid:13 O O
) O O
1997 O O
ieee O O
. O O
in O O
practice O O
, O O
however O O
, O O
it O O
appears O O
that O O
simply O O
adding O O
a O O
small O O
amount O O
of O O
the O O
hessian O O
diagonal O O
λdiag O O
( O O
a O O
) O O
to O O
the O O
hessian O O
a O O
itself O O
, O O
as O O
is O O
done O O
in O O
the O O
levenberg–marquardt O O
non-linear B O
least O O
squares O O
algorithm B O
( O O
appendix O O
a.3 O O
) O O
, O O
usually O O
16 O O
bas-relief O O
refers O O
to O O
a O O
kind O O
of O O
sculpture O O
in O O
which O O
objects O O
, O O
often O O
on O O
ornamental O O
friezes O O
, O O
are O O
sculpted O O
with O O
less O O
depth O O
than O O
they O O
actually O O
occupy O O
. O O
ex O O
14.7 O O
: O O
pedestrian B B
detection O O
build O O
and O O
test O O
one O O
of O O
the O O
pedestrian B B
detectors O O
presented O O
in O O
section O O
14.1.2. O O
ex O O
14.8 O O
: O O
simple O O
instance B B
recognition O O
use O O
the O O
feature B B
detection O O
, O O
matching B B
, O O
and O O
alignment B B
algorithms O O
you O O
developed O O
in O O
exercises O O
4.1–4.4 O O
and O O
9.2 O O
to O O
ﬁnd O O
matching B B
images O O
given O O
a O O
query O O
image O O
or O O
region B B
( O O
figure O O
14.26 O O
) O O
. O O
a O O
better O O
approach O O
is O O
to O O
hallucinate O O
virtual O O
point O O
correspondences O O
within O O
the O O
areas O O
from O O
which O O
each O O
homography B O
was O O
computed O O
and O O
to O O
feed O O
them O O
into O O
a O O
standard O O
structure O O
from O O
mo- O O
tion B B
algorithm O O
( O O
szeliski O O
and O O
torr O O
1998 O O
) O O
. O O
5. O O
convert O O
the O O
resulting O O
images O O
into O O
an O O
animated O O
gif O O
( O O
using O O
software O O
available O O
from O O
the O O
web O O
) O O
or O O
optionally O O
implement O O
cross-dissolves O O
to O O
turn O O
them O O
into O O
a O O
“ O O
slo-mo O O
” O O
video B B
. O O
taucs O O
( O O
sparse B B
direct O O
, O O
iterative B B
, O O
out O O
of O O
core O O
, O O
preconditioners O O
) O O
, O O
http O O
: O O
//www.tau.ac.il/ O O
∼stoledo/taucs/ O O
. O O
the O O
equation B B
mapping O O
a O O
3d O O
point O O
xi O O
into O O
a O O
point O O
xij O O
in O O
frame O O
j O O
can O O
be O O
re-written O O
from O O
equations B B
( O O
2.68 O O
) O O
and O O
( O O
9.5 O O
) O O
as O O
j O O
˜xij O O
, O O
˜xij O O
∼ O O
kjrjxi O O
and O O
xi O O
∼ O O
r−1 O O
j O O
k−1 O O
( O O
9.26 O O
) O O
where O O
kj O O
= O O
diag O O
( O O
fj O O
, O O
fj O O
, O O
1 O O
) O O
is O O
the O O
simpliﬁed O O
form O O
of O O
the O O
calibration B B
matrix I O
. O O
to O O
make O O
the O O
algorithm B B
more O O
efﬁcient O O
, O O
the O O
computations O O
are O O
per- O O
formed O O
by O O
discretizing O O
the O O
virtual O O
camera O O
’ O O
s O O
image B B
plane O O
using O O
a O O
regular O O
grid O O
overlaid O O
with O O
the O O
polyhedral O O
object O O
mesh O O
model O O
and O O
the O O
input O O
camera B B
centers O O
of O O
projection O O
and O O
interpolating O O
the O O
weighting B B
functions O O
between O O
vertices O O
. O O
levmar O O
: O O
levenberg–marquardt O O
nonlinear O O
least B O
squares I I
algorithms O O
, O O
http O O
: O O
//www.ics.forth O O
. O O
computer O O
vision O O
and O O
image B B
understanding O O
, O O
84 O O
( O O
1 O O
) O O
:126–143 O O
. O O
recognition B B
( O O
cvpr O O
2008 O O
) O O
, O O
anchorage O O
, O O
ak O O
. O O
( O O
optional O O
) O O
write O O
an O O
interactive B B
renderer O O
to O O
generate O O
in-between O O
frames O O
or O O
view O B
the O O
scene O O
from O O
different O O
viewpoints O O
( O O
shade O O
, O O
gortler O O
, O O
he O O
et O O
al O O
. O O
the O O
subject O O
of O O
tone B B
mapping I I
is O O
treated O O
extensively O O
in O O
( O O
reinhard O O
, O O
ward O O
, O O
pattanaik O O
et O O
al O O
. O O
the O O
requirement O O
for O O
a O O
reference O O
image B B
makes O O
their O O
approach O O
less O O
applicable O O
to O O
general O O
image B B
mosaicing O O
, O O
al- O O
though O O
an O O
extension O O
to O O
this O O
case O O
could O O
certainly O B
be O O
envisaged O O
. O O
the O O
ﬁll O O
factor O O
is O O
the O O
active O O
sensing O O
area O O
size O O
as O O
a O O
fraction O O
of O O
the O O
theoretically O O
available O O
sensing O O
area O O
( O O
the O O
product O O
of O O
the O O
horizontal O O
and O O
vertical O O
sampling B B
pitches O O
) O O
. O O
dynamic B B
3d O O
models O O
with O O
local O O
and O O
global B B
de- O O
ieee O O
transactions O O
on O O
pattern O O
analysis O O
and O O
formations O O
: O O
deformable O O
superquadrics O O
. O O
if O O
images O O
are O O
being O O
stored O O
in O O
the O O
more O O
common O O
jpeg O O
format O O
, O O
the O O
camera B B
’ O O
s O O
digital O O
signal O O
processor O O
( O O
dsp O O
) O O
next O O
performs O O
bayer O O
pattern O O
demosaicing B B
( O O
sections O O
2.3.2 O O
and O O
10.3.1 O O
) O O
, O O
which O O
is O O
a O O
mostly O O
linear B O
( O O
but O O
often O O
non-stationary O O
) O O
process O O
. O O
7.5 O O
constrained B O
structure O O
and O O
motion B B
the O O
most O O
general O O
algorithms O O
for O O
structure O O
from O O
motion B B
make O O
no O O
prior B B
assumptions O O
about O O
the O O
objects O O
or O O
scenes O O
that O O
they O O
are O O
reconstructing O O
. O O
4 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
( O O
a O O
) O O
( O O
c O O
) O O
( O O
b O O
) O O
( O O
d O O
) O O
figure O O
1.3 O O
some O O
common O O
optical O O
illusions O O
and O O
what O O
they O O
might O O
tell O O
us O O
about O O
the O O
visual O B
sys- O O
tem O O
: O O
( O O
a O O
) O O
the O O
classic O O
m¨uller-lyer O O
illusion O O
, O O
where O O
the O O
length O O
of O O
the O O
two O O
horizontal O O
lines B B
appear O O
different O O
, O O
probably O O
due O O
to O O
the O O
imagined O O
perspective B B
effects O O
. O O
note O O
that O O
radial B B
distortion I I
needs O O
to O O
be O O
removed O O
from O O
such O O
images O O
before O O
the O O
feature B B
points O O
can O O
be O O
used O O
for O O
calibration O O
. O O
11.1 O O
epipolar B B
geometry I I
537 O O
the O O
general O O
taxonomy B B
proposed O O
by O O
scharstein O O
and O O
szeliski O O
( O O
2002 O O
) O O
. O O
the O O
area O O
of O O
feature B B
point O O
detectors O O
continues O O
to O O
be O O
very O O
active O O
, O O
with O O
papers O O
appearing O O
ev- O O
ery O O
year O O
at O O
major O O
computer O O
vision O O
conferences O O
( O O
xiao O O
and O O
shah O O
2003 O O
; O O
koethe O O
2003 O O
; O O
carneiro O O
and O O
jepson O O
2005 O O
; O O
kenney O O
, O O
zuliani O O
, O O
and O O
manjunath O O
2005 O O
; O O
bay O O
, O O
tuytelaars O O
, O O
and O O
van O O
gool O O
2006 O O
; O O
platel O O
, O O
balmachnova O O
, O O
florack O O
et O O
al O O
. O O
the O O
lines B B
are O O
initially O O
used O O
to O O
establish O O
an O O
absolute O O
rotation O O
for O O
each O O
panorama O O
and O O
are O O
later O O
used O O
( O O
along O O
with O O
the O O
inferred O O
vertices O O
and O O
planes B B
) O O
to O O
infer O O
a O O
3d O O
structure O O
, O O
which O O
can O O
be O O
recovered O O
up O O
to O O
scale O O
from O O
one O O
or O O
more O O
images O O
( O O
figure O O
12.15 O O
) O O
. O O
figure O O
4.38 O O
changing O O
the O O
character O O
of O O
a O O
curve O O
without O O
affecting O O
its O O
sweep O O
( O O
finkelstein O O
and O O
salesin O O
1994 O O
) O O
c O O
( O O
cid:13 O O
) O O
1994 O O
acm O O
: O O
higher O O
frequency O O
wavelets O O
can O O
be O O
replaced O O
with O O
exemplars O O
from O O
a O O
style O O
library O O
to O O
effect O O
different O O
local B B
appearances O O
. O O
when O O
multiplied O O
together O O
, O O
these O O
yield O O
the O O
data-dependent O O
bilateral B B
weight O O
function O O
w O O
( O O
i O O
, O O
j O O
, O O
k O O
, O O
l O O
) O O
= O O
exp O O
( O O
cid:18 O O
) O O
− O O
( O O
i O O
− O O
k O O
) O O
2 O O
+ O O
( O O
j O O
− O O
l O O
) O O
2 O O
2σ2 O O
d O O
− O O
( O O
cid:107 O O
) O O
f O O
( O O
i O O
, O O
j O O
) O O
− O O
f O O
( O O
k O O
, O O
l O O
) O O
( O O
cid:107 O O
) O O
2 O O
2σ2 O O
r O O
( O O
cid:19 O O
) O O
. O O
equation B B
( O O
2.78 O O
) O O
) O O
, O O
ˆx O O
= O O
x O O
( O O
1 O O
+ O O
κ1r2 O O
+ O O
κ2r4 O O
) O O
ˆy O O
= O O
y O O
( O O
1 O O
+ O O
κ1r2 O O
+ O O
κ2r4 O O
) O O
, O O
( O O
6.59 O O
) O O
where O O
r2 O O
= O O
x2 O O
+ O O
y2 O O
and O O
κ1 O O
and O O
κ2 O O
are O O
called O O
the O O
radial B B
distortion I I
parameters O O
( O O
brown O O
1971 O O
; O O
slama O O
1980 O O
) O O
.13 O O
a O O
variety O O
of O O
techniques O O
can O O
be O O
used O O
to O O
estimate O O
the O O
radial B B
distortion I I
parameters O O
for O O
a O O
given O O
lens.14 O O
one O O
of O O
the O O
simplest O O
and O O
most O O
useful O O
is O O
to O O
take O O
an O O
image B B
of O O
a O O
scene O O
with O O
a O O
lot O O
13 O O
sometimes O O
the O O
relationship O O
between O O
x O O
and O O
ˆx O O
is O O
expressed O O
the O O
other O O
way O O
around O O
, O O
i.e. O O
, O O
using O O
primed O O
( O O
ﬁnal O O
) O O
coordinates O O
on O O
the O O
right-hand O O
side O O
, O O
x O O
= O O
ˆx O O
( O O
1 O O
+ O O
κ1 O O
ˆr2 O O
+ O O
κ2 O O
ˆr4 O O
) O O
. O O
the O O
latter O O
, O O
which O O
is O O
also O O
known O O
as O O
category-level O O
or O O
generic O O
object O O
recognition B B
( O O
ponce O O
, O O
hebert O O
, O O
schmid O O
et O O
al O O
. O O
for O O
these O O
examples B B
, O O
we O O
use O O
a O O
one-lobe O O
raised O O
cosine O O
, O O
rcos O O
( O O
x O O
) O O
= O O
( O O
1 O O
+ O O
cos O O
πx O O
) O O
box O O
( O O
x O O
) O O
, O O
( O O
3.61 O O
) O O
1 O O
2 O O
also O O
known O O
as O O
the O O
hann O O
window O O
, O O
as O O
the O O
windowing O O
function O O
. O O
after O O
an O O
initial O O
set O O
of O O
training O O
images O O
has O O
been O O
collected O O
, O O
some O O
optional O O
pre-processing O O
can O O
be O O
performed O O
, O O
such O O
as O O
subtracting O O
an O O
average O O
gradient O O
( O O
linear B B
function O O
) O O
from O O
the O O
image B B
to O O
compensate O O
for O O
global O O
shading B O
effects O O
and O O
using O O
histogram O O
equalization O O
to O O
compensate O O
for O O
varying O O
camera B B
contrast O O
( O O
figure O O
14.3c O O
) O O
. O O
in O O
this O O
case O O
, O O
the O O
posterior B B
distribution I I
is O O
a O O
multi-variate O O
gaussian O O
and O O
the O O
covariance O O
can O O
be O O
computed O O
directly O O
from O O
the O O
inverse B B
of O O
the O O
problem O O
hes- O O
sian O O
. O O
dynamic B O
monocular O O
machine O O
vision O O
. O O
line O O
segments O O
inﬂuence O O
the O O
overall O O
displacement O O
of O O
the O O
image B B
using O O
a O O
weighting B B
function O O
that O O
depends O O
on O O
the O O
mini- O O
mum O O
distance O O
to O O
the O O
line O O
segment O O
( O O
v O O
in O O
figure O O
3.52a O O
if O O
u O O
∈ O O
[ O O
0 O O
, O O
1 O O
] O O
, O O
else O O
the O O
shorter O O
of O O
the O O
two O O
distances O O
to O O
p O O
and O O
q O O
) O O
. O O
to O O
create O O
such O O
a O O
transition O O
, O O
you O O
must O O
ﬁrst O O
smoothly O O
interpolate O O
the O O
camera B B
matrices O O
, O O
i.e. O O
, O O
the O O
camera B B
positions O O
, O O
orientations O O
, O O
and O O
focal O O
lengths O O
. O O
mean B B
shift I I
, O O
on O O
the O O
other O O
hand O O
, O O
smoothes O O
the O O
distribution O O
and O O
ﬁnds O O
its O O
peaks O O
as O O
well O O
as O O
the O O
regions O O
of O O
feature B B
space O O
that O O
correspond O O
to O O
each O O
peak O O
. O O
the O O
most O O
principled O O
way O O
to O O
formulate O O
the O O
super-resolution O O
problem O O
is O O
to O O
write O O
down O O
the O O
stochastic O O
image O O
formation O O
equations B B
and O O
image B B
priors O I
and O O
to O O
then O O
use O O
bayesian O O
inference B B
to O O
recover O O
the O O
super-resolved O O
( O O
original O O
) O O
sharp O O
image B B
. O O
examples B B
of O O
such O O
outliers O O
include O O
bad O O
feature B B
matches O O
( O O
section O O
6.1.4 O O
) O O
, O O
occlusions O O
in O O
stereo B B
matching I I
( O O
chapter O O
11 O O
) O O
, O O
and O O
discontinuities O O
in O O
an O O
otherwise O O
smooth O O
image B B
, O O
depth B O
map I I
, O O
or O O
label O O
image B B
( O O
sections O O
3.7.1 O O
and O O
3.7.2 O O
) O O
. O O
b.6 O O
uncertainty B O
estimation O O
( O O
error O O
analysis O O
) O O
in O O
addition O O
to O O
computing O O
the O O
most O O
likely O O
estimate O O
, O O
many O O
applications O O
require O O
an O O
estimate O O
for O O
the O O
uncertainty B B
in O O
this O O
estimate.9 O O
the O O
most O O
general O O
way O O
to O O
do O O
this O O
is O O
to O O
compute O O
a O O
complete O O
probability O O
distribution O O
over O O
all O O
of O O
the O O
unknowns O O
but O O
this O O
is O O
generally O O
intractable O O
. O O
parametric B B
image O O
alignment B B
using O O
enhanced O O
correlation O O
coefﬁcient O O
maximization O O
. O O
to O O
perform O O
an O O
image-based B B
exploration O O
of O O
the O O
resulting O O
sea O O
of O O
images O O
( O O
aliaga O O
, O O
funkhouser O O
, O O
yanovsky O O
et O O
al O O
. O O
9.2 O O
global B B
alignment I I
449 O O
figure O O
9.12 O O
matching B B
errors O O
( O O
brown O O
, O O
szeliski O O
, O O
and O O
winder O O
2004 O O
) O O
: O O
accidental O O
matching B B
of O O
several O O
features O O
can O O
lead O O
to O O
matches O O
between O O
pairs B B
of O O
images O O
that O O
do O O
not O O
actually O O
overlap O O
. O O
instead O O
of O O
computing O O
the O O
mean O O
for O O
each O O
class O O
and O O
then O O
the O O
within-class B O
and O O
between-class B O
distributions O O
, O O
consider O O
evaluating O O
the O O
difference B B
images O O
∆ij O O
= O O
xi O O
− O O
xj O O
( O O
14.23 O O
) O O
between O O
all O O
pairs B B
of O O
training O O
images O O
( O O
xi O O
, O O
xj O O
) O O
. O O
spectral O O
matting B B
. O O
then O O
, O O
we O O
use O O
the O O
observation O O
, O O
ﬁrst O O
made O O
in O O
equation B B
( O O
2.72 O O
) O O
and O O
explored O O
in O O
more O O
detail O O
in O O
section O O
9.1.3 O O
( O O
9.5 O O
) O O
, O O
that O O
each O O
homog- O O
raphy O O
is O O
related O O
to O O
the O O
inter-camera O O
rotation O O
rij O O
through O O
the O O
( O O
unknown O O
) O O
calibration B B
matrices O O
6.3 O O
geometric B B
intrinsic O O
calibration B B
ki O O
and O O
kj O O
, O O
˜h O O
ij O O
= O O
kirir−1 O O
j O O
k−1 O O
j O O
= O O
kirijk−1 O O
j O O
333 O O
( O O
6.52 O O
) O O
. O O
the O O
input O O
should O O
be O O
a O O
grayscale O O
or O O
color B B
image O O
and O O
the O O
output O O
should O O
be O O
a O O
multi-banded O O
◦ O O
◦ O O
image B O
consisting O O
of O O
g0 O O
1 O O
and O O
g90 O O
. O O
thus O O
, O O
it O O
k O O
by O O
r1 O O
and O O
pre-multiply O O
[ O O
r|t O O
] O O
by O O
rt O O
is O O
impossible O O
based O O
on O O
image B B
measurements O O
alone O O
to O O
know O O
the O O
true O O
orientation O O
of O O
the O O
sensor B B
and O O
the O O
true O O
camera O B
intrinsics O O
. O O
14.4 O O
category O O
recognition O O
while O O
instance B B
recognition O O
techniques O O
are O O
relatively O O
mature O O
and O O
are O O
used O O
in O O
commercial O O
ap- O O
plications O O
, O O
such O O
as O O
photosynth O O
( O O
section O O
13.1.2 O O
) O O
, O O
generic O O
category O O
( O O
class O O
) O O
recognition B B
is O O
still O O
a O O
largely O O
unsolved O O
problem O O
. O O
in O O
any O O
case O O
, O O
it O O
is O O
unclear O O
when O O
a O O
fully O O
projective B B
reconstruction O O
would O O
be O O
preferable O O
to O O
a O O
partially O O
calibrated O O
one O O
, O O
especially O O
if O O
they O O
are O O
being O O
used O O
to O O
initialize O O
a O O
full O O
bundle B B
adjustment I I
of O O
all O O
the O O
parameters B B
. O O
an O O
even O O
better O O
approach O O
is O O
to O O
use O O
full O O
bundle O B
adjust- O O
ment O O
with O O
explicit O O
plane O O
equations O O
, O O
as O O
well O O
as O O
additional O O
constraints O O
to O O
force O O
reconstructed O O
co-planar O O
features O O
to O O
lie O O
exactly O O
on O O
their O O
corresponding O O
planes B O
. O O
3. O O
alternatively O O
, O O
generalize O O
a O O
previously O O
developed O O
connected O B
component O O
algorithm B B
( O O
ex- O O
ercise O O
3.14 O O
) O O
to O O
perform O O
the O O
linking B B
in O O
just O O
two O O
raster O O
passes O O
. O O
unordered O O
labels O O
another O O
case O O
with O O
multi-valued O O
labels O O
where O O
markov O O
random O O
ﬁelds O O
are O O
often O O
applied O O
are O O
unordered O O
labels O O
, O O
i.e. O O
, O O
labels O O
where O O
there O O
is O O
no O O
semantic O O
meaning O O
to O O
the O O
numerical O O
difference B O
between O O
the O O
values O O
of O O
two O O
labels O O
. O O
discriminative O O
density O O
propagation O O
for O O
3d O O
human B O
motion I I
estimation O I
. O O
when O O
the O O
3d O O
structure O O
of O O
the O O
scene O O
is O O
known O O
ahead O O
of O O
time O O
, O O
pose O O
estima- O O
tion B B
techniques O O
such O O
as O O
view O B
correlation O O
( O O
bogart O O
1991 O O
) O O
or O O
through-the-lens O O
camera B B
control O O
( O O
gleicher O O
and O O
witkin O O
1992 O O
) O O
can O O
be O O
used O O
, O O
as O O
described O O
in O O
section O O
6.2.3. O O
for O O
more O O
complex O O
scenes O O
, O O
it O O
is O O
usually O O
preferable O O
to O O
recover O O
the O O
3d O O
structure O O
simultane- O O
ously O O
with O O
the O O
camera B B
motion O O
using O O
structure-from-motion O O
techniques O O
. O O
when O O
the O O
number O O
of O O
tracked O O
points B B
drops O O
below O O
a O O
threshold O O
or O O
new O O
regions O O
in O O
the O O
image B B
become O I
visible O O
, O O
ﬁnd O O
additional O O
points B B
to O O
track O O
. O O
the O O
interactive B B
walk-through O O
experience O O
becomes O O
much O O
richer O O
and O O
more O O
navigable O O
if O O
an O O
overview O O
map O O
is O O
available O O
as O O
part O O
of O O
the O O
experience O O
. O O
alternatively O O
, O O
we O O
may O O
want O O
to O O
reduce O O
the O O
size O O
of O O
an O O
image B B
to O O
speed O O
up O O
the O O
execution O O
of O O
an O O
algorithm B B
or O O
to O O
save O O
on O O
storage O O
space O O
or O O
transmission O O
time O O
. O O
consider O O
the O O
three O O
classes O O
shown O O
as O O
different O O
colors O O
in O O
figure O O
14.16. O O
as O O
you O O
can O O
see O O
, O O
the O O
distributions O O
within O O
a O O
class O O
( O O
indicated O O
by O O
the O O
tilted O O
colored O O
axes O O
) O O
are O O
elongated O O
and O O
tilted O O
with O O
respect O O
to O O
the O O
main O O
face B B
space O O
pca O O
, O O
14.2 O O
face B B
recognition O O
675 O O
figure O O
14.16 O O
simple O O
example O O
of O O
fisher O O
linear B B
discriminant O O
analysis O O
. O O
2008 O O
) O O
, O O
and O O
face B B
swapping O I
( O O
bitouk O O
, O O
kumar O O
, O O
dhillon O O
et O O
al O O
. O O
the O O
preceding O O
set O O
of O O
transformations O O
are O O
illustrated O O
in O O
figure O O
2.4 O O
and O O
summarized O O
in O O
table O O
2.1. O O
the O O
easiest O O
way O O
to O O
think O O
of O O
them O O
is O O
as O O
a O O
set O O
of O O
( O O
potentially O O
restricted B O
) O O
3 O O
× O O
3 O O
matrices O O
operating O O
on O O
2d O O
homogeneous O O
coordinate O O
vectors O O
. O O
we O O
see O O
from O O
this O O
that O O
the O O
centroid O O
of O O
the O O
2d O O
points B B
in O O
each O O
frame O O
¯xj O O
directly O O
gives O O
us O O
the O O
last O O
element O O
of O O
˜p O O
j. O O
let O O
˜xji O O
= O O
xji O O
− O O
¯xj O O
be O O
the O O
2d O O
point O O
locations O O
after O O
their O O
image B B
centroid O O
has O O
been O O
sub- O O
tracted O O
. O O
it O O
is O O
possible O O
to O O
associate O O
a O O
risk O O
or O O
loss O O
function O O
with O O
mis-estimating O O
the O O
answer O O
( O O
section O O
b.2 O O
) O O
and O O
to O O
set O O
up O O
your O O
inference B B
algorithm O O
to O O
minimize O O
the O O
expected O O
risk O O
. O O
while O O
a O O
triangulated O O
mesh O O
obtained O O
from O O
the O O
point O O
cloud O O
can O O
sometimes O O
form O O
a O O
suitable O O
proxy O O
, O O
e.g. O O
, O O
for O O
outdoor O O
terrain O O
models O O
, O O
a O O
simple O O
dominant O O
plane O O
ﬁt O O
to O O
the O O
3d O O
points B B
visible O O
in O O
each O O
image B B
13.1 O O
view B B
interpolation I I
625 O O
( O O
a O O
) O O
( O O
b O O
) O O
figure O O
13.4 O O
photo O O
tourism O O
( O O
snavely O O
, O O
seitz O O
, O O
and O O
szeliski O O
2006 O O
) O O
: O O
c O O
( O O
cid:13 O O
) O O
2006 O O
acm O O
: O O
( O O
a O O
) O O
a O O
3d O O
overview O O
of O O
the O O
scene O O
, O O
with O O
translucent O O
washes O O
and O O
lines B B
painted O O
onto O O
the O O
planar O O
impostors O O
; O O
( O O
b O O
) O O
once O O
the O O
user O O
has O O
selected O O
a O O
region B B
of O O
interest O O
, O O
a O O
set O O
of O O
related O O
thumbnails O O
is O O
displayed O O
along O O
the O O
bottom O O
; O O
( O O
c O O
) O O
planar O O
proxy O O
selection O O
for O O
optimal O O
stabilization O O
( O O
snavely O O
, O O
garg O O
, O O
seitz O O
et O O
al O O
. O O
the O O
other O O
belief B B
propagation I I
variant O O
tested O O
by O O
szeliski O O
, O O
zabih O O
, O O
scharstein O O
et O O
al O O
. O O
it O O
is O O
not O O
easy O O
to O O
get O O
high O O
accuracy O O
unless O O
you O O
use O O
a O O
machine O O
shop O O
, O O
but O O
you O O
can O O
get O O
close O O
using O O
heavy O O
plywood O O
and O O
printed O O
patterns B O
. O O
( O O
7.10 O O
) O O
( O O
7.11 O O
) O O
an O O
alternative O O
way O O
to O O
derive O O
the O O
epipolar O O
constraint O I
is O O
to O O
notice O O
that O O
in O O
order B B
for O O
the O O
cam- O O
eras O O
to O O
be O O
oriented B B
so O O
that O O
the O O
rays O O
ˆx0 O O
and O O
ˆx1 O O
intersect O O
in O O
3d O O
at O O
point O O
p O O
, O O
the O O
vectors O O
connecting O O
the O O
two O O
camera O O
centers O O
c1 O O
− O O
c0 O O
= O O
−r−1 O O
1 O O
t O O
and O O
the O O
rays O O
corresponding O O
to O O
pixels O O
x0 O O
and O O
x1 O O
, O O
namely O O
r−1 O O
j O O
ˆxj O O
, O O
must O O
be O O
co-planar O O
. O O
all O O
that O O
is O O
required O O
is O O
that O O
the O O
function O O
be O O
linear B B
in O O
the O O
unknown O O
parameters B B
. O O
8.3 O O
spline-based B B
motion O O
. O O
a O O
simple O O
way O O
to O O
rectify O O
the O O
two O O
images O O
is O O
to O O
ﬁrst O O
rotate O O
both O O
cameras O O
so O O
that O O
they O O
are O O
looking O O
perpendicular O O
to O O
the O O
line O O
joining O O
the O O
camera B B
centers O O
c0 O O
and O O
c1 O O
. O O
the O O
simplest O O
of O O
these O O
is O O
to O O
place O O
a O O
penalty O O
on O O
the O O
image B B
derivatives O O
similar O O
to O O
equations B B
( O O
3.105 O O
and O O
3.113 O O
) O O
, O O
e.g. O O
, O O
( O O
cid:88 O O
) O O
( O O
i O O
, O O
j O O
) O O
ρp O O
( O O
s O O
( O O
i O O
, O O
j O O
) O O
− O O
s O O
( O O
i O O
+ O O
1 O O
, O O
j O O
) O O
) O O
+ O O
ρp O O
( O O
s O O
( O O
i O O
, O O
j O O
) O O
− O O
s O O
( O O
i O O
, O O
j O O
+ O O
1 O O
) O O
) O O
. O O
light O O
is O O
emitted O O
by O O
one O O
or O O
more O O
light O O
sources O O
and O O
is O O
then O O
reﬂected O O
from O O
an O O
object O O
’ O O
s O O
surface B B
. O O
in O O
order B B
to O O
endow O O
the O O
resulting O O
particle O B
system O O
with O O
internal O O
smoothness B B
constraints O O
, O O
pair- O O
wise O O
interaction O O
potentials O O
can O O
be O O
deﬁned O O
that O O
approximate O O
the O O
equivalent O O
elastic O O
bending O O
energies O O
that O O
would O O
be O O
obtained O O
using O O
local O O
ﬁnite-element O O
analysis.8 O O
instead O O
of O O
deﬁning O O
the O O
ﬁnite O O
element O O
neighborhood B B
for O O
each O O
particle O B
( O O
vertex O O
) O O
ahead O O
of O O
time O O
, O O
a O O
soft O O
inﬂuence O O
function O O
is O O
used O O
to O O
couple O O
nearby O O
particles O O
. O O
separable B B
ﬁltering O O
. O O
learning B B
internal O O
representa- O B
tions O O
by O O
error O O
propagation O O
. O O
the O O
advantage O O
of O O
using O O
a O O
series O O
of O O
one- O O
dimensional O O
transforms O O
is O O
that O O
they O O
are O O
much O O
more O O
efﬁcient O O
( O O
in O O
terms O O
of O O
basic O O
arithmetic O O
operations O O
) O O
than O O
large O O
, O O
non-separable O O
, O O
two-dimensional B B
ﬁlter O O
kernels O O
. O O
the O O
( O O
undirected O O
) O O
second O O
derivative O O
of O O
a O O
two-dimensional B B
image O O
, O O
∇2f O O
= O O
∂2f O O
∂x2 O O
+ O O
∂2y O O
∂y2 O O
, O O
( O O
3.25 O O
) O O
is O O
known O O
as O O
the O O
laplacian O O
operator O O
. O O
8.1 O O
translational B B
alignment O O
389 O O
fourier-based O O
alignment B B
relies O O
on O O
the O O
fact O O
that O O
the O O
fourier O O
transform B B
of O O
a O O
shifted O O
signal O O
has O O
the O O
same O O
magnitude O O
as O O
the O O
original O O
signal O O
but O O
a O O
linearly O O
varying O O
phase O O
( O O
section O O
3.4 O O
) O O
, O O
i.e. O O
, O O
f O O
{ O O
i1 O O
( O O
x O O
+ O O
u O O
) O O
} O O
= O O
f O O
{ O O
i1 O O
( O O
x O O
) O O
} O O
e−ju·ω O O
= O O
i1 O O
( O O
ω O O
) O O
e−ju·ω O O
, O O
( O O
8.17 O O
) O O
where O O
ω O O
is O O
the O O
vector-valued O O
angular O O
frequency O O
of O O
the O O
fourier O O
transform B B
and O O
we O O
use O O
cal- O O
ligraphic O O
notation O O
i1 O O
( O O
ω O O
) O O
= O O
f O O
{ O O
i1 O O
( O O
x O O
) O O
} O O
to O O
denote O O
the O O
fourier O O
transform B B
of O O
a O O
signal O O
( O O
sec- O O
tion B B
3.4 O O
) O O
. O O
the O O
basic O O
radiosity B B
algorithm O O
does O O
not O O
take O O
into O O
account O O
certain O O
near O O
ﬁeld O O
effects O O
, O O
such O O
as O O
the O O
darkening O O
inside O O
corners O O
and O O
scratches O O
, O O
or O O
the O O
limited O O
ambient O O
illumination O O
caused O O
by O O
partial O O
shadowing O O
from O O
other O O
surfaces O O
. O O
a O O
duality O O
based O O
approach O O
for O O
realtime O O
tv-l1 O O
optical B O
ﬂow I O
. O O
16 O O
eisemann O O
and O O
durand O O
( O O
2004 O O
) O O
call O O
this O O
the O O
cross O O
bilateral B B
ﬁlter I I
. O O
we O O
can O O
deﬁne O O
this O O
nearest B O
neighbor I I
distance O O
ratio O O
( O O
mikolajczyk O O
and O O
schmid O O
2005 O O
) O O
as O O
nndr O O
= O O
d1 O O
d2 O O
= O O
( O O
cid:107 O O
) O O
da O O
− O O
db| O O
( O O
cid:107 O O
) O O
da O O
− O O
dc| O O
, O O
( O O
4.18 O O
) O O
where O O
d1 O O
and O O
d2 O O
are O O
the O O
nearest O B
and O O
second O O
nearest O O
neighbor O O
distances O O
, O O
da O O
is O O
the O O
target O O
descriptor O O
, O O
and O O
db O O
and O O
dc O B
are O O
its O O
closest O O
two O O
neighbors O O
( O O
figure O O
4.24 O O
) O O
. O O
ex O O
9.6 O O
: O O
global B B
optimization I I
use O O
the O O
initialization B B
from O O
the O O
previous O O
algorithm B B
to O O
perform O O
a O O
full O O
bundle B B
adjustment I I
over O O
all O O
of O O
the O O
camera B B
rotations O O
and O O
focal O O
lengths O O
, O O
as O O
described O O
in O O
section O O
7.4 O O
and O O
by O O
shum O O
and O O
szeliski O O
( O O
2000 O O
) O O
. O O
references B B
837 O O
hardie O O
, O O
r. O O
c. O O
, O O
barnard O O
, O O
k. O O
j. O O
, O O
and O O
armstrong O O
, O O
e. O O
e. O O
( O O
1997 O O
) O O
. O O
processing O O
images O O
and O O
video B B
for O O
an O O
impressionist O O
effect O O
. O O
you O O
can O O
do O O
this O O
by O O
running O O
multi- O O
view O O
stereo O O
over O O
one O O
of O O
your O O
light O O
ﬁelds O O
to O O
obtain O O
a O O
depth B O
map I I
per O O
image B B
. O O
( O O
optional O O
) O O
implement O O
patch-based B B
acceleration O O
( O O
shum O O
and O O
szeliski O O
2000 O O
; O O
baker O O
and O O
matthews O O
2004 O O
) O O
. O O
p´erez O O
, O O
gangnet O O
, O O
and O O
blake O O
( O O
2003 O O
) O O
show O O
how O O
gradient B B
domain I I
reconstruction O O
can O O
be O O
used O O
to O O
do O O
seamless O O
object O O
insertion O O
in O O
image B B
editing O O
applications O O
( O O
figure O O
9.18 O O
) O O
. O O
in O O
this O O
section O O
, O O
we O O
ﬁrst O O
describe O O
the O O
most O O
general O O
form O O
, O O
the O O
bidirectional O O
reﬂectance B B
distribution O O
function O O
, O O
and O O
then O O
look O O
at O O
some O O
more O O
specialized O O
models O O
, O O
including O O
the O O
diffuse B B
, O O
specular B B
, O O
and O O
phong O O
shading B B
models O O
. O O
consider O O
the O O
feature-based B B
alignment O O
problem O O
given O O
in O O
equation B B
( O O
6.2 O O
) O O
, O O
i.e. O O
, O O
epairwise−ls O O
= O O
( O O
cid:88 O O
) O O
i O O
( O O
cid:107 O O
) O O
ri O O
( O O
cid:107 O O
) O O
2 O O
= O O
( O O
cid:107 O O
) O O
˜x O O
( O O
cid:48 O O
) O O
i O O
( O O
xi O O
; O O
p O O
) O O
− O O
ˆx O O
( O O
cid:48 O O
) O O
i O O
( O O
cid:107 O O
) O O
2 O O
. O O
pure B O
rotation I O
the O O
case O O
of O O
pure B O
rotation I O
results O O
in O O
a O O
degenerate O O
estimate O O
of O O
the O O
essential O O
matrix O O
e O O
and O O
of O O
the O O
translation B B
direction O O
ˆt O O
. O O
4. O O
use O O
your O O
computed O O
distribution O O
to O O
ﬁnd O O
the O O
skin O O
regions O O
in O O
an O O
image B B
. O O
a O O
sequential O O
factorization B B
method O O
for O O
recovering O O
shape O O
and O O
motion B B
from O O
image B B
streams O O
. O O
5.5 O O
graph B B
cuts I I
and O O
energy-based B B
methods O O
. O O
these O O
approaches O O
build O O
on O O
earlier O O
energy-based B B
segmentation O O
frameworks O O
introduced O O
by O O
leclerc O O
( O O
1989 O O
) O O
, O O
mumford O O
and O O
shah O O
( O O
1989 O O
) O O
, O O
and O O
chan O O
and O O
vese O O
( O O
1992 O O
) O O
, O O
which O O
are O O
discussed O O
in O O
more O O
detail O O
in O O
section O O
5.5. O O
examples B B
of O O
such O O
level-set O O
seg- O O
mentations O O
are O O
shown O O
in O O
figure O O
5.11 O O
, O O
which O O
shows O O
the O O
evolution B B
of O O
the O O
level B O
sets I I
from O O
a O O
series O O
of O O
distributed O O
circles O O
towards O O
the O O
ﬁnal O O
binary O O
segmentation O B
. O O
as O O
ﬁrst O O
shown O O
by O O
anandan O O
( O O
1984 O O
; O O
1989 O O
) O O
and O O
further O O
discussed O O
in O O
section O O
8.1.3 O O
and O O
( O O
8.44 O O
) O O
, O O
the O O
inverse B B
of O O
the O O
matrix O O
a O O
provides O O
a O O
lower O O
bound O O
on O O
the O O
uncertainty B B
in O O
the O O
location O O
of O O
a O O
matching B B
patch O I
. O O
we O O
then O O
look O O
at O O
pedestrian B B
detectors O O
, O O
as O O
an O O
example O O
of O O
more O O
general O O
methods O O
for O O
object O O
detection B B
. O O
can O O
you O O
do O O
it O O
without O O
peeking O O
at O O
the O O
literature O O
( O O
danielsson O O
1980 O O
; O O
borgefors O O
1986 O O
) O O
? O O
if O O
so O O
, O O
what O O
problems O O
did O O
you O O
come O O
across O O
and O O
resolve O O
? O O
later O O
on O O
, O O
you O O
can O O
use O O
the O O
distance O O
functions O O
you O O
compute O O
to O O
perform O O
feathering B B
during O O
image B B
stitching I I
( O O
section O O
9.3.2 O O
) O O
. O O
in O O
ieee O O
computer O O
society O O
conference O O
on O O
computer O O
vision O O
and O O
pattern O O
recognition B B
( O O
cvpr O O
’ O O
2004 O O
) O O
, O O
pp O O
. O O
combining O O
vision O O
algorithms O O
with O O
general O O
inference B B
techniques O O
that O O
reason O O
about O O
the O O
real O O
world O O
will O O
likely O O
lead O O
to O O
more O O
breakthroughs O O
, O O
although O O
some O O
of O O
the O O
problems O O
may O O
turn O O
out O O
to O O
be O O
“ O O
ai-complete O O
” O O
, O O
in O O
the O O
sense O O
that O O
a O O
full O O
emulation O O
of O O
human O O
experience O O
and O O
intelligence O O
may O O
be O O
necessary O O
. O O
most O O
of O O
these O O
techniques O O
rely O O
either O O
on O O
a O O
set O O
of O O
labeled O O
training O O
images O O
, O O
which O O
is O O
an O O
essential O O
component O O
of O O
all O O
learning B B
techniques O O
, O O
or O O
the O O
even O O
more O O
recent O O
explosion O O
in O O
images O O
available O O
on O O
the O O
internet O O
. O O
an O O
algorithm B B
for O O
data-driven O O
bandwidth B O
selection I O
. O O
multi-view B O
stereo I I
revisited O O
. O O
two O O
good O O
books O O
on O O
color B B
theory O O
are O O
( O O
wyszecki O O
and O O
stiles O O
2000 O O
; O O
healey O O
and O O
shafer O O
1992 O O
) O O
, O O
with O O
( O O
livingstone O O
2008 O O
) O O
providing O O
a O O
more O O
fun O O
and O O
in- O O
formal O O
introduction O O
to O O
the O O
topic O O
of O O
color B B
perception O O
. O O
9.1 O O
motion B B
models I I
433 O O
figure O O
9.3 O O
pure O O
3d O O
camera B B
rotation O O
. O O
in O O
this O O
section O O
, O O
we O O
review O O
singular O O
value O O
decomposition O O
( O O
svd O O
) O O
, O O
eigenvalue O O
decomposi- O O
tion B B
, O O
qr O O
factorization B B
, O O
and O O
cholesky O O
factorization B B
. O O
f O O
( O O
i O O
, O O
j O O
) O O
sx O O
( O O
i O O
, O O
j O O
) O O
f O O
( O O
i O O
, O O
j+1 O O
) O O
sy O O
( O O
i O O
, O O
j O O
) O O
w O O
( O O
i O O
, O O
j O O
) O O
d O O
( O O
i O O
, O O
j O O
) O O
f O O
( O O
i+1 O O
, O O
j O O
) O O
f O O
( O O
i+1 O O
, O O
j+1 O O
) O O
d O O
( O O
i O O
, O O
j+1 O O
) O O
3.7 O O
global B B
optimization I I
187 O O
figure O O
3.60 O O
an O O
unordered O O
label O O
mrf O O
( O O
agarwala O O
, O O
dontcheva O O
, O O
agrawala O O
et O O
al O O
. O O
a O O
sparse B B
probabilistic O O
learning B B
algorithm O O
for O O
real-time O O
tracking O O
. O O
ocular O O
3d O O
pose O O
estimation B B
and O O
tracking O O
by O O
detection O B
. O O
these O O
topics O O
are O O
all O O
covered O O
in O O
more O O
detail O O
in O O
section O O
8.1.3. O O
if O O
features O O
are O O
being O O
tracked O O
over O O
longer O O
image B B
sequences O O
, O O
their O O
appearance O O
can O O
undergo O O
larger O O
changes O O
. O O
lem O O
using O O
energy O O
minimization O O
or O O
bayesian O O
inference B B
techniques O O
, O O
i.e. O O
, O O
conditional O O
random O O
ﬁelds O O
( O O
section O O
3.7.2 O O
, O O
( O O
3.118 O O
) O O
) O O
( O O
kumar O O
and O O
hebert O O
2006 O O
; O O
he O O
, O O
zemel O O
, O O
and O O
carreira-perpi˜n´an O O
2004 O O
) O O
. O O
pattern O O
recognition B B
( O O
cvpr O O
2010 O O
) O O
, O O
san O O
francisco O O
, O O
ca O O
. O O
they O O
are O O
also O O
widely O O
used O O
in O O
computer O O
graphics O O
hardware O O
and O O
software O O
to O O
perform O O
fractional-level O O
decimation O O
using O O
the O O
mip-map O O
, O O
which O O
we O O
cover O O
in O O
section O O
3.6. O O
the O O
best O O
known O O
( O O
and O O
probably O O
most O O
widely O O
used O O
) O O
pyramid B B
in O O
computer O O
vision O O
is O O
burt O O
and O O
adelson O O
’ O O
s O O
( O O
1983a O O
) O O
laplacian O O
pyramid B B
. O O
bayesian O O
modeling B B
of O O
uncertainty B B
in O O
low-level O O
vision O O
. O O
5.1.2 O O
dynamic B B
snakes O O
and O O
condensation O O
. O O
in O O
ieee O O
computer O O
society O O
conference O O
on O O
computer O O
vision O O
and O O
pattern O O
recognition B B
( O O
cvpr O O
’ O O
92 O O
) O O
, O O
pp O O
. O O
3.7.1 O O
regularization B B
. O O
can O O
you O O
tell O O
if O O
this O O
achieves O O
the O O
desired O O
effect O O
of O O
making O O
the O O
image B B
look O O
brighter O O
? O O
can O O
you O O
see O O
any O O
undesirable O O
side-effects O O
or O O
artifacts O O
? O O
in O O
fact O O
, O O
adding O O
the O O
same O O
value O O
to O O
each O O
color B B
channel O O
not O O
only O O
increases O O
the O O
apparent O O
in- O O
tensity O O
of O O
each O O
pixel O O
, O O
it O O
can O O
also O O
affect O O
the O O
pixel O O
’ O O
s O O
hue B O
and O O
saturation O O
. O O
proﬁle B O
under O O
the O O
current O O
optimized O O
curve O O
, O O
and O O
uses O O
this O O
to O O
preferentially O O
keep O O
the O O
wire O O
moving O O
along O O
the O O
same O O
( O O
or O O
a O O
similar O O
looking O O
) O O
boundary O O
( O O
figure O O
5.9b–c O O
) O O
. O O
do O O
you O O
need O O
to O O
weight O O
the O O
angles O O
obtained O O
from O O
a O O
polar O O
decomposition O O
in O O
some O O
way O O
to O O
get O O
the O O
statistically O O
correct O O
estimate O O
? O O
3. O O
how O O
can O O
you O O
modify O O
your O O
techniques O O
to O O
take O O
into O O
account O O
either O O
scalar O O
( O O
6.10 O O
) O O
or O O
full O O
two-dimensional B B
point O O
covariance O O
weightings O O
( O O
6.11 O O
) O O
? O O
do O O
all O O
of O O
the O O
previously O O
devel- O O
oped O O
“ O O
shortcuts O O
” O O
still O O
work O O
or O O
does O O
full O O
weighting B B
require O O
iterative B B
optimization O O
? O O
ex O O
6.4 O O
: O O
2d O O
match O O
move/augmented O O
reality O O
replace O O
a O O
picture O O
in O O
a O O
magazine O O
or O O
a O O
book O O
with O O
a O O
different O O
image B B
or O O
video B B
. O O
occlusion O O
detectable O O
stereo— O O
occlusion O O
patterns B B
in O O
camera B B
matrix O O
. O O
seamless O O
mosaicing O O
of O O
image-based B B
texture O O
maps O O
. O O
inherent O O
ambiguities O O
in O O
recovering O O
3-d O O
motion B B
and O O
structure O O
from O I
a O O
ieee O O
transactions O O
on O O
pattern O O
analysis O O
and O O
machine O O
intelligence O O
, O O
agarwal O O
, O O
a. O O
and O O
triggs O O
, O O
b O O
. O O
3.8 O O
additional O O
reading O O
if O O
you O O
are O O
interested O O
in O O
exploring O O
the O O
topic O O
of O O
image B B
processing O O
in O O
more O O
depth O O
, O O
some O O
popular O O
textbooks B B
have O O
been O O
written O O
by O O
lim O O
( O O
1990 O O
) O O
; O O
crane O O
( O O
1997 O O
) O O
; O O
gomes O O
and O O
velho O O
( O O
1997 O O
) O O
; O O
j¨ahne O O
( O O
1997 O O
) O O
; O O
pratt O O
( O O
2007 O O
) O O
; O O
russ O O
( O O
2007 O O
) O O
; O O
burger O O
and O O
burge O O
( O O
2008 O O
) O O
; O O
gonzales O O
and O O
woods O O
( O O
2008 O O
) O O
. O O
such O O
curves O O
result O O
in O O
isolated O O
3d O O
space O O
curves O O
, O O
rather O O
than O O
elements O O
of O O
smooth O O
surface B B
meshes O O
, O O
but O O
can O O
still O O
be O O
incorporated O O
into O O
the O O
3d O O
surface B B
model O O
during O O
a O O
later O O
stage O O
of O O
surface B B
interpolation O O
( O O
section O O
12.3.1 O O
) O O
. O O
the O O
abbreviations O O
are O O
: O O
rd O O
= O O
radial B B
distortion I I
, O O
aa O O
= O O
anti-aliasing O O
ﬁlter O O
, O O
cfa O O
= O O
color O B
ﬁlter O O
array O O
, O O
q1 O O
and O O
q2 O O
= O O
quantization B B
noise O O
. O O
these O O
in- O O
clude O O
classic O O
shape-from-x O O
techniques O O
such O O
as O O
shape O O
from O O
shading B B
, O O
shape O O
from O O
texture B B
, O O
and O O
shape O O
from O O
focus B B
( O O
section O O
12.1 O O
) O O
, O O
as O O
well O O
as O O
shape O O
from O O
smooth O O
occluding O O
contours O O
( O O
sec- O O
tion B B
11.2.1 O O
) O O
and O O
silhouettes B O
( O O
section O O
12.5 O O
) O O
. O O
the O O
2d O O
intersection O O
points B B
of O O
lines B B
belonging O O
to O O
the O O
same O O
plane O O
are O O
then O O
used O O
as O O
virtual O O
measurements O O
to O O
estimate O O
the O O
epipolar B O
geometry I I
, O O
which O O
is O O
more O O
accurate O O
than O O
using O O
the O O
homographies O O
directly O O
. O O
763 O O
xxii O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
b.5.1 O O
gradient B B
descent I I
and O O
simulated B B
annealing I I
. O O
• O O
gaussian O O
: O O
the O O
( O O
unit O O
area O O
) O O
gaussian O O
of O O
width O O
σ O O
, O O
1 O O
√2πσ O O
g O O
( O O
x O O
; O O
σ O O
) O O
= O O
e− O O
x2 O O
2σ2 O O
, O O
has O O
a O O
( O O
unit O O
height O O
) O O
gaussian O O
of O O
width O O
σ−1 O O
as O O
its O O
fourier O O
transform B B
. O O
3.1.5 O O
application O O
: O O
tonal B B
adjustment I I
. O O
figure O O
14.44a O O
shows O O
some O O
examples B B
of O O
images O O
successfully O O
labeled O O
and O O
segmented O O
using O O
textonboost O O
, O O
while O O
figure O O
14.44b O O
shows O O
examples B B
where O O
it O O
does O O
not O O
do O O
as O O
well O O
. O O
ex O O
12.5 O O
: O O
surface B B
simpliﬁcation O O
use O O
progressive O O
meshes O O
( O O
hoppe O O
1996 O O
) O O
or O O
some O O
other O O
tech- O O
nique O O
from O O
section O O
12.3.2 O O
to O O
create O O
a O O
hierarchical B B
simpliﬁcation O O
of O O
your O O
surface B B
model O O
. O O
in O O
image B B
understanding O O
workshop O O
, O O
pp O O
. O O
color B B
science O O
: O O
concepts O O
and O O
methods O O
, O O
quantitative O O
data O O
and O O
formulae O O
. O O
high B O
dynamic I I
range I I
imaging O O
: O O
acquisition O O
, O O
display O O
, O O
and O O
image-based B B
lighting O I
. O O
one O O
disadvantage O O
of O O
the O O
basic O O
technique O O
, O O
however O O
, O O
is O O
that O O
the O O
model O O
does O O
a O O
poor O O
job O O
near O O
motion B B
discontinuities O O
, O O
unless O O
an O O
excessive O O
number O O
of O O
nodes O O
is O O
used O O
. O O
14.3.3 O O
application O O
: O O
location B B
recognition I I
. O O
in O O
ieee O O
computer O O
society O O
conference O O
on O O
computer O O
vision O O
and O O
pattern O O
recognition B B
( O O
cvpr O O
2008 O O
) O O
, O O
anchorage O O
, O O
ak O O
. O O
the O O
key O O
to O O
mean B O
shift I I
is O O
a O O
technique O O
for O O
efﬁciently O O
ﬁnd- O O
ing O O
peaks O O
in O O
this O O
high-dimensional O O
data O O
distribution O O
without O O
ever O O
computing O O
the O O
complete O O
function O O
explicitly O O
( O O
fukunaga O O
and O O
hostetler O O
1975 O O
; O O
cheng O O
1995 O O
; O O
comaniciu O O
and O O
meer O O
2002 O O
) O O
. O O
• O O
gabor O O
: O O
the O O
even O O
gabor O O
function O O
, O O
which O O
is O O
the O O
product O O
of O O
a O O
cosine O O
of O O
frequency O O
ω0 O O
and O O
a O O
gaussian O O
of O O
width O O
σ O O
, O O
has O O
as O O
its O O
transform B B
the O O
sum O O
of O O
the O O
two O O
gaussians O O
of O O
width O O
σ−1 O O
centered O O
at O O
ω O O
= O O
±ω0 O O
. O O
the O O
ﬁnal O O
accuracy B O
of O O
a O O
scanner O O
can O O
be O O
determined O O
using O O
slant O O
edge O O
modulation O O
techniques O O
, O O
i.e. O O
, O O
by O O
imaging O O
sharp O O
creases O O
in O O
a O O
calibration B B
object O O
( O O
goesele O O
, O O
fuchs O O
, O O
and O O
seidel O O
2003 O O
) O O
. O O
similarly O O
, O O
for O O
simultaneous O O
segmentation B B
and O O
recognition B B
( O O
winn O O
and O O
shotton O O
2006 O O
; O O
shotton O O
, O O
winn O O
, O O
rother O O
et O O
al O O
. O O
thus O O
, O O
instead O O
of O O
using O O
quadri-linear O O
interpolation B B
of O O
the O O
nearest O B
sampled O O
( O O
s O O
, O O
t O O
, O O
u O O
, O O
v O O
) O O
values O O
around O O
a O O
given O O
ray O O
to O O
determine O O
its O O
color B B
, O O
the O O
( O O
u O O
, O O
v O O
) O O
values O O
are O O
modiﬁed O O
for O O
each O O
discrete B B
( O O
si O O
, O O
ti O O
) O O
camera B B
. O O
14.4.2 O O
part-based B B
models O O
recognizing O O
an O O
object O O
by O O
ﬁnding O O
its O O
constituent O O
parts O O
and O O
measuring O O
their O O
geometric B B
rela- O O
tionships O O
is O O
one O O
of O O
the O O
oldest O O
approaches O O
to O O
object O O
recognition B B
( O O
fischler O O
and O O
elschlager O O
1973 O O
; O O
kanade O O
1977 O O
; O O
yuille O O
1991 O O
) O O
. O O
instead O O
, O O
the O O
algorithm B B
is O O
given O O
the O O
number O O
of O O
clusters O O
k O O
it O O
is O O
supposed O O
to O O
ﬁnd O O
; O O
it O O
then O O
iteratively O O
updates O O
the O O
cluster O O
center O O
location O O
based O O
on O O
the O O
samples O O
that O O
are O O
closest O O
to O O
each O O
center O O
. O O
4.2.3 O O
application O O
: O O
edge B B
editing I O
and O O
enhancement O O
. O O
an O O
mrf-based O O
deinterlacing O O
algorithm B B
with O O
exemplar-based O O
reﬁnement O O
. O O
in O O
computer O O
vision O O
, O O
image B B
segmentation O O
is O O
one O O
of O O
the O O
oldest O O
and O O
most O O
widely O O
studied O O
prob- O O
lems O O
( O O
brice O O
and O O
fennema O O
1970 O O
; O O
pavlidis O O
1977 O O
; O O
riseman O O
and O O
arbib O O
1977 O O
; O O
ohlander O O
, O O
price O O
, O O
and O O
reddy O O
1978 O O
; O O
rosenfeld O O
and O O
davis O O
1979 O O
; O O
haralick O O
and O O
shapiro O O
1985 O O
) O O
. O O
an O O
alternative O O
to O O
working O O
with O O
continuous O O
surfaces O O
is O O
to O O
represent O O
3d O O
surfaces O O
as O O
dense O O
collections O O
of O O
3d O O
oriented B B
points O O
( O O
section O O
12.4 O O
) O O
or O O
as O O
volumetric B B
primitives O O
( O O
section O O
12.5 O O
) O O
. O O
applications O O
of O O
these O O
techniques O O
include O O
video B B
de- O O
noising O O
, O O
morphing B B
, O O
and O O
tours O O
based O O
on O O
360◦ O O
video B O
. O O
a O O
second O O
notable O O
trend O O
during O O
this O O
past O O
decade O O
has O O
been O O
the O O
emergence O O
of O O
feature-based B B
techniques O O
( O O
combined O O
with O O
learning O O
) O O
for O O
object O O
recognition B B
( O O
see O O
section O O
14.3 O O
and O O
ponce O O
, O O
hebert O O
, O O
schmid O O
et O O
al O O
. O O
geos O O
: O O
geodesic O O
image O O
segmentation B O
. O O
3.4.4 O O
application O O
: O O
sharpening O O
, O O
blur O O
, O O
and O O
noise B B
removal I I
. O O
since O O
blurring O O
the O O
image B B
reduces O O
high O B
frequencies O O
, O O
adding O O
some O O
of O O
the O O
difference B B
between O O
the O O
original O O
and O O
the O O
blurred O O
image B B
makes O O
it O O
sharper O O
, O O
gsharp O O
= O O
f O O
+ O O
γ O O
( O O
f O O
− O O
hblur O O
∗ O O
f O O
) O O
. O O
to O O
reduce O O
the O O
effects O O
of O O
contrast O O
or O O
gain O O
( O O
additive O O
variations O O
are O O
already O O
removed O O
by O O
the O O
gra- O O
dient O O
) O O
, O O
the O O
128-d O O
vector O O
is O O
normalized B B
to O O
unit O O
length O O
. O O
landscape O O
of O O
clus- O O
in O O
international O O
conference O O
on O O
pattern O O
recognition B B
( O O
icpr O O
2004 O O
) O O
, O O
tering O O
algorithms O O
. O O
2001 O O
) O O
, O O
which O O
consists O O
of O O
1000 O O
images O O
from O O
a O O
corel O O
image B B
dataset O O
that O O
were O O
hand-labeled O O
by O O
30 O O
human O O
subjects O O
. O O
2. O O
draw O O
a O O
number O O
of O O
lines B B
in O O
the O O
image B B
. O O
we O O
begin O O
with O O
blue O O
screen O O
matting B O
, O O
which O O
assumes O O
that O O
the O O
background O O
is O O
a O O
constant O O
known O O
color B B
, O O
and O O
discuss O O
its O O
variants O O
, O O
two-screen O O
matting B B
( O O
when O O
multiple B B
backgrounds O O
can O O
be O O
used O O
) O O
and O O
difference B B
matting O O
( O O
where O O
the O O
known O O
background O O
is O O
arbitrary O O
) O O
. O O
as O O
we O O
continue O O
to O O
capture O O
more O O
and O O
more O O
of O O
our O O
real O O
world O O
with O O
large O O
amounts O O
of O O
high- O O
quality O O
imagery O O
and O O
video B B
, O O
the O O
interactive B B
modeling O O
, O O
exploration O O
, O O
and O O
rendering B B
techniques O O
described O O
in O O
this O O
chapter O O
will O O
play O O
an O O
even O O
bigger O O
role O O
in O O
bringing O O
virtual O O
experiences O O
based O O
on O O
remote O O
areas O O
of O O
the O O
world O O
closer O O
to O O
everyone O O
. O O
a O O
multi- O O
scale O O
model O O
of O O
adaptation O O
and O O
spatial O O
vision O O
for O O
realistic O O
image B B
display O O
. O O
the O O
results O O
of O O
detecting O O
individual O O
vanishing B B
points I I
can O O
also O O
be O O
made O O
more O O
robust B B
by O O
simulta- O O
neously O O
searching O O
for O O
pairs O O
or O O
triplets O O
of O O
mutually O O
orthogonal O O
vanishing O B
points B I
( O O
shufelt O O
1999 O O
; O O
antone O O
and O O
teller O O
2002 O O
; O O
rother O O
2002 O O
; O O
sinha O O
, O O
steedly O O
, O O
szeliski O O
et O O
al O O
. O O
next O O
, O O
we O O
present O O
some O O
global B B
optimization I I
approaches O O
to O O
natural B B
image O O
matting B B
. O O
ieee O O
transactions O O
on O O
medical B B
imaging I I
, O O
mi-2 O O
( O O
1 O O
) O O
:31–39 O O
. O O
3.4 O O
fourier O O
transforms O O
139 O O
name O O
kernel B B
transform O O
plot O O
box-3 O O
1 O O
3 O O
1 O O
1 O O
1 O O
1 O O
3 O O
( O O
1 O O
+ O O
2 O O
cos O O
ω O O
) O O
box-5 O O
1 O O
5 O O
1 O O
1 O O
1 O O
1 O O
1 O O
1 O O
5 O O
( O O
1 O O
+ O O
2 O O
cos O O
ω O O
+ O O
2 O O
cos O O
2ω O O
) O O
linear B B
1 O O
4 O O
1 O O
2 O O
1 O O
1 O O
2 O O
( O O
1 O O
+ O O
cos O O
ω O O
) O O
binomial B O
1 O O
16 O O
1 O O
4 O O
6 O O
4 O O
1 O O
1 O O
4 O O
( O O
1 O O
+ O O
cos O O
ω O O
) O O
2 O O
sobel O O
1 O O
2 O O
−1 O O
0 O O
1 O O
sin O O
ω O O
corner O O
1 O O
2 O O
−1 O O
2 O O
−1 O O
1 O O
2 O O
( O O
1 O O
− O O
cos O O
ω O O
) O O
table O O
3.3 O O
fourier O O
transforms O O
of O O
the O O
separable B B
kernels O O
shown O O
in O O
figure O O
3.14 O O
. O O
if O O
desired O O
, O O
the O O
pattern O O
can O O
be O O
rendered O O
at O O
a O O
higher O O
resolution O O
than O O
the O O
input O O
image B B
, O O
which O O
enables O O
the O O
estimation B B
of O O
the O O
psf O O
to O O
sub-pixel O O
resolution O O
( O O
figure O O
10.8a O O
) O O
. O O
this O O
contrasts O O
starkly O O
with O O
stereo O O
matching B B
( O O
which O O
is O O
an O O
“ O O
easier O O
” O O
one-dimensional O O
disparity O O
estimation B B
problem O O
) O O
, O O
where O O
combinatorial O O
optimization O O
techniques O O
have O O
been O O
the O O
method O O
of O O
choice O O
for O O
the O O
last O O
decade O O
. O O
global B B
stereo O O
reconstruc- O O
tion B B
under O O
second O O
order O O
smoothness B B
priors O I
. O O
dynamic B B
programming I I
was O O
ﬁrst O O
used O O
for O O
stereo O O
vision O O
in O O
sparse B B
, O O
edge-based B O
methods O O
( O O
baker O O
and O O
binford O O
1981 O O
; O O
ohta O O
and O O
kanade O O
1985 O O
) O O
. O O
) O O
debevec O O
and O O
malik O O
( O O
1997 O O
) O O
show O O
how O O
this O O
can O O
be O O
implemented O O
in O O
21 O O
lines B B
of O O
matlab O O
code O O
, O O
which O O
partially O O
accounts O O
for O O
the O O
popularity O O
of O O
their O O
technique O O
. O O
perspective B B
and O O
projective B B
factorization I O
. O O
for O O
example O O
, O O
if O O
we O O
are O O
classifying O O
terrain O O
from O O
aerial O O
imagery O O
, O O
it O O
makes O O
no O O
sense O O
to O O
take O O
the O O
numeric O O
difference B O
between O O
the O O
labels O O
assigned O O
to O O
forest O O
, O O
ﬁeld O O
, O O
water O O
, O O
and O O
pavement O O
. O O
other O O
ap- O O
proaches O O
use O O
voxel-based O O
representations O O
, O O
usually O O
encoded O O
as O O
octrees O O
( O O
samet O O
1989 O O
) O O
, O O
because O O
of O O
the O O
resulting O O
space–time O O
efﬁciency B B
. O O
an O O
alternative O O
approach O O
is O O
to O O
use O O
radial B B
basis O O
( O O
or O O
kernel B B
) O O
functions O O
( O O
boult O O
and O O
kender O O
1986 O O
; O O
nielson O O
1993 O O
) O O
. O O
diffuse B O
reﬂection O O
also O O
often O O
imparts O O
a O O
strong O O
body B B
color O O
to O O
the O O
light O O
since O O
it O O
is O O
caused O O
by O O
selective O O
absorption O O
and O O
re-emission O O
of O O
light O O
inside O O
the O O
object O O
’ O O
s O O
material O O
( O O
shafer O O
1985 O O
; O O
glassner O O
1995 O O
) O O
. O O
image- O O
based O O
reconstruction O O
of O O
spatial O O
appearance O O
and O O
geometric B B
detail O O
. O O
ieee O O
transactions O O
on O O
image B B
processing O O
, O O
13 O O
( O O
9 O O
) O O
:1200–1212 O O
. O O
n O O
− O O
1 O O
rj O O
, O O
j O O
: O O
n−1 O O
= O O
rj O O
, O O
j O O
: O O
n−1 O O
− O O
rijr−1 O O
ii O O
ri O O
, O O
j O O
: O O
n−1 O O
ri O O
, O O
i O O
: O O
n−1 O O
= O O
r−1/2 O O
ii O O
ri O O
, O O
i O O
: O O
n−1 O O
algorithm B O
a.1 O O
cholesky O O
decomposition O O
of O O
the O O
matrix O O
c O O
into O O
its O O
upper O O
triangular O O
form O O
r. O O
also O O
found O O
in O O
lapack O O
. O O
use O O
the O O
human-assisted O O
motion B B
segmentation O O
database O O
at O O
http O O
: O O
//people.csail.mit.edu/celiu/ O O
motionannotation/ O O
as O O
some O O
of O O
your O O
test O B
data O O
. O O
review O O
and O O
analysis O O
of O O
solutions O O
of O O
the O O
three O O
point O O
perspective O O
pose O O
estimation B B
problem O O
. O O
a O O
more O O
ﬂexible O O
approach O O
to O O
using O O
a O O
ﬁxed O O
number O O
of O O
frames O O
is O O
to O O
propagate O O
corrections O O
backwards O O
through O O
points B B
and O O
cameras O O
until O O
the O O
changes O O
on O O
parameters B B
are O O
below O O
a O O
threshold O O
( O O
steedly O O
and O O
essa O O
2001 O O
) O O
. O O
the O O
function O O
can O O
be O O
written O O
in O O
terms O O
of O O
the O O
angles O O
of O O
the O O
incident O O
and O O
reﬂected O O
directions O O
relative O O
to O O
the O O
surface B B
frame O O
as O O
fr O O
( O O
θi O O
, O O
φi O O
, O O
θr O O
, O O
φr O O
; O O
λ O O
) O O
. O O
the O O
black O O
square O O
pixel O O
’ O O
s O O
transfer B B
function O O
is O O
interpolated O O
from O O
the O O
four O O
adjacent O O
lookup O O
tables O O
( O O
gray O O
arrows O O
) O O
using O O
the O O
computed O O
( O O
s O O
, O O
t O O
) O O
values O O
. O O
3d O O
lines B B
. O O
we O O
start O O
by O O
discussing O O
various O O
pos- O O
sible O O
motion B B
models I O
( O O
section O O
9.1 O O
) O O
, O O
including O O
planar O B
motion O O
and O O
pure O O
camera O O
rotation O O
. O O
computer O O
vision O O
and O O
image B B
understanding O O
, O O
112 O O
( O O
1 O O
) O O
:30–38 O O
. O O
this O O
is O O
convenient O O
if O O
we O O
map O O
image B B
pixels O O
into O O
( O O
warped O O
) O O
rays O O
and O O
then O O
undistort O O
the O O
rays O O
to O O
obtain O O
3d O O
rays O O
in O O
space O O
, O O
i.e. O O
, O O
if O O
we O O
are O O
using O O
inverse O O
warping O O
. O O
to O O
estimate O O
the O O
most O O
likely O O
value O O
of O O
an O O
unknown O O
pixel O O
’ O O
s O O
opacity B B
and O O
( O O
unmixed O O
) O O
foreground O O
and O O
background O O
colors O O
, O O
chuang O O
et O O
al O O
. O O
multi-view B O
stereo I I
reconstruction O O
and O O
scene O O
ﬂow O O
estimation B B
with O O
a O O
global B B
image-based O O
matching B B
score O O
. O O
the O O
topic O O
of O O
scale B O
selection I I
in O O
edge O O
detection O O
is O O
nicely O O
treated O O
by O O
elder O O
and O O
zucker O O
( O O
1998 O O
) O O
, O O
while O O
approaches O O
to O O
color B B
and O O
texture B B
edge O O
detection B B
can O O
be O O
found O O
in O O
( O O
ruzon O O
and O O
tomasi O O
2001 O O
; O O
martin O O
, O O
fowlkes O O
, O O
and O O
malik O O
2004 O O
; O O
gevers O O
, O O
van O O
de O O
weijer O O
, O O
and O O
stokman O O
2006 O O
) O O
. O O
for O O
the O O
case O O
of O O
two O O
observations O O
, O O
it O O
turns O O
out O O
that O O
the O O
location O O
of O O
the O O
point O O
p O O
that O O
exactly O O
minimizes O O
the O O
true O O
reprojection O O
error O O
( O O
7.5–7.6 O O
) O O
can O O
be O O
computed O O
using O O
the O O
solution O O
of O O
degree O O
six O O
equations B O
( O O
hartley O O
and O O
sturm O O
1997 O O
) O O
. O O
image B B
and O O
vision O O
computing O O
, O O
28 O O
( O O
5 O O
) O O
:807–813 O O
. O O
in O O
this O O
case O O
, O O
pixel O O
coordinates O O
( O O
x O O
, O O
y O O
, O O
f O O
) O O
must O O
ﬁrst O O
be O O
rotated O O
using O O
the O O
known O O
tilt O O
and O O
panning O O
angles O O
before O O
being O O
projected O O
into O O
cylindrical B B
or O O
spherical B B
coordinates O O
( O O
chen O O
1995 O O
) O O
. O O
finally O O
, O O
we O O
cover O O
the O O
topics O O
of O O
image B B
compositing O O
and O O
blending B B
( O O
section O O
9.3 O O
) O O
, O O
which O O
involve O O
both O O
selecting O O
which O O
pixels O O
from O O
which O O
images O O
to O O
use O O
and O O
blending B B
them O O
together O O
so O O
as O O
to O O
disguise O O
exposure O O
differences O O
. O O
once O O
this O O
has O O
been O O
subtracted O O
from O O
the O O
lumisphere O O
, O O
the O O
remaining O O
values O O
, O O
which O O
should O O
consist O O
mostly O O
of O O
the O O
specular B B
components O O
, O O
are O O
reﬂected O O
around O O
the O O
local B B
surface O O
normal O O
( O O
2.89 O O
) O O
, O O
which O O
turns O O
each O O
lumisphere O O
into O O
a O O
copy O O
of O O
the O O
local B B
environment O O
around O O
that O O
point O O
. O O
2002 O O
) O O
c O O
( O O
cid:13 O O
) O O
2002 O O
acm O O
: O O
( O O
a O O
) O O
input O O
video B B
frame O O
; O O
( O O
b O O
) O O
after O O
removing O O
the O O
foreground O O
object O O
; O O
( O O
c O O
) O O
estimated O O
alpha B B
matte I O
; O O
( O O
d O O
) O O
insertion O O
of O O
new O O
objects O O
into O O
the O O
background O O
. O O
a O O
uniﬁed O O
factorization B B
algorithm O O
for O O
points O O
, O O
line O O
in O O
sixth O O
international O O
conference O O
on O O
segments O O
and O O
planes B B
with O O
uncertainty B B
models O O
. O O
the O O
simplest O O
radial B B
distortion I I
models O O
use O O
low-order O O
polynomials O O
( O O
c.f O O
. O O
during O O
the O O
feature B B
detection O O
( O O
extraction O O
) O O
stage O O
( O O
section O O
4.1.1 O O
) O O
, O O
each O O
image B B
is O O
searched O O
for O O
locations O O
that O O
are O O
likely O O
to O O
match O O
well O O
in O O
other O O
images O O
. O O
figure O O
3.45 O O
basic O O
set O O
of O O
2d O O
geometric B B
image O O
transformations O O
. O O
since O O
many O O
problems O O
in O O
computer O O
vision O O
are O O
inverse B B
problems O O
that O O
involve O O
estimating O O
unknown O O
quantities O O
from O O
noisy O O
input O O
data O O
, O O
we O O
have O O
also O O
looked O O
at O O
bayesian O O
statistical O O
inference B B
techniques O O
, O O
as O O
well O O
as O O
ma- O O
chine O O
learning B B
techniques O O
to O O
learn O O
probabilistic B B
models I O
from O O
large O O
amounts O O
of O O
training O O
data O O
. O O
feature B O
matching O O
. O O
2010 O O
) O O
, O O
which O O
includes O O
among O O
its O O
improvements O O
a O O
simple O O
contextual O O
model O O
, O O
was O O
among O O
the O O
two O O
best O O
object O O
detection B B
systems O O
in O O
the O O
2008 O O
visual O O
object O O
classes O O
detection B B
challenge O O
. O O
using O O
a O O
non- O O
quadratic O O
( O O
robust B B
) O O
smoothness B B
term O O
as O O
in O O
( O O
3.113 O O
) O O
plays O O
a O O
qualitatively O O
similar O O
role O O
to O O
setting O O
the O O
smoothness B B
based O O
on O O
local B B
gradient O O
information O O
in O O
a O O
gaussian O O
mrf O O
( O O
gmrf O O
) O O
( O O
tappen O O
, O O
liu O O
, O O
freeman O O
et O O
al O O
. O O
716 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
( O O
a O O
) O O
( O O
b O O
) O O
( O O
c O O
) O O
( O O
d O O
) O O
figure O O
14.52 O O
recognition B B
using O O
tiny O O
images O O
( O O
torralba O O
, O O
freeman O O
, O O
and O O
fergus O O
2008 O O
) O O
c O O
( O O
cid:13 O O
) O O
2008 O O
ieee O O
: O O
columns O O
( O O
a O O
) O O
and O O
( O O
c O O
) O O
show O O
sample O O
input O O
images O O
and O O
columns O O
( O O
b O O
) O O
and O O
( O O
d O O
) O O
show O O
the O O
corresponding O O
16 O O
nearest O B
neighbors O O
in O O
the O O
database O O
of O O
80 O O
million O O
tiny O O
images O O
. O O
bottom O O
row O O
: O O
image B B
patch O O
after O O
warping O O
back O O
toward O O
the O O
ﬁrst O O
frame O O
using O O
an O O
afﬁne B B
deformation O O
. O O
this O O
technique O O
can O O
also O O
be O O
used O O
to O O
estimate O O
the O O
3d O O
geometry O O
of O O
a O O
background O O
scene O O
and O O
how O O
its O O
appearance O O
varies O O
as O O
it O O
moves O O
into O O
shadow B B
, O O
in O O
order B B
to O O
cast O O
new O O
shadows O O
onto O O
the O O
scene O O
( O O
chuang O O
, O O
goldman O O
, O O
curless O O
et O O
al O O
. O O
in O O
order B B
to O O
capture O O
the O O
subtle O O
variations O O
in O O
orientation O O
around O O
a O O
person O O
’ O O
s O O
outline O O
, O O
a O O
large O O
number O O
of O O
orientation O O
bins O O
is O O
used O O
and O O
no O O
smoothing B B
is O O
performed O O
in O O
the O O
central O O
difference B B
gradi- O O
ent O O
computation—see O O
the O O
work O O
of O O
dalal O O
and O O
triggs O O
( O O
2005 O O
) O O
for O O
more O O
implementation O O
details O O
. O O
detecting O O
faces B B
in O O
images O O
: O O
a O O
survey O O
. O O
( O O
3.30 O O
) O O
this O O
can O O
be O O
efﬁciently O O
computed O O
using O O
a O O
recursive O O
( O O
raster-scan O O
) O O
algorithm B B
, O O
s O O
( O O
i O O
, O O
j O O
) O O
= O O
s O O
( O O
i O O
− O O
1 O O
, O O
j O O
) O O
+ O O
s O O
( O O
i O O
, O O
j O O
− O O
1 O O
) O O
− O O
s O O
( O O
i O O
− O O
1 O O
, O O
j O O
− O O
1 O O
) O O
+ O O
f O O
( O O
i O O
, O O
j O O
) O O
. O O
12.7.2 O O
application O O
: O O
3d O O
photography O O
the O O
techniques O O
described O O
in O O
this O O
chapter O O
for O O
building O O
complete O O
3d O O
models O O
from O O
multiple B B
im- O O
ages O O
and O O
then O O
recovering O O
their O O
surface B B
appearance O O
have O O
opened O O
up O O
a O O
whole O O
new O O
range O O
of O O
applications O O
that O O
often O O
go O O
under O O
the O O
name O O
3d O O
photography O O
. O O
cie O O
rgb O O
and O O
xyz O O
to O O
test O O
and O O
quantify O O
the O O
tri-chromatic O O
theory O O
of O O
perception O O
, O O
we O O
can O O
attempt O O
to O O
reproduce O O
all O O
monochromatic O O
( O O
single O O
wavelength O O
) O O
colors O O
as O O
a O O
mixture O O
of O O
three O O
suitably O O
chosen O O
primaries B O
. O O
2003 O O
) O O
: O O
( O O
a–c O O
) O O
three O O
different O O
exposures O O
; O O
( O O
d O O
) O O
merging B B
the O O
exposures O O
using O O
classic O O
algorithms O O
( O O
note O O
the O O
ghosting O O
due O O
to O O
the O O
horse O O
’ O O
s O O
head B B
movement O O
) O O
; O O
( O O
e O O
) O O
merging B B
the O O
exposures O O
with O O
motion O O
compensation O O
. O O
( O O
c O O
) O O
each O O
layer O O
is O O
then O O
animated O O
with O O
a O O
different O O
stochastic O O
motion O O
texture B B
( O O
d O O
) O O
the O O
animated O O
layers B B
are O O
then O O
composited O O
to O O
produce O O
( O O
e O O
) O O
the O O
ﬁnal O O
animation O O
13.5.3 O O
application O O
: O O
animating B B
pictures I I
while O O
video B B
textures I I
can O O
turn O O
a O O
short O O
video B B
clip O O
into O O
an O O
inﬁnitely O O
long O O
video B B
, O O
can O O
the O O
same O O
thing O O
be O O
done O O
with O O
a O O
single O O
still O O
image B B
? O O
the O O
answer O O
is O O
yes O O
, O O
if O O
you O O
are O O
willing O O
to O O
ﬁrst O O
segment O O
the O O
image B B
into O O
different O O
layers B B
and O O
then O O
animate O O
each O O
layer O O
separately O O
. O O
in O O
ieee O O
computer O O
society O O
conference O O
on O O
computer O O
vision O O
and O O
pattern O O
recognition B B
( O O
cvpr O O
2007 O O
) O O
, O O
min- O O
neapolis O O
, O O
mn O O
. O O
some O O
references B B
and O O
ideas O O
for O O
skin O O
detection B B
are O O
given O O
in O O
exercise O O
2.8 O O
and O O
by O O
forsyth O O
and O O
fleck O O
( O O
1999 O O
) O O
, O O
jones O O
and O O
rehg O O
( O O
2001 O O
) O O
, O O
vezhnevets O O
, O O
sazonov O O
, O O
and O O
andreeva O O
( O O
2003 O O
) O O
, O O
and O O
kakumanu O O
, O O
makrogiannis O O
, O O
and O O
bourbakis O O
( O O
2007 O O
) O O
. O O
14.2 O O
face B B
recognition O O
among O O
the O O
various O O
recognition B B
tasks O O
that O O
computers O O
might O O
be O O
asked O O
to O O
perform O O
, O O
face B B
recog- O O
nition O O
is O O
the O O
one O O
where O O
they O O
have O O
arguably O O
had O O
the O O
most O O
success.5 O O
while O O
computers O O
can O O
not O O
pick O O
out O O
suspects O O
from O O
thousands O O
of O O
people O O
streaming O O
in O O
front O O
of O O
video B B
cameras O O
( O O
even O O
people O O
can O O
not O O
readily O O
distinguish O O
between O O
similar O O
people O O
with O O
whom O O
they O O
are O O
not O O
familiar O O
( O O
o O O
’ O O
toole O O
, O O
jiang O O
, O O
roark O O
et O O
al O O
. O O
we O O
already O O
saw O O
in O O
section O O
7.4.1 O O
how O O
storing O O
the O O
more O O
numerous O O
3d O O
point O O
parameters O O
before O O
the O O
camera B B
param- O O
eters O O
and O O
using O O
the O O
schur O O
complement O O
( O O
7.56 O O
) O O
results O O
in O O
a O O
more O O
efﬁcient O O
algorithm B O
. O O
an O O
even O O
more O O
recent O O
hdr O O
image B B
format O O
is O O
the O O
jpeg O O
xr O O
standard.13 O O
10.2.1 O O
tone B B
mapping I O
once O O
a O O
radiance O O
map O O
has O O
been O O
computed O O
, O O
it O O
is O O
usually O O
necessary O O
to O O
display O O
it O O
on O O
a O O
lower O O
gamut O O
( O O
i.e. O O
, O O
eight-bit O O
) O O
screen O O
or O O
printer O O
. O O
the O O
red O O
vector O O
u O O
indicates O O
the O O
displacement O O
between O O
the O O
patch B B
centers O O
and O O
the O O
w O O
( O O
xi O O
) O O
weighting B B
function O O
( O O
patch B B
window O O
) O O
is O O
shown O O
as O O
a O O
dark O O
circle O O
. O O
the O O
simplest O O
way O O
to O O
ﬁnd O O
all O O
corresponding O O
feature B B
points O O
is O O
to O O
compare O O
all O O
features O O
against O O
all O O
other O O
features O O
in O O
each O O
pair O O
of O O
potentially O O
matching B B
images O O
. O O
the O O
matrices O O
a O O
and O O
the O O
noise B B
covariance O O
can O O
be O O
learned B B
ahead O O
of O O
time O O
by O O
observing O O
typical O O
sequences O O
of O O
the O O
object O O
being O O
tracked O O
( O O
blake O O
and O O
isard O O
1998 O O
) O O
. O O
another O O
extension O O
to O O
the O O
basic O O
optic O O
ﬂow O O
model O O
is O O
to O O
use O O
a O O
combination O O
of O O
global B B
( O O
para- O O
metric O O
) O O
and O O
local B B
motion O O
models O O
. O O
normalized B B
cuts I I
and O O
image B B
segmentation O O
. O O
they O O
make O O
for O O
invaluable O O
reading O O
for O O
anyone O O
interested O O
in O O
implementing O O
a O O
highly O O
tuned O O
imple- O O
mentation O O
of O O
incremental B B
image O O
registration B B
. O O
the O O
idea O O
behind O O
estimating O O
the O O
radiometric B B
response O O
function O O
is O O
relatively O O
straightforward O O
( O O
mann O O
and O O
picard O O
1995 O O
; O O
debevec O O
and O O
malik O O
1997 O O
; O O
mitsunaga O O
and O O
nayar O O
1999 O O
; O O
reinhard O O
, O O
ward O O
, O O
pattanaik O O
et O O
al O O
. O O
a O O
more O O
useful O O
representation O O
is O O
the O O
arc B O
length I O
parameterization I O
of O O
a O O
contour O O
, O O
x O O
( O O
s O O
) O O
, O O
where O O
s O O
denotes O O
the O O
arc O O
length O O
along O O
a O O
curve O O
. O O
interactive B B
design O O
of O O
multi-perspective O O
images O O
for O O
visualizing O O
urban O O
landscapes O O
. O O
13.3.1 O O
unstructured B B
lumigraph O O
. O O
fast O O
, O O
approximately O O
optimal O O
solu- O O
tions O O
for O O
single O O
and O O
dynamic B B
mrfs O O
. O O
the O O
resulting O O
neural O O
network O O
directly O O
outputs O O
the O O
likelihood O O
of O O
a O O
face B B
at O O
the O O
center O O
662 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
figure O O
14.5 O O
a O O
neural O O
network O O
for O O
face O O
detection B B
( O O
rowley O O
, O O
baluja O O
, O O
and O O
kanade O O
1998a O O
) O O
c O O
( O O
cid:13 O O
) O O
1998 O O
ieee O O
. O O
matching B B
with O O
prosac—progressive O O
sample O O
consensus O O
. O O
for O O
label O O
computations O O
of O O
this O O
kind O O
, O O
the O O
α-expansion O O
algorithm B B
developed O O
by O O
boykov O O
, O O
veksler O O
, O O
and O O
zabih O O
( O O
2001 O O
) O O
works O O
particularly O O
well O O
( O O
szeliski O O
, O O
zabih O O
, O O
scharstein O O
et O O
al O O
. O O
a O O
quasi-dense O O
approach O O
to O O
surface B B
reconstruction I I
from O O
uncalibrated O O
images O O
. O O
however O O
, O O
they O O
make O O
sampling B B
from O O
this O O
mrf O O
more O O
complex O O
. O O
linear B B
n-point O O
camera B B
pose O O
determination O O
. O O
directed B O
edges I O
, O O
which O O
allows O O
boundary O O
regions O O
to O O
be O O
oriented B B
, O O
e.g. O O
, O O
to O O
prefer O O
light O O
to O O
dark O O
tran- O O
sitions O O
or O O
vice O O
versa O O
( O O
kolmogorov O O
and O O
boykov O O
2005 O O
) O O
. O O
probability O O
models O O
for O O
high O O
dynamic B B
range O O
imaging O O
. O O
performing O O
camera B B
calibration O O
without O O
using O O
known O O
targets O O
is O O
known O O
as O O
self-calibration B B
and O O
is O O
discussed O O
in O O
textbooks B B
and O O
surveys B B
on O O
structure B B
from I I
motion I I
( O O
faugeras O O
, O O
luong O O
, O O
and O O
maybank O O
1992 O O
; O O
hartley O O
and O O
zisserman O O
2004 O O
; O O
moons O O
, O O
van O O
gool O O
, O O
and O O
vergauwen O O
2010 O O
) O O
. O O
chapter O O
11 O O
: O O
stereo B B
correspondence O O
stereomatcher O O
, O O
standalone O O
c++ O O
stereo B B
matching I I
code O O
, O O
http O O
: O O
//vision.middlebury.edu/ O O
stereo/code/ O O
( O O
scharstein O O
and O O
szeliski O O
2002 O O
) O O
. O O
14.8 O O
exercises O O
14.5 O O
context B B
and O O
scene B B
understanding I I
. O O
in O O
ieee O O
computer O O
society O O
conference O O
on O O
computer O O
vision O O
and O O
pattern O O
recognition B B
( O O
cvpr O O
’ O O
2005 O O
) O O
, O O
pp O O
. O O
in O O
ieee O O
computer O O
society O O
confer- O O
ence O O
on O O
computer O O
vision O O
and O O
pattern O O
recognition B B
( O O
cvpr O O
2008 O O
) O O
, O O
anchorage O O
, O O
ak O O
. O O
the O O
structure O O
consists O O
of O O
articulated O O
rectangular O O
body B B
parts O O
( O O
torso O O
, O O
head B B
, O O
and O O
limbs O O
) O O
connected O B
in O O
a O O
tree O O
topology O O
that O O
encodes O O
relative O O
part O O
positions O O
and O O
orientations O O
. O O
you O O
will O O
notice O O
that O O
for O O
certain O O
pure O B
spectra O O
in O O
the O O
blue–green O O
range O O
, O O
a O O
negative O O
amount O O
of O O
red O O
light O O
has O O
to O O
be O O
added O O
, O O
i.e. O O
, O O
a O O
certain O O
amount O O
of O O
red O O
has O O
to O O
be O O
added O O
to O O
the O O
color B B
being O O
matched O O
in O O
order B B
to O O
get O O
a O O
color B B
match O O
. O O
a O O
color B B
edge O O
detector O O
and O O
its O O
use O O
in O O
scene O O
segmentation O O
. O O
4.3.4 O O
application O O
: O O
rectangle O O
detection B B
once O O
sets O O
of O O
mutually O O
orthogonal O O
vanishing O B
points B I
have O O
been O O
detected O O
, O O
it O O
now O O
becomes O O
pos- O O
sible O O
to O O
search O O
for O O
3d O O
rectangular O O
structures O O
in O O
the O O
image B B
( O O
figure O O
4.47 O O
) O O
. O O
radial B B
distortion I I
can O O
be O O
estimated O O
( O O
potentially O O
ahead O O
of O O
time O O
) O O
using O O
one O O
of O O
the O O
techniques O O
discussed O O
in O O
section O O
2.1.6. O O
for O O
example O O
, O O
the O O
plumb-line B O
method I O
( O O
brown O O
1971 O O
; O O
kang O O
2001 O O
; O O
el-melegy O O
and O O
farag O O
2003 O O
) O O
adjusts O O
radial B B
distortion I I
parameters O O
until O O
slightly O O
curved O O
lines B B
become O O
straight O O
, O O
while O O
mosaic- O O
based O O
approaches O O
adjust O O
them O O
until O O
mis-registration O O
is O O
reduced O O
in O O
image B B
overlap O O
areas O O
( O O
stein O O
1997 O O
; O O
sawhney O O
and O O
kumar O O
1999 O O
) O O
. O O
references B B
835 O O
gross O O
, O O
r. O O
, O O
baker O O
, O O
s. O O
, O O
matthews O O
, O O
i. O O
, O O
and O O
kanade O O
, O O
t. O O
( O O
2005 O O
) O O
. O O
162 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
( O O
a O O
) O O
( O O
c O O
) O O
( O O
b O O
) O O
( O O
d O O
) O O
figure O O
3.43 O O
laplacian O O
pyramid B B
blend O O
of O O
two O O
images O O
of O O
arbitrary O O
shape O O
( O O
burt O O
and O O
adelson O O
1983b O O
) O O
c O O
( O O
cid:13 O O
) O O
1983 O O
acm O O
: O O
( O O
a O O
) O O
ﬁrst O O
input O O
image B B
; O O
( O O
b O O
) O O
second O O
input O O
image B B
; O O
( O O
c O O
) O O
region B B
mask O O
; O O
( O O
d O O
) O O
blended O O
image B B
. O O
12.5.1 O O
implicit O O
surfaces O O
and O O
level B B
sets I I
. O O
gradient B O
domain I I
high O O
dynamic B I
range O I
compression B O
. O O
such O O
detectors O O
can O O
be O O
used O O
in O O
automotive B O
safety I O
applications O O
, O O
e.g. O O
, O O
detecting O O
pedestrians O O
and O O
other O O
cars O O
from O O
moving O O
vehicles O O
( O O
leibe O O
, O O
cornelis O O
, O O
cornelis O O
et O O
al O O
. O O
in O O
their O O
experiments O O
, O O
they O O
ﬁnd O O
that O O
it O O
produces O O
comparable O O
results O O
to O O
ncc O O
, O O
but O O
is O O
more O O
efﬁcient O O
when O O
applied O O
to O O
a O O
large O O
number O O
of O O
overlapping O O
patches O O
using O O
a O O
moving B O
average I O
technique O O
( O O
section O O
3.2.2 O O
) O O
. O O
is O O
there O O
some O O
way O O
to O O
combine O O
a O O
non-ﬂash O O
photo O O
taken O O
just O O
before O O
the O O
ﬂash B B
goes O O
off O O
with O O
the O O
ﬂash B B
photo O O
to O O
produce O O
an O O
image B B
with O O
good O O
color B B
values O O
, O O
sharpness O O
, O O
and O O
low O O
noise B B
? O O
15 O O
petschnigg O O
, O O
agrawala O O
, O O
hoppe O O
et O O
al O O
. O O
generating O O
octree B O
models O O
of O O
3d O O
objects O O
from O O
their O O
silhouettes B O
in O O
a O O
sequence O O
of O O
images O O
. O O
notice O O
how O O
, O O
in O O
the O O
second O O
sequence O O
, O O
the O O
amount O O
of O O
reﬂected O O
light O O
is O O
quite O O
low O O
compared O O
to O O
the O O
transmitted O O
light O O
( O O
the O O
picture O O
of O O
the O O
girl O O
) O O
and O O
yet O O
the O O
algorithm B B
is O O
still O O
able O O
to O O
recover O O
both O O
layers B B
. O O
part-based B O
models O O
can O O
have O O
different O O
topologies O O
for O O
the O O
geometric B B
connections O O
between O O
the O O
parts O O
( O O
figure O O
14.41 O O
) O O
. O O
less O O
blurring O O
and O O
more O O
aliasing B B
means O O
that O O
there O O
is O O
more O O
( O O
aliased O O
) O O
high O O
fre- O O
quency O O
information O O
available O O
to O O
be O O
recovered O O
. O O
in O O
either O O
case O O
, O O
what O O
kinds O O
of O O
features O O
should O O
you O O
detect O O
and O O
then O O
match O O
in O O
order B B
to O O
establish O O
such O O
an O O
alignment B B
or O O
set O O
of O O
correspondences O O
? O O
think O O
about O O
this O O
for O O
a O O
few O O
moments O O
before O O
reading O O
on O O
. O O
pattern O O
recognition B B
, O O
40 O O
( O O
3 O O
) O O
:1106–1122 O O
. O O
5.1.5 O O
application O O
: O O
contour O O
tracking O O
and O O
rotoscoping B B
. O O
unit O O
quaternions B B
live O O
on O O
the O O
unit O O
sphere O O
( O O
cid:107 O O
) O O
q O O
( O O
cid:107 O O
) O O
= O O
1 O O
and O O
antipodal B O
( O O
opposite O O
sign O O
) O O
quaternions B O
, O O
q O O
and O O
−q O O
, O O
represent O O
the O O
same O O
rotation O O
( O O
figure O O
2.6 O O
) O O
. O O
next O O
, O O
we O O
look O O
at O O
the O O
two-frame B B
structure O O
from O O
motion B B
problem O O
( O O
section O O
7.2 O O
) O O
, O O
which O O
involves O O
the O O
determination O O
of O O
the O O
epipolar B O
geometry I I
between O O
two O O
cameras O O
and O O
which O O
can O O
also O O
be O O
used O O
to O O
recover O O
certain O O
information O O
about O O
the O O
camera B B
intrinsics O O
using O O
self-calibration O O
( O O
section O O
7.2.2 O O
) O O
. O O
traditional O O
performance- O O
driven O O
animation O O
systems O O
use O O
marker-based O O
motion B B
capture O O
( O O
ma O O
, O O
jones O O
, O O
chiang O O
et O O
al O O
. O O
fast O O
approximate O O
random B O
walker I O
segmentation O B
using O O
eigen- O O
vector O O
precomputation O O
. O O
section O O
14.5.1 O O
: O O
machine O O
learning O O
software O O
support B O
vector I O
machines I I
( O O
svm O O
) O O
software O O
( O O
http O O
: O O
//www.support-vector-machines.org/ O O
svm O O
soft.html O O
) O O
has O O
pointers O O
to O O
lots O O
of O O
svm O O
libraries O O
, O O
including O O
svmlight O O
, O O
http O O
: O O
// O O
svmlight.joachims.org/ O O
; O O
libsvm O O
, O O
http O O
: O O
//www.csie.ntu.edu.tw/∼cjlin/libsvm/ O O
( O O
fan O O
, O O
chen O O
, O O
and O O
lin O O
2005 O O
) O O
; O O
and O O
liblinear O O
, O O
http O O
: O O
//www.csie.ntu.edu.tw/∼cjlin/liblinear/ O O
( O O
fan O O
, O O
chang O O
, O O
hsieh O O
et O O
al O O
. O O
examples B B
of O O
such O O
lines B B
are O O
horizontal O O
and O O
vertical O O
building O O
edges O O
, O O
zebra O O
cross- O O
ings O O
, O O
railway O O
tracks O O
, O O
the O O
edges O O
of O O
furniture O O
such O O
as O O
tables O O
and O O
dressers O O
, O O
and O O
of O O
course O O
, O O
the O O
ubiquitous O O
calibration B B
pattern O O
( O O
figure O O
4.45 O O
) O O
. O O
12.9 O O
exercises O O
ex O O
12.1 O O
: O O
shape O O
from O O
focus B B
grab O O
a O O
series O O
of O O
focused O O
images O O
with O O
a O O
digital O O
slr O O
set O O
to O O
man- O O
ual O O
focus B B
( O O
or O O
get O O
one O O
that O O
allows O O
for O O
programmatic O O
focus B B
control O O
) O O
and O O
recover O O
the O O
depth O O
of O O
an O O
object O O
. O O
in O O
ieee O O
computer O O
society O O
confer- O O
ence O O
on O O
computer O O
vision O O
and O O
pattern O O
recognition B B
( O O
cvpr O O
2008 O O
) O O
, O O
anchorage O O
, O O
ak O O
. O O
finally O O
, O O
multiple B B
depth O O
map O O
approaches O O
often O O
adopt O O
traditional O O
image-based B B
smoothness O I
( O O
regularization B B
) O O
constraints O O
. O O
saad O O
( O O
2003 O O
) O O
has O O
a O O
nice O O
discussion O O
of O O
the O O
relationship O O
between O O
multigrid O O
and O O
parallel O O
preconditioners O O
and O O
on O O
the O O
relative O O
merits O O
of O O
using O O
multigrid O O
or O O
conjugate B B
gradient I I
approaches O O
. O O
it O O
is O O
safer O O
, O O
however O O
, O O
to O O
test O O
all O O
or O O
a O O
sufﬁcient O O
subset O O
of O O
points B B
, O O
downweighting O O
the O O
ones O O
that O O
lie O O
close O O
to O O
the O O
plane O O
at O O
inﬁnity O O
, O O
for O O
which O O
it O O
is O O
easy O O
to O O
get O O
depth O O
reversals O O
. O O
again O O
, O O
fourier O O
transforms O O
can O O
be O O
used O O
to O O
efﬁciently O O
compute O O
all O O
the O O
correlations O O
needed O O
to O O
perform O O
the O O
linear B B
regression O O
in O O
the O O
bias B O
and I O
gain I I
parameters O B
in O O
order B B
to O O
estimate O O
the O O
exposure-compensated O O
difference B O
for O O
each O O
potential O O
shift O O
( O O
exercise O O
8.1 O O
) O O
. O O
an O O
early O O
example O O
of O O
robust B B
regularization I O
is O O
the O O
graduated O O
non-convexity O O
( O O
gnc O O
) O O
algo- O O
rithm O O
introduced O O
by O O
blake O O
and O O
zisserman O O
( O O
1987 O O
) O O
. O O
2.3 O O
the O O
digital O O
camera O O
values O O
of O O
each O O
of O O
the O O
color B B
primaries O O
, O O
x O O
y O O
z O O
 O O
 O O
= O O
85 O O
( O O
2.108 O O
) O O
0.412453 O O
0.357580 O O
0.180423 O O
0.212671 O O
0.715160 O O
0.072169 O O
0.019334 O O
0.119193 O O
0.950227 O O
 O O
 O O
r709 O O
g709 O O
b709 O O
 O O
. O O
environment O O
mapping O O
and O O
other O O
applications O O
of O O
world O O
projections B B
. O O
510–517 O O
, O O
hilton O O
head B B
island O O
. O O
the O O
interpretation O O
of O O
structure B B
from I I
motion I I
. O O
one O O
simple O O
way O O
to O O
do O O
this O O
is O O
to O O
associate O O
a O O
separate O O
texture B B
map O O
with O O
each O O
triangle O O
( O O
or O O
pair O O
of O O
triangles O O
) O O
. O O
interactive B B
local O O
adjustment O O
of O O
tonal O O
values O O
. O O
the O O
term O O
image-based B B
rendering I I
was O O
introduced O O
by O O
mcmillan O O
and O O
bishop O O
( O O
1995 O O
) O O
, O O
although O O
the O O
seminal O O
paper O O
in O O
the O O
ﬁeld O O
is O O
the O O
view B O
interpolation I I
paper O O
by O O
chen O O
and O O
williams O O
( O O
1993 O O
) O O
. O O
if O O
instead O O
, O O
we O O
simply O O
wish O O
to O O
reconstruct O O
the O O
world O O
for O O
visualization O O
or O O
image-based B B
rendering I I
applications O O
, O O
as O O
in O O
the O O
photo O O
tourism O O
system O O
of O O
snavely O O
, O O
seitz O O
, O O
and O O
szeliski O O
( O O
2006 O O
) O O
, O O
this O O
assumption O O
is O O
quite O O
reasonable O O
in O O
practice O O
. O O
of O O
course O O
, O O
minimizing O O
the O O
set O O
of O O
observations O O
( O O
7.5–7.6 O O
) O O
using O O
non- O O
linear B B
least O O
squares O O
, O O
as O O
described O O
in O O
( O O
6.14 O O
and O O
6.23 O O
) O O
, O O
is O O
preferable O O
to O O
using O O
linear O O
least B B
squares I I
, O O
regardless O O
of O O
the O O
representation O O
chosen O O
. O O
optical B O
ﬂow I I
using O O
total B O
variation I O
and O O
conjugate B O
gradient I I
descent O I
, O O
http O O
: O O
//people.csail O O
. O O
from O O
accurate O O
range O O
imaging O O
sensor B B
calibration O O
to O O
accurate O O
model-based B B
3-d O O
object O O
localization O O
. O O
alignment B B
by O O
maximization O O
of O O
mutual O O
information O O
. O O
beyond O O
pixels O O
: O O
exploring O O
new O O
representations O O
and O O
applications O O
for O O
mo- O O
tion B B
analysis O O
. O O
) O O
594 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
( O O
a O O
) O O
( O O
b O O
) O O
( O O
c O O
) O O
( O O
d O O
) O O
figure O O
12.11 O O
progressive O O
mesh O O
representation O O
of O O
an O O
airplane O O
model O O
( O O
hoppe O O
1996 O O
) O O
c O O
( O O
cid:13 O O
) O O
1996 O O
acm O O
: O O
( O O
a O O
) O O
base O O
mesh O O
m O O
0 O O
( O O
150 O O
faces B B
) O O
; O O
( O O
b O O
) O O
mesh O O
m O O
175 O O
( O O
500 O O
faces B B
) O O
; O O
( O O
c O O
) O O
mesh O O
m O O
425 O O
( O O
1000 O O
faces B B
) O O
; O O
( O O
d O O
) O O
original O O
mesh O O
m O O
= O O
m O O
n O O
( O O
13,546 O O
faces B O
) O O
. O O
) O O
the O O
reason O O
they O O
call O O
their O O
resulting O O
pyramid B B
a O O
gaussian O O
pyramid B B
is O O
that O O
repeated O O
convolutions O O
of O O
the O O
binomial B B
kernel O O
converge O O
to O O
a O O
gaussian.16 O O
to O O
compute O O
the O O
laplacian O O
pyramid B B
, O O
burt O O
and O O
adelson O O
ﬁrst O O
interpolate O O
a O O
lower O O
resolu- O O
tion B B
image O O
to O O
obtain O O
a O O
reconstructed O O
low-pass B B
version O O
of O O
the O O
original O O
image B B
( O O
figure O O
3.34b O O
) O O
. O O
references B B
909 O O
taubin O O
, O O
g. O O
( O O
1995 O O
) O O
. O O
( O O
2003 O O
) O O
present O O
an O O
algorithm B B
that O O
combines O O
global B B
registration O O
with O O
local O O
motion B O
estimation I B
( O O
optical B O
ﬂow I I
) O O
to O O
accurately O O
align O O
the O O
images O O
before O O
blending B B
their O O
radiance O O
estimates O O
( O O
figure O O
10.16 O O
) O O
. O O
14.8 O O
exercises O O
ex O O
14.1 O O
: O O
face B B
detection O O
build O O
and O O
test O O
one O O
of O O
the O O
face B B
detectors O O
presented O O
in O O
section O O
14.1.1 O O
. O O
4. O O
for O O
the O O
rotation O O
technique O O
, O O
scatter O O
points B B
uniformly O O
on O O
a O O
sphere O O
until O O
you O O
get O O
a O O
similar O O
number O O
of O O
points B B
as O O
for O O
other O O
techniques O O
. O O
3. O O
at O O
run O O
time O O
, O O
for O O
each O O
new O O
camera B B
view O O
, O O
select O O
the O O
best O O
source O O
image B B
for O O
each O O
visible O O
model O O
face B B
. O O
given O O
a O O
representation O O
for O O
an O O
environment B O
matte I O
, O O
how O O
can O O
we O O
go O O
about O O
estimating O O
it O O
for O O
a O O
particular O O
object O O
? O O
the O O
trick O O
is O O
to O O
place O O
the O O
object O O
in O O
front O O
of O O
a O O
monitor O O
( O O
or O O
surrounded O O
by O O
a O O
set O O
of O O
monitors O O
) O O
, O O
where O O
we O O
can O O
change O O
the O O
illumination O O
patterns B O
b O O
( O O
x O O
) O O
and O O
observe O O
the O O
value O O
of O O
each O O
composite O O
pixel O O
ci.7 O O
as O O
with O O
traditional O O
two-screen O O
matting B B
( O O
section O O
10.4.1 O O
) O O
, O O
we O O
can O O
use O O
a O O
variety O O
of O O
solid O O
colored O O
backgrounds O O
to O O
estimate O O
each O O
pixel O O
’ O O
s O O
foreground O O
color B B
αifi O O
and O O
partial O O
coverage O O
( O O
opacity B B
) O O
αi O O
. O O
( O O
2004 O O
) O O
present O O
a O O
system O O
based O O
on O O
tracking O O
hand-drawn O O
b-spline O O
contours O O
drawn O O
at O O
selected O O
keyframes O O
, O O
using O O
a O O
combination O O
of O O
geometric B B
and O O
appearance-based O O
criteria O O
( O O
figure O O
5.12 O O
) O O
. O O
once O O
the O O
dsi O O
has O O
been O O
computed O O
, O O
the O O
next O O
step O O
in O O
most O O
stereo B B
correspondence O O
algorithms O O
is O O
to O O
produce O O
a O O
univalued O O
function O O
in O O
disparity O O
space O O
d O O
( O O
x O O
, O O
y O O
) O O
that O O
best O O
describes O O
the O O
shape O O
of O O
the O O
surfaces O O
in O O
the O O
scene O O
. O O
( O O
optional O O
) O O
match O O
pieces O O
to O O
the O O
reference O O
image B B
using O O
some O O
rotationally O O
invariant O O
fea- O O
ture O O
descriptors O O
. O O
while O O
there O O
is O O
no O O
magic O O
bullet O O
for O O
this O O
problem O O
, O O
short O O
of O O
full O O
scene B O
understanding I O
, O O
further O O
improvements O O
can O O
likely O O
be O O
made O O
by O O
applying O O
domain-speciﬁc O O
448 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
( O O
a O O
) O O
( O O
b O O
) O O
( O O
c O O
) O O
figure O O
9.11 O O
recognizing B O
panoramas I O
( O O
brown O O
, O O
szeliski O O
, O O
and O O
winder O O
2005 O O
) O O
, O O
ﬁgures O O
cour- O O
tesy O O
of O O
matthew O O
brown O O
: O O
( O O
a O O
) O O
input O O
images O O
with O O
pairwise O O
matches O O
; O O
( O O
b O O
) O O
images O O
grouped O O
into O O
connected B B
components I I
( O O
panoramas O O
) O O
; O O
( O O
c O O
) O O
individual O O
panoramas O O
registered O O
and O O
blended O O
into O O
stitched O O
composites O O
. O O
( O O
b O O
) O O
the O O
radial B B
distortion I I
and O O
chromatic B B
aberration I I
can O O
also O O
be O O
estimated O O
and O O
removed O O
. O O
the O O
algorithm B B
therefore O O
prefers O O
removing O O
regions O O
that O O
are O O
near O O
the O O
edge O O
of O O
the O O
image B B
, O O
which O O
reduces O O
the O O
likelihood O O
that O O
partially O O
visible O O
objects O O
will O O
appear O O
in O O
the O O
ﬁnal O O
composite O O
. O O
we O O
can O O
readily O O
see O O
from O O
the O O
shape O O
of O O
the O O
tracks O O
that O O
the O O
moving O O
object O O
must O O
be O O
a O O
sphere O O
, O O
but O O
how O O
can O O
we O O
infer O O
this O O
mathematically O O
? O O
it O O
turns O O
out O O
that O O
, O O
under O O
orthography O O
or O O
related O O
models O O
we O O
discuss O O
below O O
, O O
the O O
shape O O
and O O
motion B B
can O O
be O O
recovered O O
simultaneously O O
using O O
a O O
singular O O
value O O
decomposition O O
( O O
tomasi O O
and O O
358 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
( O O
a O O
) O O
( O O
b O O
) O O
( O O
c O O
) O O
figure O O
7.5 O O
3d O O
reconstruction O O
of O O
a O O
rotating O O
ping O O
pong O O
ball O O
using O O
factorization O B
( O O
tomasi O O
and O O
kanade O O
1992 O O
) O O
c O O
( O O
cid:13 O O
) O O
1992 O O
springer O O
: O O
( O O
a O O
) O O
sample O O
image B B
with O O
tracked O O
features O O
overlaid O O
; O O
( O O
b O O
) O O
sub- O O
sampled O O
feature B B
motion O O
stream O O
; O O
( O O
c O O
) O O
two O O
views O O
of O O
the O O
reconstructed O O
3d O O
model O O
. O O
( O O
7.8 O O
) O O
348 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
figure O O
7.3 O O
epipolar B O
geometry I I
: O O
the O O
vectors O O
t O O
= O O
c1 O O
− O O
c0 O O
, O O
p O O
− O O
c0 O O
and O O
p O O
− O O
c1 O O
are O O
co-planar O O
and O O
deﬁne O O
the O O
basic O O
epipolar O O
constraint O I
expressed O O
in O O
terms O O
of O O
the O O
pixel O O
measurements O O
x0 O O
and O O
x1 O O
. O O
a.1.3 O O
qr O O
factorization B B
. O O
simultaneous O O
matting B B
and O O
compositing B B
. O O
( O O
2007 O O
) O O
consumer O O
image B B
person O O
db O O
complete O O
images O O
people O O
http O O
: O O
//chenlab.ece.cornell.edu/people/andy/gallagherdataset.html O O
gallagher O O
and O O
chen O O
( O O
2008 O O
) O O
object O O
recognition B B
caltech O O
101 O O
segmentation B B
masks O O
http O O
: O O
//www.vision.caltech.edu/image O O
datasets/caltech101/ O O
101 O O
categories O O
fei-fei O O
, O O
fergus O O
, O O
and O O
perona O O
( O O
2006 O O
) O O
caltech O O
256 O O
centered O O
objects O O
256 O O
categories O O
and O O
clutter O O
http O O
: O O
//www.vision.caltech.edu/image O O
datasets/caltech256/ O O
grifﬁn O O
, O O
holub O O
, O O
and O O
perona O O
( O O
2007 O O
) O O
coil-100 O O
centered O O
objects O O
100 O O
instances O O
http O O
: O O
//www1.cs.columbia.edu/cave/software/softlib/coil-100.php O O
nene O O
, O O
nayar O O
, O O
and O O
murase O O
( O O
1996 O O
) O O
eth-80 O O
centered O O
objects O O
http O O
: O O
//www.mis.tu-darmstadt.de/datasets O O
8 O O
instances O O
, O O
10 O O
views O O
leibe O O
and O O
schiele O O
( O O
2003 O O
) O O
instance B B
recognition O O
benchmark O O
objects O O
in O O
various O O
poses O O
2550 O O
objects O O
http O O
: O O
//vis.uky.edu/∼stewe/ukbench/ O O
oxford O O
buildings O O
dataset O O
pictures O O
of O O
buildings O O
5062 O O
images O O
nist´er O O
and O O
stew´enius O O
( O O
2006 O O
) O O
norb O O
tiny O O
images O O
bounding O O
box O O
complete O O
images O O
http O O
: O O
//www.robots.ox.ac.uk/∼vgg/data/oxbuildings/ O O
http O O
: O O
//www.cs.nyu.edu/∼ylclab/data/norb-v1.0/ O O
http O O
: O O
//people.csail.mit.edu/torralba/tinyimages/ O O
philbin O O
, O O
chum O O
, O O
isard O O
et O O
al O O
. O O
learning B B
to O O
locate O O
informative O O
features O O
for O O
visual O O
identiﬁcation O O
. O O
robust B B
regression O O
and O O
outlier O O
detection B B
. O O
it O O
has O O
also O O
been O O
shown O O
to O O
be O O
closely O O
related O O
to O O
other O O
adaptive B B
smooth- O O
ing O O
techniques O O
( O O
saint-marc O O
, O O
chen O O
, O O
and O O
medioni O O
1991 O O
; O O
barash O O
2002 O O
; O O
barash O O
and O O
comaniciu O O
2004 O O
) O O
as O O
well O O
as O O
bayesian O O
regularization B B
with O O
a O O
non-linear B B
smoothness O O
term O O
that O O
can O O
be O O
de- O O
rived O O
from O O
image B B
statistics O O
( O O
scharr O O
, O O
black O O
, O O
and O O
haussecker O O
2003 O O
) O O
. O O
alternatively O O
, O O
test O O
out O O
your O O
segmentation B B
algorithm O O
on O O
the O O
berkeley O O
segmentation B B
database O O
( O O
martin O O
, O O
fowlkes O O
, O O
tal O O
et O O
al O O
. O O
alternatively O O
, O O
use O O
laplacian O O
pyramid B B
blending O O
( O O
exercise O O
3.20 O O
) O O
or O O
gradient B O
domain I I
blend- O O
ing O O
. O O
such O O
algorithms O O
iteratively O O
update O O
disparity O O
estimates O O
using O O
non-linear O O
operations O O
that O O
result O O
in O O
an O O
overall O O
behavior O O
similar O O
to O O
global B B
optimization I I
algorithms O O
. O O
spacetime B B
stereo I I
: O O
a O O
unifying O O
framework O O
for O O
depth O O
from O O
triangulation B B
. O O
c.3 O O
slides O O
and O O
lectures O O
789 O O
in O O
practice O O
, O O
for O O
eight-bit O O
color B B
channels O O
, O O
this O O
bit O O
reverse O O
can O O
be O O
stored O O
in O O
a O O
table O O
or O O
a O O
complete O O
table O O
mapping O O
from O O
labels O O
to O O
pseudocolors O O
( O O
say O O
with O O
4092 O O
entries O O
) O O
can O O
be O O
pre-computed O O
. O O
for O O
example O O
, O O
pose O O
( O O
camera B B
orientation O O
) O O
can O O
be O O
estimated O O
using O O
simple O O
least B B
squares I I
( O O
section O O
6.2.1 O O
) O O
. O O
fast O O
progressive O O
image B B
coding O O
without O O
wavelets O O
. O O
we O O
have O O
much O O
more O O
to O O
say O O
about O O
using O O
variants O O
on O O
smoothing B B
to O O
remove O O
noise B B
later O O
( O O
see O O
sections O O
3.3.1 O O
, O O
3.4 O O
, O O
and O O
3.7 O O
) O O
. O O
alternative O O
terms O O
for O O
this O O
in O O
the O O
vision O O
community O O
include O O
optimal O O
motion B B
estimation I I
( O O
weng O O
, O O
ahuja O O
, O O
and O O
huang O O
1993 O O
) O O
and O O
non-linear B B
least O O
squares O O
( O O
appendix O O
a.3 O O
) O O
( O O
taylor O O
, O O
kriegman O O
, O O
and O O
anandan O O
1991 O O
; O O
szeliski O O
and O O
kang O O
1994 O O
) O O
. O O
feature B B
matching O O
stage O O
( O O
section O O
4.1.3 O O
) O O
efﬁciently O O
searches O O
for O O
likely O O
matching B B
candidates O O
in O O
other O O
images O O
. O O
homogeneous B O
coordinates I O
( O O
section O O
2.1 O O
) O O
are O O
denoted O O
with O O
a O O
tilde O O
over O O
the O O
vector O O
, O O
e.g. O O
, O O
˜x O O
= O O
( O O
˜x O O
, O O
˜y O O
, O O
˜w O O
) O O
= O O
˜w O O
( O O
x O O
, O O
y O O
, O O
1 O O
) O O
= O O
˜w¯x O O
in O O
p O O
2. O O
the O O
cross O O
product O O
operator O O
in O O
matrix O O
form O O
is O O
denoted O O
by O O
[ O O
] O O
. O O
( O O
optional O O
) O O
: O O
prove O O
whether O O
the O O
beier–neely O O
warp O O
does O O
or O O
does O O
not O O
reduce O O
to O O
a O O
sparse B B
point-based O O
deformation O O
as O O
the O O
line O O
segments O O
become O O
shorter O O
( O O
reduce O O
to O O
points B B
) O O
. O O
in O O
ieee O O
computer O O
society O O
conference O O
on O O
computer O O
vision O O
and O O
pattern O O
recognition B B
( O O
cvpr O O
’ O O
2006 O O
) O O
, O O
pp O O
. O O
) O O
how O O
would O O
you O O
go O O
about O O
writing O O
a O O
program O O
to O O
categorize O O
each O O
of O O
these O O
images O O
into O O
the O O
appropriate O O
class O O
, O O
especially O O
if O O
you O O
were O O
also O O
given O O
the O O
choice O O
“ O O
none O O
of O O
the O O
above O O
” O O
? O O
as O O
you O O
can O O
tell O O
from O O
this O O
example O O
, O O
visual O O
category O O
recognition B B
is O O
an O O
extremely O O
challenging O O
problem O O
; O O
no O O
one O O
has O O
yet O O
constructed O O
a O O
system O O
that O O
approaches O O
the O O
performance O O
level O O
of O O
a O O
two- O O
year-old O O
child O O
. O O
2.2 O O
photometric B B
image O O
formation O O
71 O O
figure O O
2.21 O O
in O O
a O O
lens O O
subject O O
to O O
chromatic B O
aberration I O
, O O
light O O
at O O
different O O
wavelengths O O
( O O
e.g. O O
, O O
the O O
red O O
and O O
blur O O
arrows O O
) O O
is O O
focused O O
with O O
a O O
different O O
focal O O
length O O
f O O
( O O
cid:48 O O
) O O
and O O
hence O O
a O O
different O O
depth O O
z O O
( O O
cid:48 O O
) O O
i O O
, O O
resulting O O
in O O
both O O
a O O
geometric B B
( O O
in-plane O O
) O O
displacement O O
and O O
a O O
loss O O
of O O
focus B B
. O O
3.5.1 O O
interpolation B B
in O O
order B B
to O O
interpolate O O
( O O
or O O
upsample O O
) O O
an O O
image B B
to O O
a O O
higher O O
resolution O O
, O O
we O O
need O O
to O O
select O O
some O O
interpolation B B
kernel O O
with O O
which O O
to O O
convolve O O
the O O
image B B
, O O
g O O
( O O
i O O
, O O
j O O
) O O
= O O
( O O
cid:88 O O
) O O
k O O
, O O
l O O
f O O
( O O
k O O
, O O
l O O
) O O
h O O
( O O
i O O
− O O
rk O O
, O O
j O O
− O O
rl O B
) O O
. O O
some O O
costs O O
are O O
insensitive O O
to O O
differences O O
in O O
camera B B
gain O O
or O O
bias O B
, O O
for O O
example O O
gradient- O O
based O O
measures O O
( O O
seitz O O
1989 O O
; O O
scharstein O O
1994 O O
) O O
, O O
phase O B
and O O
ﬁlter-bank O O
responses O O
( O O
marr O O
and O O
poggio O O
1979 O O
; O O
kass O O
1988 O O
; O O
jenkin O O
, O O
jepson O O
, O O
and O O
tsotsos O O
1991 O O
; O O
jones O O
and O O
malik O O
1992 O O
) O O
, O O
ﬁlters O O
that O O
remove O O
regular O O
or O O
robust B B
( O O
bilaterally O O
ﬁltered O O
) O O
means O O
( O O
ansar O O
, O O
castano O O
, O O
and O O
matthies O O
2004 O O
; O O
hirschm¨uller O O
and O O
scharstein O O
2009 O O
) O O
, O O
dense O O
feature O O
descriptor O O
( O O
tola O O
, O O
lepetit O O
, O O
and O O
fua O O
2010 O O
) O O
, O O
and O O
non-parametric B B
measures O O
such O O
as O O
rank O O
and O O
census O O
transforms O O
( O O
zabih O O
and O O
woodﬁll O O
1994 O O
) O O
, O O
ordinal O O
measures O O
( O O
bhat O O
and O O
nayar O O
1998 O O
) O O
, O O
or O O
entropy O O
( O O
zitnick O O
, O O
kang O O
, O O
uyttendaele O O
et O O
al O O
. O O
two-dimensional B B
iir O O
ﬁlters O O
and O O
recursive O O
formulas O O
are O O
sometimes O O
used O O
to O O
compute O O
quan- O O
tities O O
that O O
involve O O
large O O
area O O
interactions O O
, O O
such O O
as O O
two-dimensional B B
distance O O
functions O O
( O O
sec- O O
tion B B
3.3.3 O O
) O O
and O O
connected B B
components I I
( O O
section O O
3.3.4 O O
) O O
. O O
figure O O
4.16 O O
feature B B
matching O O
: O O
how O O
can O O
we O O
extract O O
local B B
descriptors O O
that O O
are O O
invariant O O
to O O
inter-image O O
variations O O
and O O
yet O O
still O O
discriminative O O
enough O O
to O O
establish O O
correct O O
correspon- O O
dences O O
? O O
are O O
therefore O O
invariant O O
to O O
both O O
afﬁne B B
geometric O O
and O O
photometric B B
( O O
linear B B
bias-gain O O
or O O
smooth O O
monotonic O O
) O O
transformations O O
( O O
figure O O
4.15 O O
) O O
. O O
4.1 O O
points B B
and O O
patches O O
4.1.4 O O
feature B B
tracking O O
235 O O
an O O
alternative O O
to O O
independently O O
ﬁnding O O
features O O
in O O
all O O
candidate O O
images O O
and O O
then O O
matching B B
them O O
is O O
to O O
ﬁnd O O
a O O
set O O
of O O
likely O O
feature B B
locations O O
in O O
a O O
ﬁrst O O
image B B
and O O
to O O
then O O
search O O
for O O
their O O
corresponding O O
locations O O
in O O
subsequent O O
images O O
. O O
mitsunaga O O
and O O
nayar O O
( O O
1999 O O
) O O
show O O
that O O
in O O
order B B
to O O
maximize O O
the O O
signal-to-noise O O
ratio O O
( O O
snr O O
) O O
, O O
484 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
figure O O
10.15 O O
bracketed O O
set O O
of O O
exposures O O
captured O O
with O O
a O O
ﬁlm O O
camera B B
and O O
the O O
resulting O O
radiance O O
image B B
displayed O O
in O O
pseudocolor O O
( O O
debevec O O
and O O
malik O O
1997 O O
) O O
c O O
( O O
cid:13 O O
) O O
1997 O O
acm O O
. O O
cloth O O
grasp O O
point O O
detection O B
based O O
on O O
multiple-view O O
geometric B O
cues O O
with O O
application O O
to O O
robotic O O
towel O O
folding O O
. O O
these O O
kinds O O
of O O
problems O O
are O O
in O O
general O O
called O O
inverse B B
problems O O
because O O
they O O
involve O O
estimating O O
unknown O O
model O O
parameters B B
instead O O
of O O
simulating O O
the O O
forward B B
formation O O
equations.1 O O
computer O O
graphics O O
is O O
a O O
classic O O
forward B B
modeling O O
problem O O
( O O
given O O
some O O
objects O O
, O O
cameras O O
, O O
and O O
lighting B B
, O O
simulate O O
the O O
images O O
that O O
would O O
result O O
) O O
, O O
while O O
computer O O
vision O O
problems O O
are O O
usually O O
of O O
the O O
inverse B B
kind O O
( O O
given O O
one O O
or O O
more O O
images O O
, O O
recover O O
the O O
scene O O
that O O
gave O O
rise O O
to O O
these O O
images O O
) O O
. O O
10.4.4 O O
smoke B B
, O O
shadow B B
, O O
and O O
ﬂash B B
matting O O
. O O
( O O
2004 O O
) O O
) O O
show O O
similar O O
results O O
, O O
while O O
signiﬁcantly O B
improving O O
on O O
pyramid B B
blending O O
and O O
feather- O O
ing O O
algorithms O O
. O O
a O O
second O O
approach O O
to O O
specifying O O
displacements O O
for O O
local O O
deformations O O
is O O
to O O
use O O
corre- O O
sponding O O
oriented B B
line O O
segments O O
( O O
beier O O
and O O
neely O O
1992 O O
) O O
, O O
as O O
shown O O
in O O
figures O O
3.51c O O
and O O
3.52. O O
pixels O O
along O O
each O O
line O O
segment O O
are O O
transferred O O
from O O
source O O
to O O
destination O O
exactly O O
as O O
speciﬁed O O
, O O
and O O
other O O
pixels O O
are O O
warped O O
using O O
a O O
smooth O O
interpolation B B
of O O
these O O
displacements O O
. O O
to O O
recognize O O
panoramas O O
, O O
brown O O
and O O
lowe O O
( O O
2007 O O
) O O
ﬁrst O O
ﬁnd O O
all O O
pairwise O O
image B B
overlaps O O
using O O
a O O
feature-based B B
method O O
and O O
then O O
ﬁnd O O
connected B B
components I I
in O O
the O O
overlap O O
graph O B
to O O
“ O O
recognize O O
” O O
individual O O
panoramas O O
( O O
figure O O
9.11 O O
) O O
. O O
( O O
2009 O O
) O O
table O O
14.1 O O
image B O
databases O O
for B O
recognition I O
, O O
adapted O O
and O O
expanded O O
from O O
fei-fei O O
, O O
fergus O O
, O O
and O O
torralba O O
( O O
2009 O O
) O O
. O O
in O O
addition O O
to O O
merging B B
multiple O O
exposures O O
, O O
techniques O O
were O O
developed O O
to O O
merge O O
ﬂash B O
images O O
with O O
non-ﬂash O O
counterparts O O
( O O
eisemann O O
and O O
durand O O
2004 O O
; O O
petschnigg O O
, O O
agrawala O O
, O O
hoppe O O
et O O
al O O
. O O
( O O
b.23 O O
) O O
the O O
ﬁrst O O
term O O
ed O O
( O O
x O O
, O O
y O O
) O O
is O O
the O O
data O O
energy O O
or O O
data O O
penalty O O
and O O
measures O O
the O O
negative O O
log O O
likelihood O O
that O O
the O O
measurements O O
y O O
were O O
observed O O
given O O
the O O
unknown O O
state O O
x. O O
the O O
second O O
term O O
ep O O
( O O
x O O
) O O
is O O
the O O
prior B B
energy O O
and O O
it O O
plays O O
a O O
role O O
analogous O O
to O O
the O O
smoothness B B
energy O O
in O O
regularization B B
. O O
the O O
tracking O O
of O O
people O O
and O O
their O O
pose O O
from O O
frame O O
to O O
frame O O
can O O
be O O
en- O O
hanced O O
by O O
computing O O
optic O O
ﬂow O O
or O O
matching B B
the O O
appearance O O
of O O
their O O
limbs O O
from O O
one O O
frame O O
to O O
another O O
. O O
however O O
, O O
in O O
order B B
to O O
do O O
this O O
without O O
introducing O O
blur O O
or O O
jitter O O
( O O
irregular O O
motion B B
) O O
, O O
they O O
need O O
accurate O O
per-pixel O O
motion B B
estimates O O
. O O
262 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
struct O O
sedgel O O
{ O O
float O O
e O O
[ O O
2 O O
] O O
[ O O
2 O O
] O O
; O O
float O O
x O O
, O O
y O O
; O O
float O O
n_x O O
, O O
n_y O O
; O O
float O O
theta O O
; O O
float O O
length O O
; O O
float O O
strength O O
; O O
// O O
edgel O O
endpoints O O
( O O
zero B O
crossing I O
) O O
// O O
sub-pixel O O
edge O O
position O O
( O O
midpoint O O
) O O
// O O
orientation O O
, O O
as O O
normal B O
vector I O
// O O
orientation O O
, O O
as O O
angle O O
( O O
degrees O O
) O O
// O O
length O O
of O O
edgel O O
// O O
strength O O
of O O
edgel O O
( O O
gradient O O
magnitude O O
) O O
} O O
; O O
struct O O
sline O O
: O O
public O O
sedgel O O
{ O O
float O O
line_length O O
; O O
// O O
length O O
of O O
line O O
( O O
est O O
. O O
after O O
attenuation O O
, O O
the O O
resulting O O
gradient O O
ﬁeld O O
is O O
re-integrated O O
by O O
solving O O
a O O
ﬁrst-order O O
vari- O O
ational O O
( O O
least B O
squares I I
) O O
problem O O
, O O
min O O
( O O
cid:90 O O
) O O
( O O
cid:90 O O
) O O
( O O
cid:107 O O
) O O
∇i O O
( O O
x O O
, O O
y O O
) O O
− O O
g O O
( O O
x O O
, O O
y O O
) O O
( O O
cid:107 O O
) O O
2dx O O
dy O O
( O O
10.19 O O
) O O
490 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
( O O
a O O
) O O
( O O
b O O
) O O
figure O O
10.21 O O
local B B
tone O O
mapping O O
using O O
linear O O
ﬁlters O O
: O O
( O O
a O O
) O O
low-pass B B
and O O
high-pass O O
ﬁltered O O
log O O
luminance O O
images O O
and O O
color B B
( O O
chrominance O O
) O O
image B B
; O O
( O O
b O O
) O O
resulting O O
tone-mapped O O
image B B
( O O
after O O
at- O O
tenuating O O
the O O
low-pass B B
log O O
luminance O O
image B B
) O O
shows O O
visible O O
halos B B
around O O
the O O
trees O O
. O O
pedestrian B B
detection O O
: O O
a O O
bench- O O
mark O O
. O O
in O O
addition O O
to O O
blending B B
four O O
lookups O O
to O O
compute O O
the O O
ﬁnal O O
value O O
, O O
we O O
can O O
also O O
distribute O O
each O O
input O O
pixel O O
into O O
four O O
adjacent O O
lookup O O
tables O O
during O O
the O O
histogram B B
accumulation O O
phase O B
( O O
notice O O
that O O
the O O
gray O O
arrows O O
in O O
figure O O
3.9b O O
point O O
both O O
ways O O
) O O
, O O
i.e. O O
, O O
hk O O
, O O
l O O
( O O
i O O
( O O
i O O
, O O
j O O
) O O
) O O
+= O O
w O O
( O O
i O O
, O O
j O O
, O O
k O O
, O O
l O O
) O O
, O O
( O O
3.11 O O
) O O
where O O
w O O
( O O
i O O
, O O
j O O
, O O
k O O
, O O
l O O
) O O
is O O
the O O
bilinear B B
weighting O O
function O O
between O O
pixel O O
( O O
i O O
, O O
j O O
) O O
and O O
lookup O O
table O O
( O O
k O O
, O O
l O O
) O O
. O O
one O O
special O O
case O O
of O O
this O O
problem O O
is O O
pose O O
estimation B B
, O O
which O O
is O O
determining O O
a O O
camera B B
’ O O
s O O
position O O
relative O O
to O O
a O O
known O O
3d O O
object O O
or O O
scene O O
( O O
section O O
6.2 O O
) O O
. O O
( O O
chen O O
1995 O O
) O O
also O O
propose O O
using O O
environment O O
maps O O
( O O
cylin- O O
drical O O
, O O
cubic B O
, O O
or O O
spherical B B
) O O
as O O
source O O
images O O
for O O
view O O
interpolation B I
. O O
lens O O
distortion O O
calibration B B
using O O
point O O
correspondences O O
. O O
multiple B B
kernels O O
for O O
object O O
detection B B
. O O
to O O
compute O O
the O O
connected B B
components I I
of O O
an O O
image B B
, O O
we O O
ﬁrst O O
( O O
conceptually O O
) O O
split O O
the O O
image B B
into O O
horizontal O O
runs O O
of O O
adjacent O O
pixels O O
, O O
and O O
then O O
color B B
the O O
runs O O
with O O
unique O O
labels O O
, O O
re-using O O
the O O
labels O O
of O O
vertically O O
adjacent O O
runs O O
whenever O O
possible O O
. O O
we O O
have O O
already O O
seen O O
a O O
number O O
of O O
tools O O
for O O
interactively O O
segmenting O O
objects O O
in O O
an O O
image B B
, O O
including O O
snakes B B
( O O
section O O
5.1.1 O O
) O O
, O O
scissors O O
( O O
section O O
5.1.3 O O
) O O
, O O
and O O
grabcut O O
segmentation B O
( O O
sec- O O
tion B B
5.5 O O
) O O
. O O
( O O
optional O O
) O O
use O O
an O O
lcd O O
projector O O
to O O
project O O
artiﬁcial O O
texture B B
onto O O
the O O
scene O O
. O O
non-separable O O
extensions O O
of O O
quadrature O O
mirror O O
ﬁlters O O
to O O
multiple B B
dimensions O O
. O O
better O O
results O O
can O O
usually O O
be O O
obtained O O
by O O
clustering O O
in O O
the O O
joint B B
domain O O
of O O
color B B
and O O
lo- O O
cation O O
. O O
color B B
lines O O
: O O
ong O O
, O O
e.-j. O O
, O O
micilotta O O
, O O
a. O O
s. O O
, O O
bowden O O
, O O
r. O O
, O O
and O O
hilton O O
, O O
a O O
. O O
modify O O
your O O
depth O O
estimation O I
algorithm B O
to O O
match O O
and O O
estimate O O
the O O
geometry O O
of O O
straight O O
lines B B
and O O
incorporate O O
it O O
into O O
your O O
image-based B B
rendering I I
algorithm O O
. O O
in O O
this O O
chapter O O
, O O
we O O
look O O
at O O
the O O
converse O O
problem O O
of O O
estimating O O
the O O
locations O O
of O O
3d O O
points B B
from O O
multiple B B
images O O
given O O
only O O
a O O
sparse B B
set O O
of O O
correspondences O O
between O O
image B B
features O O
. O O
does O O
this O O
explain O O
the O O
usual O O
depth O O
of O O
ﬁeld O O
markings O O
on O O
a O O
lens O O
that O O
bracket O O
the O O
in-focus O O
marker O O
, O O
as O O
in O O
figure O O
2.20a O O
? O O
3. O O
now O O
consider O O
a O O
zoom O O
lens O O
with O O
a O O
varying O O
focal O O
length O O
f. O O
assume O O
that O O
as O O
you O O
zoom O O
, O O
the O O
lens O O
stays O O
in O O
focus B B
, O O
i.e. O O
, O O
the O O
distance O O
from O O
the O O
rear O O
nodal B B
point I O
to O O
the O O
sensor B B
plane O O
zi O O
adjusts O O
itself O O
automatically O O
for O O
a O O
ﬁxed O O
focus O B
distance O O
zo O O
. O O
moving O O
the O O
denominator O O
over O O
to O O
the O O
left O O
hand O O
side O O
, O O
we O O
end O O
up O O
with O O
a O O
set O O
of O O
simultaneous O O
linear B B
equations O O
, O O
xi O O
( O O
p20xi O O
+ O O
p21yi O O
+ O O
p22zi O O
+ O O
p23 O O
) O O
= O O
p00xi O O
+ O O
p01yi O O
+ O O
p02zi O O
+ O O
p03 O O
, O O
yi O O
( O O
p20xi O O
+ O O
p21yi O O
+ O O
p22zi O O
+ O O
p23 O O
) O O
= O O
p10xi O O
+ O O
p11yi O O
+ O O
p12zi O O
+ O O
p13 O O
, O O
( O O
b.3 O O
) O O
( O O
b.4 O O
) O O
which O O
we O O
can O O
solve O O
using O O
linear O O
least B O
squares I I
( O O
appendix O O
a.2 O O
) O O
to O O
obtain O O
an O O
estimate O O
of O O
p O O
. O O
9.1.5 O O
application O O
: O O
video B B
summarization I I
and O O
compression B B
. O O
traditionally O O
, O O
optical B B
ﬂow I I
algorithms O O
( O O
section O O
8.4 O O
) O O
compute O O
an O O
independent O O
motion B B
esti- O O
mate O O
for O O
each O O
pixel O O
, O O
i.e. O O
, O O
the O O
number O O
of O O
ﬂow O O
vectors O O
computed O O
is O O
equal O O
to O O
the O O
number O O
of O O
input O O
pixels O O
. O O
munder O O
and O O
gavrila O O
( O O
2006 O O
) O O
compare O O
a O O
number O O
of O O
pedestrian B B
detectors O O
and O O
conclude O O
that O O
those O O
based O O
on O O
local B B
receptive O O
ﬁelds O O
and O O
svms O O
perform O O
the O O
best O O
, O O
with O O
a O O
boosting-based O O
ap- O O
proach O O
coming O O
close O O
. O O
manual O O
ini- O O
tialization O O
is O O
used O O
to O O
estimate O O
a O O
rough O O
pose O O
( O O
skeleton O O
) O O
and O O
height O O
model O O
, O O
and O O
this O O
is O O
then O O
used O O
to O O
segment O O
the O O
person O O
’ O O
s O O
outline O O
using O O
the O O
grab O O
cut O O
segmentation B B
algorithm O O
( O O
section O O
5.5 O O
) O O
. O O
figure O O
14.11 O O
pose O O
detection B B
using O O
random O O
forests O O
( O O
rogez O O
, O O
rihan O O
, O O
ramalingam O O
et O O
al O O
. O O
in O O
this O O
section O O
, O O
we O O
describe O O
a O O
number O O
of O O
algorithms O O
that O O
proceed O O
either O O
by O O
recursively O O
splitting B B
the O O
whole O O
image B B
into O O
pieces O O
based O O
on O O
region B B
statistics O O
or O O
, O O
conversely O O
, O O
merging B O
pixels O O
and O O
regions O O
together O O
in O O
a O O
hierarchical B B
fashion O O
. O O
while O O
this O O
description O O
is O O
a O O
little O O
sketchy O O
, O O
it O O
should O O
be O O
enough O O
to O O
enable O O
a O O
motivated O O
stu- O O
dent O O
to O O
implement O O
this O O
algorithm B B
( O O
exercise O O
3.14 O O
) O O
. O O
in O O
ieee O O
computer O O
society O O
conference O O
on O O
computer O O
vision O O
and O O
pattern O O
recognition B B
( O O
cvpr O O
’ O O
97 O O
) O O
, O O
pp O O
. O O
re- O O
call O O
from O O
equation B B
( O O
9.26 O O
) O O
that O O
the O O
3d O O
to O O
2d O O
projection O O
is O O
given O O
by O O
˜xik O O
∼ O O
kkrkxi O O
. O O
combinatorial O O
preconditioners O O
and O O
mul- O O
tilevel O O
solvers O O
for O O
problems O O
in O O
computer O O
vision O O
and O O
image B B
processing O O
. O O
finemediumcoarsel= O O
0l= O O
1l= O O
2 O O
152 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
( O O
a O O
) O O
( O O
b O O
) O O
figure O O
3.33 O O
the O O
gaussian O O
pyramid B B
shown O O
as O O
a O O
signal O O
processing O O
diagram O O
: O O
the O O
( O O
a O O
) O O
analysis O O
and O O
( O O
b O O
) O O
re-synthesis O O
stages O O
are O O
shown O O
as O O
using O O
similar O O
computations O O
. O O
say O O
we O O
are O O
given O O
two O O
images O O
that O O
overlap O O
to O O
a O O
fair O O
amount O O
( O O
e.g. O O
, O O
for O O
image O O
stitching O O
, O O
as O O
in O O
figure O O
4.16 O O
, O O
or O O
for O O
tracking O O
objects O O
in O O
a O O
video B B
) O O
. O O
in O O
international O O
joint B B
conference O O
on O O
artiﬁcial O O
intelligence O O
( O O
ijcai O O
2001 O O
) O O
. O O
8 O O
dense O O
motion O O
estimation B B
8.1 O O
translational B B
alignment O O
. O O
the O O
ﬁelds O O
of O O
medical B O
image I I
segmentation O O
( O O
mcinerney O O
and O O
terzopoulos O O
1996 O O
) O O
and O O
med- O O
ical O O
image B B
registration I I
( O O
kybic O O
and O O
unser O O
2003 O O
) O O
( O O
section O O
8.3.1 O O
) O O
are O O
rich O O
research O O
ﬁelds O O
with O O
their O O
own O O
specialized O O
conferences O O
, O O
such O O
as O O
medical B B
imaging I I
computing O O
and O O
computer O O
as- O O
sisted O O
intervention O O
( O O
miccai O O
) O O
,11 O O
and O O
journals O O
, O O
such O O
as O O
medical B B
image I I
analysis O O
and O O
ieee O O
transactions O O
on O O
medical B B
imaging I I
. O O
how O O
would O O
you O O
segment O O
this O O
image B B
based O O
on O O
color B B
alone O O
? O O
figure O O
5.16b O O
shows O O
the O O
distribution O O
of O O
pixels O O
in O O
l*u*v* O O
space O O
, O O
which O O
is O O
equivalent O O
to O O
what O O
a O O
vision O O
algorithm B B
that O O
ignores O O
spatial O O
location O O
would O O
see O O
. O O
the O O
development O O
of O O
interactive B B
video O O
tours O O
spurred O O
a O O
renewed O O
interest O O
in O O
360◦ O O
video-based O O
virtual O O
travel O O
and O O
mapping O O
experiences O O
, O O
as O O
evidenced O O
by O O
commercial O O
sites O O
such O O
as O O
google O O
’ O O
s O O
street O O
view O O
and O O
bing O O
maps O O
. O O
( O O
1996 O O
) O O
extends O O
the O O
basic O O
light B O
ﬁeld I I
rendering O O
approach O O
by O O
taking O O
into O O
account O O
the O O
3d O O
location O O
of O O
surface B B
points O O
corresponding O O
to O O
each O O
3d O O
ray O O
. O O
( O O
1999 O O
) O O
provide O O
a O O
good O O
tutorial O O
and O O
survey O O
on O O
bundle B B
adjustment I I
, O O
while O O
lourakis O O
and O O
argyros O O
( O O
2009 O O
) O O
and O O
engels O O
, O O
stew´enius O O
, O O
and O O
nist´er O O
( O O
2006 O O
) O O
provide O O
tips O O
on O O
implementation O O
and O O
effective O O
practices O O
. O O
in O O
ieee O O
computer O O
society O O
conference O O
on O O
com- O O
puter O O
vision O O
and O O
pattern O O
recognition B B
( O O
cvpr O O
2008 O O
) O O
, O O
anchorage O O
, O O
ak O O
. O O
model-based B B
estimation O O
of O O
3d O O
human B O
motion I I
. O O
when O O
multiple B B
estimates O O
of O O
f O O
are O O
available O O
, O O
e.g. O O
, O O
from O O
different O O
homographies O O
, O O
the O O
median B B
value O O
can O O
be O O
used O O
as O O
the O O
ﬁnal O O
estimate O O
. O O
while O O
simulated B B
annealing I I
has O O
largely O O
been O O
superseded O O
by O O
the O O
newer O O
graph B O
cuts I I
and O O
loopy B B
belief I I
propagation I I
techniques O O
, O O
it O O
still O O
occasionally O O
ﬁnds O O
use O O
, O O
especially O O
in O O
highly O O
connected O O
and O O
highly O O
non-submodular O O
graphs O O
( O O
rother O O
, O O
kolmogorov O O
, O O
lempitsky O O
et O O
al O O
. O O
pyramid-based O O
texture B B
analysis/synthesis O O
. O O
motion B B
deblurring O O
and O O
super- O O
resolution O O
from O O
an O O
image B B
sequence O O
. O O
we O O
do O O
not O O
explain O O
the O O
details O O
of O O
the O O
algorithm B B
here O O
, O O
except O O
to O O
say O O
that O O
it O O
involves O O
a O O
series O O
of O O
log2 O O
n O O
stages O O
, O O
where O O
each O O
stage O O
performs O O
small O O
2× O O
2 O O
transforms O O
( O O
matrix O O
multiplications O O
with O O
known O O
coefﬁcients O O
) O O
followed O O
by O O
some O O
semi-global O B
permutations O O
. O O
( O O
recall B B
that O O
these O O
can O O
be O O
obtained O O
from O O
a O O
camera B B
’ O O
s O O
exif O O
tags O O
, O O
but O O
that O O
they O O
actually O O
follow O O
a O O
power O O
of O O
2 O O
progression O O
. O O
) O O
additional O O
secondary O O
rays O O
can O O
then O O
be O O
cast O O
along O O
the O O
specular B B
direction O O
towards O O
other O O
objects O O
in O O
the O O
scene O O
, O O
keeping O O
track O O
of O O
any O O
attenuation O O
or O O
color B B
change O O
that O O
the O O
specular B B
reﬂection O O
induces O O
. O O
large O O
cells O O
are O O
used O O
to O O
present O O
regions O O
of O O
smooth O O
motion B B
, O O
while O O
smaller O O
cells O O
are O O
added O O
in O O
regions O O
of O O
motion B B
discontinuities O O
( O O
figure O O
8.9c O O
) O O
. O O
object O O
recognition B B
and O O
scene B O
understanding I O
. O O
) O O
in O O
some O O
situations O O
, O O
e.g. O O
, O O
when O O
merging B B
range O O
data O O
maps O O
, O O
the O O
correspondence B B
between O O
data O O
points O O
is O O
not O O
known O O
a O O
priori O O
. O O
combined O O
depth O O
and O O
outlier O O
estimation B B
in O O
multi-view B B
stereo I I
. O O
774–781 O O
, O O
hilton O O
head B B
island O O
. O O
this O O
can O O
be O O
modeled O O
either O O
explicitly O O
( O O
making O O
correspondence B B
more O O
difﬁcult O O
) O O
or O O
using O O
telecentric O O
optics B B
, O O
which O O
approximate O O
an O O
orthographic B O
camera O O
and O O
require O O
an O O
aperture O O
in O O
front O O
of O O
the O O
lens O O
( O O
nayar O O
, O O
watanabe O O
, O O
and O O
noguchi O O
1996 O O
) O O
. O O
the O O
resulting O O
system O O
( O O
see O O
figure O O
4.33 O O
for O O
some O O
examples B B
) O O
is O O
shown O O
to O O
outperform O O
previously O O
developed O O
techniques O O
. O O
2008 O O
) O O
or O O
even O O
pre-segment O O
the O O
image B B
into O O
a O O
small O O
number O O
of O O
mattes O O
that O O
the O O
user O O
can O O
select O O
with O O
simple O O
clicks O O
( O O
levin O O
, O O
acha O O
, O O
and O O
lischinski O O
2008 O O
) O O
. O O
fast O O
image O O
and O O
video B B
colorization O I
using O O
chrominance O O
blending B O
. O O
in O O
ieee O O
com- O O
puter O O
society O O
conference O O
on O O
computer O O
vision O O
and O O
pattern O O
recognition B B
( O O
cvpr O O
2008 O O
) O O
, O O
anchorage O O
, O O
ak O O
. O O
the O O
moment O O
camera B O
. O O
these O O
are O O
attenuated O O
( O O
compressed O O
) O O
based O O
on O O
local B B
contrast O O
, O O
g O O
( O O
x O O
) O O
, O O
and O O
integrated O O
to O O
produce O O
the O O
new O O
logarithmic O O
exposure O O
image O O
i O O
( O O
x O O
) O O
, O O
which O O
is O O
exponentiated O O
to O O
produce O O
the O O
ﬁnal O O
intensity O O
image B B
, O O
whose O O
dynamic B B
range O O
is O O
7.5:1. O O
to O O
obtain O O
the O O
compressed O O
log-luminance O O
image B B
i O O
( O O
x O O
, O O
y O O
) O O
. O O
given O O
a O O
template O O
image B O
i0 O O
( O O
x O O
) O O
sampled O O
at O O
discrete B B
pixel O O
locations O O
{ O O
xi O O
= O O
( O O
xi O O
, O O
yi O O
) O O
} O O
, O O
we O O
wish O O
to O O
ﬁnd O O
where O O
it O O
is O O
located O O
in O O
image B B
i1 O O
( O O
x O O
) O O
. O O
n^zi=102mmf= O O
100mmzo=5mdgrgrbgbggrgrbgbg O O
2.1 O O
geometric B B
primitives O O
and O O
transformations O O
31 O O
before O O
we O O
can O O
intelligently O O
analyze O O
and O O
manipulate O O
images O O
, O O
we O O
need O O
to O O
establish O O
a O O
vocabulary O B
for O O
describing O O
the O O
geometry O O
of O O
a O O
scene O O
. O O
furthermore O O
, O O
because O O
our O O
model O O
is O O
probabilistic B B
, O O
it O O
is O O
possible O O
to O O
estimate O O
( O O
in O O
principle O O
) O O
complete O O
probability O O
distributions O O
over O O
the O O
unknowns O O
being O O
recovered O O
and O O
, O O
in O O
particular O O
, O O
to O O
model O O
the O O
uncertainty B B
in O O
the O O
solution O O
, O O
which O O
can O O
be O O
useful O O
in O O
latter O O
processing O O
stages O O
. O O
in O O
ieee O O
computer O O
society O O
confer- O O
ence O O
on O O
computer O O
vision O O
and O O
pattern O O
recognition B B
( O O
cvpr O O
2008 O O
) O O
, O O
anchorage O O
, O O
ak O O
. O O
fully O O
automated B B
( O O
sparse B B
) O O
3d O O
modeling B B
systems O O
were O O
built O O
using O O
such O O
techniques O O
( O O
beardsley O O
, O O
torr O O
, O O
and O O
zisserman O O
1996 O O
; O O
schaffalitzky O O
and O O
zisserman O O
2002 O O
; O O
brown O O
and O O
lowe O O
2003 O O
; O O
snavely O O
, O O
seitz O O
, O O
and O O
szeliski O O
2006 O O
) O O
. O O
this O O
latter O O
work O O
also O O
argues O O
that O O
blending B B
in O O
the O O
log O O
domain O O
, O O
i.e. O O
, O O
using O O
multiplicative O O
rather O O
than O O
additive O O
offsets O O
, O O
is O O
preferable O O
, O O
as O O
it O O
more O O
closely O O
matches O O
texture B B
contrasts O O
across O O
seam O O
boundaries O O
. O O
2009 O O
) O O
are O O
classiﬁed O O
as O O
using O O
geometric O O
visibility B O
models O O
in O O
the O O
taxonomy B B
of O O
seitz O O
, O O
curless O O
, O O
diebel O O
et O O
al O O
. O O
2d O O
and O O
3d O O
feature-based B B
alignment O O
. O O
( O O
1999 O O
) O O
, O O
this O O
indirect O O
component O O
ii O O
is O O
modeled O O
as O O
ii O O
= O O
ri O O
( O O
cid:90 O O
) O O
ai O O
( O O
x O O
) O O
b O O
( O O
x O O
) O O
dx O O
, O O
where O O
ai O O
is O O
the O O
rectangular O O
area O O
of O O
support O O
for O O
that O O
pixel O O
, O O
ri O O
is O O
the O O
colored O O
reﬂectance B O
or O O
( O O
13.1 O O
) O O
( O O
13.2 O O
) O O
636 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
transmittance O O
( O O
for O O
colored O O
glossy O O
surfaces O O
or O O
glass O O
) O O
, O O
and O O
b O O
( O O
x O O
) O O
is O O
the O O
background O O
( O O
environ- O O
ment O O
) O O
image B B
, O O
which O O
is O O
integrated O O
over O O
the O O
area O O
ai O O
( O O
x O O
) O O
. O O
the O O
topics O O
we O O
cover O O
include O O
video-based O O
animation O O
( O O
section O O
13.5.1 O O
) O O
, O O
periodic O O
video B B
turned O O
into O O
video B B
textures I I
( O O
section O O
13.5.2 O O
) O O
, O O
and O O
3d O O
video B B
constructed O O
from O O
multiple B B
video O O
streams O O
( O O
section O O
13.5.4 O O
) O O
. O O
while O O
some O O
may O O
consider O O
image B B
processing O O
to O O
be O O
outside O O
the O O
purview O O
of O O
computer O O
vision O O
, O O
most O O
computer O O
vision O O
applications O O
, O O
such O O
as O O
computational O O
photography O O
and O O
even O O
recognition B I
, O O
require O O
care O O
in O O
designing O O
the O O
image B B
processing O O
stages O O
in O O
order B B
to O O
achieve O O
acceptable O O
results O O
. O O
the O O
manufacturer O O
is O O
free O O
to O O
use O O
sensors O O
with O O
sensitivities O O
that O O
do O O
not O O
match O O
the O O
standard O O
xyz O O
deﬁnitions O O
, O O
so O O
long O O
as O O
they O O
can O O
later O O
be O O
converted O O
( O O
through O O
a O O
linear B B
transform O O
) O O
to O O
the O O
standard O O
colors O O
. O O
in O O
this O O
case O O
, O O
( O O
b.13 O O
) O O
becomes O O
e O O
= O O
( O O
cid:88 O O
) O O
i O O
= O O
( O O
cid:88 O O
) O O
i O O
( O O
cid:107 O O
) O O
˜yi O O
− O O
h O O
ix O O
( O O
cid:107 O O
) O O
σ−1 O O
i O O
( O O
˜yi O O
− O O
h O O
ix O O
) O O
t O O
ci O O
( O O
˜yi O O
− O O
h O O
ix O O
) O O
, O O
( O O
b.16 O O
) O O
which O O
is O O
a O O
simple O O
quadratic O O
form O O
in O O
x O O
, O O
which O O
can O O
be O O
solved O O
using O O
linear O O
least B O
squares I O
( O O
ap- O O
pendix O O
a.2 O O
) O O
. O O
face B B
authentication O O
for O O
multiple O O
subjects O O
using O O
eigenﬂow O O
. O O
15 O O
conclusion O O
733 O O
more O O
traditional O O
quantitative O O
techniques O O
in O O
computer O O
vision O O
such O O
as O O
motion B B
estimation I I
, O O
stereo B B
correspondence O O
, O O
and O O
image B B
enhancement O O
, O O
all O O
beneﬁt O O
from O O
better O O
prior B B
models O O
for O O
im- O O
ages O O
, O O
motions O O
, O O
and O O
disparities O O
, O O
as O O
well O O
as O O
efﬁcient O O
statistical O O
inference B B
techniques O O
such O O
as O O
those O O
for O O
inhomogeneous O O
and O O
higher-order O O
markov O O
random O O
ﬁelds O O
. O O
figure O O
4.14 O O
shows O O
how O O
the O O
square B O
root I O
of O O
the O O
moment O O
matrix O O
can O O
be O O
used O O
to O O
transform B B
local O O
patches O O
into O O
a O O
frame O B
which O O
is O O
similar O O
up O O
to O O
rotation O O
. O O
siftgpu O O
: O O
a O O
gpu O O
implementation O O
of O O
scale O O
invariant O O
feature B B
transform O O
( O O
sift O O
) O O
. O O
425– O O
lumigraph O O
rendering B B
. O O
for O O
larger O O
amounts O O
of O O
noise B B
, O O
the O O
linearization O O
performed O O
by O O
the O O
lucas–kanade O O
algorithm B O
in O O
( O O
8.35 O O
) O O
is O O
only O O
approximate O O
, O O
so O O
the O O
above O O
quantity O O
becomes O O
a O O
cramer–rao O O
lower O O
bound O O
on O O
the O O
true O O
covariance O O
. O O
( O O
2008 O O
) O O
for O O
examples O O
of O O
fully O O
automated B B
driving O O
) O O
; O O
• O O
match B B
move I I
: O O
merging B B
computer-generated O O
imagery O O
( O O
cgi O O
) O O
with O O
live O O
action O O
footage O O
by O O
tracking O O
feature B B
points O O
in O O
the O O
source O O
video B B
to O O
estimate O O
the O O
3d O O
camera B B
motion O O
and O O
shape O O
of O O
the O O
environment O O
. O O
10.2 O O
high B O
dynamic I I
range I I
imaging O O
495 O O
( O O
a O O
) O O
( O O
b O O
) O O
figure O O
10.28 O O
interactive B B
local O O
tone B O
mapping I O
( O O
lischinski O O
, O O
farbman O O
, O O
uyttendaele O O
et O O
al O O
. O O
a O O
qualitative O O
approach O O
to O O
understanding O O
intensities O O
and O O
shading B B
variations O O
and O O
explaining O O
them O O
by O O
the O O
effects O O
of O O
image B B
formation O O
phenomena O O
, O O
such O O
as O O
surface B B
orientation O O
and O O
shadows O O
, O O
was O O
championed O O
by O O
barrow O O
and O O
tenenbaum O O
( O O
1981 O O
) O O
in O O
their O O
paper O O
on O O
intrinsic B B
images O O
( O O
fig- O O
ure O O
1.7d O O
) O O
, O O
along O O
with O O
the O O
related O O
2 O O
1/2 O O
-d O O
sketch O O
ideas O O
of O O
marr O O
( O O
1982 O O
) O O
. O O
m2 O O
tracker O O
: O O
a O O
multi-view B O
approach O O
to O O
segmenting O O
international O O
journal O O
of O O
computer O O
vision O O
, O O
miˇcuˇs´ık O O
, O O
b. O O
and O O
koˇseck´a O O
, O O
j O O
. O O
note O O
that O O
incomplete B O
factorization O B
can O O
also O O
beneﬁt O O
from O O
reordering O O
. O O
intersections O O
of O O
planes B B
are O O
used O O
to O O
determine O O
the O O
extent O O
of O O
each O O
plane O O
, O O
i.e. O O
, O O
an O O
initial O O
coarse O O
ge- O O
ometry O O
, O O
which O O
is O O
then O O
reﬁned O O
with O O
the O O
addition O O
of O O
rectangular O O
or O O
wedge-shaped O O
indentations O O
and O O
extrusions O O
( O O
figure O O
12.16c O O
) O O
. O O
the O O
system O O
computes O O
color B B
distributions O O
for O O
the O O
foreground O O
and O O
background O O
and O O
solves O O
a O O
binary O O
mrf O O
. O O
we O O
continue O O
our O O
exploration O O
of O O
image-based B B
rendering I I
with O O
the O O
light B O
ﬁeld I I
and O O
lumigraph O O
four-dimensional O O
representations O O
of O O
a O O
scene O O
’ O O
s O O
appearance O O
( O O
section O O
13.3 O O
) O O
, O O
which O O
can O O
be O O
used O O
to O O
render O O
the O O
scene O O
from O O
any O O
arbitrary O O
viewpoint O O
. O O
unlike O O
single O O
image O O
denoising O O
, O O
where O O
the O O
only O O
information O O
available O O
is O O
in O O
the O O
current O O
picture O O
, O O
video B B
denoisers O O
can O O
average O O
or O O
borrow O O
information O O
from O O
adjacent O O
frames O O
. O O
re- O O
cently O O
, O O
the O O
development O O
of O O
reliable O O
image-based B B
modeling O O
techniques O O
, O O
as O O
well O O
as O O
the O O
preva- O O
lence O O
of O O
digital O O
cameras O O
and O O
3d O O
computer O O
games O O
, O O
has O O
spurred O O
renewed O O
interest O O
in O O
this O O
area O O
. O O
essentially O O
, O O
for O O
the O O
cost O O
of O O
an O O
o O O
( O O
n O O
) O O
pre-computation O O
phase O O
( O O
where O O
n O O
is O O
the O O
number O O
of O O
pixels O O
in O O
the O O
image B B
) O O
, O O
subsequent O O
differences O O
of O O
rectangles O O
can O O
be O O
computed O O
in O O
4r O O
additions O O
or O O
subtractions O O
, O O
where O O
r O O
∈ O O
{ O O
2 O O
, O O
3 O O
, O O
4 O O
} O O
is O O
the O O
number O O
of O O
rectangles O O
in O O
the O O
feature B B
. O O
the O O
basic O O
ray O O
tracing O O
algorithm B B
associates O O
a O O
light O O
ray O O
with O O
each O O
pixel O O
in O O
the O O
camera B B
im- O O
age O O
and O O
ﬁnds O O
its O O
intersection O O
with O O
the O O
nearest O B
surface O O
. O O
poisson O O
surface B B
reconstruction I I
( O O
kazhdan O O
, O O
bolitho O O
, O O
and O O
hoppe O O
2006 O O
) O O
uses O O
a O O
closely O O
related O O
volumetric B B
function O O
, O O
namely O O
a O O
smoothed O O
0/1 O O
inside–outside O O
( O O
characteristic O O
) O O
function O O
, O O
which O O
can O O
be O O
thought O O
of O O
as O O
a O O
clipped O O
signed B O
distance O O
function O O
. O O
finally O O
, O O
we O O
describe O O
how O O
3d O O
lines B B
with O O
common O O
vanishing B B
points I I
can O O
be O O
grouped O O
together O O
. O O
in O O
seventh O O
international O O
conference O O
on O O
pattern O O
recognition B B
( O O
icpr O O
’ O O
84 O O
) O O
, O O
pp O O
. O O
unit O O
quaternions B B
the O O
unit O O
quaternion O O
representation O O
is O O
closely O O
related O O
to O O
the O O
angle/axis O O
representation O O
. O O
hence O O
, O O
the O O
light B O
ﬁeld I I
“ O O
collapses O O
” O O
to O O
the O O
usual O O
2d O O
texture-map O O
deﬁned O O
over O O
an O O
object O O
’ O O
s O O
surface B B
. O O
evaluation B O
of O O
stereo B B
matching I I
costs O O
on O O
im- O O
ages O O
with O O
radiometric O O
differences O O
. O O
when O O
the O O
motion B B
in O O
the O O
scene O O
is O O
very O O
large O O
, O O
i.e. O O
, O O
when O O
objects O O
appear O O
and O O
disappear O O
com- O O
pletely O O
, O O
a O O
sensible O O
solution O O
is O O
to O O
simply O O
select O O
pixels O O
from O O
only O O
one O O
image B B
at O O
a O O
time O O
as O O
the O O
source O O
for O O
the O O
ﬁnal O O
composite O O
( O O
milgram O O
1977 O O
; O O
davis O O
1998 O O
; O O
agarwala O O
, O O
dontcheva O O
, O O
agrawala O O
446 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
et O O
al O O
. O O
the O O
general O O
version O O
of O O
this O O
problem O O
requires O O
the O O
estimation B B
of O O
the O O
full O O
3d O O
camera B B
pose O O
along O O
with O O
the O O
focal O O
length O O
( O O
zoom O O
) O O
of O O
the O O
lens O O
and O O
potentially O O
its O O
radial B B
distortion I I
parameters O O
( O O
roble O O
1999 O O
) O O
. O O
the O O
basic O O
problem O O
in O O
creating O O
video B B
textures I I
is O O
how O O
to O O
perform O O
this O O
re-arrangement O O
without O O
introducing O O
visual O O
artifacts O O
. O O
we O O
then O O
describe O O
the O O
hough O O
transform B B
, O O
which O O
can O O
be O O
used O O
to O O
group O O
edgels O O
into O O
line O O
segments O O
even O O
across O O
gaps O O
and O O
occlusions O O
. O O
finally O O
, O O
some O O
of O O
the O O
most O O
recent O O
work O O
in O O
scene B O
understanding I O
exploits O O
the O O
existence O O
of O O
large O O
numbers O O
of O O
labeled O O
( O O
or O O
even O O
unlabeled O O
) O O
images O O
to O O
perform O O
matching B B
directly O O
against O O
whole O O
images O O
, O O
where O O
the O O
images O O
themselves O O
implicitly O O
encode O O
the O O
expected O O
relationships O O
between O O
objects O O
( O O
figure O O
14.51 O O
) O O
( O O
russell O O
, O O
torralba O O
, O O
liu O O
et O O
al O O
. O O
3d O O
alignment B B
. O O
a O O
compact O O
algorithm B B
for O O
rectiﬁcation B B
of O O
stereo B B
pairs O O
. O O
write O O
down O O
the O O
equations B B
for O O
the O O
roc O O
, O O
i.e. O O
, O O
tpr O O
( O O
fpr O O
) O O
, O O
and O O
the O O
auc O O
. O O
generalized B O
principal O O
component O O
analysis O O
. O O
( O O
2000 O O
) O O
suggest O O
matching B B
triplets O O
or O O
larger O O
neighborhoods O O
of O O
adjacent O O
video B B
frames O O
, O O
much O O
in O O
the O O
same O O
way O O
as O O
video B B
rewrite O O
matches O O
triphones O O
. O O
the O O
1/2.5 O O
” O O
sensor B B
on O O
the O O
canon O O
sd800 O O
cam- O O
era O O
actually O O
measures O O
5.76mm O O
× O O
4.29mm O O
, O O
i.e. O O
, O O
a O O
sixth O O
of O O
the O O
size O O
( O O
on O O
side O O
) O O
of O O
a O O
35mm O O
full-frame O O
( O O
36mm O O
× O O
24mm O O
) O O
dslr O O
sensor B B
. O O
rg1 O O
= O O
arg O O
min O O
( O O
rt O O
rk0 O O
) O O
2 O O
= O O
arg O O
min O O
r O O
r O O
( O O
cid:88 O O
) O O
k O O
rt O O
( O O
cid:34 O O
) O O
( O O
cid:88 O O
) O O
k O O
rk0rt O O
k0 O O
( O O
cid:35 O O
) O O
r. O O
( O O
9.34 O O
) O O
9.2 O O
global B B
alignment I O
445 O O
t O O
ˆk O O
rk O O
to O O
be O O
close O O
to O O
the O O
world O O
z-axis O O
, O O
rg2 O O
= O O
rgˆk O O
. O O
they O O
are O O
often O O
used O O
to O O
perform O O
high-accuracy O O
low-pass B B
ﬁltering O O
operations O O
. O O
feature B B
detectors O O
. O O
5.1.4 O O
level B B
sets I I
. O O
to O O
further O O
increase O O
the O O
efﬁciency B B
of O O
the O O
infer- O O
ence O O
algorithm B B
, O O
felzenszwalb O O
and O O
huttenlocher O O
( O O
2005 O O
) O O
restrict O O
the O O
pairwise O O
energy O O
functions O O
vij O O
( O O
li O O
, O O
lj O O
) O O
to O O
be O O
mahalanobis O O
distances O O
on O O
functions O O
of O O
location O O
variables O O
and O O
then O O
use O O
fast O O
distance O O
transform B B
algorithms O O
to O O
minimize O O
each O O
pairwise O O
interaction O O
in O O
time O O
that O O
is O O
closer O O
to O O
linear B B
in O O
n. O O
figure O O
14.40 O O
shows O O
the O O
results O O
of O O
using O O
their O O
pictorial O O
structures O O
algorithm B B
to O O
ﬁt O O
an O O
articu- O O
14.4 O O
category O O
recognition O O
703 O O
( O O
a O O
) O O
( O O
b O O
) O O
( O O
c O O
) O O
( O O
d O O
) O O
( O O
e O O
) O O
( O O
f O O
) O O
( O O
g O O
) O O
figure O O
14.41 O O
graphical O O
models O O
for O O
geometric O O
spatial O O
priors O O
( O O
carneiro O O
and O O
lowe O O
2006 O O
) O O
c O O
( O O
cid:13 O O
) O O
2006 O O
springer O O
: O O
( O O
a O O
) O O
constellation O O
( O O
fergus O O
, O O
perona O O
, O O
and O O
zisserman O O
2007 O O
) O O
; O O
( O O
b O O
) O O
star O O
( O O
crandall O O
, O O
felzenszwalb O O
, O O
and O O
huttenlocher O O
2005 O O
; O O
fergus O O
, O O
perona O O
, O O
and O O
zisserman O O
2005 O O
) O O
; O O
( O O
c O O
) O O
k-fan O O
( O O
k O O
= O O
2 O O
) O O
( O O
crandall O O
, O O
felzenszwalb O O
, O O
and O O
huttenlocher O O
2005 O O
) O O
; O O
( O O
d O O
) O O
tree O O
( O O
felzenszwalb O O
and O O
huttenlocher O O
2005 O O
) O O
; O O
( O O
e O O
) O O
bag O O
of O O
features O O
( O O
csurka O O
, O O
dance O O
, O O
fan O O
et O O
al O O
. O O
( O O
2.87 O O
) O O
( O O
2.88 O O
) O O
the O O
second O O
major O O
component O O
of O O
a O O
typical O O
brdf O O
is O O
specular B B
( O O
gloss O O
or O O
highlight O O
) O O
reﬂection O O
, O O
which O O
depends O O
strongly O O
on O O
the O O
direction O O
of O O
the O O
outgoing O O
light O O
. O O
3. O O
compensate O O
for O O
the O O
high-frequency O O
motion B B
, O O
zooming O O
in O O
slightly O O
( O O
a O O
user-speciﬁed O O
amount O O
) O O
to O O
avoid O O
missing O O
edge O O
pixels O O
. O O
the O O
other O O
major O O
reason O O
why O O
this O O
book O O
has O O
a O O
strong O O
focus B B
on O O
applications O O
is O O
that O O
they O O
can O O
be O O
used O O
to O O
formulate O O
and O O
constrain O O
the O O
potentially O O
open-ended O O
problems O O
endemic O O
in O O
vision O O
. O O
1996 O O
) O O
.20 O O
in O O
some O O
cases O O
, O O
e.g. O O
, O O
if O O
a O O
dense O O
depth O O
map O O
has O O
been O O
estimated O O
for O O
an O O
image B B
( O O
shade O O
, O O
gortler O O
, O O
he O O
et O O
al O O
. O O
the O O
resulting O O
projection O O
equations B B
can O O
be O O
written O O
as O O
y O O
( O O
1 O O
) O O
= O O
f O O
t O O
( O O
pi O O
; O O
cj O O
) O O
= O O
pi O O
− O O
cj O O
, O O
y O O
( O O
2 O O
) O O
= O O
f O O
r O O
( O O
y O O
( O O
1 O O
) O O
; O O
qj O O
) O O
= O O
r O O
( O O
qj O O
) O O
y O O
( O O
1 O O
) O O
, O O
y O O
( O O
3 O O
) O O
= O O
f O O
p O O
( O O
y O O
( O O
2 O O
) O O
) O O
= O O
y O O
( O O
2 O O
) O O
z O O
( O O
2 O O
) O O
, O O
xi O O
= O O
f O O
c O O
( O O
y O O
( O O
3 O O
) O O
; O O
k O O
) O O
= O O
k O O
( O O
k O O
) O O
y O O
( O O
3 O O
) O O
. O O
13.5.2 O O
video B B
textures I I
video-based O O
animation O O
is O O
a O O
powerful O O
means O O
of O O
creating O O
photo-realistic O O
videos O O
by O O
re-purposing O O
existing O O
video B B
footage O O
to O O
match O O
some O O
other O O
desired O O
activity O B
or O O
script O O
. O O
the O O
above O O
image B B
formation O O
equations B B
lead O O
to O O
the O O
following O O
least B B
squares I I
problem O O
, O O
( O O
cid:107 O O
) O O
ok O O
( O O
x O O
) O O
− O O
d O O
{ O O
bk O O
( O O
x O O
) O O
∗ O O
s O O
( O O
ˆhk O O
( O O
x O O
) O O
) O O
} O O
( O O
cid:107 O O
) O O
2 O O
. O O
figure O O
14.24 O O
head B O
tracking I O
with O O
3d O O
aams O O
( O O
matthews O O
, O O
xiao O O
, O O
and O O
baker O O
2007 O O
) O O
c O O
( O O
cid:13 O O
) O O
2007 O O
springer O O
. O O
for O O
image O O
compositing B O
, O O
smith O O
and O O
blinn O O
( O O
1996 O O
) O O
were O O
the O O
ﬁrst O O
to O O
bring O O
this O O
topic O O
to O O
the O O
attention O O
of O O
the O O
graphics O O
community O O
, O O
while O O
wang O O
and O O
cohen O O
( O O
2007a O O
) O O
provide O O
a O O
recent O O
in-depth O O
survey O O
. O O
a O O
slightly O O
more O O
complex O O
scenario O O
is O O
when O O
you O O
take O O
multiple B B
overlapping O O
handheld O O
pic- O O
tures O O
of O O
a O O
whiteboard O B
or O O
other O O
large O O
planar O O
object O O
( O O
he O O
and O O
zhang O O
2005 O O
; O O
zhang O O
and O O
he O O
2007 O O
) O O
. O O
( O O
optional O O
) O O
limit O O
the O O
local B B
gain O O
f O O
( O O
cid:48 O O
) O O
( O O
i O O
) O O
in O O
the O O
transfer B B
function O O
. O O
7.2.3 O O
application O O
: O O
view B B
morphing I I
. O O
kernelized O O
locality-sensitive O O
hashing B B
for O O
scalable O O
image B B
search I O
. O O
as O O
in O O
the O O
work O O
of O O
rowland O O
and O O
perrett O O
( O O
1995 O O
) O O
, O O
faces B B
can O O
be O O
turned O O
into O O
caricatures O O
by O O
exaggerating O O
their O O
displacement O O
from O O
the O O
mean O O
image O O
. O O
to- O O
day O O
, O O
some O O
recognition B B
algorithms O O
use O O
databases O O
such O O
as O O
labelme O O
( O O
russell O O
, O O
torralba O O
, O O
murphy O O
et O O
al O O
. O O
13.6 O O
additional O O
reading O O
649 O O
early O O
work O O
on O O
planar O B
impostors O O
and O O
layers B B
was O O
carried O O
out O O
by O O
shade O O
, O O
lischinski O O
, O O
salesin O O
et O O
al O O
. O O
) O O
however O O
, O O
the O O
computational O O
complexity O O
of O O
each O O
linearized O O
gauss–newton O O
step O O
can O O
be O O
reduced O O
using O O
sparse B O
matrix O O
techniques O O
( O O
section O O
7.4.1 O O
) O O
( O O
szeliski O O
and O O
kang O O
1994 O O
; O O
triggs O O
, O O
mclauchlan O O
, O O
hartley O O
et O O
al O O
. O O
references B B
811 O O
chiu O O
, O O
k. O O
and O O
raskar O O
, O O
r. O O
( O O
2009 O O
) O O
. O O
use O O
a O O
pair O O
of O O
cameras O O
to O O
compare O O
the O O
accuracy B O
of O O
your O O
shape O O
from O O
focus B B
and O O
shape O O
from O O
stereo B B
techniques O O
. O O
one O O
of O O
the O O
easiest O O
ways O O
to O O
do O O
this O O
is O O
to O O
assign O O
a O O
unique O O
color B B
to O O
each O O
integer O O
label O O
. O O
9.2.3 O O
recognizing B O
panoramas I I
the O O
ﬁnal O O
piece O O
needed O O
to O O
perform O O
fully O O
automated B B
image O O
stitching O O
is O O
a O O
technique O O
to O O
recognize O O
which O O
images O O
actually O O
go O O
together O O
, O O
which O O
brown O O
and O O
lowe O O
( O O
2007 O O
) O O
call O O
recognizing O O
panora- O O
9.2 O O
global B B
alignment I O
447 O O
( O O
a O O
) O O
( O O
b O O
) O O
( O O
c O O
) O O
figure O O
9.10 O O
deghosting O O
a O O
mosaic O O
with O O
motion O O
parallax O O
( O O
shum O O
and O O
szeliski O O
2000 O O
) O O
c O O
( O O
cid:13 O O
) O O
2000 O O
ieee O O
: O O
( O O
a O O
) O O
composite O O
with O O
parallax O O
; O O
( O O
b O O
) O O
after O O
a O O
single O O
deghosting O O
step O O
( O O
patch B O
size O O
32 O B
) O O
; O O
( O O
c O O
) O O
after O O
multiple B B
steps O O
( O O
sizes O O
32 O O
, O O
16 O O
and O O
8 O O
) O O
. O O
while O O
optimizing O O
the O O
binary O O
mrf O O
energy O O
( O O
5.50 O O
) O O
requires O O
the O O
use O O
of O O
combinatorial O O
op- O B
timization O O
techniques O O
, O O
such O O
as O O
maximum O O
ﬂow O O
, O O
an O O
approximate O O
solution O O
can O O
be O O
obtained O O
by O O
converting O O
the O O
binary O O
energy O O
terms O O
into O O
quadratic O O
energy O O
terms O O
deﬁned O O
over O O
a O O
continuous O O
[ O O
0 O O
, O O
1 O O
] O O
random O O
ﬁeld O O
, O O
which O O
then O O
becomes O O
a O O
classical O O
membrane-based O O
regularization B B
problem O O
( O O
3.100–3.102 O O
) O O
. O O
( O O
a.34 O O
) O O
note O O
that O O
the O O
upper O O
triangular O O
matrices O O
r O O
produced O O
by O O
the O O
cholesky O O
factorization B B
of O O
c O O
= O O
at O O
a O O
and O O
the O O
qr O O
factorization B B
of O O
a O O
are O O
the O O
same O O
, O O
but O O
that O O
solving O O
( O O
a.34 O O
) O O
is O O
generally O O
more O O
stable O O
( O O
less O O
sensitive O O
to O O
roundoff O O
error O O
) O O
but O O
slower O O
( O O
by O O
a O O
constant O O
factor O O
) O O
. O O
real-time O O
edge-aware O O
image B B
processing O O
with O O
the O O
bilateral B B
grid O O
. O O
we O O
discuss O O
such O O
techniques O O
in O O
the O O
next O O
section O O
, O O
where O O
we O O
look O O
at O O
the O O
inﬂuence O O
that O O
large O O
image O O
databases O O
have O O
had O O
on O O
object O O
recognition B B
and O O
scene B O
understanding I O
. O O
such O O
constraints O O
can O O
be O O
incorporated O O
into O O
a O O
non-linear B B
minimization O O
of O O
the O O
parameters B B
in O O
k O O
and O O
( O O
r O O
, O O
t O O
) O O
, O O
as O O
described O O
in O O
section O O
6.2.2. O O
in O O
the O O
case O O
where O O
the O O
camera B B
is O O
already O O
calibrated O O
, O O
i.e. O O
, O O
the O O
matrix O O
k O O
is O O
known O O
( O O
sec- O O
tion B B
6.3 O O
) O O
, O O
we O O
can O O
perform O O
pose O O
estimation B B
using O O
as O O
few O O
as O O
three O O
points B B
( O O
fischler O O
and O O
bolles O O
1981 O O
; O O
haralick O O
, O O
lee O O
, O O
ottenberg O O
et O O
al O O
. O O
starting O O
with O O
a O O
video B B
sequence O O
, O O
each O O
pixel O O
is O O
modeled O O
as O O
a O O
linear B B
combination O O
of O O
its O O
( O O
unknown O O
) O O
background O O
color O O
and O O
a O O
constant O O
foreground O O
( O O
smoke B O
) O O
color B B
that O O
is O O
common O O
to O O
all O O
pixels O O
. O O
modeling B B
multiscale O O
subbands O O
of O O
photographic O O
images O O
ieee O O
transactions O O
on O O
pattern O O
analysis O O
and O O
with O O
ﬁelds O O
of O O
gaussian O O
scale O O
mixtures O O
. O O
wolberg O O
( O O
1990 O O
) O O
and O O
oppenheim O O
, O O
schafer O O
, O O
and O O
buck O O
( O O
1999 O O
) O O
discuss O O
additional O O
windowing O O
functions O O
, O O
which O O
include O O
the O O
lanczos O O
window O O
, O O
the O O
positive O O
ﬁrst O O
lobe O O
of O O
a O O
sinc B O
function O O
. O O
morphological O O
image B B
compositing O O
. O O
examples B O
of O O
such O O
ﬁelds O O
include O O
1-bit O O
( O O
black O O
and O O
white O O
) O O
scanned O O
document O O
images O O
as O O
well O O
as O O
images O O
segmented O O
into O O
foreground O O
and O O
background O O
regions O O
. O O
temporal O O
texture B B
modeling O O
. O O
the O O
resulting O O
set O O
of O O
images O O
can O O
be O O
thought O O
of O O
as O O
a O O
concentric B O
mosaic I O
( O O
shum O O
and O O
he O O
1999 O O
; O O
shum O O
, O O
wang O O
, O O
chai O O
et O O
al O O
. O O
alternative O O
multi-view B B
cost O O
metrics O O
include O O
measures O O
such O O
as O O
synthetic O O
focus B B
sharpness O O
and O O
the O O
entropy O O
of O O
the O O
pixel O O
color O O
distribution O O
( O O
vaish O O
, O O
szeliski O O
, O O
zitnick O O
et O O
al O O
. O O
figure O O
2.19 O O
shows O O
a O O
diagram O O
of O O
the O O
most O O
basic O O
lens O O
model O O
, O O
i.e. O O
, O O
the O O
thin B O
lens O O
composed O O
of O O
a O O
single O O
piece O O
of O O
glass O O
with O O
very O O
low O O
, O O
equal O O
curvature O O
on O O
both O O
sides O O
. O O
) O O
we O O
are O O
also O O
using O O
the O O
camera B B
center O O
cj O O
instead O O
of O O
the O O
world O O
translation B B
tj O O
, O O
since O O
this O O
is O O
a O O
more O O
natural B B
parameter O O
to O O
estimate O O
. O O
interactive B B
motion O O
generation O O
from O O
examples B B
. O O
in O O
their O O
paper O O
on O O
full-frame O O
video B B
stabilization I O
, O O
matsushita O O
, O O
ofek O O
, O O
ge O O
et O O
al O O
. O O
in O O
the O O
case O O
of O O
stereo B B
matching I I
, O O
however O O
, O O
we O O
have O O
some O O
additional O O
information O O
available O O
, O O
namely O O
the O O
positions O O
and O O
calibration B B
data O O
for O O
the O O
cameras O O
that O O
took O O
the O O
pictures O O
of O O
the O O
same O O
static O O
scene O O
( O O
section O O
7.2 O O
) O O
. O O
( O O
2.11 O O
) O O
zxλpqyr= O O
( O O
1-λ O O
) O O
p+λq O O
2.1 O O
geometric B B
primitives O O
and O O
transformations O O
35 O O
a O O
disadvantage O O
of O O
the O O
endpoint O O
representation O O
for O O
3d O O
lines B B
is O O
that O O
it O O
has O O
too O O
many O O
degrees O O
of O O
freedom O O
, O O
i.e. O O
, O O
six O O
( O O
three O O
for O O
each O O
endpoint O O
) O O
instead O O
of O O
the O O
four O O
degrees O O
that O O
a O O
3d O O
line O O
truly O O
has O O
. O O
self-calibration B B
of O O
rotating O O
and O O
zooming O O
cameras O O
. O O
implement O O
a O O
line O O
simpliﬁcation O O
algorithm B B
( O O
optional O O
) O O
re-render O O
this O O
curve O O
using O O
either O O
an O O
approximating O O
or O O
interpolating O O
spline B B
or O O
bezier O O
curve O O
( O O
szeliski O O
and O O
ito O O
1986 O O
; O O
bartels O O
, O O
beatty O O
, O O
and O O
barsky O O
1987 O O
; O O
farin O O
1996 O O
) O O
. O O
this O O
can O O
also O O
be O O
re-written O O
as O O
x1 O O
y1 O O
1 O O
 O O
 O O
∼ O O
f1 O O
f1 O O
f−1 O O
0 O O
f−1 O O
0 O O
1 O O
 O O
 O O
x0 O O
y0 O O
1 O O
 O O
1 O O
 O O
r10 O O
 O O
∼ O O
r10 O O
 O O
x1 O O
y1 O O
f1 O O
x0 O O
y0 O O
f0 O O
 O O
, O O
( O O
9.5 O O
) O O
( O O
9.6 O O
) O O
( O O
9.7 O O
) O O
or O O
which O O
reveals O O
the O O
simplicity O O
of O O
the O O
mapping O O
equations B B
and O O
makes O O
all O O
of O O
the O O
motion B B
parameters O O
explicit O O
. O O
14.4.4 O O
application O O
: O O
intelligent B B
photo I I
editing I O
. O O
3d O O
planes B B
. O O
the O O
two-dimensional B B
general- O O
ization O O
of O O
the O O
one-dimensional O O
domain O O
scaling O O
law O O
given O O
in O O
table O O
3.1 O O
is O O
g O O
( O O
ax O O
) O O
⇔ O O
|a|−1g O O
( O O
a−t O O
f O O
) O O
. O O
figure11.15b O O
shows O O
how O O
such O O
spatio-temporal O O
selection O O
or O O
shifting O O
of O O
windows O O
corresponds O O
to O O
selecting O O
the O O
most O O
likely O O
un-occluded O O
volumetric B B
region O O
in O O
the O O
epipolar B O
plane I O
image I I
vol- O I
ume O O
. O O
in O O
ieee O O
computer O O
society O O
conference O O
on O O
computer O O
vision O O
and O O
pattern O O
recognition B B
( O O
cvpr O O
2008 O O
) O O
, O O
anchorage O O
, O O
ak O O
. O O
spline-based B B
image O O
registration B O
. O O
conversely O O
, O O
if O O
the O O
surface B B
is O O
totally O O
specular B B
( O O
e.g. O O
, O O
mirrored O O
) O O
, O O
each O O
surface B B
point O O
reﬂects O O
a O O
miniature O O
copy O O
of O O
the O O
environment O O
surrounding O O
that O O
point O O
. O O
the O O
theory O O
and O O
practice O O
of O O
bayesian O O
image B B
labeling O O
. O O
next O O
, O O
we O O
examine O O
neighborhood B B
( O O
area-based O O
) O O
operators O O
, O O
where O O
each O O
new O O
pixel O O
’ O O
s O O
value O O
depends O O
on O O
a O O
small O O
number O O
of O O
neighboring O O
input O O
values O O
( O O
sections O O
3.2 O O
and O O
3.3 O O
) O O
. O O
a O O
theory O O
of O O
single-viewpoint O O
catadioptric O O
image B B
formation O O
. O O
2006 O O
; O O
ferrari O O
, O O
tuytelaars O O
, O O
and O O
van O O
gool O O
2006b O O
; O O
gordon O O
and O O
lowe O O
2006 O O
; O O
obdrˇz´alek O O
and O O
matas O O
2006 O O
; O O
sivic O O
and O O
zisserman O O
2009 O O
) O O
tend O O
to O O
use O O
viewpoint-invariant O O
2d O O
features O O
, O O
such O O
as O O
those O O
we O O
saw O O
in O O
section O O
4.1.2. O O
af- O O
686 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
ter O O
extracting O O
informative O O
sparse B B
2d O O
features O O
from O O
both O O
the O O
new O O
image B B
and O O
the O O
images O O
in O O
the O O
database O O
, O O
image B B
features O O
are O O
matched O O
against O O
the O O
object O O
database O O
, O O
using O O
one O O
of O O
the O O
sparse B B
fea- O O
ture O O
matching B B
strategies O O
described O O
in O O
section O O
4.1.3. O O
whenever O O
a O O
sufﬁcient O O
number O O
of O O
matches O O
have O O
been O O
found O O
, O O
they O O
are O O
veriﬁed O O
by O O
ﬁnding O O
a O O
geometric B B
transformation O O
that O O
aligns O O
the O O
two O O
sets O O
of O O
features O O
( O O
figure O O
14.26 O O
) O O
. O O
segmentation B B
processes O O
in O O
visual O O
perception O O
: O O
a O O
cooperative O O
neural O I
model O O
. O O
local B B
features O O
and O O
kernels O O
for O O
classiﬁcation O O
of O O
texture B B
and O O
object O O
categories O O
: O O
a O O
comprehensive O O
study O O
. O O
with O O
high-pass O O
and O O
low-pass B B
ﬁlters O O
and O O
then O O
keeping O O
the O O
odd O O
and O O
even O O
sub-sequences O O
, O O
the O O
lifting B B
scheme O O
ﬁrst O O
splits O O
the O O
sequence O O
into O O
its O O
even O O
and O O
odd O O
sub-components O O
. O O
11 O O
stereo B B
correspondence O O
535 O O
stereo B B
matching I I
is O O
the O O
process O O
of O O
taking O O
two O O
or O O
more O O
images O O
and O O
estimating O O
a O O
3d O O
model O O
of O O
the O O
scene O O
by O O
ﬁnding O O
matching B B
pixels O O
in O O
the O O
images O O
and O O
converting O O
their O O
2d O O
positions O O
into O O
3d O O
depths O O
. O O
786 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
section O O
14.4.1 O O
: O O
bag B O
of I O
words I I
two O O
bag B O
of I O
words I O
classiﬁers O O
, O O
http O O
: O O
//people.csail.mit.edu/fergus/iccv2005/bagwords.html O O
( O O
fei-fei O O
and O O
perona O O
2005 O O
; O O
sivic O O
, O O
russell O O
, O O
efros O O
et O O
al O O
. O O
instead O O
of O O
forming O O
c O O
= O O
aat O O
, O O
which O O
is O O
p O O
× O O
p O O
, O O
we O O
form O O
the O O
matrix O O
ˆc O O
= O O
at O O
a O O
, O O
( O O
a.13 O O
) O O
which O O
is O O
n O O
× O O
n. O O
( O O
this O O
involves O O
taking O O
the O O
dot O O
product O O
between O O
every O O
pair O O
of O O
difference B B
images O O
ai O O
and O O
aj O O
. O O
bayesian O O
face B B
recognition O O
. O O
how O O
are O O
the O O
photons O O
arriving O O
at O O
this O O
sensor B B
converted O O
into O O
the O O
digital O O
( O O
r O O
, O O
g O O
, O O
b O O
) O O
values O O
that O O
we O O
observe O O
when O O
we O O
look O O
at O O
a O O
digital O O
image O O
? O O
in O O
this O O
section O O
, O O
we O O
develop O O
a O O
simple O O
model O O
that O O
accounts O O
for O O
the O O
most O O
important O O
effects O O
such O O
as O O
exposure O O
( O O
gain O O
and O O
shutter O O
speed O O
) O O
, O O
non- O O
linear B B
mappings O O
, O O
sampling B B
and O O
aliasing B B
, O O
and O O
noise B B
. O O
6.4 O O
additional O O
reading O O
hartley O O
and O O
zisserman O O
( O O
2004 O O
) O O
provide O O
a O O
wonderful O O
introduction O O
to O O
the O O
topics O O
of O O
feature-based B B
alignment O O
and O O
optimal O O
motion B B
estimation I I
, O O
as O O
well O O
as O O
an O O
in-depth O O
discussion O O
of O O
camera B B
cali- O O
bration O O
and O O
pose O O
estimation B B
techniques O O
. O O
the O O
photo O O
tourism O O
system O O
developed O O
by O O
snavely O O
, O O
seitz O O
, O O
and O O
szeliski O O
( O O
2006 O O
) O O
uses O O
structure B O
from I I
motion I I
to O O
compute O O
the O O
3d O O
locations O O
and O O
poses O O
of O O
all O O
the O O
cameras O O
taking O O
the O O
images O O
, O O
along O O
with O O
a O O
sparse B B
3d O O
point-cloud O O
model O O
of O O
the O O
scene O O
( O O
section O O
7.4.4 O O
, O O
figure O O
7.11 O O
) O O
. O O
we O O
introduce O O
topics O O
from O O
the O O
information O O
and O O
document O O
re- O O
trieval O O
communities O O
, O O
such O O
as O O
frequency O O
vectors O O
, O O
feature B B
quantization O O
, O O
and O O
inverted O O
indices O O
1 O O
however O O
, O O
some O O
recent O O
research O O
suggests O O
that O O
direct B B
image O O
matching B B
may O O
be O O
feasible O O
for O O
large O O
enough O O
databases O O
( O O
russell O O
, O O
torralba O O
, O O
liu O O
et O O
al O O
. O O
11.8 O O
exercises O O
573 O O
ex O O
11.5 O O
: O O
aggregation O O
and O O
window-based B O
stereo O O
implement O O
one O O
or O O
more O O
of O O
the O O
matching B B
cost O O
aggregation O O
strategies O O
described O O
in O O
section O O
11.4 O O
: O O
• O O
convolution O O
with O O
a O O
box O O
or O O
gaussian O O
kernel B B
; O O
• O O
shifting O O
window O O
locations O O
by O O
applying O O
a O O
min O O
ﬁlter O O
( O O
scharstein O O
and O O
szeliski O O
2002 O O
) O O
; O O
• O O
picking O O
a O O
window O O
that O O
maximizes O O
some O O
match-reliability O O
metric O O
( O O
veksler O O
2001 O O
, O O
2003 O O
) O O
; O O
• O O
weighting B B
pixels O O
by O O
their O O
similarity B B
to O O
the O O
central O O
pixel O O
( O O
yoon O O
and O O
kweon O O
2006 O O
) O O
. O O
however O O
, O O
for O O
a O O
planar O O
scene O O
, O O
as O O
discussed O O
above O O
in O O
( O O
2.66 O O
) O O
, O O
we O O
can O O
replace O O
the O O
last O O
row O O
of O O
p O O
0 O O
in O O
( O O
2.64 O O
) O O
with O O
a O O
general O O
plane O O
equation O O
, O O
ˆn0 O O
· O O
p O O
+ O O
c0 O O
that O O
maps O O
points B B
on O O
the O O
plane O O
to O O
d0 O O
= O O
0 O O
values O O
( O O
figure O O
2.12b O O
) O O
. O O
exercise O O
13.10 O O
has O O
you O O
construct O O
a O O
concentric B O
mosaic I O
rendering O B
system O O
from O O
a O O
series O O
of O O
hand-held O O
photos O O
or O O
video B B
. O O
13.4.2 O O
the O O
modeling B B
to O O
rendering B B
continuum O O
. O O
such O O
techniques O O
are O O
discussed O O
in O O
textbooks B B
and O O
papers O O
on O O
numerical O O
optimization O O
( O O
toint O O
1987 O O
; O O
bj¨orck O O
1996 O O
; O O
conn O O
, O O
gould O O
, O O
and O O
toint O O
2000 O O
; O O
nocedal O O
and O O
wright O O
2006 O O
) O O
. O O
what O O
if O O
your O O
kernel B B
is O O
not O O
separable B B
and O O
yet O O
you O O
still O O
want O O
a O O
faster O O
way O O
to O O
implement O O
it O O
? O O
perona O O
( O O
1995 O O
) O O
, O O
who O O
ﬁrst O O
made O O
the O O
link O O
between O O
kernel B B
separability O O
and O O
svd O O
, O O
suggests O O
using O O
more O O
terms O O
in O O
the O O
( O O
3.21 O O
) O O
series O O
, O O
i.e. O O
, O O
summing O O
up O O
a O O
number O O
of O O
separable B B
convolutions O O
. O O
furthermore O O
, O O
when O O
dealing O O
with O O
3d O O
head B B
rotations O O
, O O
the O O
pose O O
of O O
a O O
person O O
’ O O
s O O
head B B
should O O
be O O
discounted O O
when O O
performing O O
recognition B B
. O O
object O O
class O O
recognition B B
by O O
boosting B B
a O O
part O O
based O O
model O O
. O O
( O O
see O O
section O O
3.5.2 O O
for O O
higher-order O O
generalizations O O
of O O
such O O
spline B B
functions O O
. O O
however O O
, O O
since O O
square O O
roots O O
are O O
relatively O O
fast O O
on O O
modern O O
computers O O
, O O
this O O
is O O
not O O
worth O O
the O O
bother O O
and O O
cholesky O O
factorization B B
is O O
usually O O
preferred O O
. O O
matching B B
images O O
by O O
comparing O O
their O O
gradient O O
ﬁelds O O
. O O
these O O
ﬁlters O O
include O O
: O O
• O O
the O O
linear B B
[ O O
1 O O
, O O
2 O O
, O O
1 O O
] O O
ﬁlter O O
gives O O
a O O
relatively O O
poor O O
response O O
; O O
• O O
the O O
binomial B O
[ O O
1 O O
, O O
4 O O
, O O
6 O O
, O O
4 O O
, O O
1 O O
] O O
ﬁlter O O
cuts O O
off O O
a O O
lot O O
of O O
frequencies O O
but O O
is O O
useful O O
for O O
computer O O
vision O O
analysis O O
pyramids O O
; O O
• O O
the O O
cubic B B
ﬁlters O O
from O O
( O O
3.79 O O
) O O
; O O
the O O
a O O
= O O
−1 O O
ﬁlter O O
has O O
a O O
sharper O O
fall-off O O
than O O
the O O
a O O
= O O
−0.5 O O
ﬁlter O O
( O O
figure O O
3.31 O O
) O O
; O O
0.50 O O
0.25 O O
|n| O O
linear B O
binomial O O
0.3750 O O
0 O O
0.2500 O O
1 O O
2 O O
0.0625 O O
3 O O
4 O O
cubic B O
a O O
= O O
−1 O O
0.5000 O O
0.3125 O O
0.0000 O O
-0.0625 O O
cubic B O
a O O
= O O
−0.5 O O
0.50000 O O
0.28125 O O
0.00000 O O
-0.03125 O O
windowed B O
sinc I O
0.4939 O O
0.2684 O O
0.0000 O O
-0.0153 O O
0.0000 O O
qmf-9 O O
0.5638 O O
0.2932 O O
-0.0519 O O
-0.0431 O O
0.0198 O O
jpeg O O
2000 O O
0.6029 O O
0.2669 O O
-0.0782 O O
-0.0169 O O
0.0267 O O
table O O
3.4 O O
filter O O
coefﬁcients O O
for O O
2× O O
decimation O O
. O O
however O O
for O O
image-based O O
rendering B B
, O O
such O O
quantized O O
maps O O
lead O O
to O O
very O O
unappealing O B
view O O
synthesis O O
results O O
, O O
i.e. O O
, O O
the O O
scene O O
appears O O
to O O
be O O
made O O
up O O
of O O
many O O
thin B O
shear- O O
ing O O
layers B B
. O O
motion B O
estimation I B
can O O
be O O
made O O
more O O
reliable O O
by O O
learning O O
the O O
typi- O O
cal O O
dynamics O O
or O O
motion B B
statistics O O
of O O
the O O
scenes O O
or O O
objects O O
being O O
tracked O O
, O O
e.g. O O
, O O
the O O
natural B B
gait O O
of O O
walking O O
people O O
( O O
section O O
8.2.2 O O
) O O
. O O
b.5.4 O O
graph B O
cuts I I
the O O
computer O O
vision O O
community O O
has O O
adopted O O
“ O O
graph B B
cuts I I
” O O
as O O
an O O
informal O O
name O O
to O O
describe O O
a O O
large O O
family O O
of O O
mrf O O
inference B B
algorithms O O
based O O
on O O
solving O O
one O O
or O O
more O O
min-cut O O
or O O
max- O O
ﬂow O O
problems O O
( O O
boykov O O
, O O
veksler O O
, O O
and O O
zabih O O
2001 O O
; O O
boykov O O
and O O
kolmogorov O O
2010 O O
; O O
boykov O O
, O O
b.5 O O
markov O O
random O O
ﬁelds O O
771 O O
( O O
a O O
) O O
( O O
b O O
) O O
figure O O
b.3 O O
graph B B
cuts I I
for O O
minimizing O O
binary O O
sub-modular O O
mrf O O
energies O O
( O O
boykov O O
and O O
jolly O O
2001 O O
) O O
c O O
( O O
cid:13 O O
) O O
2001 O O
ieee O O
: O O
( O O
a O O
) O O
energy O O
function O O
encoded O O
as O O
a O O
max O O
ﬂow O O
problem O O
; O O
( O O
b O O
) O O
the O O
minimum O O
cut O O
determines O O
the O O
region B B
boundary O O
. O O
322 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
6.2.1 O O
linear B B
algorithms O O
the O O
simplest O O
way O O
to O O
recover O O
the O O
pose O O
of O O
the O O
camera B B
is O O
to O O
form O O
a O O
set O O
of O O
linear B B
equations O O
analo- O O
gous O O
to O O
those O O
used O O
for O O
2d O O
motion B B
estimation I I
( O O
6.19 O O
) O O
from O O
the O O
camera B B
matrix O O
form O O
of O O
perspec- O O
tive O O
projection O O
( O O
2.55–2.56 O O
) O O
, O O
xi O O
= O O
p00xi O O
+ O O
p01yi O O
+ O O
p02zi O O
+ O O
p03 O O
p20xi O O
+ O O
p21yi O O
+ O O
p22zi O O
+ O O
p23 O O
yi O O
= O O
p10xi O O
+ O O
p11yi O O
+ O O
p12zi O O
+ O O
p13 O O
p20xi O O
+ O O
p21yi O O
+ O O
p22zi O O
+ O O
p23 O O
, O O
( O O
6.33 O O
) O O
( O O
6.34 O O
) O O
where O O
( O O
xi O O
, O O
yi O O
) O O
are O O
the O O
measured O O
2d O O
feature B B
locations O O
and O O
( O O
xi O O
, O O
yi O O
, O O
zi O O
) O O
are O O
the O O
known O O
3d O O
feature B B
locations O O
( O O
figure O O
6.4 O O
) O O
. O O
two O O
simple O O
de-interlacing B O
techniques O O
are O O
bob O O
, O O
which O O
copies O O
the O O
line O O
above O O
or O O
below O O
the O O
missing O O
line O O
from O O
the O O
same O O
ﬁeld O O
, O O
and O O
weave O O
, O O
which O O
copies O O
the O O
corresponding O O
line O O
from O O
the O O
ﬁeld O O
before O O
or O O
after O O
. O O
2006 O O
) O O
as O O
data O O
terms O O
, O O
or O O
implicitly O O
, O O
because O O
even O O
pixel-wise O O
disparity O O
costs O O
look O O
at O O
several O O
pixels O O
in O O
either O O
the O O
left O O
or O O
right O O
image B B
( O O
barnard O O
1989 O O
; O O
boykov O O
, O O
veksler O O
, O O
and O O
zabih O O
2001 O O
) O O
. O O
ex O O
2.1 O O
: O O
least B O
squares I I
intersection O O
point O O
and O O
line O O
ﬁtting—advanced O O
equation B B
( O O
2.4 O O
) O O
shows O O
how O O
the O O
intersection O O
of O O
two O O
2d O O
lines B B
can O O
be O O
expressed O O
as O O
their O O
cross O O
product O O
, O O
assuming O O
the O O
lines B B
are O O
expressed O O
as O O
homogeneous B O
coordinates I O
. O O
their O O
technique O O
was O O
the O O
ﬁrst O O
to O O
introduce O O
the O O
concept O O
of O O
boosting B B
to O O
the O O
computer O O
vision O O
community O O
, O O
which O O
involves O O
train- O O
ing O O
a O O
series O O
of O O
increasingly O O
discriminating O O
simple O O
classiﬁers O O
and O O
then O O
blending B O
their O O
outputs O O
( O O
hastie O O
, O O
tibshirani O O
, O O
and O O
friedman O O
2001 O O
; O O
bishop O O
2006 O O
) O O
. O O
thus O O
, O O
to O O
a O O
ﬁrst O O
approximation O O
, O O
we O O
can O O
view O O
energy O O
minimization O O
being O O
performed O O
when O O
solving O O
a O O
regularized O O
problem O O
and O O
the O O
maximum O O
a O O
posteriori O O
inference B B
being O O
performed O O
in O O
an O O
mrf O O
as O O
equivalent O O
. O O
let O O
us O O
re-write O O
the O O
last O O
row O O
of O O
˜p O O
as O O
p3 O O
= O O
s3 O O
[ O O
ˆn0|c0 O O
] O O
, O O
where O O
( O O
cid:107 O O
) O O
ˆn0 O O
( O O
cid:107 O O
) O O
= O O
1. O O
we O O
then O O
have O O
the O O
equation B B
( O O
2.66 O O
) O O
d O O
= O O
s3 O O
z O O
( O O
ˆn0 O O
· O O
pw O O
+ O O
c0 O O
) O O
, O O
where O O
z O O
= O O
p2 O O
· O O
¯pw O O
= O O
rz O O
· O O
( O O
pw O O
− O O
c O O
) O O
is O O
the O O
distance O O
of O O
pw O O
from O O
the O O
camera B B
center O O
c O O
( O O
2.25 O O
) O O
along O O
the O O
optical O O
axis O O
z O O
( O O
figure O O
2.11 O O
) O O
. O O
2. O O
use O O
structure B B
from I I
motion I I
to O O
recover O O
all O O
of O O
the O O
camera B B
poses O O
and O O
match O O
up O O
the O O
vanish- O O
ing O O
points B B
. O O
unlike O O
the O O
svd O O
and O O
eigenvalue O O
decompositions O O
, O O
qr O O
factorization B B
does O O
not O O
require O O
iteration O B
and O O
can O O
be O O
computed O O
exactly O O
in O O
o O O
( O O
m O O
n O O
2 O O
+ O O
n O O
3 O O
) O O
operations O O
, O O
where O O
m O O
is O O
the O O
number O O
of O O
rows O O
and O O
n O O
is O O
the O O
number O O
of O O
columns O O
( O O
for O O
a O O
tall O O
matrix O O
) O O
. O O
steerable B B
ﬁlters O O
. O O
the O O
opening B O
and O O
closing B O
operations O O
tend O O
to O O
leave O O
large O O
regions O O
and O O
smooth O O
boundaries O O
unaffected O O
, O O
while O O
removing O O
small O O
objects O O
or O O
holes O O
and O O
smoothing B B
boundaries O O
. O O
8.2.2 O O
learned B B
motion O O
models O O
. O O
some O O
examples B B
of O O
the O O
20 O O
visual O O
classes O O
in O O
the O O
2008 O O
challenge O O
are O O
shown O O
in O O
fig- O O
ure O O
14.54. O O
the O O
slides O O
from O O
the O O
voc O O
workshops,22 O O
are O O
a O O
great O O
source O O
for O O
pointers O O
to O O
the O O
best O O
recognition B B
techniques O O
currently O O
available O O
. O O
10.2.1 O O
tone B B
mapping I I
. O O
20 O O
because O O
lines B B
often O O
occur O O
at O O
depth O O
or O O
orientation O O
discontinuities O O
, O O
it O O
may O O
be O O
preferable O O
to O O
compute O O
correlation O O
scores O O
( O O
or O O
to O O
match O O
color O O
histograms O O
( O O
bay O O
, O O
ferrari O O
, O O
and O O
van O O
gool O O
2005 O O
) O O
) O O
separately O O
on O O
each O O
side O O
of O O
the O O
line O O
. O O
( O O
2009 O O
) O O
relate O O
the O O
random B O
walker I O
to O O
water- O O
sheds O O
and O O
other O O
segmentation B B
techniques O O
. O O
tracking O O
such O O
silhouettes B O
over O O
time O O
supports O O
the O O
analysis O O
of O O
multiple B B
people O O
moving O O
around O O
a O O
scene O O
, O O
including O O
building O O
shape O O
and O O
appearance O O
models O O
12 O O
older O O
surveys B O
include O O
those O O
by O O
gavrila O O
( O O
1999 O O
) O O
and O O
moeslund O O
and O O
granum O O
( O O
2001 O O
) O O
. O O
10.4.4 O O
smoke B B
, O O
shadow B B
, O O
and O O
ﬂash B B
matting O O
in O O
addition O O
to O O
matting B B
out O O
solid O O
objects O O
with O O
fractional O O
boundaries O O
, O O
it O O
is O O
also O O
possible O O
to O O
matte O O
out O O
translucent O O
media O O
such O O
as O O
smoke B B
( O O
chuang O O
, O O
agarwala O O
, O O
curless O O
et O O
al O O
. O O
information O O
retrieval O O
systems O O
do O O
this O O
by O O
matching O O
word O O
distributions O O
( O O
term O O
frequencies O O
) O O
nid/nd O O
between O O
the O O
query O O
and O O
target O O
documents O O
, O O
where O O
nid O O
is O O
how O O
many O O
times O O
word O O
i O O
occurs O O
in O O
document O O
d O O
, O O
and O O
nd O O
is O O
the O O
total B B
number O O
of O O
words O O
in O O
document O O
d. O O
in O O
order B B
to O O
downweight O O
words O O
that O O
occur O O
frequently O O
and O O
to O O
focus B B
the O O
search O O
on O O
rarer O O
( O O
and O O
hence O O
, O O
more O O
informative O O
) O O
terms O O
, O O
an O O
inverse B B
document O O
frequency O O
weighting B B
log O O
n/ni O O
is O O
applied O O
, O O
where O O
ni O O
is O O
the O O
number O O
of O O
documents O O
containing O O
word O O
i O O
, O O
and O O
n O O
is O O
the O O
total B B
number O O
of O O
documents O O
in O O
the O O
database O O
. O O
14 O O
recognition B B
657 O O
of O O
all O O
the O O
visual O B
tasks O O
we O O
might O O
ask O O
a O O
computer O O
to O O
perform O O
, O O
analyzing O O
a O O
scene O O
and O O
recog- O O
nizing O O
all O O
of O O
the O O
constituent O O
objects O O
remains O O
the O O
most O O
challenging O O
. O O
computer O O
vision O O
and O O
pattern O O
recognition B B
( O O
cvpr O O
’ O O
2003 O O
) O O
, O O
pp O O
. O O
rapid O O
pose O O
estimation B B
is O O
also O O
central O O
to O O
tracking O O
the O O
position O O
and O O
orientation O O
of O O
the O O
hand- O O
held O O
remote O O
controls O O
used O O
in O O
nintendo O O
’ O O
s O O
wii O O
game O O
systems O O
. O O
this O O
involves O O
selecting O O
a O O
ﬁnal O O
compositing B B
surface O O
( O O
ﬂat O O
, O O
cylindrical B B
, O O
spherical B B
, O O
etc O O
. O O
while O O
szeliski O O
( O O
1999 O O
) O O
and O O
kang O O
abcdefabcdefabcdefleftmiddlerightabcdefabcdefabcdefleftmiddleright O O
562 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
( O O
a O O
) O O
( O O
b O O
) O O
( O O
c O O
) O O
( O O
d O O
) O O
figure O O
11.17 O O
local B B
( O O
5 O O
× O O
5 O O
window-based B O
) O O
matching B B
results O O
( O O
kang O O
, O O
szeliski O O
, O O
and O O
chai O O
2001 O O
) O O
c O O
( O O
cid:13 O O
) O O
2001 O O
ieee O O
: O O
( O O
a O O
) O O
window O O
that O O
is O O
not O O
spatially O O
perturbed O O
( O O
centered O O
) O O
; O O
( O O
b O O
) O O
spatially O O
perturbed O O
window O O
; O O
( O O
c O O
) O O
using O O
the O O
best O O
ﬁve O O
of O O
10 O O
neighboring O O
frames O O
; O O
( O O
d O O
) O O
using O O
the O O
better O O
half O O
sequence O O
. O O
“ O O
nulling O O
” O O
ﬁlters O O
and O O
the O O
separation O O
of O O
transparent B B
motion O O
. O O
after O O
image B B
coordinates O O
are O O
trans- O O
formed O O
using O O
the O O
matrices O O
a−1/2 O O
, O O
they O O
are O O
related O O
by O O
a O O
pure B O
rotation I O
r O O
, O O
which O O
can O O
be O O
estimated O O
using O O
a O O
dominant O O
orientation O O
technique O O
. O O
as O O
you O O
can O O
see O O
in O O
the O O
image B B
below O O
the O O
kernel B B
, O O
this O O
ﬁlter O O
effectively O O
emphasizes O O
horizontal O O
edges O O
. O O
muja O O
and O O
lowe O O
( O O
2009 O O
) O O
compare O O
a O O
number O O
of O O
these O O
approaches O O
, O O
introduce O O
a O O
new O O
one O O
of O O
their O O
own O O
( O O
priority O O
search O O
on O O
hierarchical B B
k-means O O
trees O O
) O O
, O O
and O O
conclude O O
that O O
mul- O O
tiple O O
randomized O O
k-d B B
trees I O
often O O
provide O O
the O O
best O O
performance O O
. O O
recovering O O
the O O
position O O
and O O
orientation O O
of O O
free-form O O
objects O O
from O O
image B B
contours O O
using O O
3-d O O
distance O O
maps O O
. O O
recovering O O
3d O O
shape O O
and O O
motion B B
from O O
image B B
streams O O
using O O
nonlinear O O
least B B
squares I I
. O O
2006 O O
) O O
, O O
or O O
using O O
other O O
local B B
transformations O O
such O O
as O O
histograms O O
or O O
rank O O
transforms O O
( O O
cox O O
, O O
roy O O
, O O
and O O
hingorani O O
1995 O O
; O O
zabih O O
and O O
woodﬁll O O
1994 O O
) O O
, O O
or O O
to O O
max- O O
imize O O
mutual O O
information O O
( O O
viola O O
and O O
wells O O
iii O O
1997 O O
; O O
kim O O
, O O
kolmogorov O O
, O O
and O O
zabih O O
2003 O O
) O O
. O O
6.3.4 O O
rotational B O
motion I I
. O O
smoothness B O
in O O
these O O
parameters B B
along O O
the O O
boundary O O
is O O
enforced O O
using O O
regularization O O
and O O
the O O
optimization O O
is O O
performed O O
using O O
dynamic O O
programming O I
. O O
( O O
b O O
) O O
compute O O
inverted O O
indices O O
from O O
visual B O
words I I
to O O
images O O
( O O
with O O
word O O
counts O O
) O O
. O O
next O O
, O O
the O O
analog O O
to O O
digital O O
( O O
a/d O O
) O O
converter O O
on O O
the O O
sensing O O
chip O O
applies O O
an O O
electronic O O
gain O O
, O O
usually O O
controlled O O
by O O
the O O
iso O O
setting O O
on O O
your O O
camera B B
. O O
in O O
order B B
to O O
evaluate O O
the O O
large O O
number O O
of O O
design O O
alternatives O O
in O O
multi- O O
view O O
stereo O I
, O O
seitz O O
, O O
curless O O
, O O
diebel O O
et O O
al O O
. O O
1996 O O
) O O
c O O
( O O
cid:13 O O
) O O
1996 O O
acm O O
: O O
( O O
a O O
) O O
a O O
ray O O
is O O
represented O O
by O O
its O O
4d O O
two-plane O O
parameters B O
( O O
s O O
, O O
t O O
) O O
and O O
( O O
u O O
, O O
v O O
) O O
; O O
( O O
b O O
) O O
a O O
slice O O
through O O
the O O
3d O O
light B O
ﬁeld I I
subset O O
( O O
u O O
, O O
v O O
, O O
s O O
) O O
. O O
the O O
problem O O
with O O
using O O
a O O
ﬁxed O O
threshold O O
is O O
that O O
it O O
is O O
difﬁcult O O
to O O
set O O
; O O
the O O
useful O O
range O O
false O O
positive O O
ratetrue O O
positive O O
rate0.10.8011equal O O
error O O
raterandom O O
chancetpfpfntnθd O O
# O O
230 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
figure O O
4.24 O O
fixed O O
threshold O O
, O O
nearest B O
neighbor I I
, O O
and O O
nearest B B
neighbor I I
distance O O
ratio O O
matching B B
. O O
( O O
2000 O O
) O O
http O O
: O O
//www.frvt.org/feret O O
frvt O O
http O O
: O O
//www.frvt.org/ O O
cmu O O
pie O O
database O O
centered O O
face B B
images O O
faces B B
in O O
various O O
poses O O
centered O O
face B B
image O O
faces B B
in O O
various O O
poses O O
phillips O O
, O O
scruggs O O
, O O
o O O
’ O O
toole O O
et O O
al O O
. O O
for O O
this O O
reason O O
, O O
lowe O O
( O O
2004 O O
) O O
suggests O O
using O O
a O O
hough O O
transform B B
( O O
section O O
4.3.2 O O
) O O
to O O
accumulate O O
votes O O
for O O
likely O O
geo- O O
metric O O
transformations O O
. O O
computer O O
vision O O
and O O
image B B
understanding O O
, O O
103 O O
( O O
1 O O
) O O
:22–32 O O
. O O
this O O
step O O
involves O O
taking O O
every O O
matching B B
feature O O
and O O
counting O O
the O O
number O O
of O O
k O O
= O O
15 O O
nearest O O
adjacent O O
features O O
that O O
also O O
match O O
between O O
the O O
two O O
documents O O
. O O
( O O
optional O O
) O O
re-ﬁt O O
the O O
line O O
parameters O O
by O O
throwing O O
away O O
outliers O O
or O O
using O O
a O O
robust B B
norm O O
or O O
inﬂuence O O
function O O
. O O
appendix O O
a.4–a.5 O O
: O O
direct B B
and O O
iterative B B
sparse O O
matrix O O
solvers O O
suitesparse O O
( O O
various O O
reordering O O
algorithms O O
, O O
cholmod O O
) O O
and O O
suitesparse O O
qr O O
, O O
http O O
: O O
//www.cise.uﬂ.edu/research/sparse/suitesparse/ O O
( O O
davis O O
2006 O O
, O O
2008 O O
) O O
. O O
this O O
formulation O O
of O O
the O O
inference B B
problem O O
is O O
called O O
an O O
m-estimator O O
in O O
the O O
robust B B
statistics O O
literature O O
( O O
huber O O
1981 O O
; O O
hampel O O
, O O
ronchetti O O
, O O
rousseeuw O O
et O O
al O O
. O O
( O O
8.42 O O
) O O
the O O
gradients O O
required O O
for O O
j O O
1 O O
( O O
xi O O
+ O O
u O O
) O O
can O O
be O O
evaluated O O
at O O
the O O
same O O
time O O
as O O
the O O
image B B
warps O O
required O O
to O O
estimate O O
i1 O O
( O O
xi O O
+ O O
u O O
) O O
( O O
section O O
3.6.1 O O
( O O
3.89 O O
) O O
) O O
and O O
, O O
in O O
fact O O
, O O
are O O
often O O
computed O O
as O O
a O O
side-product O O
of O O
image B B
interpolation O O
. O O
in O O
fact O O
, O O
the O O
earliest O O
face B O
recognition O O
systems O O
, O O
such O O
as O O
those O O
by O O
fischler O O
and O O
elschlager O O
( O O
1973 O O
) O O
, O O
kanade O O
( O O
1977 O O
) O O
, O O
and O O
yuille O O
( O O
1991 O O
) O O
, O O
found O O
distinctive O O
feature B B
points O O
on O O
facial O O
images O O
and O O
performed O O
recognition B B
on O O
the O O
basis O O
of O O
their O O
relative O O
positions O O
or O O
distances O O
. O O
barring O O
the O O
ability O O
to O O
pre-calibrate O O
the O O
camera B B
or O O
to O O
take O O
repeated O O
shots O O
of O O
the O O
same O O
scene O O
, O O
the O O
simplest O O
2.3 O O
the O O
digital O O
camera O O
77 O O
approach O O
is O O
to O O
look O O
for O O
regions O O
of O O
near-constant O O
value O O
and O O
to O O
estimate O O
the O O
noise B B
variance O O
in O O
such O O
regions O O
( O O
liu O O
, O O
szeliski O O
, O O
kang O O
et O O
al O O
. O O
of O O
the O O
local B B
aggregation O O
methods O O
compared O O
by O O
gong O O
, O O
yang O O
, O O
wang O O
et O O
al O O
. O O
note O O
that O O
now O O
we O O
have O O
placed O O
the O O
image B B
plane O O
in O O
front O O
of O O
the O O
nodal B B
point I O
( O O
projection O O
center O O
of O O
the O O
lens O O
) O O
. O O
some O O
of O O
the O O
more O O
recent O O
techniques O O
rely O O
on O O
ﬁrst O O
segmenting O O
the O O
input O O
color B B
images O O
and O O
then O O
estimating O O
per-segment O O
motions O O
that O O
produce O O
a O O
coherent O O
motion B B
ﬁeld O O
while O O
also O O
modeling B B
occlusions O O
( O O
zitnick O O
, O O
kang O O
, O O
uyttendaele O O
et O O
al O O
. O O
a.5 O O
iterative B B
techniques O O
when O O
problems O O
become O O
large O O
, O O
the O O
amount O O
of O O
memory O O
required O O
to O O
store O O
the O O
hessian O O
matrix O O
c O O
and O O
its O O
factor O O
r O O
, O O
and O O
the O O
amount O O
of O O
time O O
it O O
takes O O
to O O
compute O O
the O O
factorization B B
, O O
can O O
be- O O
come O O
prohibitively O O
large O O
, O O
especially O O
when O O
there O O
are O O
large O O
amounts O O
of O O
ﬁll-in O O
. O O
11.1 O O
epipolar B B
geometry I I
given O O
a O O
pixel O O
in O O
one O O
image B B
, O O
how O O
can O O
we O O
compute O O
its O O
correspondence B B
in O O
the O O
other O O
image B B
? O O
in O O
chapter O O
8 O O
, O O
we O O
saw O O
that O O
a O O
variety O O
of O O
search O O
techniques O O
can O O
be O O
used O O
to O O
match O O
pixels O O
based O O
on O O
their O O
local B B
appearance O O
as O O
well O O
as O O
the O O
motions O O
of O O
neighboring O O
pixels O O
. O O
action O O
recognition B B
datasets O O
, O O
http O O
: O O
//www.cs.berkeley.edu/projects/vision/action O O
, O O
has O O
point- O O
ers O O
to O O
several O O
datasets O O
for O O
action O O
and O O
activity B O
recognition I O
, O O
as O O
well O O
as O O
some O O
papers O O
. O O
two O O
commonly O O
used O O
point O O
processes O O
are O O
multiplication B O
and O O
addition O O
with O O
a O O
constant O O
, O O
g O O
( O O
x O O
) O O
= O O
af O O
( O O
x O O
) O O
+ O O
b O O
. O O
as O O
with O O
line O O
ﬁtting O O
, O O
one O O
possible O O
approach O O
is O O
to O O
have O O
each O O
line O O
vote O O
for O O
all O O
possible O O
vanishing O B
point O O
directions O O
, O O
either O O
using O O
a O O
cube B B
map I I
( O O
tuytelaars O O
, O O
van O O
gool O O
, O O
and O O
proesmans O O
1997 O O
; O O
antone O O
and O O
teller O O
2002 O O
) O O
or O O
a O O
gaussian O O
sphere O O
( O O
collins O O
and O O
weiss O O
1990 O O
) O O
, O O
optionally O O
using O O
knowledge O O
about O O
the O O
uncertainty B B
in O O
the O O
vanish- O O
ing O O
point O O
location O O
to O O
perform O O
a O O
weighted B B
vote O O
( O O
collins O O
and O O
weiss O O
1990 O O
; O O
brillaut-o O O
’ O O
mahoney O O
1991 O O
; O O
shufelt O O
1999 O O
) O O
. O O
a O O
normalized B B
cut O O
between O O
the O O
two O O
groups O O
, O O
shown O O
as O O
a O O
dashed O O
line O O
, O O
separates O O
them O O
into O O
two O O
clusters O O
. O O
4.3 O O
lines B B
. O O
the O O
actual O O
process O O
of O O
matting B B
, O O
i.e. O O
, O O
recovering O O
the O O
foreground O O
, O O
background O O
, O O
and O O
alpha B B
matte I O
values O O
from O O
one O O
or O O
more O O
images O O
, O O
has O O
a O O
rich O O
history O O
, O O
which O O
we O O
study O O
in O O
section O O
10.4 O O
. O O
the O O
cu- O O
bic O O
interpolant O O
is O O
a O O
c O O
1 O O
( O O
derivative-continuous O O
) O O
piecewise-cubic O O
spline B O
( O O
the O O
term O O
“ O O
spline B B
” O O
is O O
synonymous O O
with O O
“ O O
piecewise-polynomial O O
” O O
) O O
14 O O
whose O O
equation B B
is O O
1 O O
− O O
( O O
a O O
+ O O
3 O O
) O O
x2 O O
+ O O
( O O
a O O
+ O O
2 O O
) O O
|x|3 O O
a O O
( O O
|x| O O
− O O
1 O O
) O O
( O O
|x| O O
− O O
2 O O
) O O
2 O O
0 O O
if O O
|x| O O
< O O
1 O O
if O O
1 O O
≤ O O
|x| O O
< O O
2 O O
otherwise O O
, O O
( O O
3.79 O O
) O O
h O O
( O O
x O O
) O O
= O O
where O O
a O O
speciﬁes O O
the O O
derivative O O
at O O
x O O
= O O
1 O O
( O O
parker O O
, O O
kenyon O O
, O O
and O O
troxel O O
1983 O O
) O O
. O O
deciding O O
which O O
alignment B B
model O O
is O O
most O O
appropriate O O
for O O
a O O
given O O
situation O O
or O O
set O O
of O O
data O O
is O O
a O O
model O O
selection O O
problem O O
( O O
hastie O O
, O O
tibshirani O O
, O O
and O O
friedman O O
2001 O O
; O O
torr O O
2002 O O
; O O
bishop O O
2006 O O
; O O
robert O O
2007 O O
) O O
, O O
an O O
important O O
topic O O
we O O
do O O
not O O
cover O O
in O O
this O O
book O O
. O O
2. O O
to O O
acquire O O
ground O O
truth O O
data O O
, O O
place O O
your O O
object O O
in O O
front O O
of O O
a O O
computer O O
monitor O O
and O O
display O O
a O O
variety O O
of O O
solid O O
background O O
colors O O
as O O
well O O
as O O
some O O
natural B B
imagery O O
. O O
more O O
recent O O
papers O O
assume O O
this O O
distribution O O
to O O
be O O
more O O
peaked O O
around O O
0 O O
and O O
1 O O
, O O
or O O
sometimes O O
use O O
markov O O
random O O
ﬁelds O O
( O O
mrfs O O
) O O
to O O
deﬁne O O
a O O
global B B
correlated O O
prior B B
on O O
p O O
( O O
α O O
) O O
( O O
wang O O
and O O
cohen O O
2007a O O
) O O
. O O
12.1.2 O O
shape O O
from O O
texture B B
. O O
compositing B O
digital O O
images O O
. O O
face B B
recognition O O
: O O
component-based O O
versus O O
global B B
approaches O O
. O O
in O O
situations O O
where O O
a O O
large O O
number O O
of O O
points B B
at O O
inﬁnity O O
are O O
available O O
, O O
e.g. O O
, O O
when O O
shooting O O
outdoor O O
scenes O O
or O O
when O O
the O O
camera B B
motion O O
is O O
small O O
compared O O
to O O
distant O O
objects O O
, O O
this O O
suggests O O
an O O
alternative O O
ransac O O
strategy B O
for O O
estimating O O
the O O
camera B B
motion O O
. O O
a.2 O O
linear B B
least O O
squares O O
. O O
while O O
many O O
computer O O
vision O O
applications O O
ignore O O
uncertainty B B
modeling I O
, O O
it O O
is O O
often O O
useful O O
to O O
compute O O
these O O
estimates O O
just O O
to O O
get O O
an O O
intuitive O O
feeling O O
for O O
the O O
reliability O O
of O O
the O O
estimates O O
. O O
successive B O
approximation I O
. O O
( O O
2006 O O
) O O
use O O
face B B
and O O
sky O O
detection B O
to O O
determine O O
regions O O
of O O
interest O O
in O O
order B B
to O O
decide O O
which O O
pieces O O
from O O
a O O
collection O O
of O O
images O O
to O O
stitch O O
into O O
a O O
collage O O
. O O
where O O
does O O
the O O
function O O
ˆh O O
( O O
x O O
( O O
cid:48 O O
) O O
) O O
come O O
from O O
? O O
quite O O
often O O
, O O
it O O
can O O
simply O O
be O O
computed O O
as O O
the O O
inverse B B
of O O
h O O
( O O
x O O
) O O
. O O
image B B
mosaicing O O
using O O
sequential O O
bundle B B
adjustment I I
. O O
this O O
problem O O
is O O
generally O O
known O O
as O O
vignetting B B
and O O
comes O O
in O O
several O O
different O O
forms O O
, O O
including O O
natural B B
, O O
optical O B
, O O
and O O
mechanical B O
vignetting O O
( O O
sec- O O
tion B B
2.2.3 O O
) O O
( O O
ray O O
2002 O O
) O O
. O O
it O O
is O O
also O O
possible O O
to O O
change O O
the O O
orientation O O
of O O
the O O
kernel B B
in O O
joint B B
parameter O O
space O O
for O O
applications O O
such O O
as O O
spatio-temporal O O
( O O
video B B
) O O
segmentations O O
( O O
wang O O
, O O
thiesson O O
, O O
xu O O
et O O
al O O
. O O
12.6.3 O O
application O O
: O O
facial B B
animation I I
perhaps O O
the O O
most O O
widely O O
used O O
application O O
of O O
3d O O
head B B
modeling O I
is O O
facial B O
animation I O
. O O
2d O O
vs. O O
3d O O
deformable O O
face B B
models O O
: O O
represen- O O
tational O O
power O O
, O O
construction O O
, O O
and O O
real-time O O
ﬁtting O O
. O O
in O O
order B B
to O O
accelerate O O
the O O
solution O O
of O O
this O O
sparse B B
linear O O
system O O
, O O
fattal O O
, O O
lischinski O O
, O O
and O O
werman O O
( O O
2002 O O
) O O
use O O
multigrid O O
, O O
whereas O O
agarwala O O
, O O
dontcheva O O
, O O
agrawala O O
et O O
al O O
. O O
( O O
a O O
) O O
( O O
b O O
) O O
figure O O
3.47 O O
inverse B B
warping I O
algorithm O O
: O O
( O O
a O O
) O O
a O O
pixel O O
g O O
( O O
x O O
( O O
cid:48 O O
) O O
) O O
is O O
sampled O O
from O O
its O O
corresponding O O
location O O
x O O
= O O
ˆh O O
( O O
x O O
( O O
cid:48 O O
) O O
) O O
in O O
image B B
f O O
( O O
x O O
) O O
; O O
( O O
b O O
) O O
detail O O
of O O
the O O
source O O
and O O
destination O O
pixel O O
locations O O
. O O
the O O
noisy O O
image B B
formation O O
process O O
can O O
be O O
written O O
as O O
o O O
( O O
x O O
, O O
y O O
) O O
= O O
s O O
( O O
x O O
, O O
y O O
) O O
+ O O
n O O
( O O
x O O
, O O
y O O
) O O
, O O
( O O
3.66 O O
) O O
where O O
s O O
( O O
x O O
, O O
y O O
) O O
is O O
the O O
( O O
unknown O O
) O O
image B B
we O O
are O O
trying O O
to O O
recover O O
, O O
n O O
( O O
x O O
, O O
y O O
) O O
is O O
the O O
additive O O
noise B B
signal O O
, O O
and O O
o O O
( O O
x O O
, O O
y O O
) O O
is O O
the O O
observed O O
noisy O O
image B B
. O O
for O O
this O O
reason O O
, O O
the O O
ladybug O O
camera B O
has O O
a O O
programmable O O
exposure O O
capability O O
that O O
enables O O
the O O
bracketing O O
of O O
exposures O O
at O O
subsequent O O
video B B
frames O O
. O O
8.5 O O
layered B B
motion O O
in O O
many O O
situation O O
, O O
visual O O
motion O O
is O O
caused O O
by O O
the O O
movement O O
of O O
a O O
small O O
number O O
of O O
objects O O
at O O
different O O
depths O O
in O O
the O O
scene O O
. O O
references B B
927 O O
yu O O
, O O
y. O O
and O O
malik O O
, O O
j O O
. O O
finding O O
the O O
vanishing B O
points I I
common O O
to O O
such O O
4.3 O O
lines B B
255 O O
( O O
a O O
) O O
( O O
b O O
) O O
( O O
c O O
) O O
figure O O
4.45 O O
real-world O O
vanishing B B
points I I
: O O
( O O
a O O
) O O
architecture B B
( O O
sinha O O
, O O
steedly O O
, O O
szeliski O O
et O O
al O O
. O O
2004 O O
; O O
li O O
and O O
hart- O O
ley O O
2007 O O
; O O
enqvist O O
, O O
josephson O O
, O O
and O O
kahl O O
2009 O O
) O O
.3 O O
since O O
the O O
two O O
surfaces O O
being O O
aligned O O
usually O O
only O O
have O O
partial O O
overlap O O
and O O
may O O
also O O
have O O
outliers O O
, O O
robust B B
matching O O
criteria O O
( O O
section O O
6.1.4 O O
and O O
appendix O O
b.3 O O
) O O
are O O
typically O O
used O O
. O O
after O O
reconstructing O O
the O O
image B B
from O O
the O O
remaining O O
edges O O
, O O
the O O
undesirable O O
visual O O
features O O
have O O
been O O
removed O O
( O O
figure O O
4.39 O O
) O O
. O O
polynomial-time O O
exact O O
inference B B
in O O
np-hard O O
binary O O
mrfs O O
via O O
reweighted O O
perfect O O
matching O B
. O O
notice O O
, O O
however O O
, O O
that O O
when O O
there O O
is O O
no O O
light O O
dispersion O O
in O O
the O O
scene O O
, O O
i.e. O O
, O O
no O O
smoke B B
or O O
fog O O
, O O
all O O
the O O
coincident O O
rays O O
along O O
a O O
portion O O
of O O
free O O
space O O
( O O
between O O
solid O O
or O O
refractive O O
objects O O
) O O
have O O
the O O
same O O
color B B
value O O
. O O
the O O
resulting O O
region B B
boundaries O O
are O O
turned O O
into O O
a O O
much O O
smaller O O
graph O B
, O O
where O O
nodes O O
are O O
located O O
wherever O O
three O O
or O O
four O O
regions O O
meet O O
. O O
image-based B B
spatio-temporal O O
modeling B B
and O O
view B O
interpolation I I
of O O
dynamic B B
events O O
. O O
cham O O
and O O
rehg O O
( O O
1999 O O
) O O
and O O
sidenbladh O O
, O O
black O O
, O O
and O O
fleet O O
( O O
2000 O O
) O O
track O O
limbs O O
using O O
optical O O
ﬂow O O
and O O
templates O O
, O O
along O O
with O O
techniques O O
for O O
dealing O O
with O O
multiple O O
hypotheses O O
and O O
uncertainty B B
. O O
3.3.4 O O
connected B B
components I I
another O O
useful O O
semi-global O O
image O I
operation O O
is O O
ﬁnding O O
connected B B
components I I
, O O
which O O
are O O
de- O O
ﬁned O O
as O O
regions O O
of O O
adjacent O O
pixels O O
that O O
have O O
the O O
same O O
input O O
value O O
( O O
or O O
label O O
) O O
. O O
chapter O O
14 O O
: O O
recognition B B
for O O
a O O
list O O
of O O
visual O B
recognition O I
datasets O O
, O O
see O O
tables O O
14.1–14.2 O O
. O O
the O O
ambient O O
( O O
no-ﬂash O O
) O O
image B B
a O O
is O O
ﬁltered O O
with O O
a O O
regular O O
bilateral B B
ﬁlter I I
to O O
produce O O
abase O O
, O O
which O O
is O O
used O O
in O O
shadow B B
and O O
specularity O O
regions O O
, O O
and O O
a O O
joint B B
bilaterally O O
ﬁltered O O
noise B B
reduced O O
image B B
anr O O
. O O
( O O
14.9 O O
) O O
we O O
can O O
apply O O
the O O
eigenvalue O O
decomposition O O
( O O
a.6 O O
) O O
to O O
represent O O
this O O
matrix O O
as O O
m−1 O O
( O O
cid:88 O O
) O O
i=0 O O
n−1 O O
( O O
cid:88 O O
) O O
i=0 O O
c O O
= O O
uλu O O
t O O
= O O
λiuiut O O
i O O
, O O
( O O
14.10 O O
) O O
where O O
the O O
λi O O
are O O
the O O
eigenvalues B B
of O O
c O O
and O O
the O O
ui O O
are O O
the O O
eigenvectors O O
. O O
1. O O
compute O O
the O O
horizontal O O
and O O
vertical O O
derivatives O O
of O O
the O O
image B B
ix O O
and O O
iy O O
by O O
con- O O
volving O O
the O O
original O O
image B B
with O O
derivatives O O
of O O
gaussians O O
( O O
section O O
3.2.3 O O
) O O
. O O
true O O
multi-image O O
alignment B B
and O O
its O O
application O O
to O O
mosaicing O O
and O O
lens O O
distortion O O
correction O O
. O O
lifted O O
wavelets O O
are O O
called O O
second-generation O O
wavelets O O
because O O
they O O
can O O
easily O O
adapt O O
to O O
non-regular O O
sampling B B
topologies O O
, O O
e.g. O O
, O O
those O O
that O O
arise O O
in O O
computer O O
graphics O O
applications O O
such O O
as O O
multi-resolution O O
surface B B
manipulation O O
( O O
schr¨oder O O
and O O
sweldens O O
1995 O O
) O O
. O O
while O O
all O O
of O O
these O O
global B B
illumination I O
effects O O
can O O
have O O
a O O
strong O O
effect O O
on O O
the O O
appearance O O
of O O
a O O
scene O O
, O O
and O O
hence O O
its O O
3d O O
interpretation O O
, O O
they O O
are O O
not O O
covered O O
in O O
more O O
detail O O
in O O
this O O
book O O
. O O
with O O
the O O
advent O O
of O O
huge O O
repositories O O
of O O
images O O
on O O
the O O
web O O
( O O
a O O
topic O O
we O O
return O O
to O O
in O O
section O O
14.5.1 O O
) O O
, O O
it O O
often O O
makes O O
more O O
sense O O
to O O
ﬁnd O O
a O O
different O O
image B B
to O O
serve O O
as O O
the O O
source O O
of O O
the O O
missing O O
pixels O O
. O O
image B B
deblurring O O
with O O
blurred/noisy O O
image B B
pairs O O
. O O
ex O O
3.15 O B
: O O
fourier O O
transform B B
prove O O
the O O
properties B B
of O O
the O O
fourier O O
transform B B
listed O O
in O O
ta- O O
ble O O
3.1 O O
and O O
derive O O
the O O
formulas O O
for O O
the O O
fourier O O
transforms O O
listed O O
in O O
tables O O
3.2 O O
and O O
3.3. O O
these O O
exercises O O
are O O
very O O
useful O O
if O O
you O O
want O O
to O O
become O O
comfortable O O
working O O
with O O
fourier O O
transforms O O
, O O
which O O
is O O
a O O
very O O
useful O O
skill O O
when O O
analyzing O O
and O O
designing O O
the O O
behavior O O
and O O
efﬁciency B B
of O O
many O O
computer O O
vision O O
algorithms O O
. O O
ieee O O
computer O O
graphics O O
and O O
applications O O
, O O
recent O O
advances O O
in O O
augmented B O
reality I O
. O O
6.1 O O
2d O O
and O O
3d O O
feature-based B B
alignment O O
feature-based B B
alignment O O
is O O
the O O
problem O O
of O O
estimating O O
the O O
motion B B
between O O
two O O
or O O
more O O
sets O O
of O O
matched O O
2d O O
or O O
3d O O
points B B
. O O
such O O
tech- O O
niques O O
go O O
under O O
a O O
variety O O
of O O
names O O
, O O
including O O
contextual O O
classiﬁcation O O
( O O
kittler O O
and O O
f¨oglein O O
1984 O O
) O O
and O O
iterated B O
conditional I O
modes I O
( O O
icm O O
) O O
( O O
besag O O
1986 O O
) O O
.7 O O
variables O O
can O O
either O O
be O O
updated O O
sequentially O O
, O O
e.g. O O
, O O
in O O
raster O O
scan O O
, O O
or O O
in O O
parallel O O
, O O
e.g. O O
, O O
using O O
red–black O O
coloring O O
on O O
a O O
checker- O O
board O O
. O O
however O O
, O O
if O O
we O O
want O O
to O O
deal O O
with O O
issues O O
such O O
as O O
focus B B
, O O
exposure O O
, O O
vignetting B B
, O O
and O O
aber- O O
2.2 O O
photometric B B
image O O
formation O O
69 O O
figure O O
2.19 O O
a O O
thin B O
lens O O
of O O
focal O O
length O O
f O O
focuses O O
the O O
light O O
from O O
a O O
plane O O
a O O
distance O O
zo O O
in O O
front O O
of O O
the O O
lens O O
at O O
a O O
distance O O
zi O O
behind O O
the O O
lens O O
, O O
where O O
1 O O
f O O
. O O
reﬂectance B B
analysis O O
for O O
3d O O
computer O O
graphics O O
model O O
generation O O
. O O
to O O
ensure O O
that O O
the O O
random O O
sampling O B
has O O
a O O
good O O
chance O O
of O O
ﬁnding O O
a O O
true O O
set O O
of O O
inliers B B
, O O
a O O
sufﬁcient O O
number O O
of O O
trials O O
s O O
must O O
be O O
tried O O
. O O
it O O
is O O
then O O
a O O
simple O O
matter O O
of O O
using O O
optical O O
triangulation B B
to O O
estimate O O
the O O
3d O O
locations O O
of O O
all O O
the O O
points B B
seen O O
in O O
a O O
particular O O
stripe O O
. O O
obdrˇz´alek O O
and O O
matas O O
( O O
2006 O O
) O O
general- O O
ize O O
lowe O O
’ O O
s O O
approach O O
to O O
use O O
feature B B
descriptors O O
with O O
full O O
local B B
afﬁne O O
frames O O
and O O
evaluate O O
their O O
approach O O
on O O
a O O
number O O
of O O
object O O
recognition B B
databases O O
. O O
examples B B
of O O
actions O O
that O O
are O O
commonly O O
recognized O O
include O O
walking O O
and O O
running O O
, O O
jumping O O
, O O
dancing O O
, O O
picking O O
up O O
objects O O
, O O
sitting O O
down O O
and O O
standing O O
up O O
, O O
and O O
waving O O
. O O
motion B B
texture O O
: O O
a O O
two-level O O
statistical O O
model O O
for O O
character O O
motion B B
synthesis O O
. O O
in O O
ieee O O
computer O O
society O O
conference O O
on O O
computer O O
vision O O
and O O
pattern O O
recognition B B
( O O
cvpr O O
’ O O
97 O O
) O O
, O O
pp O O
. O O
the O O
kernels O O
we O O
just O O
discussed O O
are O O
all O O
examples B B
of O O
blurring O O
( O O
smoothing B B
) O O
or O O
low-pass B B
ker- O O
nels O O
( O O
since O O
they O O
pass O O
through O O
the O O
lower O O
frequencies O O
while O O
attenuating O O
higher O O
frequencies O O
) O O
. O O
while O O
these O O
are O O
all O O
encouraging O O
developments O O
, O O
the O O
gap O O
between O O
human O O
and O O
machine O O
per- O O
formance O O
in O O
semantic O O
scene B O
understanding I O
remains O O
large O O
. O O
video B B
mosaics O O
for O O
virtual O O
environments O O
. O O
12.4 O O
point-based B B
representations O O
595 O O
+ O O
=⇒ O O
( O O
x O O
, O O
y O O
, O O
z O O
) O O
( O O
a O O
) O O
( O O
nx O O
, O O
ny O O
, O O
nz O O
) O O
( O O
b O O
) O O
( O O
c O O
) O O
figure O O
12.12 O O
geometry O O
images O O
( O O
gu O O
, O O
gortler O O
, O O
and O O
hoppe O O
2002 O O
) O O
c O O
( O O
cid:13 O O
) O O
2002 O O
acm O O
: O O
( O O
a O O
) O O
the O O
257× O O
257 O O
geometry O O
image B B
deﬁnes O O
a O O
mesh O O
over O O
the O O
surface B B
; O O
( O O
b O O
) O O
the O O
512 O O
× O O
512 O O
normal O O
map O O
deﬁnes O O
vertex O O
normals O B
; O O
( O O
c O O
) O O
ﬁnal O O
lit O O
3d O O
model O O
. O O
the O O
resulting O O
three O O
values O O
are O O
normalized B B
by O O
their O O
expected O O
standard O O
deviations O O
and O O
then O O
mapped O O
to O O
the O O
two O O
( O O
of O O
b O O
= O O
10 O O
) O O
nearest O B
1d O O
bins O O
. O O
the O O
source O O
video B B
frames O O
can O O
then O O
be O O
re-combined O O
using O O
image-based O O
rendering B B
techniques O O
, O O
such O O
as O O
view B B
interpolation I I
, O O
to O O
13.5 O O
video-based O O
rendering O O
639 O O
figure O O
13.12 O O
video B B
rewrite O O
( O O
bregler O O
, O O
covell O O
, O O
and O O
slaney O O
1997 O O
) O O
c O O
( O O
cid:13 O O
) O O
1997 O O
acm O O
: O O
the O O
video B B
frames O O
are O O
composed O O
from O O
bits O O
and O O
pieces O O
of O O
old O O
video B B
footage O O
matched O O
to O O
a O O
new O O
audio O O
track O O
. O O
activity B O
recognition I O
. O O
) O O
for O O
parametric O O
motion B B
, O O
the O O
( O O
gauss–newton O O
) O O
hessian O O
and O O
gradient-weighted O O
residual O O
vec- O O
tor O O
become O O
and O O
a O O
= O O
( O O
cid:88 O O
) O O
i O O
x O O
( O O
cid:48 O O
) O O
( O O
xi O O
) O O
[ O O
∇i O O
t O O
j O O
t O O
1 O O
( O O
x O O
( O O
cid:48 O O
) O O
i O O
) O O
∇i1 O O
( O O
x O O
( O O
cid:48 O O
) O O
i O O
) O O
] O O
j O O
x O O
( O O
cid:48 O O
) O O
( O O
xi O O
) O O
b O O
= O O
− O O
( O O
cid:88 O O
) O O
i O O
x O O
( O O
cid:48 O O
) O O
( O O
xi O O
) O O
[ O O
ei∇i O O
t O O
j O O
t O O
1 O O
( O O
x O O
( O O
cid:48 O O
) O O
i O O
) O O
] O O
. O O
5. O O
train O O
and O O
test O O
a O O
classiﬁer O O
that O O
uses O O
the O O
individual O O
feature B B
matching O O
ids O O
as O O
well O O
as O O
( O O
op- O O
tionally O O
) O O
the O O
feature B B
locations O O
to O O
perform O O
face B B
recognition O O
. O O
consider O O
the O O
orthographic B O
and O O
weak O O
perspective O B
projection O O
models O O
introduced O O
in O O
equations B B
( O O
2.47–2.49 O O
) O O
. O O
14.3 O O
instance B B
recognition O O
687 O O
( O O
a O O
) O O
( O O
b O O
) O O
( O O
c O O
) O O
( O O
d O O
) O O
figure O O
14.27 O O
3d O O
object O O
recognition B B
with O O
afﬁne B B
regions O O
( O O
rothganger O O
, O O
lazebnik O O
, O O
schmid O O
et O O
al O O
. O O
the O O
resulting O O
warps O O
are O O
not O O
identical O O
because O O
line O O
lengths O O
or O O
distances O O
to O O
lines B B
may O O
be O O
different O O
. O O
computer O O
vision O O
and O O
image B B
understanding O O
, O O
73 O O
( O O
1 O O
) O O
:82–98 O O
. O O
researchers O O
noticed O O
that O O
a O O
lot O O
of O O
the O O
stereo B B
, O O
ﬂow O O
, O O
shape-from-x O O
, O O
and O O
edge O O
detection O O
al- O O
1.2 O O
a O O
brief O O
history O O
15 O O
gorithms O O
could O O
be O O
uniﬁed O O
, O O
or O O
at O O
least O O
described O O
, O O
using O O
the O O
same O O
mathematical O O
framework O O
if O O
they O O
were O O
posed O O
as O O
variational O O
optimization O O
problems O O
( O O
see O O
section O O
3.7 O O
) O O
and O O
made O O
more O O
ro- O O
bust O O
( O O
well-posed O O
) O O
using O O
regularization O O
( O O
figure O O
1.8e O O
) O O
( O O
see O O
section O O
3.7.1 O O
and O O
terzopoulos O O
1983 O O
; O O
poggio O O
, O O
torre O O
, O O
and O O
koch O O
1985 O O
; O O
terzopoulos O O
1986b O O
; O O
blake O O
and O O
zisserman O O
1987 O O
; O O
bertero O O
, O O
pog- O O
gio O O
, O O
and O O
torre O O
1988 O O
; O O
terzopoulos O O
1988 O O
) O O
. O O
the O O
results O O
can O O
be O O
quite O O
good O O
, O O
as O O
seen O O
in O O
the O O
normalized B B
zero O O
image B I
in O O
figure O O
3.13 O O
. O O
the O O
deformation O O
of O O
the O O
shadow B B
as O O
it O O
crosses O O
the O O
object O O
being O O
scanned O O
then O O
reveals O O
its O O
3d O O
shape O O
, O O
as O O
with O O
regular O O
light B B
stripe I O
rangeﬁnding O O
( O O
exercise O O
12.2 O O
) O O
. O O
360 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
additional O O
cues O O
, O O
such O O
as O O
the O O
appearance O O
and O O
disappearance O O
of O O
points B B
, O O
or O O
perspective B B
effects O O
, O O
both O O
of O O
which O O
are O O
discussed O O
below O O
, O O
can O O
be O O
used O O
to O O
remove O O
this O O
ambiguity O O
. O O
a O O
boundary-fragment-model O O
for O O
object O O
detection B B
. O O
graphcut O O
textures O O
: O O
image B B
and O O
video B B
synthesis O O
using O O
graph O O
cuts O O
. O O
a O O
least B B
squares I I
solution O O
to O O
this O O
problem O O
is O O
to O O
ﬁnd O O
the O O
minimum O O
of O O
the O O
sum O O
of O O
squared O O
differences O O
( O O
ssd O O
) O O
function O O
essd O O
( O O
u O O
) O O
= O O
( O O
cid:88 O O
) O O
i O O
[ O O
i1 O O
( O O
xi O O
+ O O
u O O
) O O
− O O
i0 O O
( O O
xi O O
) O O
] O O
2 O O
= O O
( O O
cid:88 O O
) O O
i O O
e2 O O
i O O
, O O
( O O
8.1 O O
) O O
where O O
u O O
= O O
( O O
u O O
, O O
v O O
) O O
is O O
the O O
displacement O O
and O O
ei O O
= O O
i1 O O
( O O
xi O O
+ O O
u O O
) O O
− O O
i0 O O
( O O
xi O O
) O O
is O O
called O O
the O O
residual O O
error O O
( O O
or O O
the O O
displaced O O
frame O O
difference O O
in O O
the O O
video B B
coding O O
literature O O
) O O
.1 O O
( O O
we O O
ignore O O
for O O
the O O
moment O O
the O O
possibility O O
that O O
parts O O
of O O
i0 O O
may O O
lie O O
outside O O
the O O
boundaries O O
of O O
i1 O O
or O O
be O O
otherwise O O
not O O
visible O O
. O O
when O O
a O O
user O O
participates O O
in O O
a O O
desktop O O
video-conference O O
or O O
video B B
chat O O
, O O
the O O
camera B B
is O O
usually O O
placed O O
on O O
top O O
of O O
the O O
monitor O O
. O O
figure O O
7.13 O O
shows O O
an O O
example O O
of O O
the O O
skeletal B O
set I O
computed O O
for O O
784 O O
images O O
of O O
the O O
pantheon O O
in O O
rome O O
. O O
fully O O
automated B B
single O O
image B B
matting O O
results O O
have O O
also O O
been O O
reported O O
( O O
levin O O
, O O
acha O O
, O O
and O O
lischinski O O
2008 O O
; O O
singaraju O O
, O O
rother O O
, O O
and O O
rhemann O O
2009 O O
) O O
. O O
( O O
2008 O O
) O O
, O O
who O O
use O O
a O O
coarse-to-ﬁne B B
strategy O O
with O O
per-pixel O O
2d O O
uncertainty B B
estimates O O
, O O
which O O
are O O
then O O
used O O
to O O
guide O O
the O O
reﬁnement O O
and O O
search O O
at O O
the O O
next O O
ﬁner O O
level O O
. O O
11.2 O O
sparse B B
correspondence I I
. O O
these O O
bases O O
are O O
widely O O
used O O
in O O
image B B
and O O
video B B
compression I I
standards O O
such O O
as O O
jpeg O O
. O O
in O O
ieee O O
computer O O
society O O
conference O O
on O O
computer O O
vision O O
and O O
pattern O O
recognition B B
( O O
cvpr O O
2009 O O
) O O
, O O
miami O O
beach O O
, O O
fl O O
. O O
the O O
simplest O O
ﬁlter O O
to O O
implement O O
is O O
the O O
moving B O
average I O
or O O
box O O
ﬁlter O O
, O O
which O O
simply O O
averages O O
the O O
pixel O O
values O O
in O O
a O O
k O O
× O O
k O O
window O O
. O O
two-screen O O
matting B B
. O O
again O O
, O O
while O O
quadric O O
surfaces O O
are O O
useful O O
in O O
the O O
study O O
of O O
multi-view B B
geometry O O
and O O
can O O
also O O
serve O O
as O O
useful O O
modeling B B
primitives O O
( O O
spheres O O
, O O
ellipsoids O O
, O O
cylinders O O
) O O
, O O
we O O
do O O
not O O
study O O
them O O
in O O
great O O
detail O O
in O O
this O O
book O O
. O O
how O O
about O O
steering O O
a O O
directional O O
second O O
derivative O O
ﬁlter O O
∇ˆu O O
· O O
∇ˆugˆu O O
, O O
which O O
is O O
the O O
result O O
of O O
taking O O
a O O
( O O
smoothed O O
) O O
directional B O
derivative I O
and O O
then O O
taking O O
the O O
directional B O
derivative I I
again O O
? O O
for O O
example O O
, O O
gxx O O
is O O
the O O
second O O
directional O O
derivative O O
in O O
the O O
x O O
direction O O
. O O
to O O
build O O
up O O
their O O
models O O
, O O
they O O
ﬁrst O O
associate O O
a O O
lumitexels O O
, O O
which O O
contains O O
a O O
3d O O
position O O
, O O
a O O
surface B B
normal O O
, O O
and O O
a O O
set O O
of O O
sparse B B
radiance O O
samples O O
, O O
with O O
each O O
surface B B
point O O
. O O
explicit O O
surface B B
representations O O
, O O
such O O
as O O
triangle O O
meshes O O
, O O
splines B B
( O O
farin O O
1992 O O
, O O
1996 O O
) O O
, O O
and O O
subdivision O O
sur- O O
faces B B
( O O
stollnitz O O
, O O
derose O O
, O O
and O O
salesin O O
1996 O O
; O O
zorin O O
, O O
schr¨oder O O
, O O
and O O
sweldens O O
1996 O O
; O O
warren O O
and O O
weimer O O
2001 O O
; O O
peters O O
and O O
reif O O
2008 O O
) O O
, O O
enable O O
not O O
only O O
the O O
creation O O
of O O
highly O O
detailed O O
models O O
but O O
also O O
processing O O
operations O O
, O O
such O O
as O O
interpolation B B
( O O
section O O
12.3.1 O O
) O O
, O O
fairing O O
or O O
smoothing B B
, O O
and O O
decimation O O
and O O
simpliﬁcation B O
( O O
section O O
12.3.2 O O
) O O
. O O
computer O O
vision O O
and O O
image B B
understanding O O
, O O
104 O O
( O O
2-3 O O
) O O
:190–209 O O
. O O
similar O O
improvements O O
from O O
using O O
spatio-temporal O O
selection O O
are O O
reported O O
by O O
( O O
kang O O
and O O
szeliski O O
2004 O O
) O O
and O O
are O O
evident O O
even O O
when O O
local B B
measurements O O
are O O
combined O O
with O O
global O O
optimization O O
. O O
( O O
10.7 O O
) O O
putting O O
all O O
of O O
these O O
terms O O
together O O
, O O
they O O
obtain O O
a O O
least B B
squares I I
problem O O
in O O
the O O
unknowns O O
{ O O
gk O O
} O O
and O O
{ O O
ei O O
} O O
, O O
e O O
= O O
( O O
cid:88 O O
) O O
i O O
( O O
cid:88 O O
) O O
j O O
w O O
( O O
zi O O
, O O
j O O
) O O
[ O O
g O O
( O O
zi O O
, O O
j O O
) O O
− O O
log O O
ei O O
− O O
log O O
tj O O
] O O
2 O O
+ O O
λ O O
( O O
cid:88 O O
) O O
k O O
w O O
( O O
k O O
) O O
g O O
( O O
cid:48 O O
) O O
( O O
cid:48 O O
) O O
( O O
k O O
) O O
2 O O
. O O
power O O
watersheds O O
: O O
a O O
new O O
image B B
segmentation O O
framework O O
extending O O
graph B B
cuts I I
, O O
random B O
walker I O
and O O
optimal O O
spanning O O
814 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
forest O O
. O O
if O O
the O O
object O O
being O O
tracked O O
or O O
recognized O O
has O O
large O O
variations O O
in O O
location O O
, O O
scale O O
, O O
or O O
ori- O O
entation O O
, O O
these O O
can O O
be O O
modeled O O
as O O
an O O
additional O O
transformation O O
on O O
the O O
control O O
points B B
, O O
e.g. O O
, O O
x O O
( O O
cid:48 O O
) O O
k O O
= O O
srxk O O
+ O O
t O O
( O O
2.18 O O
) O O
, O O
which O O
can O O
be O O
estimated O O
at O O
the O O
same O O
time O O
as O O
the O O
values O O
of O O
the O O
control O O
points B B
. O O
the O O
term O O
super- O O
resolution O O
usually O O
describes O O
techniques O O
for O O
aligning O O
and O O
merging B B
multiple O O
images O O
to O O
produce O O
higher-resolution O O
composites O O
( O O
keren O O
, O O
peleg O O
, O O
and O O
brada O O
1988 O O
; O O
irani O O
and O O
peleg O O
1991 O O
; O O
cheese- O O
man O O
, O O
kanefsky O O
, O O
hanson O O
et O O
al O O
. O O
a O O
more O O
direct B B
method O O
is O O
to O O
treat O O
the O O
2d O O
kernel B B
as O O
a O O
2d O O
matrix O O
k O O
and O O
to O O
take O O
its O O
singular O O
value O O
decomposition O O
( O O
svd O O
) O O
, O O
σiuivt O O
i O O
( O O
3.21 O O
) O O
k O O
= O O
( O O
cid:88 O O
) O O
i O O
( O O
see O O
appendix O O
a.1.1 O O
for O O
the O O
deﬁnition O O
of O O
the O O
svd O O
) O O
. O O
a O O
matte-less O O
, O O
variational O O
approach O O
to O O
automatic B B
scene O O
compositing B B
. O O
the O O
basic O O
idea O O
behind O O
fusion O O
moves O O
is O O
to O O
replace O O
portions O O
of O O
the O O
current O O
best O O
estimate O O
with O O
hypotheses O O
generated O O
by O O
more O O
basic O O
techniques O O
( O O
or O O
their O O
shifted O O
versions O O
) O O
and O O
to O O
alternate O O
them O O
with O O
local O O
gradient B O
descent I I
for O O
better O O
energy O O
minimization O O
. O O
it O O
is O O
therefore O O
a O O
good O O
idea O O
to O O
think O O
carefully O O
about O O
the O O
problem O O
at O O
hand O O
and O O
to O O
implement O O
several O O
approaches O O
( O O
successive B O
approximation I O
, O O
hough O O
, O O
and O O
ransac O O
) O O
to O O
determine O O
the O O
one O O
that O O
works O O
best O O
for O O
your O O
application O O
. O O
because O O
the O O
number O O
of O O
non-zero O O
ti O O
terms O O
in O O
a O O
typical O O
query O O
or O O
document O O
is O O
small O O
( O O
m O O
≈ O O
200 O O
) O O
compared O O
to O O
the O O
number O O
of O O
visual B B
words I I
( O O
v O O
≈ O O
20 O O
, O O
000 O O
) O O
, O O
the O O
distance O O
between O O
pairs B B
of O O
( O O
sparse B B
) O O
tf-idf O O
vectors O O
can O O
be O O
computed O O
quite O O
quickly O O
. O O
the O O
resulting O O
mis-alignment O O
can O O
be O O
used O O
to O O
improve O O
the O O
estimate O O
of O O
the O O
focal O O
length O O
and O O
to O O
re-adjust O O
the O O
rotation O O
estimates O O
, O O
as O O
described O O
in O O
section O O
9.1.4. O O
rotating O O
the O O
camera B B
by O O
90◦ O O
around O O
its O O
optic O O
axis O O
and O O
re-shooting O O
the O O
panorama O O
is O O
a O O
good O O
way O O
to O O
check O O
for O O
aspect O O
ratio O O
and O O
skew O O
pixel O O
problems O O
, O O
as O O
is O O
generating O O
a O O
full O O
hemi-spherical O O
panorama O O
when O O
there O O
is O O
sufﬁcient O O
texture B O
. O O
12.6 O O
model-based B O
reconstruction O O
. O O
newer O O
tech- O O
niques O O
such O O
as O O
local B B
feature I O
analysis I O
( O O
penev O O
and O O
atick O O
1996 O O
) O O
and O O
elastic O O
bunch O O
graph O O
match- O O
ing O O
( O O
wiskott O O
, O O
fellous O O
, O O
kr¨uger O O
et O O
al O O
. O O
an O O
integrated O O
bayesian O O
approach O O
to O O
layer O O
extraction O O
from O O
image B B
sequences O O
. O O
note O O
also O O
that O O
the O O
individual O O
difference-from-mean O O
images O O
ai O O
= O O
xi O O
− O O
¯x O O
are O O
long O O
vectors O O
of O O
length O O
p O O
( O O
the O O
number O O
of O O
pixels O O
in O O
the O O
image B B
) O O
, O O
while O O
the O O
total B B
number O O
of O O
ex- O O
emplars O O
n O O
( O O
the O O
number O O
of O O
faces B B
in O O
the O O
training O O
database O O
) O O
is O O
much O O
smaller O O
. O O
if O O
we O O
are O O
going O O
to O O
approximate O O
faces B B
by O O
a O O
linear B B
subspace O O
, O O
it O O
is O O
more O O
useful O O
to O O
have O O
a O O
space O O
that O O
discriminates O O
between O O
different O O
classes O O
( O O
people O O
) O O
and O O
is O O
less O O
sensitive O O
to O O
within-class B O
variations O O
( O O
belhumeur O O
, O O
hespanha O O
, O O
and O O
kriegman O O
1997 O O
) O O
. O O
tracking O O
with O O
kalman O O
snakes B B
. O O
overlapping O O
patches O O
are O O
extracted O O
from O O
different O O
levels O O
of O O
a O O
pyramid B B
and O O
then O O
pre-processed O O
as O O
shown O O
in O O
figure O O
14.3b O O
. O O
) O O
, O O
practical O O
image B B
processing O O
and O O
computer O O
vision O O
, O O
john O O
wiley O O
. O O
high-quality O O
techniques O O
for O O
optimal O O
seam O O
ﬁnding O O
and O O
blending B B
are O O
another O O
important O O
component O O
of O O
image B B
stitching I O
systems O O
. O O
( O O
no- O O
tice O O
how O O
the O O
least B O
squares I I
variant O O
of O O
the O O
conjugate B B
gradient I I
algorithm O O
splits O O
the O O
multiplication B B
by O O
the O O
c O O
= O O
at O O
a O O
matrix O O
across O O
steps O O
4 O O
and O O
8 O O
. O O
a O O
more O O
complete O O
ana- O O
lytic O O
model O O
also O O
includes O O
tangential B O
distortions O O
and O O
decentering B O
distortions O O
( O O
slama O O
1980 O O
) O O
, O O
but O O
these O O
distortions O O
are O O
not O O
covered O O
in O O
this O O
book O O
. O O
4.1.3 O O
feature B B
matching O O
once O O
we O O
have O O
extracted O O
features O O
and O O
their O O
descriptors O O
from O O
two O O
or O O
more O O
images O O
, O O
the O O
next O O
step O O
is O O
to O O
establish O O
some O O
preliminary O O
feature B B
matches O O
between O O
these O O
images O O
. O O
traditional O O
approaches O O
associated O O
with O O
regularization O O
and O O
markov O O
random O O
ﬁelds O O
include O O
continuation O O
( O O
blake O O
and O O
zisserman O O
1987 O O
) O O
, O O
simulated B O
annealing I I
( O O
geman O O
and O O
geman O O
1984 O O
; O O
marroquin O O
, O O
mitter O O
, O O
and O O
poggio O O
1987 O O
; O O
barnard O O
1989 O O
) O O
, O O
highest B O
conﬁdence I O
ﬁrst I O
( O O
chou O O
and O O
brown O O
1990 O O
) O O
, O O
and O O
mean-ﬁeld O O
annealing O O
( O O
geiger O O
and O O
girosi O O
1991 O O
) O O
. O O
1. O O
extract O O
your O O
layers B B
using O O
the O O
technique O O
you O O
developed O O
in O O
exercise O O
8.9 O O
. O O
the O O
mapping O O
equation B B
( O O
2.70 O O
) O O
thus O O
reduces O O
to O O
˜x1 O O
∼ O O
˜h O O
10 O O
˜x0 O O
, O O
( O O
2.71 O O
) O O
where O O
˜h O O
10 O O
is O O
a O O
general O O
3 O O
× O O
3 O O
homography B B
matrix O O
and O O
˜x1 O O
and O O
˜x0 O O
are O O
now O O
2d O O
homogeneous B O
coordinates I O
( O O
i.e. O O
, O O
3-vectors O O
) O O
( O O
szeliski O O
1996 O O
) O O
.this O O
justiﬁes O O
the O O
use O O
of O O
the O O
8-parameter O O
homog- O O
raphy O O
as O O
a O O
general O O
alignment B B
model O O
for O O
mosaics O O
of O O
planar O B
scenes O O
( O O
mann O O
and O O
picard O O
1994 O O
; O O
szeliski O O
1996 O O
) O O
. O O
14.5 O O
context B B
and O O
scene B B
understanding I I
713 O O
( O O
a O O
) O O
( O O
b O O
) O O
( O O
c O O
) O O
figure O O
14.50 O O
contextual O O
scene O O
models O O
for O O
object O O
recognition B B
( O O
sudderth O O
, O O
torralba O O
, O O
freeman O O
et O O
al O O
. O O
in O O
that O O
case O O
, O O
the O O
cross-correlation O O
function O O
should O O
be O O
replaced O O
with O O
a O O
windowed B B
( O O
weighted B B
) O O
cross-correlation O O
function O O
, O O
ewcc O O
( O O
u O O
) O O
= O O
( O O
cid:88 O O
) O O
i O O
w0 O O
( O O
xi O O
) O O
i0 O O
( O O
xi O O
) O O
w1 O O
( O O
xi O O
+ O O
u O O
) O O
i1 O O
( O O
xi O O
+ O O
u O O
) O O
, O O
= O O
[ O O
w0 O O
( O O
x O O
) O O
i0 O O
( O O
x O O
) O O
] O O
¯∗ O O
[ O O
w1 O O
( O O
x O O
) O O
i1 O O
( O O
x O O
) O O
] O O
( O O
8.21 O O
) O O
( O O
8.22 O O
) O O
where O O
the O O
weighting B B
functions O O
w0 O O
and O O
w1 O O
are O O
zero O O
outside O O
the O O
valid O O
ranges O O
of O O
the O O
images O O
and O O
both O O
images O O
are O O
padded O O
so O O
that O O
circular O O
shifts O O
return O O
0 O O
values O O
outside O O
the O O
original O O
image B B
boundaries O O
. O O
12.2.1 O O
range O O
data O O
merging B B
. O O
2. O O
at O O
render O O
time O O
, O O
use O O
the O O
rigid O O
geometry O O
to O O
determine O O
the O O
new O O
pixel O O
location O O
but O O
then O O
add O O
a O O
fraction O O
of O O
the O O
non-rigid B B
displacement O O
as O O
well O O
. O O
patches O O
with O O
large O O
contrast O O
changes O O
( O O
gradients O O
) O O
are O O
easier O O
to O O
localize O O
, O O
although O O
straight O O
line O O
segments O O
at O O
a O O
single O O
orientation O O
suffer O O
from O O
the O O
aperture B O
problem I O
( O O
horn O O
and O O
schunck O O
1981 O O
; O O
lucas O O
and O O
kanade O O
1981 O O
; O O
anandan O O
1989 O O
) O O
, O O
i.e. O O
, O O
it O O
is O O
only O O
possible O O
to O O
align O O
the O O
patches O O
along O O
the O O
direction O O
normal O O
to O O
the O O
edge O O
direction O O
( O O
figure O O
4.4b O O
) O O
. O O
object O O
detection B B
using O O
the O O
statistics O O
of O O
parts O O
. O O
( O O
for O O
bright O O
scenes O O
, O O
where O O
a O O
large O O
aperture O O
or O O
slow O O
shutter O O
speed O O
are O O
desired O O
to O O
get O O
a O O
shallow O O
depth O O
of O O
ﬁeld O O
or O O
motion B B
blur O O
, O O
neutral O O
density O O
ﬁlters O O
are O O
sometimes O O
used O O
by O O
photographers O O
. O O
anisotropic B B
diffusion O O
in O O
image B B
processing O O
. O O
2.1 O O
geometric B B
primitives O O
and O O
transformations O O
in O O
this O O
section O O
, O O
we O O
introduce O O
the O O
basic O O
2d O O
and O O
3d O O
primitives O O
used O O
in O O
this O O
textbook O O
, O O
namely O O
points B B
, O O
lines B B
, O O
and O O
planes B B
. O O
( O O
1999 O O
) O O
call O O
such O O
a O O
representation O O
an O O
environment B O
matte I O
, O O
since O O
it O O
generalizes O O
the O O
process O O
of O O
object O O
matting B B
( O O
section O O
10.4 O O
) O O
to O O
not O O
only O O
cut O O
and O O
paste O O
an O O
object O O
from O O
one O O
image B B
into O O
another O O
but O O
also O O
take O O
into O O
account O O
the O O
subtle O O
refractive O O
or O O
reﬂective O O
interplay O O
between O O
the O O
object O O
and O O
its O O
environment O O
. O O
automatic B O
interpretation O O
and O O
coding O O
of O O
face B B
images O O
using O O
ﬂexible O O
models O O
. O O
in O O
the O O
future O O
, O O
the O O
need O O
to O O
compute O O
high B O
dynamic I I
range I I
images O O
from O O
multiple B B
exposures O O
may O O
be O O
eliminated O O
by O O
advances O O
in O O
camera B B
sensor O O
technology O O
( O O
figure O O
10.18 O O
) O O
( O O
yang O O
, O O
el O O
gamal O O
, O O
fowler O O
et O O
al O O
. O O
another O O
signiﬁcant O O
trend O O
from O O
this O O
past O O
decade O O
has O O
been O O
the O O
development O O
of O O
more O O
efﬁcient O O
algorithms O O
for O O
complex O O
global B B
optimization I I
problems O O
( O O
see O O
sections O O
3.7 O O
and O O
b.5 O O
and O O
szeliski O O
, O O
zabih O O
, O O
scharstein O O
et O O
al O O
. O O
scale B O
invariance I O
in O O
many O O
situations O O
, O O
detecting O O
features O O
at O O
the O O
ﬁnest O O
stable O O
scale O O
possible O O
may O O
not O O
be O O
appro- O O
priate O O
. O O
6.3.2 O O
vanishing B B
points I I
. O O
automatic B B
occlusion O O
removal O O
from O O
minimum O O
number O O
of O O
images O O
. O O
instead O O
of O O
computing O O
per-pixel O O
foreground O O
and O O
background O O
colors O O
, O O
levin O O
, O O
lischinski O O
, O O
and O O
weiss O O
( O O
2008 O O
) O O
assume O O
only O O
that O O
these O O
color B B
distribution O O
can O O
locally O O
be O O
well O O
approximated O O
as O O
mixtures O O
of O O
two O O
colors O O
, O O
which O O
is O O
known O O
as O O
the O O
color B B
line O O
model O O
( O O
figure O O
10.43a–c O O
) O O
. O O
shadow B B
matting O O
. O O
high O O
quality O O
rendering B B
using O O
the O O
talisman O O
architecture B B
. O O
once O O
we O O
have O O
aligned O O
the O O
images O O
, O O
we O O
must O O
choose O O
a O O
ﬁnal O O
compositing B B
surface O O
for O O
warping O O
the O O
aligned O O
images O O
( O O
section O O
9.3.1 O O
) O O
. O O
bayesian O O
inference B B
techniques O O
can O O
then O O
be O O
used O O
to O O
combine O O
prior B B
and O O
measurement O O
models O O
to O O
estimate O O
the O O
unknowns O O
and O O
to O O
model O O
their O O
uncertainty B B
. O O
the O O
afﬁne B B
transform O O
is O O
written O O
as O O
x O O
( O O
cid:48 O O
) O O
= O O
a¯x O O
, O O
where O O
a O O
is O O
an O O
arbitrary O O
3 O O
× O O
4 O O
matrix O O
, O O
i.e. O O
, O O
x O O
( O O
cid:48 O O
) O O
= O O
a00 O O
a01 O O
a02 O O
a03 O O
a10 O O
a11 O O
a12 O O
a13 O O
a20 O O
a21 O O
a22 O O
a23 O O
 O O
¯x O O
. O O
the O O
best O O
choice O O
of O O
representation O O
and O O
rendering B B
algorithm O O
depends O O
on O O
both O O
the O O
quantity O O
and O O
quality O O
of O O
the O O
input O O
imagery O O
as O O
well O O
as O O
the O O
intended O O
application O O
. O O
3.2 O O
linear B B
ﬁltering O O
. O O
the O O
situation O O
becomes O O
more O O
involved O O
when O O
more O O
than O O
one O O
source O O
image B B
is O O
available O O
for O O
appearance O O
recovery B B
, O O
which O O
is O O
the O O
usual O O
case O O
. O O
to O O
compute O O
a O O
layered B B
representation O O
of O O
a O O
video B B
sequence O O
, O O
wang O O
and O O
adelson O O
( O O
1994 O O
) O O
ﬁrst O O
estimate O O
afﬁne B B
motion O O
models O O
over O O
a O O
collection O O
of O O
non-overlapping O O
patches O O
and O O
then O O
cluster O O
these O O
estimates O O
using O O
k-means O O
. O O
two-dimensional B B
signal O O
and O O
image B B
processing O O
. O O
this O O
is O O
exactly O O
the O O
same O O
kind O O
of O O
motion B B
that O O
you O O
would O O
use O O
if O O
you O O
had O O
overlapping O O
photographic O O
prints O O
. O O
once O O
you O O
have O O
aggregated O O
the O O
costs O O
in O O
the O O
dsi O O
, O O
pick O O
the O O
winner O O
at O O
each O O
pixel O O
( O O
winner-take- O O
all O O
) O O
, O O
and O O
then O O
optionally O O
perform O O
one O O
or O O
more O O
of O O
the O O
following O O
post-processing O O
steps O O
: O O
1. O O
compute O O
matches O O
both O O
ways O O
and O O
pick O O
only O O
the O O
reliable O O
matches O O
( O O
draw O O
the O O
others O O
in O O
another O O
color B B
) O O
; O O
2. O O
tag O O
matches O O
that O O
are O O
unsure O O
( O O
whose O O
conﬁdence O O
is O O
too O O
low O O
) O O
; O O
3. O O
ﬁll O O
in O O
the O O
matches O O
that O O
are O O
unsure O O
from O O
neighboring O O
values O O
; O O
4. O O
reﬁne O O
your O O
matches O O
to O O
sub-pixel O O
disparity O O
by O O
either O O
ﬁtting O O
a O O
parabola O O
to O O
the O O
dsi O O
values O O
around O O
the O O
winner O O
or O O
by O O
using O O
an O O
iteration O O
of O O
lukas–kanade O O
. O O
video B B
compression I I
using O O
mosaic O O
representa- O O
tions O O
. O O
the O O
two-dimensional B B
discrete O O
data O O
energy O O
is O O
written O O
as O O
ed O O
= O O
( O O
cid:88 O O
) O O
i O O
, O O
j O O
w O O
( O O
i O O
, O O
j O O
) O O
[ O O
f O O
( O O
i O O
, O O
j O O
) O O
− O O
d O O
( O O
i O O
, O O
j O O
) O O
] O O
2 O O
, O O
( O O
3.101 O O
) O O
where O O
the O O
local B B
weights O O
w O O
( O O
i O O
, O O
j O O
) O O
control O O
how O O
strongly O O
the O O
data O O
constraint O O
is O O
enforced O O
. O O
7.4 O O
bundle B O
adjustment I I
7.3 O O
factorization B B
. O O
1. O O
convert O O
your O O
image B B
to O O
l*a*b* O O
space O O
, O O
or O O
keep O O
the O O
original O O
rgb O O
colors O O
, O O
and O O
augment O O
them O O
with O O
the O O
pixel O O
( O O
x O O
, O O
y O O
) O O
locations O O
. O O
unlike O O
regular O O
super-resolution O O
, O O
where O O
small O O
errors O O
in O O
guessing O O
unknown O O
values O O
usually O O
show O O
up O O
as O O
blur O O
or O O
aliasing B B
, O O
demosaicing B B
artifacts O O
often O O
produce O O
spurious O O
colors O O
or O O
high-frequency O O
patterned O O
zippering O O
, O O
which O O
are O O
quite O O
visible O O
to O O
the O O
eye O O
( O O
figure O O
10.35b O O
) O O
. O O
tv-l1 O O
optical B O
ﬂow I O
on O O
the O O
gpu O O
, O O
http O O
: O O
//cs.unc.edu/∼cmzach/opensource.html O O
( O O
zach O O
, O O
pock O O
, O O
and O O
bischof O O
2007a O O
) O O
. O O
to O O
construct O O
the O O
pyramid B B
, O O
we O O
ﬁrst O O
blur O O
and O O
sub- O O
sample O O
the O O
original O O
image B B
by O O
a O O
factor O O
of O O
two O O
and O O
store O O
this O O
in O O
the O O
next O O
level O O
of O O
the O O
pyramid B B
( O O
figure O O
3.33 O O
) O O
. O O
3.1 O O
point O O
operators O O
101 O O
now O O
that O O
we O O
have O O
seen O O
how O O
images O O
are O O
formed O O
through O O
the O O
interaction O O
of O O
3d O O
scene O O
elements O O
, O O
lighting B B
, O O
and O O
camera B B
optics O O
and O O
sensors O O
, O O
let O O
us O O
look O O
at O O
the O O
ﬁrst O O
stage O O
in O O
most O O
computer O O
vision O O
applications O O
, O O
namely O O
the O O
use O O
of O O
image B B
processing O O
to O O
preprocess O O
the O O
image B B
and O O
convert O O
it O O
into O O
a O O
form O O
suitable O O
for O O
further O O
analysis O O
. O O
in O O
order B B
to O O
reduce O O
the O O
bias O B
towards O O
longer O O
focal O O
lengths O O
, O O
we O O
multiply O O
each O O
residual O O
( O O
3d O O
error O O
) O O
by O O
( O O
cid:112 O O
) O O
fjfk O O
, O O
which O O
is O O
similar O O
to O O
projecting O O
the O O
3d O O
rays O O
into O O
a O O
“ O O
virtual O O
camera O O
” O O
of O O
intermediate O O
focal O O
length O O
. O O
9.1.6 O O
cylindrical B B
and O O
spherical B B
coordinates O O
. O O
each O O
image B B
shows O O
a O O
video B B
frame O O
along O O
with O O
the O O
estimate O O
yaw O O
, O O
pitch O O
, O O
and O O
roll O O
parameters B B
and O O
the O O
ﬁtted O O
3d O O
deformable O O
mesh O O
. O O
as O O
we O O
will O O
see O O
in O O
this O O
section O O
, O O
it O O
can O O
greatly O O
improve O O
the O O
performance O O
of O O
object O O
recognition B B
algorithms O O
( O O
divvala O O
, O O
hoiem O O
, O O
hays O O
et O O
al O O
. O O
the O O
relationship O O
of O O
this O O
approximation O O
to O O
feature-based B B
registration O O
is O O
discussed O O
in O O
section O O
9.2.4. O O
compositional B O
approach O O
. O O
2004 O O
) O O
often O O
precompute O O
such O O
a O O
segmentation B B
using O O
either O O
the O O
watershed B B
or O O
the O O
related O O
tobogganing B O
technique O O
( O O
section O O
5.1.3 O O
) O O
. O O
( O O
8.47 O O
) O O
398 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
note O O
that O O
here O O
, O O
in O O
deriving O O
the O O
lucas–kanade O O
update O O
from O O
the O O
original O O
weighted B B
ssd O O
function O O
( O O
8.5 O O
) O O
, O O
we O O
have O O
neglected O O
taking O O
the O O
derivative O O
of O O
the O O
w1 O B
( O O
xi O O
+ O O
u O O
) O O
weighting B B
function O O
with O O
respect O O
to O O
u O O
, O O
which O O
is O O
usually O O
acceptable O O
in O O
practice O O
, O O
especially O O
if O O
the O O
weighting B B
function O O
is O O
a O O
binary O O
mask O O
with O O
relatively O O
few O O
transitions O O
. O O
apply O O
your O O
region B B
segmentation O O
to O O
a O O
video B B
sequence O O
and O O
use O O
it O O
to O O
track O O
moving O O
regions O O
from O O
frame O O
to O O
frame O O
. O O
of O O
course O O
, O O
many O O
other O O
approaches O O
have O O
been O O
developed O O
for O O
detecting O O
color B B
edges O O
, O O
dating O O
back O O
to O O
early O O
work O O
by O O
nevatia O O
( O O
1977 O O
) O O
. O O
the O O
local B B
2d O O
psf O O
estimation B B
technique O O
can O O
also O O
be O O
used O O
to O O
estimate O O
vignetting B B
. O O
improving O O
color B B
modeling O O
for O O
alpha O O
matting B B
. O O
instead O O
, O O
we O O
use O O
a O O
direct B B
model O O
for O O
the O O
posterior B B
distribution I O
p O O
( O O
x|y O O
) O O
, O O
whose O O
negative O O
log O O
likelihood O O
can O O
be O O
written O O
as O O
e O O
( O O
x|y O O
) O O
= O O
ed O O
( O O
x O O
, O O
y O O
) O O
+ O O
es O O
( O O
x O O
, O O
y O O
) O O
vp O O
( O O
xp O O
, O O
y O O
) O O
+ O O
( O O
cid:88 O O
) O O
( O O
p O O
, O O
q O O
) O O
∈n O O
= O O
( O O
cid:88 O O
) O O
p O O
vp O O
, O O
q O O
( O O
xp O O
, O O
xq O O
, O O
y O O
) O O
, O O
( O O
3.118 O O
) O O
using O O
the O O
notation O O
introduced O O
in O O
( O O
3.116 O O
) O O
. O O
single-frame O O
human O O
detection O B
and O O
pose O O
estimation B B
algorithms O O
can O O
sometimes O O
be O O
used O O
by O O
themselves O O
to O O
perform O O
tracking O O
( O O
ramanan O O
, O O
forsyth O O
, O O
and O O
zisserman O O
2005 O O
; O O
rogez O O
, O O
rihan O O
, O O
ra- O O
malingam O O
et O O
al O O
. O O
these O O
observations O O
underlie O O
the O O
surface B B
light I O
ﬁeld I I
representation O O
introduced O O
by O O
wood O O
, O O
azuma O O
, O O
aldinger O O
et O O
al O O
. O O
middlebury O O
color B B
datasets O O
: O O
registered O O
color B B
images O O
taken O O
by O O
different O O
cameras O O
to O O
study O O
how O O
they O O
transform B B
gamuts O O
and O O
colors O O
, O O
http O O
: O O
//vision.middlebury.edu/color/data/ O O
( O O
chakrabarti O O
, O O
scharstein O O
, O O
and O O
zickler O O
2009 O O
) O O
. O O
550 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
ing O O
cost O O
based O O
on O O
its O O
color B B
similarity I O
and O O
spatial O O
distance O O
, O O
just O O
as O O
in O O
bilinear B B
ﬁltering O I
( O O
fig- O O
ure O O
11.9c O O
) O O
. O O
for O O
interior O O
modeling B B
, O O
instead O O
of O O
working O O
with O O
single O O
pictures O O
, O O
it O O
is O O
more O O
useful O O
to O O
work O O
with O O
panoramas O O
, O O
since O O
you O O
can O O
see O O
larger O O
extents O O
of O O
walls O O
and O O
other O O
structures O O
. O O
multiresolution O O
sampling B B
procedure O O
for O O
analysis O O
and O O
synthesis O O
of O O
texture B B
images O O
. O O
( O O
massey O O
and O O
bender O O
1996 O O
) O O
and O O
sometimes O O
as O O
video B B
overlays O O
( O O
irani O O
and O O
anandan O O
1998 O O
) O O
. O O
correctcorrectincorrectcorrectcorrectcorrectcorrectcorrectcorrectcorrectcorrectcorrectcorrectcorrectcorrectcorrectcorrectcorrectincorrectincorrectcorrectincorrectcorrectcorrectcorrect O O
706 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
figure O O
14.43 O O
interleaved O O
recognition B B
and O O
segmentation B B
( O O
leibe O O
, O O
leonardis O O
, O O
and O O
schiele O O
2008 O O
) O O
c O O
( O O
cid:13 O O
) O O
2008 O O
springer O O
. O O
we O O
also O O
discuss O O
how O O
these O O
models O O
can O O
be O O
used O O
to O O
compute O O
the O O
global B B
illumination I O
corresponding O O
to O O
a O O
scene O O
. O O
the O O
ﬁrst O O
is O O
to O O
ﬁnd O O
features O O
in O O
one O O
image B B
that O O
can O O
be O O
accurately O O
tracked O O
using O O
a O O
local B B
search O O
tech- O O
nique O O
, O O
such O O
as O O
correlation O O
or O O
least B B
squares I I
( O O
section O O
4.1.4 O O
) O O
. O O
ultimately O O
, O O
however O O
, O O
the O O
most O O
principled O O
way O O
to O O
deal O O
with O O
exposure O O
differences O O
is O O
to O O
stitch O O
images O O
in O O
the O O
radiance O O
domain O O
, O O
i.e. O O
, O O
to O O
convert O O
each O O
image B B
into O O
a O O
radiance O O
image B B
using O O
its O O
exposure O O
value O O
and O O
then O O
create O O
a O O
stitched O O
, O O
high B O
dynamic I I
range I I
image O O
, O O
as O O
discussed O O
in O O
sec- O O
tion B B
10.2 O O
( O O
eden O O
, O O
uyttendaele O O
, O O
and O O
szeliski O O
2006 O O
) O O
. O O
sometimes O O
, O O
it O O
is O O
not O O
possible O O
to O O
ﬁnd O O
exactly O O
matching B B
subsequences O O
in O O
the O O
original O O
video B B
. O O
the O O
smoothness B B
weights O O
are O O
modulated O O
by O O
the O O
intensity O O
gradients O O
( O O
edges O O
) O O
, O O
which O O
makes O O
this O O
a O O
conditional O O
random O O
ﬁeld O O
( O O
crf O O
) O O
. O O
consider O O
, O O
for O O
example O O
, O O
the O O
camera B B
matrix O O
calibration B B
problem O O
( O O
section O O
6.2.1 O O
) O O
: O O
given O O
an O O
image B B
of O O
a O O
calibration B B
pattern O O
consisting O O
of O O
known O O
3d O O
point O O
positions O O
, O O
compute O O
the O O
3× O O
4 O O
camera B B
matrix O O
p O O
that O O
maps O O
these O O
points B B
onto O O
the O O
image B B
plane O O
. O O
11.4.1 O O
sub-pixel O O
estimation O B
and O O
uncertainty B B
. O O
620 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
( O O
a O O
) O O
( O O
d O O
) O O
( O O
b O O
) O O
( O O
e O O
) O O
( O O
g O O
) O O
( O O
h O O
) O O
( O O
c O O
) O O
( O O
f O O
) O O
( O O
i O O
) O O
figure O O
13.1 O O
image-based B B
and O O
video-based O O
rendering O O
: O O
( O O
a O O
) O O
a O O
3d O O
view O O
of O O
a O O
photo O O
tourism O O
re- O O
construction O O
( O O
snavely O O
, O O
seitz O O
, O O
and O O
szeliski O O
2006 O O
) O O
c O O
( O O
cid:13 O O
) O O
2006 O O
acm O O
; O O
( O O
b O O
) O O
a O O
slice O O
through O O
a O O
4d O O
light B O
ﬁeld I I
( O O
gortler O O
, O O
grzeszczuk O O
, O O
szeliski O O
et O O
al O O
. O O
feature-based B B
alignment O O
is O O
then O O
used O O
as O O
a O O
building O O
block O O
for O O
3d O O
pose O O
estimation B B
( O O
extrinsic B O
calibration O O
) O O
in O O
section O O
6.2 O O
and O O
camera B B
( O O
intrinsic B B
) O O
calibration B B
in O O
section O O
6.3. O O
chapter O O
6 O O
also O O
describes O O
applications O O
of O O
these O O
techniques O O
to O O
photo O O
alignment O B
for O O
ﬂip-book O O
animations O O
, O O
3d O O
pose O O
estimation B B
from O O
a O O
hand-held O O
camera B B
, O O
and O O
single-view O O
reconstruction O O
of O O
building O O
models O O
. O O
( O O
b O O
) O O
spatial O O
pyramid B B
matching O I
( O O
lazebnik O O
, O O
schmid O O
, O O
and O O
ponce O O
2006 O O
) O O
c O O
( O O
cid:13 O O
) O O
2006 O O
ieee O O
divides O O
the O O
image B B
into O O
a O O
pyramid B B
of O O
pooling O O
regions O O
and O O
computes O O
separate O O
visual O O
word O O
histograms O O
( O O
distributions O O
) O O
inside O O
each O O
spatial O O
bin O O
. O O
3d O O
model O O
acquisition O O
from O O
extended O O
in O O
fourth O O
european O O
conference O O
on O O
computer O O
vision O O
( O O
eccv O O
’ O O
96 O O
) O O
, O O
image B B
sequences O O
. O O
a O O
robustiﬁed O O
least B O
squares I O
estimate O O
( O O
appendix O O
b.3 O O
) O O
for O O
the O O
vanishing O O
point O O
can O O
therefore O O
be O O
written O O
as O O
wi O O
( O O
ai O O
) O O
mimt O O
i O O
( O O
cid:33 O O
) O O
v O O
= O O
vt O O
m O O
v O O
, O O
( O O
4.31 O O
) O O
e O O
= O O
( O O
cid:88 O O
) O O
i O O
ρ O O
( O O
ai O O
) O O
= O O
vt O O
( O O
cid:32 O O
) O O
( O O
cid:88 O O
) O O
i O O
where O O
mi O O
= O O
pi0 O O
× O O
pi1 O O
is O O
the O O
segment O O
line O O
equation O O
weighted B O
by O O
its O O
length O O
li O O
, O O
and O O
wi O O
= O O
ρ O O
( O O
cid:48 O O
) O O
( O O
ai O O
) O O
/ai O O
is O O
the O O
inﬂuence O O
of O O
each O O
robustiﬁed O O
( O O
reweighted O O
) O O
measurement O O
on O O
the O O
ﬁnal O O
error O O
( O O
appendix O O
b.3 O O
) O O
. O O
( O O
a.9 O O
) O O
if O O
the O O
matrix O O
c O O
is O O
of O O
full O O
rank O O
, O O
the O O
eigenvalues B B
are O O
all O O
positive O O
and O O
the O O
matrix O O
is O O
called O O
sym- O O
metric O O
positive O O
deﬁnite O O
( O O
spd O O
) O O
. O O
the O O
psf O O
is O O
a O O
combination O O
( O O
convolution O O
) O O
of O O
the O O
blur O O
induced O O
by O O
the O O
optical O O
system O O
( O O
lens O O
) O O
and O O
the O O
ﬁnite O O
integration O O
area O O
of O O
a O O
chip O O
sensor.16 O O
15 O O
the O O
actual O O
theorem O O
states O O
that O O
fs O O
must O O
be O O
at O O
least O O
twice O O
the O O
signal O O
bandwidth O O
but O O
, O O
since O O
we O O
are O O
not O O
dealing O O
with O O
modulated O O
signals O O
such O O
as O O
radio O O
waves O O
during O O
image B B
capture O O
, O O
the O O
maximum O O
frequency O O
sufﬁces O B
. O O
finally O O
, O O
markov O O
random O O
ﬁeld O O
models O O
can O O
be O O
deﬁned O O
over O O
discrete O B
variables O O
, O O
such O O
as O O
image B B
labels O O
( O O
where O O
the O O
variables O O
have O O
no O O
proper O O
ordering O O
) O O
, O O
for O O
which O O
regularization B B
does O O
not O O
apply O O
. O O
( O O
9.25 O O
) O O
for O O
multi-image O O
alignment B B
, O O
instead O O
of O O
having O O
a O O
single O O
collection O O
of O O
pairwise O O
feature B B
corre- O O
spondences O O
, O O
{ O O
( O O
xi O O
, O O
ˆx O O
( O O
cid:48 O O
) O O
i O O
) O O
} O O
, O O
we O O
have O O
a O O
collection O O
of O O
n O O
features O O
, O O
with O O
the O O
location O O
of O O
the O O
ith O O
feature B B
point O O
in O O
the O O
jth O O
image B O
denoted O O
by O O
xij O O
and O O
its O O
scalar O O
conﬁdence O O
( O O
i.e. O O
, O O
inverse B B
variance O O
) O O
denoted O O
by O O
cij.9 O O
each O O
image B B
also O O
has O O
some O O
associated O O
pose O O
parameters B B
. O O
ill-posed O O
problems O O
in O O
early O O
vision O O
: O O
from O O
computational B O
theory I O
to O O
analogue O O
networks O O
. O O
12.1 O O
shape O O
from O O
x O O
in O O
addition O O
to O O
binocular O O
disparity O O
, O O
shading B B
, O O
texture B B
, O O
and O O
focus B B
all O O
play O O
a O O
role O O
in O O
how O O
we O O
per- O O
ceive O O
shape O O
. O O
these O O
lines B B
are O O
then O O
used O O
to O O
infer O O
planes B B
and O O
a O O
block-structured O O
model O O
for O O
the O O
scene O O
, O O
as O O
described O O
in O O
more O O
detail O O
in O O
section O O
12.6.1 O O
. O O
if O O
only O O
the O O
ﬁrst O O
singular O O
value O O
σ0 O O
is O O
non-zero O O
, O O
the O O
kernel B B
is O O
separable B B
and O O
√σ0u0 O O
and O O
√σ0vt O O
0 O O
provide O O
the O O
vertical O O
and O O
horizontal O O
3.2 O O
linear B B
ﬁltering O O
117 O O
kernels O O
( O O
perona O O
1995 O O
) O O
. O O
ieee O O
transactions O O
on O O
image B B
processing O O
, O O
9 O O
( O O
5 O O
) O O
:889–896 O O
. O O
2010 O O
) O O
.2 O O
by O O
taking O O
the O O
time O O
to O O
train O O
classiﬁers O O
on O O
sample O O
patches O O
and O O
their O O
afﬁne B B
deformations O O
, O O
extremely O O
fast O O
and O O
reliable O O
feature B B
detectors O O
can O O
be O O
constructed O O
, O O
which O O
enables O O
much O O
faster O O
motions O O
to O O
be O O
supported O O
( O O
figure O O
4.29 O O
) O O
. O O
we O O
close O O
with O O
a O O
discussion O O
of O O
3d O O
videos O O
created O O
from O O
multiple B B
video O O
streams O O
( O O
section O O
13.5.4 O O
) O O
, O O
as O O
well O O
as O O
video-based B O
walkthroughs I O
of O O
environments O O
( O O
section O O
13.5.5 O O
) O O
, O O
which O O
have O O
found O O
widespread O O
application O O
in O O
immersive O O
outdoor O O
mapping O O
and O O
driving O O
direction O O
systems O O
. O O
note O O
that O O
for O O
color O O
images O O
, O O
it O O
may O O
be O O
necessary O O
to O O
estimate O O
a O O
different O O
bias B O
and I O
gain I O
for O O
each O O
color B B
channel O O
to O O
compensate O O
for O O
the O O
automatic B B
color O O
correction O O
performed O O
by O O
some O O
digital O O
cameras O O
( O O
section O O
2.3.2 O O
) O O
. O O
2031 O O
, O O
geometric B B
methods O O
in O O
computer O O
vision O O
ii O O
, O O
pp O O
. O O
others O O
, O O
however O O
, O O
focus B B
instead O O
on O O
accuracy B O
, O O
viewing O O
detection B B
as O O
a O O
more O O
challenging O O
variant O O
of O O
generic O O
class O O
recognition B B
( O O
section O O
14.4 O O
) O O
in O O
which O O
the O O
locations O O
and O O
extents O O
of O O
objects O O
are O O
to O O
be O O
determined O O
as O O
accurately O O
as O O
possible O O
. O O
note O O
that O O
iterating O O
equations B B
( O O
6.22 O O
) O O
is O O
not O O
guaranteed O O
to O O
converge O O
, O O
since O O
it O O
is O O
not O O
minimizing O O
a O O
well-deﬁned O O
energy O O
function O O
. O O
4. O O
take O O
many O O
pictures O O
at O O
different O O
distances O O
and O O
orientations O O
relative O O
to O O
the O O
calibration B B
target O O
and O O
report O O
on O O
both O O
your O O
re-projection O O
errors O O
and O O
accuracy B B
. O O
instead O O
, O O
a O O
natural B B
way O O
to O O
explore O O
a O O
space O O
is O O
often O O
to O O
just O O
walk O O
through O O
it O O
along O O
some O O
pre- O O
speciﬁed O O
paths O O
, O O
just O O
as O O
museums O O
or O O
home O O
tours O O
guide O O
users O O
along O O
a O O
particular O O
path O O
, O O
say O O
down O O
the O O
middle O O
of O O
each O O
room.13 O O
similarly O O
, O O
city-level O O
exploration O O
can O O
be O O
achieved O O
by O O
driving O O
down O O
the O O
middle O O
of O O
each O O
street O O
and O O
allowing O O
the O O
user O O
to O O
branch O O
at O O
each O O
intersection O O
. O O
performance O O
evaluation O O
and O O
analysis O O
of O O
vanishing O B
point O O
detection B B
tech- O O
niques O O
. O O
in O O
order B B
to O O
provide O O
even O O
more O O
realism O O
in O O
their O O
fac¸ade O O
system O O
, O O
debevec O O
, O O
taylor O O
, O O
and O O
malik O O
( O O
1996 O O
) O O
also O O
include O O
a O O
model-based B B
stereo O O
component O O
, O O
which O O
optionally O O
computes O O
an O O
offset O O
( O O
parallax O O
) O O
map O O
for O O
each O O
coarse O O
planar O O
facet O O
of O O
their O O
3d O O
model O O
. O O
4.3.3 O O
vanishing B B
points I I
in O O
many O O
scenes O O
, O O
structurally O O
important O O
lines B B
have O O
the O O
same O O
vanishing O B
point O O
because O O
they O O
are O O
parallel O O
in O O
3d O O
. O O
( O O
optional O O
) O O
associate O O
color B B
values O O
with O O
each O O
contour O O
to O O
help O O
in O O
the O O
matching B B
. O O
blind O O
motion B B
deblurring O O
using O O
image O O
statistics O O
. O O
support B O
vector I O
machines I I
. O O
7.2.3 O O
application O O
: O O
view B B
morphing I I
. O O
in O O
image B B
understanding O O
workshop O O
, O O
pp O O
. O O
5.2.3 O O
region B B
merging O O
( O O
agglomerative B B
clustering O O
) O O
5.2.4 O O
graph-based B B
segmentation O O
. O O
( O O
2007 O O
) O O
apply O O
another O O
idea O O
from O O
information O O
retrieval O O
, O O
namely O O
14.3 O O
instance B B
recognition O O
693 O O
figure O O
14.31 O O
location O O
or O O
building O O
recognition B B
using O O
randomized O O
trees O O
( O O
philbin O O
, O O
chum O O
, O O
isard O O
et O O
al O O
. O O
when O O
a O O
large O O
database O O
of O O
source O O
images O O
is O O
available O O
, O O
e.g. O O
, O O
when O O
images O O
are O O
taken O O
from O O
a O O
522 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
( O O
a O O
) O O
( O O
b O O
) O O
( O O
c O O
) O O
figure O O
10.53 O O
texture B B
transfer O O
( O O
efros O O
and O O
freeman O O
2001 O O
) O O
c O O
( O O
cid:13 O O
) O O
2001 O O
acm O O
: O O
( O O
a O O
) O O
reference O O
( O O
tar- O O
get O O
) O O
image B B
; O O
( O O
b O O
) O O
source O O
texture B B
; O O
( O O
c O O
) O O
image B B
( O O
partially O O
) O O
rendered O O
using O O
the O O
texture B B
. O O
however O O
, O O
this O O
approach O O
may O O
fail O O
to O O
propagate O O
strong O O
oriented B B
structures O O
. O O
fast O O
and O O
exact O O
solution O O
of O O
total B B
variation I O
models O O
on O O
the O O
gpu O O
. O O
as O O
before O O
, O O
the O O
orientations O O
and O O
strengths O O
of O O
the O O
edges O O
can O O
be O O
computed O O
by O O
interpolating O O
the O O
gradient O O
ﬁeld O O
or O O
estimating O O
these O O
values O O
from O O
the O O
difference B B
of O O
gaussian O O
image B B
( O O
see O O
exercise O O
4.7 O O
) O O
. O O
how O O
are O O
the O O
high-pass O O
h O O
and O O
low-pass B B
l O O
ﬁlters O O
shown O O
in O O
figure O O
3.37b O O
chosen O O
and O O
how O O
can O O
the O O
corresponding O O
reconstruction O O
ﬁlters O O
i O O
and O O
f O O
be O O
computed O O
? O O
can O O
ﬁlters O O
be O O
designed O O
finemediumcoarsel= O O
0l= O O
1l= O O
2l= O O
3l= O O
4finemediumcoarsel= O O
0l= O O
1l= O O
2 O O
156 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
( O O
a O O
) O O
( O O
b O O
) O O
figure O O
3.37 O O
two-dimensional B B
wavelet O O
decomposition O O
: O O
( O O
a O O
) O O
high-level O O
diagram O O
showing O O
the O O
low-pass B B
and O O
high-pass O O
transforms O O
as O O
single O O
boxes O O
; O O
( O O
b O O
) O O
separable B B
implementation O O
, O O
which O O
in- O O
volves O O
ﬁrst O O
performing O O
the O O
wavelet O O
transform B B
horizontally O O
and O O
then O O
vertically O O
. O O
technical O O
perspective B B
: O O
computational O O
photography O O
on O O
large O O
collections O O
of O O
images O O
. O O
these O O
additional O O
links O O
( O O
factors O O
) O O
enable O O
the O O
smoothness B B
to O O
depend O O
on O O
the O O
input O O
data O O
. O O
knockout O O
uses O O
a O O
lo- O O
cal O O
color B B
estimate O O
of O O
foreground O O
and O O
background O O
for O O
each O O
pixel O O
and O O
computes O O
α O O
along O O
each O O
color B B
axis O O
. O O
references B B
889 O O
rother O O
, O O
c. O O
, O O
bordeaux O O
, O O
l. O O
, O O
hamadi O O
, O O
y. O O
, O O
and O O
blake O O
, O O
a O O
. O O
unlike O O
gaussian O O
elimination O O
, O O
which O O
may O O
require O O
pivoting O O
( O O
row O O
and O O
column O O
reordering O O
) O O
or O O
may O O
become O O
un- O O
stable O O
( O O
sensitive O O
to O O
roundoff O O
errors O O
or O O
reordering O O
) O O
, O O
cholesky O O
factorization B B
remains O O
stable O O
for O O
positive O O
deﬁnite O O
matrices O O
, O O
such O O
as O O
those O O
that O O
arise O O
from O O
normal O O
equations O O
in O O
least B B
squares I I
prob- O O
lems O O
( O O
appendix O O
a.2 O O
) O O
. O O
to O O
ﬁx O O
this O O
, O O
either O O
pick O O
one O O
frame O O
as O O
being O O
at O O
the O O
origin O O
or O O
add O O
a O O
constraint B B
to O O
make O O
the O O
average O O
frame O O
offsets O O
be O O
0. O O
the O O
formulas O O
for O O
adding O O
rotation O O
and O O
scale O O
transformations O O
are O O
straightforward O O
and O O
are O O
left O O
as O O
an O O
exercise O O
( O O
exercise O O
6.2 O O
) O O
. O O
top-points O O
as O O
interest O O
points B B
for O O
image B B
matching O B
. O O
the O O
results O O
of O O
this O O
match O O
computation O O
gives O O
us O O
a O O
jump O O
table O O
or O O
, O O
equivalently O O
, O O
a O O
transition O O
probability O O
between O O
any O O
two O O
frames O O
in O O
the O O
original O O
video B B
. O O
emerging O O
technologies O O
of O O
augmented B B
reality I O
: O O
interfaces O O
and O O
design O O
. O O
the O O
unstructured B B
lumigraph O O
ren- O O
dering O O
( O O
ulr O O
) O O
system O O
of O O
buehler O O
, O O
bosse O O
, O O
mcmillan O O
et O O
al O O
. O O
extraction O O
of O O
high-resolution O O
frames O O
from O O
video B B
sequences O O
. O O
in- O O
stead O O
, O O
algorithm B B
a.3 O O
is O O
extended O O
to O O
insert O O
s−t O O
and O O
st O O
operations O O
at O O
the O O
appropriate O O
places O O
( O O
bj¨orck O O
1996 O O
; O O
golub O O
and O O
van O O
loan O O
1996 O O
; O O
trefethen O O
and O O
bau O O
1997 O O
; O O
saad O O
2003 O O
; O O
nocedal O O
and O O
wright O O
2006 O O
) O O
. O O
shape O O
matching O O
and O O
object O O
recognition B B
using O O
shape O O
contexts O O
. O O
8.2 O O
parametric B B
motion O O
401 O O
if O O
the O O
appearance O O
of O O
the O O
warped O O
and O O
template O O
images O O
is O O
similar O O
enough O O
, O O
we O O
can O O
replace O O
the O O
gradient O O
of O O
˜i1 O O
( O O
x O O
) O O
with O O
the O O
gradient O O
of O O
i0 O O
( O O
x O O
) O O
, O O
as O O
suggested O O
previously O O
( O O
8.43 O O
) O O
. O O
it O O
can O O
also O O
be O O
used O O
to O O
perform O O
hdr O O
merging B O
and O O
tone B B
mapping I I
simultaneously O O
( O O
raman O O
and O O
chaudhuri O O
2007 O O
, O O
2009 O O
) O O
. O O
a O O
computational O O
framework O O
and O O
an O O
algorithm B B
for O O
the O O
measurement O O
of O O
visual O O
motion O O
. O O
pyramid-based O O
algorithms O O
( O O
section O O
3.5 O O
) O O
can O O
also O O
be O O
used O O
to O O
perform O O
such O O
large-area O O
smoothing B B
computations O O
. O O
another O O
highly O O
ranked O O
algorithm B B
, O O
by O O
yang O O
, O O
wang O O
, O O
yang O O
et O O
al O O
. O O
these O O
kinds O O
of O O
features O O
can O O
be O O
matched O O
based O O
on O O
their O O
orien- O O
tation O O
and O O
local B B
appearance O O
( O O
edge O O
proﬁles O O
) O O
and O O
can O O
also O O
be O O
good O O
indicators O O
of O O
object O O
bound- O O
aries O O
and O O
occlusion O O
events O O
in O O
image B B
sequences O O
. O O
another O O
essential O O
component O O
of O O
whole O O
body B B
modeling O O
and O O
tracking O O
is O O
the O O
ﬁtting O O
of O O
parameterized O O
shape O O
models O O
to O O
visual O O
data O O
. O O
in O O
ieee O O
computer O O
society O O
conference O O
on O O
computer O O
vision O O
and O O
pattern O O
recognition B B
( O O
cvpr O O
’ O O
98 O O
) O O
, O O
pp O O
. O O
figure O O
5.8b O O
shows O O
why O O
the O O
measurement O O
density O O
itself O O
is O O
often O O
multi-modal O O
: O O
the O O
locations O O
of O O
the O O
edges O O
perpendicular O O
to O O
the O O
spline B B
curve O O
can O O
have O O
multiple B B
local O O
maxima O O
due O O
to O O
background O O
clutter O O
. O O
the O O
layout B O
consistent I O
random O O
ﬁeld O O
for O O
recognizing O O
and O O
segmenting O O
partially O O
occluded O O
objects O O
. O O
in O O
theory O O
, O O
a O O
higher O O
gain O O
allows O O
the O O
camera B B
to O O
perform O O
better O O
under O O
low O O
light O O
conditions O O
( O O
less O O
motion B B
blur O O
due O O
to O O
long O O
exposure O O
times O O
when O O
the O O
aperture O O
is O O
already O O
maxed O O
out O O
) O O
. O O
ieee O O
transactions O O
on O O
medical B B
imaging I I
, O O
16 O O
( O O
2 O O
) O O
:187–198 O O
. O O
if O O
two O O
or O O
more O O
ﬁnite O O
orthogonal O O
vanishing O B
points B I
have O O
been O O
observed O O
, O O
the O O
single-image O O
cali- O O
bration O O
method O O
based O O
on O O
vanishing B B
points I I
( O O
section O O
6.3.2 O O
) O O
can O O
be O O
used O O
instead O O
. O O
the O O
viterbi O O
algorithm B B
computes O O
an O O
optimal O O
match O O
in O O
o O O
( O O
n O O
2|e| O O
+ O O
n O O
p O O
) O O
time O O
, O O
where O O
n O O
is O O
the O O
number O O
of O O
potential O O
locations O O
or O O
poses O O
for O O
each O O
part O O
, O O
|e| O O
is O O
the O O
number O O
of O O
edges O O
( O O
pairwise O O
constraints O O
) O O
, O O
and O O
p O O
= O O
|v O O
| O O
is O O
the O O
number O O
of O O
parts O O
( O O
vertices O O
in O O
the O O
graphical O O
model O O
, O O
which O O
is O O
equal O O
to O O
|e| O O
+ O O
1 O O
in O O
a O O
tree O O
) O O
. O O
because O O
it O O
requires O O
the O O
solution O O
of O O
large O O
sparse O B
eigenvalue O O
problems O O
, O O
normalized B B
cuts I I
can O O
be O O
quite O O
slow O O
. O O
356 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
most O O
cameras O O
today O O
have O O
square O O
pixels O O
and O O
an O O
optical O B
center O O
near O O
the O O
middle O O
of O O
the O O
image B B
, O O
and O O
are O O
much O O
more O O
likely O O
to O O
deviate O O
from O O
a O O
simple O O
camera B B
model O O
due O O
to O O
radial B B
distortion I I
( O O
section O O
6.3.5 O O
) O O
, O O
which O O
should O O
be O O
compensated O O
for O O
whenever O O
possible O O
. O O
3.3 O O
more O O
neighborhood B B
operators O O
we O O
can O O
thus O O
re-write O O
( O O
3.34 O O
) O O
as O O
f O O
( O O
t+1 O O
) O O
( O O
i O O
, O O
j O O
) O O
= O O
127 O O
( O O
3.40 O O
) O O
f O O
( O O
t O O
) O O
( O O
i O O
, O O
j O O
) O O
+ O O
η O O
( O O
cid:80 O O
) O O
k O O
, O O
l O O
f O O
( O O
t O O
) O O
( O O
k O O
, O O
l O O
) O O
r O O
( O O
i O O
, O O
j O O
, O O
k O O
, O O
l O O
) O O
1 O O
+ O O
η O O
( O O
cid:80 O O
) O O
k O O
, O O
l O O
r O O
( O O
i O O
, O O
j O O
, O O
k O O
, O O
l O O
) O O
1 O O
+ O O
ηr O O
( O O
cid:88 O O
) O O
k O O
, O O
l O O
η O O
= O O
f O O
( O O
t O O
) O O
( O O
i O O
, O O
j O O
) O O
+ O O
r O O
( O O
i O O
, O O
j O O
, O O
k O O
, O O
l O O
) O O
[ O O
f O O
( O O
t O O
) O O
( O O
k O O
, O O
l O O
) O O
− O O
f O O
( O O
t O O
) O O
( O O
i O O
, O O
j O O
) O O
] O O
, O O
where O O
r O O
= O O
( O O
cid:80 O O
) O O
( O O
k O O
, O O
l O O
) O O
r O O
( O O
i O O
, O O
j O O
, O O
k O O
, O O
l O O
) O O
, O O
( O O
k O O
, O O
l O O
) O O
are O O
the O O
n4 O O
neighbors O O
of O O
( O O
i O O
, O O
j O O
) O O
, O O
and O O
we O O
have O O
made O O
the O O
iterative B B
nature O O
of O O
the O O
ﬁltering O O
explicit O O
. O O
as O O
the O O
sophistication O O
and O O
reliability O O
of O O
these O O
techniques O O
continues O O
to O O
improve O O
, O O
we O O
can O O
ex- O O
pect O O
to O O
see O O
even O O
more O O
user-friendly O O
applications O O
for O O
photorealistic O O
3d O O
modeling B B
from O O
images O O
( O O
exercise O O
12.8 O O
) O O
. O O
references B B
919 O O
wang O O
, O O
j. O O
and O O
cohen O O
, O O
m. O O
f. O O
( O O
2007b O O
) O O
. O O
the O O
antipodal B O
point O O
to O O
q2 O O
, O O
namely O O
−q2 O O
, O O
represents O O
the O O
same O O
rotation O O
as O O
q2 O O
. O O
2.2.1 O O
lighting B B
. O O
the O O
accuracy B O
of O O
the O O
ﬂow O O
vector O O
is O O
checked O O
using O O
a O O
photo-consistency O O
measure O O
before O O
a O O
given O O
warped O O
pixel O O
is O O
considered O O
valid O O
and O O
is O O
used O O
to O O
compute O O
a O O
high O O
dy- O O
namic O O
range O O
radiance O O
estimate O O
, O O
which O O
is O O
the O O
goal O O
of O O
their O O
overall O O
algorithm B B
. O O
6.1.1 O O
2d O O
alignment B B
using O O
least B B
squares I I
given O O
a O O
set O O
of O O
matched O O
feature B B
points O O
{ O O
( O O
xi O O
, O O
x O O
( O O
cid:48 O O
) O O
i O O
) O O
} O O
and O O
a O O
planar O O
parametric O O
transformation1 O O
of O O
the O O
form O O
x O O
( O O
cid:48 O O
) O O
= O O
f O O
( O O
x O O
; O O
p O O
) O O
, O O
( O O
6.1 O O
) O O
how O O
can O O
we O O
produce O O
the O O
best O O
estimate O O
of O O
the O O
motion B B
parameters O O
p O O
? O O
the O O
usual O O
way O O
to O O
do O O
this O O
is O O
to O O
use O O
least B B
squares I I
, O O
i.e. O O
, O O
to O O
minimize O O
the O O
sum O O
of O O
squared O O
residuals O O
where O O
els O O
= O O
( O O
cid:88 O O
) O O
i O O
( O O
cid:107 O O
) O O
ri O O
( O O
cid:107 O O
) O O
2 O O
= O O
( O O
cid:88 O O
) O O
i O O
( O O
cid:107 O O
) O O
f O O
( O O
xi O O
; O O
p O O
) O O
− O O
x O O
( O O
cid:48 O O
) O O
i O O
( O O
cid:107 O O
) O O
2 O O
, O O
ri O O
= O O
f O O
( O O
xi O O
; O O
p O O
) O O
− O O
x O O
( O O
cid:48 O O
) O O
i O O
= O O
ˆx O O
( O O
cid:48 O O
) O O
i O O
− O O
˜x O O
( O O
cid:48 O O
) O O
i O O
( O O
6.2 O O
) O O
( O O
6.3 O O
) O O
is O O
the O O
residual O O
between O O
the O O
measured O O
location O O
ˆx O O
( O O
cid:48 O O
) O O
i O O
and O O
its O O
corresponding O O
current O O
predicted O O
location O O
˜x O O
( O O
cid:48 O O
) O O
i O O
= O O
f O O
( O O
xi O O
; O O
p O O
) O O
. O O
9.3 O O
compositing B B
455 O O
agrawala O O
et O O
al O O
. O O
thus O O
, O O
the O O
fourier O O
transform B B
is O O
a O O
linear B B
operator O O
. O O
robust B B
rotation O O
and O O
translation B B
estimation O O
in O O
multiview O O
reconstruction O O
. O O
the O O
value O O
p O O
= O O
2 O O
is O O
the O O
usual O O
weighted B B
mean O O
, O O
which O O
is O O
equivalent O O
to O O
correlation O O
( O O
3.12 O O
) O O
after O O
normalizing B O
by O O
the O O
sum O O
of O O
the O O
weights O O
( O O
bovik O O
2000 O O
, O O
section O O
3.2 O O
) O O
( O O
haralick O O
and O O
shapiro O O
1992 O O
, O O
section O O
7.2.6 O O
) O O
. O O
light B O
ﬁeld I I
video O O
stabilization O O
. O O
in O O
this O O
chapter O O
, O O
we O O
present O O
a O O
simpliﬁed O O
model O O
of O O
such O O
an O O
image B B
formation O O
process O O
. O O
in O O
photogrammetry B B
, O O
it O O
is O O
common O O
to O O
set O O
up O O
a O O
camera B B
in O O
a O O
large O O
ﬁeld O O
looking O O
at O O
distant O O
calibration B B
targets O O
whose O O
exact O O
location O O
has O O
been O O
precomputed O O
using O O
surveying O O
equipment O O
( O O
slama O O
1980 O O
; O O
atkinson O O
1996 O O
; O O
kraus O O
1997 O O
) O O
. O O
6.5 O O
exercises O O
337 O O
3. O O
compute O O
an O O
optimal O O
2d O O
translation B B
and O O
rotation O O
between O O
the O O
ﬁrst O O
image B B
and O O
all O O
subse- O O
quent O O
images O O
, O O
using O O
least O O
squares O O
( O O
section O O
6.1.1 O O
) O O
with O O
optional O O
ransac O O
for O O
robustness O O
( O O
section O O
6.1.4 O O
) O O
. O O
yuille O O
( O O
2010 O O
) O O
discusses O O
the O O
relationships O O
between O O
mean O O
ﬁeld O O
theory O O
and O O
loopy B B
belief I I
propagation I I
. O O
the O O
visual B O
hull I I
concept O O
for O O
silhouette-based O O
image B B
understanding O O
. O O
pﬁnder O O
: O O
real- O O
time O O
tracking O O
of O O
the O O
human B O
body I I
. O O
5.3.1 O O
k-means B B
and O O
mixtures O O
of O O
gaussians O O
. O O
9 O O
this O O
is O O
particularly O O
true O O
of O O
classic O O
photogrammetry B B
applications O O
, O O
where O O
the O O
reporting O O
of O O
precision B O
is O O
almost O O
always O O
considered O O
mandatory O O
( O O
f¨orstner O O
2005 O O
) O O
. O O
the O O
topic O O
of O O
registering O O
3d O O
point O O
data O O
sets O O
is O O
called O O
absolute B O
orientation I O
( O O
horn O O
1987 O O
) O O
and O O
3d O O
pose O O
estimation B B
( O O
lorusso O O
, O O
eggert O O
, O O
and O O
fisher O O
1995 O O
) O O
. O O
in O O
particular O O
, O O
many O O
of O O
the O O
topics O O
introduced O O
under O O
the O O
rubric O O
of O O
image-based B B
rendering I I
, O O
such O O
as O O
image B B
stitching I I
( O O
see O O
chapter O O
9 O O
) O O
, O O
light-ﬁeld O O
capture O O
and O O
rendering B B
( O O
see O O
section O O
13.3 O O
) O O
, O O
and O O
high B O
dynamic I I
range I I
( O O
hdr O O
) O O
image B B
capture O O
through O O
exposure O O
bracketing O O
( O O
figure1.5b O O
) O O
( O O
see O O
section O O
10.2 O O
and O O
mann O O
and O O
picard O O
1995 O O
; O O
debevec O O
and O O
malik O O
1997 O O
) O O
, O O
were O O
re-christened O O
as O O
computational O O
photography O O
( O O
see O O
chapter O O
10 O O
) O O
to O O
acknowledge O O
the O O
increased O O
use O O
of O O
such O O
techniques O O
in O O
everyday O O
digital O O
photography O O
. O O
3.1.1 O O
pixel O O
transforms O O
a O O
general O O
image B B
processing O O
operator O O
is O O
a O O
function O O
that O O
takes O O
one O O
or O O
more O O
input O O
images O O
and O O
produces O O
an O O
output O O
image B B
. O O
image B O
stitching I O
algorithms O O
create O O
the O O
high-resolution O O
photo-mosaics O O
used O O
to O O
produce O O
today O O
’ O O
s O O
digital O O
maps O O
and O O
satellite O O
photos O O
. O O
multiscale O O
image B B
segmentation O O
by O O
integrated O O
edge O O
and O O
region B B
detection O O
. O O
compare O O
the O O
results O O
of O O
your O O
denoising O O
using O O
different O O
wavelet O O
and O O
pyramid B B
representations O O
. O O
as O O
in O O
2d O O
, O O
the O O
resulting O O
homogeneous O O
coordinate O I
˜x O O
( O O
cid:48 O O
) O O
must O O
be O O
normalized B O
in O O
order B B
to O O
obtain O O
an O O
inhomogeneous O O
result O O
x. O O
perspective B B
transformations O O
preserve O O
straight O O
lines B B
( O O
i.e. O O
, O O
they O O
remain O O
straight O O
after O O
the O O
transformation O O
) O O
. O O
13.5.5 O O
application O O
: O O
video-based B B
walkthroughs I I
video O B
camera B O
arrays O O
enable O O
the O O
simultaneous O O
capture O O
of O O
3d O O
dynamic B B
scenes O O
from O O
multiple B B
viewpoints O O
, O O
which O O
can O O
then O O
enable O O
the O O
viewer O O
to O O
explore O O
the O O
scene O O
from O O
viewpoints O O
near O O
the O O
original O O
capture O O
locations O O
. O O
here O O
, O O
points B B
are O O
projected O O
onto O O
the O O
image B B
plane O O
by O O
dividing O O
them O O
2.1 O O
geometric B B
primitives O O
and O O
transformations O O
by O O
their O O
z O O
component O O
. O O
i2t O O
: O O
image B B
parsing O O
to O O
text O O
description O O
. O O
when O O
the O O
weighting B B
functions O O
are O O
uniform O O
, O O
the O O
gmrf O O
becomes O O
a O O
special O O
case O O
of O O
wiener O O
ﬁltering O O
( O O
section O O
3.4.3 O O
) O O
. O O
weizmann O O
segmentation B B
evaluation O O
database O O
of O O
100 O O
grayscale O O
images O O
with O O
ground O O
truth O O
segmentations O O
, O O
http O O
: O O
//www.wisdom.weizmann.ac.il/∼vision/seg O O
evaluation B B
db/ O O
index.html O O
( O O
alpert O O
, O O
galun O O
, O O
basri O O
et O O
al O O
. O O
15 O O
in O O
fact O O
, O O
the O O
discontinued O O
fujifilm O O
finepix O O
f40fd O O
camera B B
takes O O
a O O
pair O O
of O O
ﬂash O B
and O O
no O O
ﬂash B B
images O O
in O O
quick O O
succession O O
; O O
however O O
, O O
it O O
only O O
lets O O
you O O
decide O O
to O O
keep O O
one O O
of O O
them O O
. O O
this O O
transformation O O
is O O
also O O
known O O
as O O
2d O O
rigid B O
body I B
motion O O
or O O
the O O
2d O O
euclidean O O
transformation O O
( O O
since O O
euclidean O O
distances O O
are O O
preserved O O
) O O
. O O
12.6 O O
model-based B B
reconstruction O O
607 O O
and O O
detecting O O
if O O
they O O
are O O
carrying O O
objects O O
( O O
haritaoglu O O
, O O
harwood O O
, O O
and O O
davis O O
2000 O O
; O O
mittal O O
and O O
davis O O
2003 O O
; O O
dimitrijevic O O
, O O
lepetit O O
, O O
and O O
fua O O
2006 O O
) O O
. O O
chapter O O
14 O O
recognition B O
. O O
the O O
fast O O
fourier O O
transform B B
algorithm O O
can O O
compute O O
the O O
transform B B
of O O
an O O
n O O
× O O
m O O
image B O
in O O
o O O
( O O
n O O
m O O
log O O
n O O
m O O
) O O
operations O O
( O O
bracewell O O
1986 O O
) O O
. O O
digital O O
image O O
processing O O
: O O
an O O
algorithmic O O
introduc- O O
tion B B
using O O
java O O
. O O
does O O
this O O
produce O O
signiﬁcantly O O
lower O O
reprojection O O
errors O O
? O O
can O O
you O O
upgrade O O
this O O
reconstruc- O O
tion B B
to O O
a O O
metric O O
one O O
? O O
ex O O
7.5 O O
: O O
bundle O O
adjuster O O
it O O
really O O
is O O
not O O
. O O
in O O
a O O
calibrated O O
camera B O
setting O O
, O O
this O O
can O O
correspond O O
to O O
estimating O O
consistent O O
rotations O O
for O O
all O O
of O O
the O O
cameras O O
, O O
for O O
ex- O O
ample O O
, O O
using O O
matched O O
vanishing B O
points I I
( O O
antone O O
and O O
teller O O
2002 O O
) O O
. O O
4.3.3 O O
vanishing B B
points I I
. O O
when O O
the O O
algorithm B B
was O O
ﬁrst O O
introduced O O
in O O
2006 O O
, O O
it O O
was O O
the O O
top O O
ranked O O
algorithm B B
on O O
the O O
evaluation B B
site O O
at O O
http O O
: O O
//vision.middlebury.edu/stereo O O
; O O
in O O
early O O
2010 O O
, O O
it O O
still O O
had O B
the O O
top O O
rank O O
on O O
the O O
new O O
evaluation B B
datasets O O
. O O
the O O
lucas–kanade O O
update B O
rule I O
can O O
also O O
be O O
applied O O
to O O
the O O
bias–gain O O
equation B O
( O O
8.9 O O
) O O
to O O
obtain O O
elk−bg O O
( O O
u O O
+ O O
∆u O O
) O O
= O O
( O O
cid:88 O O
) O O
i O O
[ O O
j O O
1 O O
( O O
xi O O
+ O O
u O O
) O O
∆u O O
+ O O
ei O O
− O O
αi0 O O
( O O
xi O O
) O O
− O O
β O O
] O O
2 O O
( O O
8.45 O O
) O O
( O O
lucas O O
and O O
kanade O O
1981 O O
; O O
gennert O O
1988 O O
; O O
fuh O O
and O O
maragos O O
1991 O O
; O O
baker O O
, O O
gross O O
, O O
and O O
matthews O O
2003 O O
) O O
. O O
14.3 O O
instance B B
recognition O O
691 O O
simple O O
metric O O
to O O
a O O
dozen O O
other O O
metrics O O
and O O
conclude O O
that O O
it O O
performs O O
just O O
about O O
as O O
well O O
as O O
more O O
complicated O O
metrics O O
. O O
in O O
practice O O
, O O
however O O
, O O
it O O
is O O
more O O
accurate O O
to O O
re-estimate O O
any O O
unknown O O
intrinsic B O
calibration O O
parameters B O
using O O
non-linear B B
least O O
squares O O
( O O
6.42 O O
) O O
. O O
14.1.2 O O
pedestrian B B
detection O O
. O O
as O O
before O O
, O O
the O O
image B B
is O O
split O O
into O O
its O O
lumi- O O
nance O O
and O O
chrominance O O
channels O O
. O O
section O O
12.6 O O
examines O O
three O O
more O O
specialized O O
application O O
areas O O
( O O
architecture B O
, O O
faces B B
, O O
and O O
human O O
bodies O O
) O O
, O O
which O O
can O O
use O O
model-based B O
reconstruction O O
to O O
ﬁt O O
parameterized O O
models O O
to O O
the O O
sensed O O
data O O
. O O
conversely O O
, O O
the O O
sinc B B
ﬁlter O O
is O O
an O O
ideal O O
low- O O
pass O O
ﬁlter O O
. O O
in O O
this O O
technique O O
, O O
each O O
input O O
image B B
is O O
used O O
to O O
compute O O
a O O
separate O O
homography B B
( O O
6.19–6.23 O O
) O O
˜h O O
mapping O O
the O O
plane O O
’ O O
s O O
calibration B B
points O O
( O O
xi O O
, O O
yi O O
, O O
0 O O
) O O
into O O
image B B
coordinates O O
( O O
xi O O
, O O
yi O O
) O O
, O O
( O O
6.49 O O
) O O
xi O O
= O O
xi O O
yi O O
1 O O
 O O
∼ O O
k O O
( O O
cid:104 O O
) O O
r0 O O
r1 O O
t O O
( O O
cid:105 O O
) O O
 O O
xi O O
yi O O
1 O O
 O O
∼ O O
˜hpi O O
, O O
where O O
the O O
ri O O
are O O
the O O
ﬁrst O O
two O O
columns O O
of O O
r O O
and O O
∼ O O
indicates O O
equality O O
up O O
to O O
scale O O
. O O
8.5.2 O O
transparent B B
layers O O
and O O
reﬂections B B
. O O
in O O
practice O O
, O O
the O O
interpolation B B
and O O
decimation O O
steps O O
are O O
concate- O O
nated O O
into O O
a O O
single O O
polyphase O O
digital O O
ﬁltering O O
operation O O
( O O
szeliski O O
, O O
winder O O
, O O
and O O
uyttendaele O O
2010 O O
) O O
. O O
while O O
most O O
feature B B
detectors O O
simply O O
look O O
for O O
local O O
maxima O O
in O O
the O O
interest O O
function O O
, O O
this O O
can O O
lead O O
to O O
an O O
uneven O O
distribution O O
of O O
feature B B
points O O
across O O
the O O
image B B
, O O
e.g. O O
, O O
points B B
will O O
be O O
denser O O
in O O
regions O O
of O O
higher O O
contrast O O
. O O
handbook O O
of O O
face B B
recognition O O
, O O
springer O O
. O O
references B B
881 O O
pﬁster O O
, O O
h. O O
, O O
zwicker O O
, O O
m. O O
, O O
van O O
baar O O
, O O
j. O O
, O O
and O O
gross O O
, O O
m. O O
( O O
2000 O O
) O O
. O O
hierarchical B B
part-based O O
visual O O
object O O
categorization O O
. O O
for O O
this O O
reason O O
, O O
scaled O O
orthography O O
is O O
actually O O
more O O
commonly O O
used O O
, O O
x O O
= O O
[ O O
si O O
2×2|0 O O
] O O
p. O O
( O O
2.48 O O
) O O
this O O
model O O
is O O
equivalent O O
to O O
ﬁrst O O
projecting O O
the O O
world O O
points B B
onto O O
a O O
local B B
fronto-parallel O O
image B B
plane O O
and O O
then O O
scaling O O
this O O
image B B
using O O
regular O O
perspective B B
projection O O
. O O
the O O
corresponding O O
pixels O O
in O O
the O O
source O O
images O O
can O O
then O O
be O O
“ O O
erased O O
” O O
, O O
since O O
they O O
are O O
already O O
accounted O O
for O O
, O O
and O O
therefore O O
do O O
not O O
contribute O O
to O O
further O O
photoconsistency B B
computations O O
. O O
graphical O O
models O O
and O O
image B B
processing O O
, O O
54 O O
( O O
1 O O
) O O
:56–74 O O
. O O
this O O
line O O
of O O
work O O
has O O
been O O
extended O O
to O O
a O O
more O O
holistic O O
approach O O
that O O
simultaneously O O
reasons O O
about O O
object O O
identity O O
, O O
location O O
, O O
surface B B
orientations O O
, O O
occlusions O O
, O O
and O O
camera B B
viewing O O
parameters B B
( O O
hoiem O O
, O O
efros O O
, O O
and O O
hebert O O
2008a O O
, O O
b O O
) O O
. O O
chapter O O
8 O O
: O O
dense O O
motion O O
estimation B B
the O O
middlebury O O
optic O O
ﬂow O O
evaluation B B
web O O
site O O
, O O
http O O
: O O
//vision.middlebury.edu/ﬂow/data O O
( O O
baker O O
, O O
scharstein O O
, O O
lewis O O
et O O
al O O
. O O
in O O
fact O O
, O O
it O O
is O O
possible O O
to O O
carry O O
out O O
most O O
image B B
processing O O
operations O O
by O O
representing O O
images O O
as O O
splines B B
and O O
manipulating O O
them O O
in O O
a O O
multi-resolution O O
framework O O
( O O
unser O O
1999 O O
) O O
. O O
2.1 O O
geometric B B
primitives O O
and O O
transformations O O
41 O O
figure O O
2.5 O O
rotation O O
around O O
an O O
axis O O
ˆn O O
by O O
an O O
angle O O
θ O O
. O O
to O O
make O O
the O O
representation O O
more O O
compact O O
, O O
run-length O O
coding O O
is O O
used O O
to O O
encode O O
the O O
empty O O
, O O
seen O O
, O O
and O O
varying O O
( O O
signed B B
distance O O
) O O
voxels O O
, O O
and O O
only O O
the O O
signed B B
distance O O
values O O
near O O
each O O
surface B B
are O O
stored.4 O O
once O O
the O O
merged O O
signed B B
distance O O
function O O
has O O
been O O
computed O O
, O O
a O O
zero-crossing O O
surface B B
extraction O O
algorithm B B
, O O
such O O
as O O
marching B B
cubes I I
( O O
lorensen O O
and O O
cline O O
1987 O O
) O O
, O O
can O O
be O O
used O O
to O O
recover O O
a O O
meshed O O
surface B B
model O O
. O O
in O O
ieee O O
computer O O
society O O
conference O O
on O O
computer O O
vision O O
and O O
pattern O O
recognition B B
( O O
cvpr O O
2008 O O
) O O
, O O
anchorage O O
, O O
ak O O
. O O
the O O
resulting O O
pyramid B B
has O O
perfect B O
reconstruction I O
, O O
i.e. O O
, O O
the O O
laplacian O O
images O O
plus O O
the O O
base-level O O
gaussian O O
( O O
l2 O O
in O O
figure O O
3.34b O O
) O O
are O O
sufﬁcient O O
to O O
exactly O O
reconstruct O O
the O O
original O O
image B B
. O O
after O O
a O O
normalized B B
cut O O
has O O
been O O
computed O O
at O O
the O O
coarsest O O
level O O
of O O
analysis O O
, O O
the O O
membership O O
values O O
of O O
ﬁner-level O O
nodes O O
are O O
computed O O
by O O
interpolating O O
parent O O
values O O
and O O
mapping O O
values O O
within O O
 O O
= O O
0.1 O O
of O O
0 O O
and O O
1 O O
to O O
pure O O
boolean O O
values O O
. O O
apply O O
the O O
resulting O O
representations O O
to O O
one O O
of O O
the O O
following O O
two O O
tasks O O
: O O
• O O
compression B B
: O O
compute O O
the O O
entropy O O
in O O
each O O
band O O
for O O
the O O
different O O
wavelet O O
implemen- O O
tations O O
, O O
assuming O O
a O O
given O O
quantization B O
level O O
( O O
say O O
, O O
1/4 O O
gray O O
level O O
, O O
to O O
keep O O
the O O
rounding O O
error O O
acceptable O O
) O O
. O O
however O O
, O O
in O O
this O O
case O O
, O O
the O O
subsampling O O
only O O
occurs O O
at O O
every O O
octave B O
level O O
, O O
i.e. O O
, O O
the O O
image B B
is O O
repeatedly O O
blurred O O
with O O
wider O O
gaussians O O
until O O
a O O
full O O
octave B B
of O O
resolution O O
change O O
has O O
been O O
achieved O O
( O O
figure O O
4.11 O O
) O O
. O O
ex O O
13.6 O O
: O O
rendering B B
from O O
sprites B B
or O O
layers B B
extend O O
your O O
view B O
interpolation I I
algorithm O O
to O O
handle O O
multiple B B
planes O O
or O O
sprites B B
( O O
section O O
13.2.1 O O
) O O
( O O
shade O O
, O O
gortler O O
, O O
he O O
et O O
al O O
. O O
estimating O O
such O O
noise B B
levels O O
directly O O
from O O
the O O
measurements O O
or O O
their O O
residuals O O
, O O
however O O
, O O
can O O
be O O
problematic O O
, O O
as O O
such O O
estimates O O
themselves O O
become O O
contaminated O O
by O O
outliers O O
. O O
extend O O
your O O
algorithm B B
to O O
handle O O
this O O
case O O
in O O
some O O
useful O O
way O O
. O O
interpolation B B
. O O
pattern O O
recognition B B
( O O
cvpr O O
’ O O
2004 O O
) O O
, O O
pp O O
. O O
( O O
2006 O O
) O O
divide O O
their O O
survey O O
into O O
sections O O
on O O
tracking O O
( O O
background B O
subtraction I O
, O O
deformable O O
templates O O
, O O
ﬂow O O
, O O
and O O
probabilistic B B
models I O
) O O
, O O
recovering O O
3d O O
pose O O
from O O
2d O O
observations O O
, O O
and O O
data O O
association O O
and O O
body B B
parts O O
. O O
3d O O
planes B B
can O O
also O O
be O O
represented O O
as O O
homogeneous B B
coordinates I O
˜m O O
= O O
( O O
a O O
, O O
b O O
, O O
c O O
, O O
d O O
) O O
with O O
a O O
corresponding O O
plane O O
equation O O
¯x O O
· O O
˜m O O
= O O
ax O O
+ O O
by O O
+ O O
cz O O
+ O O
d O O
= O O
0 O O
. O O
we O O
also O O
describe O O
a O O
general O O
resampling O O
algorithm B B
called O O
plane B O
sweep I O
that O O
can O O
be O O
used O O
to O O
perform O O
multi-image O O
stereo B B
matching I I
with O O
arbitrary O O
camera B B
conﬁgurations O O
. O O
recall B B
that O O
the O O
energy O O
we O O
are O O
minimizing O O
in O O
map O O
estimation B O
( O O
b.26 O O
) O O
is O O
the O O
negative O O
log O O
likelihood O O
( O O
b.12 O O
, O O
b.13 O O
, O O
and O O
b.22 O O
) O O
of O O
a O O
factored O O
gibbs O O
posterior B B
distribution I O
, O O
p O O
( O O
x O O
) O O
= O O
( O O
cid:89 O O
) O O
( O O
i O O
, O O
j O O
) O O
∈n O O
φi O O
, O O
j O O
( O O
xi O O
, O O
xj O O
) O O
, O O
( O O
b.29 O O
) O O
b.5 O O
markov O O
random O O
ﬁelds O O
where O O
are O O
the O O
pairwise O O
interaction O O
potentials O O
. O O
272 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
figure O O
5.3 O O
elastic O O
net O O
: O O
the O O
open O O
squares O O
indicate O O
the O O
cities O O
and O O
the O O
closed O O
squares O O
linked O O
by O O
straight O O
line O O
segments O O
are O O
the O O
tour O O
points B B
. O O
references B O
849 O O
kazhdan O B
, O O
m. O O
, O O
bolitho O O
, O O
m. O O
, O O
and O O
hoppe O O
, O O
h. O O
( O O
2006 O O
) O O
. O O
ex O O
3.20 O O
: O O
pyramid B B
blending O O
write O O
a O O
program O O
that O O
takes O O
as O O
input O O
two O O
color O O
images O O
and O O
a O O
binary O O
mask O O
image B B
and O O
produces O O
the O O
laplacian O O
pyramid B B
blend O O
of O O
the O O
two O O
images O O
. O O
cardboard O O
people O O
: O O
a O O
parameterized O O
model O O
of O O
articulated O O
image B B
motion O O
. O O
fraction O O
, O O
so O O
that O O
the O O
second O O
row O O
adds O O
up O O
to O O
one O O
, O O
i.e. O O
, O O
the O O
rgb O O
triplet O O
( O O
1 O O
, O O
1 O O
, O O
1 O O
) O O
maps O O
to O O
a O O
y O O
value O O
of O O
1. O O
linearly O O
blending B B
the O O
( O O
¯r O O
( O O
λ O O
) O O
, O O
¯g O O
( O O
λ O O
) O O
, O O
¯b O O
( O O
λ O O
) O O
) O O
curves O O
in O O
figure O O
2.28a O O
according O O
to O O
( O O
2.103 O O
) O O
, O O
we O O
obtain O O
the O O
resulting O O
( O O
¯x O O
( O O
λ O O
) O O
, O O
¯y O O
( O O
λ O O
) O O
, O O
¯z O O
( O O
λ O O
) O O
) O O
curves O O
shown O O
in O O
figure O O
2.28b O O
. O O
1999 O O
) O O
( O O
c O O
) O O
multiple B B
refractions O O
can O O
be O O
handled O O
using O O
a O O
mixture O O
of O O
gaussians O O
model O O
and O O
( O O
d O O
) O O
real-time O O
mattes O O
can O O
be O O
pulled O O
using O O
a O O
single O O
graded O O
colored O O
background O O
( O O
chuang O O
, O O
zongker O O
, O O
hindorff O O
et O O
al O O
. O O
the O O
same O O
videos O O
can O O
also O O
be O O
used O O
to O O
generate O O
turn-by-turn O O
driv- O O
ing O O
directions O O
, O O
taking O O
advantage O O
of O O
both O O
expanded O O
ﬁelds O O
of O O
view O O
and O O
image-based B B
rendering I I
to O O
enhance O O
the O O
experience O O
( O O
chen O O
, O O
neubert O O
, O O
ofek O O
et O O
al O O
. O O
textonboost O O
for O O
image O O
under- O O
standing O O
: O O
multi-class O O
object O O
recognition B B
and O O
segmentation B B
by O O
jointly O O
modeling B B
appear- O O
ance O O
, O O
shape O O
and O O
context B B
. O O
) O O
themodelhasanumberofparameters O O
{ O O
af O O
, O O
ab O O
, O O
ao O O
, O O
bf O O
, O O
bb O O
, O O
bo O O
, O O
cf O O
, O O
cb O O
} O O
.itmightseemproblematicthatsomanyparametersneedtobeset O O
, O O
butinfacttheycanbelearnedfromlabeledtrainingframesasfollows O O
: O O
bo=log O O
( O O
2wo O O
) O O
bf=log O O
( O O
wf O O
) O O
bb=log O O
( O O
wb O O
) O O
( O O
18 O O
) O O
wherewo O O
, O O
wfandwbarethemeanwidthsofoccluded O O
, O O
foregroundandbackgroundregionsrespectively.thisfollowssimplyfromthefactthat2exp−b0istheprobabilityofescapefromanoccludedstate O O
, O O
andsoon.thenconsiderationofviewinggeometrytogetherwithanassumptionabouttypical O O
556 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
problems O O
with O O
dynamic O O
programming O O
stereo B B
include O O
the O O
selection O O
of O O
the O O
right O O
cost O O
for O O
occluded O O
pixels O O
and O O
the O O
difﬁculty O O
of O O
enforcing O O
inter-scanline O O
consistency O O
, O O
although O O
several O O
methods O O
propose O O
ways O O
of O O
addressing O O
the O O
latter O O
( O O
ohta O O
and O O
kanade O O
1985 O O
; O O
belhumeur O O
1996 O O
; O O
cox O O
, O O
hingorani O O
, O O
rao O O
et O O
al O O
. O O
3-d O O
scene O O
data O O
recovery B B
using O O
omnidirectional O O
multi- O O
baseline O O
stereo B B
. O O
2.1.5 O O
3d O O
to O O
2d O O
projections B B
. O O
12.6 O O
model-based B B
reconstruction O O
. O O
jpeg2000 O O
: O O
standard O O
for O O
interactive B O
imaging O O
. O O
such O O
as O O
translation B B
, O O
rotation O O
, O O
or O O
perspective B B
division O O
( O O
figure O O
6.5 O O
) O O
. O O
b.3 O O
robust B B
statistics O O
. O O
one O O
of O O
the O O
simplest O O
approaches O O
is O O
to O O
just O O
smooth O O
the O O
data O O
, O O
e.g. O O
, O O
by O O
convolving O O
it O O
with O O
a O O
ﬁxed O O
kernel O B
of O O
width O O
h O O
, O O
f O O
( O O
x O O
) O O
= O O
( O O
cid:88 O O
) O O
i O O
k O O
( O O
x O O
− O O
xi O O
) O O
= O O
( O O
cid:88 O O
) O O
i O O
k O O
( O O
cid:18 O O
) O O
( O O
cid:107 O O
) O O
x O O
− O O
xi O O
( O O
cid:107 O O
) O O
2 O O
h2 O O
( O O
cid:19 O O
) O O
, O O
( O O
5.34 O O
) O O
where O O
xi O O
are O O
the O O
input O O
samples O O
and O O
k O O
( O O
r O O
) O O
is O O
the O O
kernel B B
function O O
( O O
or O O
parzen O O
window O O
) O O
.9 O O
this O O
approach O O
is O O
known O O
as O O
kernel B B
density O O
estimation B B
or O O
the O O
parzen O O
window O O
technique O O
( O O
duda O O
, O O
hart O O
, O O
and O O
stork O O
2001 O O
, O O
section O O
4.3 O O
; O O
bishop O O
2006 O O
, O O
section O O
2.5.1 O O
) O O
. O O
( O O
3.2 O O
) O O
figure O O
3.3 O O
shows O O
how O O
an O O
image B B
can O O
be O O
represented O O
either O O
by O O
its O O
color B B
( O O
appearance O O
) O O
, O O
as O O
a O O
grid O O
of O O
numbers O O
, O O
or O O
as O O
a O O
two-dimensional B B
function O O
( O O
surface B B
plot O O
) O O
. O O
variants O O
of O O
this O O
algorithm B B
are O O
used O O
in O O
almost O O
all O O
motion-compensated O O
video B O
compression I I
schemes O O
such O O
as O O
mpeg O O
and O O
h.263 O O
( O O
le O O
gall O O
1991 O O
) O O
. O O
the O O
feature B B
distribution O O
histogram B O
is O O
used O O
to O O
learn O O
a O O
decision O O
surface O O
using O O
a O O
classiﬁcation O O
algorithm B B
, O O
such O O
as O O
a O O
support O O
vector O I
machine O O
. O O
this O O
is O O
related O O
to O O
the O O
view O O
selection O O
problem O O
discussed O O
in O O
section O O
9.3.1. O O
one O O
simple O O
heuristic O O
is O O
to O O
10 O O
note O O
that O O
here O O
we O O
use O O
the O O
convention O O
common O O
in O O
computer O O
graphics O O
that O O
the O O
vertical O O
world O O
axis O O
corresponds O O
to O O
y. O O
this O O
is O O
a O O
natural B B
choice O O
if O O
we O O
wish O O
the O O
rotation O O
matrix O O
associated O O
with O O
a O O
“ O O
regular O O
” O O
image B B
taken O O
horizontally O O
to O O
be O O
the O O
identity O O
, O O
rather O O
than O O
a O O
90◦ O O
rotation O O
around O O
the O O
x-axis O O
. O O
4. O O
if O O
your O O
camera B B
has O O
a O O
raw O O
+ O O
jpeg O O
mode O O
, O O
how O O
close O O
can O O
you O O
come O O
to O O
the O O
noise-free O O
true O O
pixel O O
values O O
? O O
( O O
this O O
suggestion O O
may O O
not O O
be O O
that O O
useful O O
, O O
since O O
cameras O O
generally O O
use O O
reasonably O O
high O O
quality O O
settings O O
for O O
their O O
raw O O
+ O O
jpeg O O
models O O
. O O
in O O
ieee O O
computer O O
society O O
conference O O
on O O
computer O O
vision O O
and O O
pattern O O
recognition B B
( O O
cvpr O O
’ O O
2004 O O
) O O
, O O
pp O O
. O O
for O O
example O O
, O O
a O O
chip O O
that O O
is O O
only O O
0.6 O O
the O O
dimension O O
of O O
a O O
35mm O O
frame O O
will O O
make O O
a O O
50mm O O
lens O O
image B B
the O O
same O O
angular O O
extent O O
as O O
a O O
50/0.6 O O
= O O
50 O O
× O O
1.6 O O
=80mm O O
lens O O
, O O
as O O
demonstrated O O
in O O
( O O
2.60 O O
) O O
. O O
their O O
representation O O
is O O
not O O
only O O
overcomplete B O
( O O
which O O
eliminates O O
the O O
aliasing B B
problem O O
) O O
but O O
is O O
also O O
orientationally O O
selective O O
and O O
has O O
identical O O
analysis O O
and O O
synthesis O O
basis O O
functions O O
, O O
i.e. O O
, O O
it O O
is O O
self-inverting B O
, O O
just O O
like O O
“ O O
regular O O
” O O
wavelets O O
. O O
since O O
the O O
last O O
row O O
is O O
always O O
[ O O
0 O O
0 O O
0 O O
1 O O
] O O
, O O
there O O
is O O
no O O
perspective B B
division O O
and O O
we O O
can O O
write O O
( O O
7.40 O O
) O O
where O O
xji O O
is O O
the O O
location O O
of O O
the O O
ith O O
point O O
in O O
the O O
jth O O
frame O O
, O O
˜p O O
j O O
is O O
the O O
upper O O
2 O O
× O O
4 O O
portion O O
of O O
the O O
projection O O
matrix O O
p O O
j O O
, O O
and O O
¯pi O O
= O O
( O O
xi O O
, O O
yi O O
, O O
zi O O
, O O
1 O O
) O O
is O O
the O O
augmented O B
3d O O
point O O
position.10 O O
let O O
us O O
assume O O
( O O
for O O
now O O
) O O
that O O
every O O
point O O
i O O
is O O
visible O O
in O O
every O O
frame O O
j. O O
we O O
can O O
take O O
the O O
xji O O
= O O
˜p O O
j O O
¯pi O O
, O O
centroid O O
( O O
average O O
) O O
of O O
the O O
projected O O
point O O
locations O O
xji O O
in O O
frame O O
j O O
, O O
¯xj O O
= O O
1 O O
n O O
( O O
cid:88 O O
) O O
i O O
xji O O
= O O
˜p O O
j O O
1 O O
n O O
( O O
cid:88 O O
) O O
i O O
¯pi O O
= O O
˜p O O
j¯c O O
, O O
( O O
7.41 O O
) O O
where O O
¯c O O
= O O
( O O
¯x O O
, O O
¯y O O
, O O
¯z O O
, O O
1 O O
) O O
is O O
the O O
augmented O B
3d O O
centroid O O
of O O
the O O
point O O
cloud O O
. O O
as O O
well O O
, O O
the O O
fourier O O
transform B B
of O O
two O O
convolved O O
images O O
is O O
the O O
product O O
of O O
their O O
individual O O
fourier O O
trans- O O
forms O O
( O O
section O O
3.4 O O
) O O
. O O
here O O
, O O
rather O O
than O O
trying O O
to O O
produce O O
a O O
single O O
panoramic O O
image B B
, O O
the O O
com- O O
plete O O
original O O
video B B
is O O
kept O O
and O O
used O O
to O O
re-synthesize O O
views O O
( O O
from O O
different O O
camera B B
origins O O
) O O
using O O
ray O O
remapping O O
( O O
light B O
ﬁeld I I
rendering O O
) O O
, O O
thus O O
endowing O O
the O O
panorama O O
with O O
a O O
sense O O
of O O
3d O O
438 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
( O O
a O O
) O O
( O O
b O O
) O O
figure O O
9.7 O O
projection O O
from O O
3d O O
to O O
( O O
a O O
) O O
cylindrical B B
and O O
( O O
b O O
) O O
spherical B B
coordinates O O
. O O
10.1.1 O O
radiometric B B
response O O
function O O
as O O
we O O
can O O
see O O
in O O
figure O O
10.2 O O
, O O
a O O
number O O
of O O
factors O O
affect O O
how O O
the O O
intensity O O
of O O
light O O
arriving O O
at O O
the O O
lens O O
ends O O
up O O
being O O
mapped O O
into O O
stored O O
digital O O
values O O
. O O
integrating O O
region B B
growing O O
and O O
edge O O
detection O O
. O O
boykov O O
and O O
jolly O O
( O O
2001 O O
) O O
were O O
the O O
ﬁrst O O
to O O
apply O O
the O O
binary O O
mrf O O
optimization O O
algorithm B O
developed O O
by O O
greig O O
, O O
porteous O O
, O O
and O O
seheult O O
( O O
1989 O O
) O O
to O O
binary O O
object O O
segmentation B B
. O O
( O O
a O O
) O O
models O O
ﬁt O O
directly O O
to O O
ﬁve O O
input O O
video B B
streams O O
( O O
pighin O O
, O O
szeliski O O
, O O
and O O
salesin O O
2002 O O
) O O
c O O
( O O
cid:13 O O
) O O
2002 O O
springer O O
: O O
the O O
bottom O O
row O O
shows O O
the O O
results O O
of O O
re-animating O O
a O O
synthetic O O
texture-mapped O O
3d O O
model O O
with O O
pose O O
and O O
expression O O
parameters B B
ﬁtted O O
to O O
the O O
input O O
images O O
in O O
the O O
top O O
row O O
. O O
while O O
most O O
researchers O O
set O O
these O O
functions O O
heuristically O O
, O O
scharstein O O
and O O
pal O O
( O O
2007 O O
) O O
show O O
how O O
the O O
free O O
parameters B B
in O O
such O O
conditional O O
random O O
ﬁelds O O
( O O
section O O
3.7.2 O O
, O O
( O O
3.118 O O
) O O
) O O
can O O
be O O
learned B B
from O O
ground O O
truth O O
disparity O O
maps O O
. O O
bayesian O O
modeling B B
of O O
uncertainty B B
in O O
low-level O O
vision O O
. O O
the O O
resulting O O
quantized O O
visual B O
words I I
can O O
then O O
be O O
used O O
with O O
classical O O
information O O
retrieval O O
( O O
document O O
relevance O O
) O O
techniques O O
to O O
quickly O O
winnow O O
down O O
a O O
set O O
of O O
potential O O
candidates O O
from O O
a O O
database O O
of O O
millions O O
of O O
images O O
( O O
section O O
14.3.2 O O
) O O
. O O
( O O
2001 O O
) O O
generalize O O
the O O
lumigraph O O
approach O O
to O O
irregularly O O
spaced O O
collections O O
of O O
images O O
, O O
while O O
levoy O O
( O O
2006 O O
) O O
provides O O
a O O
survey O O
and O O
more O O
gentle O O
intro- O O
duction O O
to O O
the O O
topic O O
of O O
light B O
ﬁeld I I
and O O
image-based B B
rendering I I
. O O
in O O
order B B
to O O
ﬁnd O O
the O O
minimum O O
of O O
this O O
continuous O O
problem O O
, O O
the O O
function O O
f O O
( O O
x O O
, O O
y O O
) O O
is O O
usually O O
ﬁrst O O
discretized O O
on O O
a O O
regular O O
grid.21 O O
the O O
most O O
principled O O
way O O
to O O
perform O O
this O O
discretization O O
is O O
to O O
use O O
ﬁnite O O
element O O
analysis O O
, O O
i.e. O O
, O O
to O O
approximate O O
the O O
function O O
with O O
a O O
piecewise O O
continuous O O
spline B B
, O O
and O O
then O O
perform O O
the O O
analytic O B
integration O O
( O O
bathe O O
2007 O O
) O O
. O O
creating O O
such O O
collages O O
, O O
which O O
show O O
visible O O
seams O O
and O O
inconsistencies O O
that O O
add O O
to O O
the O O
artistic O O
effect O O
, O O
is O O
popular O O
on O O
web O O
sites O O
such O O
as O O
flickr O O
, O O
where O O
they O O
more O O
commonly O O
go O O
under O O
the O O
name O O
panography B O
( O O
section O O
6.1.2 O O
) O O
. O O
10.4.5 O O
video B B
matting O O
. O O
image B B
sequence O O
enhancement O O
using O O
sub-pixel O O
displacements O O
. O O
pop-up O O
light B O
ﬁeld I I
: O O
an O O
interactive B B
image-based O O
modeling B B
and O O
rendering B B
system O O
. O O
a O O
good O O
survey O O
on O O
image B B
matting O O
is O O
given O O
by O O
wang O O
and O O
cohen O O
( O O
2007a O O
) O O
. O O
5 O O
note O O
that O O
as O O
points B B
get O O
further O O
away O O
from O O
a O O
camera B B
, O O
i.e. O O
, O O
closer O O
toward O O
the O O
plane O O
at O O
inﬁnity O O
, O O
errors O O
in O O
chirality O O
become O O
more O O
likely O O
. O O
for O O
this O O
reason O O
, O O
most O O
super-resolution O O
algorithms O O
assume O O
some O O
form O O
of O O
image B B
prior O O
. O O
alternatively O O
, O O
the O O
original O O
images O O
can O O
be O O
used O O
directly O O
using O O
a O O
process O O
called O O
the O O
unstructured B B
lumigraph O O
, O O
which O O
we O O
6 O O
see O O
http O O
: O O
//lightﬁeld.stanford.edu/acq.html O O
for O O
a O O
description O O
of O O
some O O
of O O
the O O
gantries O O
and O O
camera B B
arrays O O
built O O
at O O
the O O
stanford O O
computer O O
graphics O O
laboratory O O
. O O
linear O O
programming O O
relaxations O O
and O O
belief B B
propagation I I
— O O
an O O
empirical O O
study O O
. O O
this O O
approach O O
to O O
locally O O
weighted O O
regularization B B
has O O
inspired O O
later O O
algorithms O O
for O O
high O O
dynamic B B
range O O
tone B B
mapping I O
( O O
lischinski O O
, O O
farbman O O
, O O
uyt- O O
tendaele O O
et O O
al O O
. O O
( O O
2007 O O
) O O
use O O
context B B
to O O
improve O O
the O O
results O O
of O O
crf O O
segmentation B B
by O O
noting O O
that O O
certain O O
adjacencies O O
( O O
relationships O O
) O O
are O O
more O O
likely O O
than O O
others O O
, O O
e.g. O O
, O O
a O O
person O O
is O O
more O O
likely O O
to O O
be O O
on O O
a O O
horse O O
than O O
on O O
a O O
dog O O
. O O
robust B B
estimation O O
of O O
a O O
multi-layered O O
motion B B
represen- O O
tation O O
. O O
it O O
also O O
includes O O
a O O
description O O
of O O
a O O
slant-edge O O
calibration B B
algorithm O O
called O O
sfrmat2 O O
. O O
planar O O
calibration O O
patterns B O
when O O
a O O
ﬁnite O O
workspace O O
is O O
being O O
used O O
and O O
accurate O O
machining O O
and O O
motion B B
control O O
platforms O O
are O O
available O O
, O O
a O O
good O O
way O O
to O O
perform O O
calibration B B
is O O
to O O
move O O
a O O
planar O O
calibration O O
target O O
in O O
a O O
controlled O O
fashion O O
through O O
the O O
workspace O O
volume O O
. O O
bayesian O O
reconstruction O O
of O O
3d O O
human B O
motion I I
from O O
single-camera O O
video B B
. O O
weiss O O
( O O
1997 O O
) O O
8.5 O O
layered B B
motion O O
417 O O
ﬂow O O
initial O O
layers B B
ﬁnal O O
layers B B
color O O
image B B
( O O
input O O
frame O O
) O O
layers B B
with O O
pixel O O
assignments O O
and O O
ﬂow O O
figure O O
8.15 O O
layered B O
motion O O
estimation B B
results O O
( O O
wang O O
and O O
adelson O O
1994 O O
) O O
c O O
( O O
cid:13 O O
) O O
1994 O O
ieee O O
. O O
1995 O O
; O O
blake O O
and O O
isard O O
1998 O O
) O O
, O O
continuing O O
through O O
tech- O O
niques O O
such O O
as O O
intelligent B B
scissors I I
( O O
mortensen O O
and O O
barrett O O
1995 O O
, O O
1999 O O
; O O
p´erez O O
, O O
blake O O
, O O
and O O
gangnet O O
2001 O O
) O O
, O O
and O O
culminating O O
in O O
level B O
sets I I
( O O
malladi O O
, O O
sethian O O
, O O
and O O
vemuri O O
1995 O O
; O O
caselles O O
, O O
kimmel O O
, O O
and O O
sapiro O O
1997 O O
; O O
sethian O O
1999 O O
; O O
paragios O O
and O O
deriche O O
2000 O O
; O O
sapiro O O
2001 O O
; O O
osher O O
and O O
paragios O O
2003 O O
; O O
paragios O O
, O O
faugeras O O
, O O
chan O O
et O O
al O O
. O O
the O O
amount O O
of O O
aliasing B B
that O O
operations O O
inject O O
. O O
seamless O O
image B B
stitching I I
of O O
scenes O O
with O O
large O O
motions O O
and O O
exposure O O
differences O O
. O O
in O O
ieee O O
computer O O
society O O
conference O O
on O O
computer O O
vision O O
and O O
pattern O O
recognition B B
( O O
cvpr O O
’ O O
96 O O
) O O
, O O
pp O O
. O O
it O O
has O O
the O O
same O O
effect O O
on O O
the O O
amount O O
of O O
light O O
reaching O O
the O O
sensor B B
as O O
doubling O O
the O O
exposure O O
duration O O
, O O
e.g. O O
, O O
from O O
1/125 O O
to O O
1/250 O O
, O O
see O O
exercise O O
2.5 O O
. O O
( O O
optional O O
) O O
using O O
the O O
same O O
images O O
, O O
develop O O
a O O
technique O O
that O O
segments O O
the O O
image B B
into O O
near-constant O O
regions O O
( O O
liu O O
, O O
szeliski O O
, O O
kang O O
et O O
al O O
. O O
12.3 O O
surface B B
representations O O
. O O
devising O O
a O O
method O O
to O O
blend O O
all O O
of O O
these O O
different O O
sources O O
while O O
avoid- O O
ing O O
sharp O O
transitions O O
and O O
dealing O O
with O O
scene O O
motion B B
is O O
a O O
challenging O O
problem O O
. O O
multiple B B
class O O
segmentation B B
using O O
a O O
uniﬁed O O
framework O O
over O O
mean-shift O O
patches O O
. O O
to O O
reduce O O
the O O
effects O O
of O O
location O O
and O O
dominant O O
orientation O O
misestimation O O
, O O
each O O
of O O
the O O
original O O
256 O O
weighted B O
gradient O O
magnitudes O O
is O O
softly O O
added O O
to O O
2 O O
× O O
2 O O
× O O
2 O O
histogram B B
bins O O
using O O
trilinear O O
interpolation B B
. O O
the O O
nicest O O
aspect O O
of O O
unit O O
quaternions B B
is O O
that O O
there O O
is O O
a O O
simple O O
algebra O O
for O O
composing O O
rota- O O
tions O O
expressed O O
as O O
unit O O
quaternions B B
. O O
feature B B
correspondence O O
by O O
interleaving O O
shape O O
and O O
texture B B
computa- O O
tions O O
. O O
scene B O
completion I O
using O O
millions O O
of O O
photographs O O
. O O
multilevel B B
computational O O
processes O O
for O O
visual O O
surface B B
reconstruc- O I
tion B B
. O O
in O O
ieee O O
computer O O
society O O
con- O O
892 O O
computer O O
vision O O
: O O
algorithms O O
and O O
applications O O
( O O
september O O
3 O O
, O O
2010 O O
draft O O
) O O
ference O O
on O O
computer O O
vision O O
and O O
pattern O O
recognition B B
( O O
cvpr O O
’ O O
91 O O
) O O
, O O
pp O O
. O O
in O O
ieee O O
computer O O
society O O
conference O O
on O O
computer O O
vision O O
and O O
pattern O O
recognition B B
( O O
cvpr O O
’ O O
2005 O O
) O O
, O O
pp O O
. O O
the O O
standard O O
operations O O
used O O
in O O
binary O O
morphology O O
include O O
: O O
• O O
dilation B O
: O O
dilate O O
( O O
f O O
, O O
s O O
) O O
= O O
θ O O
( O O
c O O
, O O
1 O O
) O O
; O O
• O O
erosion B O
: O O
erode O O
( O O
f O O
, O O
s O O
) O O
= O O
θ O O
( O O
c O O
, O O
s O O
) O O
; O O
• O O
majority O O
: O O
maj O O
( O O
f O O
, O O
s O O
) O O
= O O
θ O O
( O O
c O O
, O O
s/2 O O
) O O
; O O
• O O
opening B O
: O O
open O O
( O O
f O O
, O O
s O O
) O O
= O O
dilate O O
( O O
erode O O
( O O
f O O
, O O
s O O
) O O
, O O
s O O
) O O
; O O
3.3 O O
more O O
neighborhood B B
operators O O
129 O O
• O O
closing B O
: O O
close O O
( O O
f O O
, O O
s O O
) O O
= O O
erode O O
( O O
dilate O O
( O O
f O O
, O O
s O O
) O O
, O O
s O O
) O O
. O O
